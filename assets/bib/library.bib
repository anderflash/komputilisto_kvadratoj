Automatically generated by Mendeley Desktop 1.10.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@phdthesis{Olsson2007,
abstract = {An eye tracker makes it possible to record the gaze point of a person looking at for example a computer monitor. Modern techniques are very flexible and allow the user to behave naturally without the need of cumbersome equipment such as special contact lenses or electrical probes. This is valuable in psychological research, marketing research and Human Computer Interaction. Eye trackers also give people who are severely paralyzed and unable to type and speak means to communicate using their eyes. Measurement noise makes the use of digital filters necessary. An example is an eye-controlled cursor for a desktop environment such as Windows. The cursor has to be stable enough to allow the user to select folders, icons or other items of interest. While this type of application requires a fast real-time filter, others are less sensitive to processing time but demand an even higher level of accuracy. This work explores three areas of eye tracking filtration and aims at enhancing the performance of the filters used in the eye tracking systems built by Tobii Technology, Sweden. First, a post-processing algorithm to find fixations in raw gaze data is detailed. Second, modifications to an existing reading detection algorithm are described to make it more robust to natural irregularities in reading patterns. Third, a real-time filter for an eye-controlled cursor to be used in a desktop environment is designed using a low-pass filter in parallel with a change detector. The fixation filter produced fewer false fixations and was also able to detect fixations lying spatially closer together than the previously used filter. The reading detection algorithm was shown to be robust to natural irregularities in reading such as revisits to previously read text or skipped paragraphs. The eye-cursor filter proved to respond quicker than the previously used moving average filter while maintaining a high level of noise attenuation.},
address = {Stockholm, Sweden},
annote = {- crossRef (Larsson2010)},
author = {Olsson, Pontus},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2007/Olsson/Olsson - 2007 - Real-time and Offline Filters for Eye Tracking.pdf:pdf},
keywords = {Control Engineering,Reglerteknik,Technology,eye tracking,gaze analysis,teknik},
language = {eng},
mendeley-tags = {eye tracking,gaze analysis},
pages = {45},
publisher = {KTH Electrical Engineering},
school = {KTH Electrical Engineering},
title = {{Real-time and Offline Filters for Eye Tracking}},
url = {http://kth.diva-portal.org/smash/record.jsf?pid=diva2:573446},
year = {2007}
}
@inproceedings{ebm,
author = {Lee, Jae-Young and Yoo, Suk I},
booktitle = {Proc. of the 2002 International Conference on Imaging Science, Systems, and Technology},
organization = {Citeseer},
title = {{An elliptical boundary model for skin color detection}},
year = {2002}
}
@inproceedings{Snowdon2001,
author = {Snowdon, Dave and Churchill, E.F. and Munro, A.J.},
booktitle = {Collaborative Virtual Environments},
doi = {10.1.1.114.9226},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Collaborative Virtual Environments/2001/Snowdon, Churchill, Munro/Snowdon, Churchill, Munro - 2001 - Collaborative virtual environments Digital spaces and places for CSCW An introduction.pdf:pdf},
pages = {3--17},
publisher = {Citeseer},
title = {{Collaborative virtual environments: Digital spaces and places for CSCW: An introduction}},
year = {2001}
}
@article{Morris2002,
abstract = {This work is motivated by our goal of providing non-contact head and eye based control of computer systems for people with motor difficulties. The system described here uses spatio-temporal filtering and variance maps to locate the head and find the eye-feature points, respectively. These feature points are accurately tracked in the succeeding frames by using a modified version of the Lucas–Kanade tracking algorithm with pyramidal implementation. Accurate head and eye tracking results are obtained at a processing rate of more than 30 frames per second (fps) in more than 90\% cases with a low false positive blink detection rate of 0.01\%. This is achieved under varying lighting conditions for people of different ethnicity, with and without wearing glasses.},
author = {Morris, T and Blenkhorn, P and Zaidi, Farhan},
doi = {10.1006/jnca.2002.0130},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Network and Computer Applications/2002/Morris, Blenkhorn, Zaidi/Morris, Blenkhorn, Zaidi - 2002 - Blink detection for real-time eye tracking.pdf:pdf},
issn = {10848045},
journal = {Journal of Network and Computer Applications},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = apr,
number = {2},
pages = {129--143},
title = {{Blink detection for real-time eye tracking}},
url = {http://www.sciencedirect.com/science/article/pii/S108480450290130X http://linkinghub.elsevier.com/retrieve/pii/S108480450290130X},
volume = {25},
year = {2002}
}
@inproceedings{Kim2011,
abstract = {Estimation of human head position and orientation has become an increasingly important issue in human-computer interaction field. Over the last decade, many approaches have been introduced to achieve head pose estimation in both academical and industrial fields, but the low-cost and real-time application still proves to be a difficult task. Motivated by the past researches, we propose an automatic and monocular head pose estimation system. We applied a number of improvements to a direct linear transformation algorithm called Pose from Orthography and Scaling with ITerations (POSIT) and applied it for the head pose estimation. User's virtual head model is also recovered by analyzing laser scan database and corrected by the head pose. The entire process is completely automatic with no need for users to pre-register for identification or initialize their head position. Experiments on a public dataset show realtime performance with lower errors than previous head pose estimation methods.},
author = {Kim, Woo Won and Park, Sangheon and Hwang, Jinkyu and Lee, Sangyoun},
booktitle = {2011 8th International Conference on Information, Communications \& Signal Processing},
doi = {10.1109/ICICS.2011.6173539},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 8th International Conference on Information, Communications \& Signal Processing/2011/Kim et al/Kim et al. - 2011 - Automatic head pose estimation from a single camera using projective geometry.pdf:pdf},
isbn = {978-1-4577-0031-6},
month = dec,
pages = {1--5},
publisher = {IEEE},
title = {{Automatic head pose estimation from a single camera using projective geometry}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6173539&contentType=Conference+Publications&searchField=Search_All&queryText=.QT.projective+geometry.QT.},
year = {2011}
}
@article{Holmqvist2011,
author = {Holmqvist, K and Nystr\"{o}m, M and Andersson, R},
file = {::},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Eye tracking: A comprehensive guide to methods and measures}},
url = {http://books.google.com/books?hl=pt-BR&lr=&id=5rIDPV1EoLUC&oi=fnd&pg=PT27&dq=Eye+Tracking:+A+comprehensive+guide+to+methods+and+measures&ots=_u6CRZqQpO&sig=Lple_koXcqQ4jWwSt0dBu7HdYy0},
year = {2011}
}
@inproceedings{inktuitive,
author = {Mistry, Pranav and Sekiya, Kayato and Bradshaw, Andrea},
booktitle = {4th International Conference on Intelligent Environments (IE 08)},
doi = {10.1049/cp:20081089},
isbn = {978 0 86341 894 5},
keywords = {SBGames},
mendeley-tags = {SBGames},
pages = {P11--P11},
publisher = {IET},
title = {{Inktuitive: an intuitive physical design workspace}},
url = {http://digital-library.theiet.org/content/conferences/10.1049/cp_20081089},
year = {2008}
}
@article{Chong2013,
address = {New York, New York, USA},
author = {Chong, Ming Ki and Gellersen, Hans W.},
doi = {10.1145/2470654.2466207},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Spontaneous interaction,device association,group,guessability study,input techniques,pairing,wireless},
pages = {1559},
publisher = {ACM Press},
title = {{How groups of users associate wireless devices}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466207},
year = {2013}
}
@inproceedings{Tavares2010,
author = {Tavares, Anderson Carlos M and Fernandes, Sergio Murilo M and {Lencastre P. de Menezes Cruz}, Maria},
booktitle = {2010 International Conference on Cyberworlds},
doi = {10.1109/CW.2010.71},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 International Conference on Cyberworlds/2010/Tavares, Fernandes, Lencastre P. de Menezes Cruz/Tavares, Fernandes, Lencastre P. de Menezes Cruz - 2010 - NHE Collaborative Virtual Environment with Augmented Reality on Web.pdf:pdf},
isbn = {978-1-4244-8301-3},
keywords = {- virtual collaborative spaces,augmented,collaboration,computer vision,mixed and virtual,networked},
month = oct,
pages = {438--444},
publisher = {IEEE},
title = {{NHE: Collaborative Virtual Environment with Augmented Reality on Web}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5656154},
year = {2010}
}
@inproceedings{Pilet2010,
abstract = {Tracking is a major issue of virtual and augmented real- ity applications. Single object tracking on monocular video streams is fairly well understood. However, when it comes to multiple objects, existing methods lack scalability and can recognize only a limited number of objects. Thanks to recent progress in feature matching, state-of-the-art image retrieval techniques can deal with millions of images. However, these methods do not focus on real-time video processing and can not track retrieved objects. In this paper,we present a method that combines the speed and accuracy of tracking with the scalability of image re- trieval. At the heart of our approach is a bi-layer clustering process that allows our system to index and retrieve objects based on tracks of features, thereby effectively summarizing the information available on multiple video frames. As a result, our system is able to track in real-time multiple objects, recognized with low delay from a database of more than 300 entries.},
author = {Pilet, Julien and Saito, Hideo},
booktitle = {2010 IEEE Virtual Reality Conference (VR)},
doi = {10.1109/VR.2010.5444811},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 IEEE Virtual Reality Conference (VR)/2010/Pilet, Saito/Pilet, Saito - 2010 - Virtually augmenting hundreds of real pictures An approach based on learning, retrieval, and tracking.pdf:pdf},
isbn = {978-1-4244-6237-7},
month = mar,
pages = {71--78},
publisher = {IEEE},
title = {{Virtually augmenting hundreds of real pictures: An approach based on learning, retrieval, and tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5444811},
year = {2010}
}
@article{Peterka2008,
abstract = {A solid-state dynamic parallax barrier autostereoscopic display mitigates some of the restrictions present in static barrier systems, such as fixed view-distance range, slow response to head movements, and fixed stereo operating mode. By dynamically varying barrier parameters in real time, viewers may move closer to the display and move faster laterally than with a static barrier system, and the display can switch between 3D and 2D modes by disabling the barrier on a per-pixel basis. Moreover, Dynallax can output four independent eye channels when two viewers are present, and both head-tracked viewers receive an independent pair of left-eye and right-eye perspective views based on their position in 3D space. The display device is constructed by using a dual-stacked LCD monitor where a dynamic barrier is rendered on the front display and a modulated virtual environment composed of two or four channels is rendered on the rear display. Dynallax was recently demonstrated in a small-scale head-tracked prototype system. This paper summarizes the concepts presented earlier, extends the discussion of various topics, and presents recent improvements to the system.},
author = {Peterka, Tom and Kooima, Robert L and Sandin, Daniel J and Johnson, Andrew and Leigh, Jason and DeFanti, Thomas A},
doi = {10.1109/TVCG.2007.70627},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on visualization and computer graphics/2008/Peterka et al/Peterka et al. - 2008 - Advances in the Dynallax solid-state dynamic parallax barrier autostereoscopic visualization display system.pdf:pdf},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Algorithms,Biomedical,Computer Graphics,Computer-Assisted,Computer-Assisted: instrumen,Computer-Assisted: instrumentat,Computer-Assisted: methods,Data Display,Equipment Design,Equipment Failure Analysis,Image Enhancement,Image Enhancement: instrumentation,Image Enhancement: methods,Image Interpretation,Imaging,Numerical Analysis,Photogrammetry,Photogrammetry: instrumentation,Photogrammetry: methods,Signal Processing,Technology Assessment,Three-Dimensional,Three-Dimensional: instrumentation,Three-Dimensional: methods,User-Computer Interface},
month = jan,
number = {3},
pages = {487--99},
pmid = {18369259},
title = {{Advances in the Dynallax solid-state dynamic parallax barrier autostereoscopic visualization display system.}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4407697},
volume = {14},
year = {2008}
}
@inproceedings{Sun2013,
abstract = {Architectural sketching and massing are used by designers to analyze and explore the design space of buildings. This paper describes a novel multi-touch interface for fast architectural sketching and massing of tall buildings. It incorporates a family of multi-touch gestures, enabling one to quickly sketch the 2D contour of a base floor plan and extrude it to model a building with multi-floor structures. Further, it provides a set of gestures to users: select and edit a range of floors; scale contours of a building; copy, paste, and rotate a building, i.e., create a twisted structure; edit profile curves of a building's profile; and collapse and remove a selected range of floors. The multi-touch system also allows users to apply textures or geometric facades to the building, and to compare different designs side-by-side. To guide the design process, we describe interactions with a domain expert, a practicing architect. The final interface is evaluated by architects and students in an architecture Dept., which demonstrates that the system allows rapid conceptual design and massing of novel multi-story building structures.},
address = {New York, New York, USA},
author = {Sun, Qian and Lin, Juncong and Fu, Chi-Wing and Kaijima, Sawako and He, Ying},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470689},
isbn = {9781450318990},
pages = {247--256},
publisher = {ACM Press},
title = {{A multi-touch interface for fast architectural sketching and massing}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470689},
year = {2013}
}
@inproceedings{Heminghous2006,
abstract = {To evaluate differences across viewers' visual attentional patterns, scanpath comparison has recently gained popularity in eye tracking studies, supplementing traditional objective (performance) and subjective measures (e.g., heat maps or [retrospective] talk-aloud). We introduce iComp, an open-source visualization tool that implements quantitative scanpath comparison in loci and sequence. iComp can be used to objectively compare the attentional qualities of synthetic images.},
address = {New York, New York, USA},
author = {Heminghous, John and Duchowski, Andrew T.},
booktitle = {ACM SIGGRAPH 2006 Research posters on - SIGGRAPH '06},
doi = {10.1145/1179622.1179836},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM SIGGRAPH 2006 Research posters on - SIGGRAPH '06/2006/Heminghous, Duchowski/Heminghous, Duchowski - 2006 - iComp a tool for scanpath visualization and comparison.pdf:pdf},
isbn = {1595933646},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
pages = {186},
publisher = {ACM Press},
title = {{iComp: a tool for scanpath visualization and comparison}},
url = {http://dl.acm.org/citation.cfm?id=1179836 http://portal.acm.org/citation.cfm?doid=1179622.1179836},
year = {2006}
}
@article{Correll2013,
address = {New York, New York, USA},
author = {Correll, Michael a. and Alexander, Eric C. and Gleicher, Michael},
doi = {10.1145/2470654.2481373},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2697},
publisher = {ACM Press},
title = {{Quantity estimation in visualizations of tagged text}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481373},
year = {2013}
}
@misc{Martinez2013,
author = {Martinez, Enrique Sanchez},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{Games Factory}},
url = {http://www.arrakis.es/~esanchez/},
urldate = {2013/07/23},
year = {2013}
}
@article{Ambrosini2011,
abstract = {When observing someone else acting on an object, people implement goal-specific eye movement programs that are driven by their own motor representation of the observed action. Usually, however, we observe people acting in contexts where more objects, different in shape and size, are present. Is our brain able to select the intended target even when there are different objects in the visual scene? And if this is the case, what kind of information does our motor system capitalize on? We recorded eye movements while participants observed an actor reaching for and grasping one of two objects requiring two different kinds of grip to be picked up. In a control condition, the actor merely reached for and touched one of the two objects without preshaping her hand according to the target features. Results showed higher accuracy and earlier saccadic movements when participants observed an actually grasping hand than when they observed a mere reaching hand devoid of any kind of target-related preshaping. This clearly suggests that the hand preshaping provided the observer with enough motor cues to proactively and reliably saccade toward the object to be grasped, thus identifying it even when the action target was not previously known. Our findings strongly corroborate the direct matching hypothesis suggesting that in processing others' actions, we take advantage of the same motor knowledge that enables us to efficiently perform those actions.},
annote = {- cited by: 18
- kw: identification I-VT eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Ambrosini, E},
doi = {10.​1152/​jn.​00118.​2011},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of neurophysiology/2011/Ambrosini/Ambrosini - 2011 - Grasping with the eyes.pdf:pdf},
journal = {Journal of neurophysiology},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
number = {3},
pages = {1437--1442},
title = {{Grasping with the eyes}},
url = {http://jn.physiology.org/content/106/3/1437.short},
volume = {106},
year = {2011}
}
@book{duda1973pattern,
author = {Duda, Richard O and Hart, Peter E and Others},
publisher = {Wiley New York},
title = {{Pattern classification and scene analysis}},
volume = {3},
year = {1973}
}
@inproceedings{Shibo2012,
abstract = {Kinect, as a new type of human-machine interaction sensor, is able to capture range images and color images of the scene simultaneously, but there is space parallax between them. A stereo calibration is expected to overcome it. Much different from the previous approaches, we introduced a new method in this paper to solve this problem which uses the range image directly. The method obtains the range calibration images of a newly designed calibration board and extracts calibration point pairs by an algorithm developed in this paper. Our experiments show that the method can complete calibration of the Kinect successfully.},
author = {Shibo, Li and Qing, Zhuo},
booktitle = {2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics},
doi = {10.1109/IHMSC.2012.156},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics/2012/Shibo, Qing/Shibo, Qing - 2012 - A New Approach to Calibrate Range Image and Color Image from Kinect.pdf:pdf},
isbn = {978-1-4673-1902-7},
month = aug,
pages = {252--255},
publisher = {IEEE},
title = {{A New Approach to Calibrate Range Image and Color Image from Kinect}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6305770&contentType=Conference+Publications&searchField=Search_All&queryText=kinect+calibration},
year = {2012}
}
@inproceedings{Salvucci2000,
abstract = {The process of fixation identification—separating and labeling fixations and saccades in eye-tracking protocols—is an essential part of eye-movement data analysis and can have a dramatic impact on higher-level analyses. However, algorithms for performing fixation identification are often described informally and rarely compared in a meaningful way. In this paper we propose a taxonomy of fixation identification algorithms that classifies algorithms in terms of how they utilize spatial and temporal information in eye-tracking protocols. Using this taxonomy, we describe five algorithms that are representative of different classes in the taxonomy and are based on commonly employed techniques. We then evaluate and compare these algorithms with respect to a number of qualitative characteristics. The results of these comparisons offer interesting implications for the use of the various algorithms in future work.},
address = {New York, New York, USA},
annote = {- keyword coletado},
author = {Salvucci, Dario D. and Goldberg, Joseph H.},
booktitle = {Proceedings of the symposium on Eye tracking research \& applications - ETRA '00},
doi = {10.1145/355017.355028},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the symposium on Eye tracking research \& applications - ETRA '00/2000/Salvucci, Goldberg/Salvucci, Goldberg - 2000 - Identifying fixations and saccades in eye-tracking protocols.pdf:pdf},
isbn = {1581132808},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
pages = {71--78},
publisher = {ACM Press},
title = {{Identifying fixations and saccades in eye-tracking protocols}},
url = {http://dl.acm.org/citation.cfm?id=355028 http://portal.acm.org/citation.cfm?doid=355017.355028},
year = {2000}
}
@article{Blignaut2009,
abstract = {It is hypothesized that the number, position, size, and duration of fixations are functions of the metric used for dispersion in a dispersion-based fixation detection algorithm, as well as of the threshold value. The sensitivity of the I-DT algorithm for the various independent variables was determined through the analysis of gaze data from chess players during a memory recall experiment. A procedure was followed in which scan paths were generated at distinct intervals in a range of threshold values for each of five different metrics of dispersion. The percentage of points of regard (PORs) used, the number of fixations returned, the spatial dispersion of PORs within fixations, and the difference between the scan paths were used as indicators to determine an optimum threshold value. It was found that a fixation radius of 1 degrees provides a threshold that will ensure replicable results in terms of the number and position of fixations while utilizing about 90\% of the gaze data captured.},
annote = {- keyword coletado
- cited by: 24- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Blignaut, Pieter},
doi = {10.3758/APP.71.4.881},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Attention, perception \& psychophysics/2009/Blignaut/Blignaut - 2009 - Fixation identification the optimum threshold for a dispersion algorithm.pdf:pdf},
issn = {1943-3921},
journal = {Attention, perception \& psychophysics},
keywords = {Adolescent,Adult,Algorithms,Attention,Computer Graphics,Discrimination (Psychology),Eye Tracking,Female,Fixation,Humans,Male,Memory,Middle Aged,Ocular,Orientation,Pattern Recognition,Psychomotor Performance,Psychophysics,Reaction Time,Saccades,Segmentation,Sensory Thresholds,Short-Term,Visual,Young Adult},
mendeley-tags = {Eye Tracking,Segmentation},
month = may,
number = {4},
pages = {881--95},
pmid = {19429966},
title = {{Fixation identification: the optimum threshold for a dispersion algorithm.}},
url = {http://link.springer.com/article/10.3758/APP.71.4.881 http://www.ncbi.nlm.nih.gov/pubmed/19429966},
volume = {71},
year = {2009}
}
@inproceedings{Krassanakis2013,
abstract = {The features processed in a primary stage of vision can be of guid- ance to visual search. The list of preattentive features indicated by psychologi- cal research bare many similarities to the fundamental cartographic design tools (visual and dynamic variables). This paper presents the performance of two ex- perimental studies, which examine the influence of preattentive vision in map reading process. The experimental studies involve both “top-down” and “bot- tom-up” procedures. The methodology of eye tracking is used in the experi- ments.},
address = {Scarborough, UK.},
annote = {- cited by: 2
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Krassanakis, V},
booktitle = {Proceedings of the 1st International Workshop on Eye Tracking for Spatial Research},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 1st International Workshop on Eye Tracking for Spatial Research/2013/Krassanakis/Krassanakis - 2013 - Exploring the map reading process with eye movement analysis.pdf:pdf},
keywords = {Preattentive vision,cartographic experimentation,dynamic variables,eye move-,gaze analysis,ment analysis,visual variables},
mendeley-tags = {gaze analysis},
pages = {2--7},
title = {{Exploring the map reading process with eye movement analysis}},
url = {http://spatialeyetracking.org/wp-content/uploads/2013/10/et4s_2013_paper1.pdf},
year = {2013}
}
@inproceedings{Kang2011,
abstract = {Human visual attention is an area of research that has a strong effect on the field of human-robot-interaction. It has various applications for human-care robots and service robots. The ability of human visual attention to acquire knowledge on informative objects through interaction with the environment is an important research issue in the field of human-computer interaction and augmented cognition. Such knowledge can be acquired by automatically detecting visually attentive regions using the fixation extracted from eye-tracking data. Therefore, the optimal fixation must be selected from human eye-tracking data to detect the region of interest. In this paper, eye movement tracking was accurately used to capture human eye movements and to characterize the location and extent of a user's interest as an input mechanism to drive the interaction system. Furthermore, both top-down and bottom-up processes of the human visual system were at work in the process of selective attention. The correlation between human eye movement information and the bottom-up saliency map was calculated and compared with the correlation that was calculated by combining the top-down and bottom-up processes. The experiment results showed that the human visual attention system cannot be constructed with the bottom-up process alone and requires the combination of the top-down and bottom-up processes together.},
address = {Karon Beach, Phuket},
author = {Kang, Dooseok and Lee, Sukhan and Lee, Yu-Bu},
booktitle = {2011 IEEE International Conference on Robotics and Biomimetics},
doi = {10.1109/ROBIO.2011.6181594},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 IEEE International Conference on Robotics and Biomimetics/2011/Kang, Lee, Lee/Kang, Lee, Lee - 2011 - Human visual attention with context-specific top-down saliency.pdf:pdf},
isbn = {978-1-4577-2138-0},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = dec,
pages = {2055--2060},
publisher = {IEEE},
title = {{Human visual attention with context-specific top-down saliency}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6181594 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6181594},
year = {2011}
}
@inproceedings{Wang2006,
address = {Montreal},
author = {Wang, Xiangyu and Dunston, P.S.},
booktitle = {Proceedings of Joint International Conference on Computing and Decision Making in Civil and Building Engineering. Montreal, Canad\'{a}:[sn]},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of Joint International Conference on Computing and Decision Making in Civil and Building Engineering. Montreal, Canad\'{a}sn/2006/Wang, Dunston/Wang, Dunston - 2006 - Groupware Concepts for Augmented Reality Mediated Human-To-Human Collaboration.pdf:pdf},
keywords = {augmented reality,computer-supported cooperative work,cscw,groupware,mobility},
pages = {1836--1842},
title = {{Groupware Concepts for Augmented Reality Mediated Human-To-Human Collaboration}},
url = {http://itc.scix.net/data/works/att/w78-2006-tf278.pdf},
year = {2006}
}
@article{Morimoto1997,
abstract = {The authors present a fast electronic image stabilization system that compensates for 3D rotation. The extended Kalman filter framework is employed to estimate the rotation between frames, which is represented using unit quaternions. A small set of automatically selected and tracked feature points are used as measurements. The effectiveness of this technique is also demonstrated by constructing mosaic images from the motion estimates, and comparing them to mosaics built from 2D stabilization algorithms. Two different stabilization schemes are presented. The first, implemented in a real-time platform based on a Datacube MV200 board, estimates the motion between two consecutive frames and is able to process gray level images of resolution 128×120 at 10 Hz. The second scheme estimates the motion between the current frame and an inverse mosaic; this allows better estimation without the need for indexing the new image frames. Experimental results for both schemes using real and synthetic image sequences are presented},
address = {San Juan},
author = {Morimoto, C. and Chellappa, R.},
doi = {10.1109/CVPR.1997.609396},
isbn = {0-8186-7822-4},
journal = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {660--665},
publisher = {IEEE Comput. Soc},
title = {{Fast 3D stabilization and mosaic construction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=609396 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=609396},
year = {1997}
}
@article{Benford1998,
author = {Benford, Steve and Greenhalgh, Chris and Reynard, Gail and Brown, Chris and Koleva, Boriana},
doi = {10.1145/292834.292836},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM Transactions on Computer-Human Interaction/1998/Benford et al/Benford et al. - 1998 - Understanding and constructing shared spaces with mixed-reality boundaries.pdf:pdf},
issn = {10730516},
journal = {ACM Transactions on Computer-Human Interaction},
month = sep,
number = {3},
pages = {185--223},
title = {{Understanding and constructing shared spaces with mixed-reality boundaries}},
url = {http://portal.acm.org/citation.cfm?doid=292834.292836},
volume = {5},
year = {1998}
}
@article{VanDam2000,
author = {van Dam, a.},
doi = {10.1109/38.814559},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Computer Graphics and Applications/2000/van Dam/van Dam - 2000 - Beyond WIMP.pdf:pdf},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {1},
pages = {50--51},
title = {{Beyond WIMP}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=814559},
volume = {20},
year = {2000}
}
@misc{Goran2010,
author = {Goran, C},
booktitle = {US Patent App. 12/848,201},
file = {:home/acmt/Dropbox/Documentos/Mendeley/US Patent App. 12848,201/2010/Goran/Goran - 2010 - Anamorphic projection device.pdf:pdf},
keywords = {anamorphism},
mendeley-tags = {anamorphism},
title = {{Anamorphic projection device}},
url = {http://www.google.com.br/patents?hl=pt-BR&lr=&vid=USPATAPP12848201&id=oacCAgAAEBAJ&oi=fnd&dq=anamorphism+handheld+projector&printsec=abstract#v=onepage&q=anamorphism handheld projector&f=false},
year = {2010}
}
@inproceedings{Breuer2008,
abstract = {This paper presents a fully automated algorithm for reconstructing a textured 3D model of a face from a single photograph or a raw video stream. The algorithm is based on a combination of Support Vector Machines (SVMs) and a Morphable Model of 3D faces. After SVM face detection, individual facial features are detected using a novel regression- and classification-based approach, and probabilistically plausible configurations of features are selected to produce a list of candidates for several facial feature positions. In the next step, the configurations of feature points are evaluated using a novel criterion that is based on a Morphable Model and a combination of linear projections. To make the algorithm robust with respect to head orientation, this process is iterated while the estimate of pose is refined. Finally, the feature points initialize a model-fitting procedure of the Morphable Model. The result is a high resolution 3D surface model.},
author = {Breuer, Pia and Kim, Kwang-In and Kienzle, Wolf and Scholkopf, Bernhard and Blanz, Volker},
booktitle = {2008 8th IEEE International Conference on Automatic Face \& Gesture Recognition},
doi = {10.1109/AFGR.2008.4813339},
isbn = {978-1-4244-2153-4},
keywords = {Biological system modeling,Computer vision,Deformable models,Face detection,Facial features,Image reconstruction,Shape,Streaming media,Support vector machine classification,Support vector machines,face recognition,face reconstruction,facial feature,reconstruction},
mendeley-tags = {reconstruction},
month = sep,
pages = {1--8},
publisher = {IEEE},
shorttitle = {Automatic Face \& Gesture Recognition, 2008. FG '08},
title = {{Automatic 3D face reconstruction from single images or video}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4813339},
year = {2008}
}
@article{Reitmaier2013,
address = {New York, New York, USA},
author = {Reitmaier, Thomas and Benz, Pierre and Marsden, Gary},
doi = {10.1145/2470654.2470709},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {381},
publisher = {ACM Press},
title = {{Designing and theorizing co-located interactions}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470709},
year = {2013}
}
@article{Glenstrup1995,
abstract = {Today, the human eye-gaze can be recorded by relatively unobtrusive techniques. This thesis argues that it is possible to use the eye-gaze of a computer user in the interface to aid the control of the application. Care must be taken, though, that eye-gaze tracking data is used in a sensible way, since the nature of human eye-movements is a combination of several voluntary and involuntary cognitive processes. The main reason for eye-gaze based user interfaces being attractive is that the direction of the eye-gaze can express the interests of the user -- it is a potential porthole into the current cognitive processes -- and communication through the direction of the eyes is faster than any other mode of human communication. It is argued that eye-gaze tracking data is best used in multimodal interfaces where the user interacts with the data instead of the interface, in so-called noncommand user interfaces. Furthermore, five usability criteria for eye-gaze media are given. This thesis also sugges...},
author = {Glenstrup, Arne John and Engell-nielsen, Theo},
file = {:home/acmt/Dropbox/Documentos/Mendeley/University of Copenhagen, DK-2100/1995/Glenstrup, Engell-nielsen/Glenstrup, Engell-nielsen - 1995 - Eye controlled media Present and future state.pdf:pdf},
journal = {University of Copenhagen, DK-2100},
title = {{Eye controlled media: Present and future state}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.6067&rep=rep1&type=pdf},
year = {1995}
}
@book{McPherson2001,
abstract = {This book describes the basis, application, and interpretation of statistics, and presents a wide range of univariate and multivariate statistical methodology. In its first edition it has proved popular across all science and technology based disciplines, including the social sciences, and in areas of commerce. It is used both as a reference on statistical methodology for researchers and technicians, and as a textbook with particular appeal for graduate classes containing students of mixed mathematical and statistical background. The book is developed without the use of calculus, although several self-contained sections containing calculus are included to provide additional insight for readers who have a calculus background. Based on the author's "Statistics in Scientific Investigation," the book has been extended substantially in the area of multivariate applications and through the expansion of logistic regression and log linear methodology. It presumes readers have access to a statistical computing package and includes guidance on the application of statistical computing packages. The new edition retains the unique feature of being written from the users' perspective; it connects statistical models and methods to investigative questions and background information, and connects statistical results with interpretations in plain English. In keeping with this approach, methods are grouped by usage rather than by commonality of statistical methodology. Guidance is provided on the choice of appropriate methods. The use of real life examples has been retained and expanded. Using the power of the Internet, expanded reports on the examples are available at a Springer Web site as Word documents. Additionaly, all data sets are available at the Web site as Excel files, and program files and data sets are provided for SAS users and SPSS users. The programs are annotated so users can adapt for their own data sets. Glen McPherson has had a long career as an acedmic and a consultant in applied statistics. After holding a tenured position for thirty years at The University of Tasmania in Australia, where he developed and directed under-graduate and gradate programs in applied statistics, he resigned to devote more time to book writing and to his consultancy role to government, business, and industry. The practical experience built into the book is drawn from the two thousand consulantcies he has undetaken across virtually all areas in which statistics has an application.},
author = {McPherson, Glen},
isbn = {0387951105},
pages = {640},
publisher = {Springer},
title = {{Applying and Interpreting Statistics: A Comprehensive Guide (Google eBook)}},
url = {http://books.google.com/books?id=FezZhTX9OgQC&pgis=1},
year = {2001}
}
@article{Raskar2001,
author = {Raskar, R and Beardsley, P},
file = {::},
journal = {\ldots  2001. CVPR 2001. Proceedings of the \ldots},
title = {{A self-correcting projector}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=991004},
year = {2001}
}
@inproceedings{Shih2003,
author = {Shih, Timothy K T.K. and Lin, Nigel H N.H. and Chuang, Jung-ken},
booktitle = {23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.},
doi = {10.1109/ICDCSW.2003.1203626},
file = {:home/acmt/Dropbox/Documentos/Mendeley/23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings/2003/Shih, Lin, Chuang/Shih, Lin, Chuang - 2003 - Augmented Video Conferencing.pdf:pdf},
isbn = {0-7695-1921-0},
keywords = {analog technology,communication will replace traditional,distance learning,mpeg,multimedia communication system,synchronization,video conferencing},
pages = {646--651},
publisher = {IEEE Computer Society Press},
title = {{Augmented Video Conferencing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1203626},
year = {2003}
}
@article{Teubl2012,
author = {Teubl, Fernando and Kurashima, Celso and Cabral, Marcio and Zuffo, Marcelo},
doi = {10.1109/SVR.2012.1},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Teubl et al/Teubl et al. - 2012 - FastFusion A Scalable Multi-projector System.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {-multi-projector system,virtual reality,visual},
month = may,
pages = {26--35},
publisher = {Ieee},
title = {{FastFusion: A Scalable Multi-projector System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297557},
year = {2012}
}
@book{williams1999visual,
author = {Williams, AM M and Davids, K and Williams, JG G P},
isbn = {9780419248002},
publisher = {Taylor \& Francis},
title = {{Visual Perception and Action in Sport}},
url = {http://books.google.com.br/books?hl=en&lr=&id=uONBuqh6tQoC&oi=fnd&pg=PR2&dq=Visual+perception+and+action+in+sport&ots=jGnktEj5uv&sig=ia6hnz6Z_CoprcWmKUbzYSAFYr8 http://books.google.com.br/books?id=uONBuqh6tQoC},
year = {1999}
}
@article{Tavares2012,
author = {Tavares, Anderson C.M. and Cruz, Maria L.P. De M. and Fernandes, Sergio M.M.},
doi = {10.1109/SVR.2012.32},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Tavares, Cruz, Fernandes/Tavares, Cruz, Fernandes - 2012 - Augmented Reality in Collaborative Virtual Environment for Discrete Event Systems Modeling and Simulat.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {-augmented reality,collaborative virtual envi-,discrete event systems,modeling and simulation,ronment},
month = may,
pages = {155--164},
publisher = {Ieee},
title = {{Augmented Reality in Collaborative Virtual Environment for Discrete Event Systems Modeling and Simulation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297572},
year = {2012}
}
@book{Nakano2013,
address = {London},
doi = {10.1007/978-1-4471-4784-8},
editor = {Nakano, Yukiko I. and Conati, Cristina and Bader, Thomas},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2013/Unknown/Unknown - 2013 - Eye Gaze in Intelligent User Interfaces.pdf:pdf},
isbn = {978-1-4471-4783-1},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
publisher = {Springer London},
title = {{Eye Gaze in Intelligent User Interfaces}},
url = {http://www.springerlink.com/index/10.1007/978-1-4471-4784-8},
year = {2013}
}
@inproceedings{Klingner2010,
abstract = {We propose a new way of analyzing pupil measurements made in conjunction with eye tracking: fixation-aligned pupillary response averaging, in which short windows of continuous pupil measurements are selected based on patterns in eye tracking data, temporally aligned, and averaged together. Such short pupil data epochs can be selected based on fixations on a particular spot or a scan path. The windows of pupil data thus selected are aligned by temporal translation and linear warping to place corresponding parts of the gaze patterns at corresponding times and then averaged together. This approach enables the measurement of quick changes in cognitive load during visual tasks, in which task components occur at unpredictable times but are identifiable via gaze data. We illustrate the method through example analyses of visual search and map reading. We conclude with a discussion of the scope and limitations of this new method.},
address = {New York, New York, USA},
annote = {- cited by: 8
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Klingner, Jeff},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743732},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Klingner/Klingner - 2010 - Fixation-aligned pupillary response averaging.pdf:pdf},
isbn = {9781605589947},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {275},
publisher = {ACM Press},
title = {{Fixation-aligned pupillary response averaging}},
url = {http://dl.acm.org/citation.cfm?id=1743732 http://portal.acm.org/citation.cfm?doid=1743666.1743732},
year = {2010}
}
@inproceedings{Komogortsev2010,
abstract = {This paper presents a set of qualitative and quantitative scores designed to assess performance of any eye movement classification algorithm. The scores are designed to provide a foundation for the eye tracking researchers to communicate about the performance validity of various eye movement classification algorithms. The paper concentrates on the five algorithms in particular: Velocity Threshold Identification (I-VT), Dispersion Threshold Identification (I-DT), Minimum Spanning Tree Identification (MST), Hidden Markov Model Identification (I-HMM) and Kalman Filter Identification (I-KF). The paper presents an evaluation of the classification performance of each algorithm in the case when values of the input parameters are varied. Advantages provided by the new scores are discussed. Discussion on what is the "best" classification algorithm is provided for several applications. General recommendations for the selection of the input parameters for each algorithm are provided.},
address = {New York, New York, USA},
annote = {- cited by: 15
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Komogortsev, OV Oleg V. and Jayarathna, Sampath and Koh, Do Hyong and Gowda, Sandeep Munikrishne},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743682},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Komogortsev et al/Komogortsev et al. - 2010 - Qualitative and quantitative scoring and evaluation of the eye movement classification algorithms.pdf:pdf},
isbn = {9781605589947},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {65},
publisher = {ACM Press},
title = {{Qualitative and quantitative scoring and evaluation of the eye movement classification algorithms}},
url = {http://dl.acm.org/citation.cfm?id=1743682 http://portal.acm.org/citation.cfm?doid=1743666.1743682},
year = {2010}
}
@article{Williams1999,
author = {Williams, AM and Grant, A},
journal = {International Journal of Sport Psychology},
pages = {194--220},
title = {{Training perceptual skill in sport.}},
url = {http://psycnet.apa.org/?fa=main.doiLanding&uid=1999-11726-004},
volume = {30},
year = {1999}
}
@article{Tsang2010,
abstract = {We introduce eSeeTrack, an eye-tracking visualization prototype that facilitates exploration and comparison of sequential gaze orderings in a static or a dynamic scene. It extends current eye-tracking data visualizations by extracting patterns of sequential gaze orderings, displaying these patterns in a way that does not depend on the number of fixations on a scene, and enabling users to compare patterns from two or more sets of eye-gaze data. Extracting such patterns was very difficult with previous visualization techniques. eSeeTrack combines a timeline and a tree-structured visual representation to embody three aspects of eye-tracking data that users are interested in: duration, frequency and orderings of fixations. We demonstrate the usefulness of eSeeTrack via two case studies on surgical simulation and retail store chain data. We found that eSeeTrack allows ordering of fixations to be rapidly queried, explored and compared. Furthermore, our tool provides an effective and efficient mechanism to determine pattern outliers. This approach can be effective for behavior analysis in a variety of domains that are described at the end of this paper.},
author = {Tsang, Hoi Ying and Tory, Melanie and Swindells, Colin},
doi = {10.1109/TVCG.2010.149},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on visualization and computer graphics/2010/Tsang, Tory, Swindells/Tsang, Tory, Swindells - 2010 - eSeeTrack--visualizing sequential fixation patterns.pdf:pdf},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Computer Graphics,Computer Simulation,Computer-Assisted Instruction,Eye Movement Measurements,Eye Movement Measurements: statistics \& numerical ,Fixation,Humans,Laparoscopy,Laparoscopy: education,Ocular,eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
number = {6},
pages = {953--62},
pmid = {20975132},
title = {{eSeeTrack--visualizing sequential fixation patterns.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613432 http://www.ncbi.nlm.nih.gov/pubmed/20975132},
volume = {16},
year = {2010}
}
@article{Jang2013,
abstract = {We propose a novel approach for the identification of human implicit visual search intention based on eye movement patterns and pupillary analysis, in general, as well as pupil size, gradient of pupil size variation, fixation length and fixation count corresponding to areas of interest, and fixation count corresponding to non-areas of interest, in particular. The proposed model identifies human implicit visual search intention as task-free visual browsing or task-oriented visual search. Task-oriented visual search is further identified as task-oriented visual search intent generation, task-oriented visual search intent maintenance, or task-oriented visual search intent disappearance. During a visual search, measurement of the pupillary response is greatly influenced by external factors such the intensity and size of the visual stimulus. To alleviate the effects of external factors, we propose a robust baseline model that can accurately measure the pupillary response. Graphical representation of the measured parameter values shows significant differences among the different intent conditions, which can then be used as features for identification. By using the eye movement patterns and pupillary analysis, we can detect the transitions between different implicit intentions—task-free visual browsing intent to task-oriented visual search intent and task-oriented visual search intent maintenance to task-oriented visual search intent disappearance—using a hierarchical support vector machine. In the proposed model, the hierarchical support vector machine is able to identify the transitions between different intent conditions with greater than 90 \% accuracy.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Jang, Young-Min and Mallipeddi, Rammohan and Lee, Minho},
doi = {10.1007/s11257-013-9142-7},
file = {:home/acmt/Dropbox/Documentos/Mendeley/User Modeling and User-Adapted Interaction/2013/Jang, Mallipeddi, Lee/Jang, Mallipeddi, Lee - 2013 - Identification of human implicit visual search intention based on eye movement and pupillary analysis.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = apr,
title = {{Identification of human implicit visual search intention based on eye movement and pupillary analysis}},
url = {http://link.springer.com/article/10.1007/s11257-013-9142-7 http://link.springer.com/10.1007/s11257-013-9142-7},
year = {2013}
}
@article{Fares2013,
address = {New York, New York, USA},
author = {Fares, Ribel and Fang, Shaomin and Komogortsev, Oleg},
doi = {10.1145/2470654.2466183},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Input, mouse, MAGIC, animated, eye, tracking, mult},
pages = {1387},
publisher = {ACM Press},
title = {{Can we beat the mouse with MAGIC?}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466183},
year = {2013}
}
@inproceedings{Ryan2010,
abstract = {Analysis of recordings made by a wearable eye tracker is complicated by video stream synchronization, pupil coordinate mapping, eye movement analysis, and tracking of dynamic Areas Of Interest (AOIs) within the scene. In this paper a semi-automatic system is developed to help automate these processes. Synchronization is accomplished via side by side video playback control. A deformable eye template and calibration dot marker allow reliable initialization via simple drag and drop as well as a user-friendly way to correct the algorithm when it fails. Specifically, drift may be corrected by nudging the detected pupil center to the appropriate coordinates. In a case study, the impact of surrogate nature views on physiological health and perceived well-being is examined via analysis of gaze over images of nature. A match-moving methodology was developed to track AOIs for this particular application but is applicable toward similar future studies.},
address = {New York, New York, USA},
annote = {- cited by: 7
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Ryan, Wayne J. and Duchowski, Andrew T. and Vincent, Ellen A. and Battisto, Dina},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743722},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Ryan et al/Ryan et al. - 2010 - Match-moving for area-based analysis of eye movements in natural tasks.pdf:pdf},
isbn = {9781605589947},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {235},
publisher = {ACM Press},
title = {{Match-moving for area-based analysis of eye movements in natural tasks}},
url = {http://dl.acm.org/citation.cfm?id=1743722 http://portal.acm.org/citation.cfm?doid=1743666.1743722},
year = {2010}
}
@inproceedings{Veneri2010,
abstract = {Eye movement is the most simple and repetitive movement that enable humans to interact with the environment. The common daily activities, such as watching television or reading a book, involve this natural activity which consists of rapidly shifting our gaze from one region to another. The identification of the main components of eye movement during visual exploration such as fixations and saccades, is the objective of the analysis of eye movements in various contexts ranging from basic neuro sciences and visual sciences to virtual reality interactions and robotics. However, many of the algorithms that detect fixations present a number of problems. In this article, we present a new fixation identification algorithm based on the analysis of variance and F-test. We present the new algorithm and we compare it with the common fixations algorithm based on dispersion. To demonstrate the performance of our approach we tested the algorithm in a group of healthy subjects.},
annote = {- cited by: 5
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Veneri, Giacomo and Piu, Pietro and Federighi, Pamela and Rosini, Francesca and Federico, Antonio and Rufa, Alessandra},
booktitle = {2010 2nd International Workshop on Cognitive Information Processing},
doi = {10.1109/CIP.2010.5604221},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 2nd International Workshop on Cognitive Information Processing/2010/Veneri et al/Veneri et al. - 2010 - Eye fixations identification based on statistical analysis - Case study.pdf:pdf},
isbn = {978-1-4244-6459-3},
keywords = {Eye Tracking,F-test,Segmentation,analysis of variance,eye fixations identification,eye movement},
mendeley-tags = {Eye Tracking,Segmentation},
month = jun,
pages = {446--451},
publisher = {IEEE},
title = {{Eye fixations identification based on statistical analysis - Case study}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5604221 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5604221},
year = {2010}
}
@inproceedings{Leung2009,
abstract = {In this paper, we proposed a movable hand-held display system which uses a projector to project display content onto an ordinary cardboard which can move freely within the projection area. Such a system can give users greater freedom of control of the display such as the viewing angle and distance. At the same time, the size of the cardboard can be made to a size that fits one's application. A projector-camera pair is calibrated and used as the tracking and projection system. We present a vision based algorithm to detect an ordinary cardboard and track its subsequent motion. Display content is then pre-warped and projected onto the cardboard at the correct position. Experimental results show that our system can project onto the cardboard in reasonable precision.},
address = {Miami, FL},
author = {Chang, M.M.Y.},
booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2009.5206658},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2009 IEEE Conference on Computer Vision and Pattern Recognition/2009/Chang/Chang - 2009 - A projector-based movable hand-held display system.pdf:pdf},
isbn = {978-1-4244-3992-8},
keywords = {anamorphism,display content,keystone,movable handheld display system,ordinary cardboard,projector-camera pair},
mendeley-tags = {anamorphism,keystone},
month = jun,
pages = {1109--1114},
publisher = {IEEE},
title = {{A projector-based movable hand-held display system}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206658 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206658},
year = {2009}
}
@article{Camilli2008,
abstract = {In human factors and ergonomics research, the analysis of eye movements has gained popularity as a method for obtaining information concerning the operators cognitive strategies and for drawing inferences about the cognitive state of an individual. For example, recent studies have shown that the distribution of eye fixations is sensitive to variations in mental workload\&\#x2014;dispersed when workload is high, and clustered when workload is low. Spatial statistics algorithms can be used to obtain information about the type of distribution and can be applied over fixations recorded during small epochs of time to assess online changes in the level of mental load experienced by the individuals. In order to ease the computation of the statistical index and to encourage research on the spatial properties of visual scanning, A Simple Tool for Examining Fixations has been developed. The software application implements functions for fixation visualization, management, and analysis, and includes a tool for fixation identification from raw gaze point data. Updated information can be obtained online at www .astef.info, where the installation package is freely downloadable.},
annote = {- cited by: 25
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Camilli, Marco and Nacchia, Roberto and Terenzi, Michela and Nocera, Francesco},
doi = {10.3758/BRM.40.2.373},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2008/Camilli et al/Camilli et al. - 2008 - ASTEF A simple tool for examining fixations.pdf:pdf},
issn = {1554-351X},
journal = {Behavior research methods},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = may,
number = {2},
pages = {373--382},
title = {{ASTEF: A simple tool for examining fixations}},
url = {http://link.springer.com/article/10.3758/BRM.40.2.373 http://www.springerlink.com/index/10.3758/BRM.40.2.373},
volume = {40},
year = {2008}
}
@article{Uzor2013,
address = {New York, New York, USA},
author = {Uzor, Stephen and Baillie, Lynne},
doi = {10.1145/2470654.2466159},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1233},
publisher = {ACM Press},
title = {{Exploring \& designing tools to enhance falls rehabilitation in the home}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466159},
year = {2013}
}
@article{Lopes2013,
address = {New York, New York, USA},
author = {Lopes, Pedro and Butzmann, Lars and Baudisch, Patrick},
doi = {10.1145/2459236.2459276},
isbn = {9781450319041},
journal = {Proceedings of the 4th Augmented Human International Conference on - AH '13},
keywords = {force feedback, mobile device, muscle Contraction,},
pages = {231--232},
publisher = {ACM Press},
title = {{Muscle-propelled force feedback}},
url = {http://dl.acm.org/citation.cfm?doid=2459236.2459276},
year = {2013}
}
@inproceedings{Belluta1989,
author = {Belluta, P and Collini, G and Verri, V and Torre, V},
booktitle = {IEEE Workshop on interpretation of 3D scenes},
pages = {41--49},
title = {{3D visual information from vanishing points}},
year = {1989}
}
@article{Feild2013,
address = {New York, New York, USA},
author = {Feild, Henry and White, Ryen W. and Fu, Xin},
doi = {10.1145/2470654.2481416},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2999},
publisher = {ACM Press},
title = {{Supporting orientation during search result examination}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481416},
year = {2013}
}
@article{Jansen2013,
address = {New York, New York, USA},
author = {Jansen, Yvonne and Dragicevic, Pierre and Fekete, Jean-Daniel},
doi = {10.1145/2470654.2481359},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2593},
publisher = {ACM Press},
title = {{Evaluating the efficiency of physical visualizations}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481359},
year = {2013}
}
@inproceedings{Mostafa2013,
abstract = {Microseismic visualization systems present complex 3D data of small seismic events within oil reservoirs to allow experts to explore and interact with that data. Yet existing systems suffer several problems: 3D spatial navigation and orientation is difficult, and selecting 3D data is challenging due to the problems of occlusion and lack of depth perception. Our work mitigates these problems by applying both proxemic interactions and a spatial input device to simplify how experts navigate through the visualization, and a painting metaphor to simplify how they select that information.},
address = {New York, New York, USA},
author = {Mostafa, Ahmed E and Greenberg, Saul and {Vital Brazil}, Emilio and Sharlin, Ehud and Sousa, Mario C},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
doi = {10.1145/2468356.2468670},
isbn = {9781450319522},
pages = {1749--1754},
publisher = {ACM Press},
title = {{Interacting with microseismic visualizations}},
year = {2013}
}
@article{Sato2013,
address = {New York, New York, USA},
author = {Sato, Takashi G. and Kamamoto, Yutaka and Harada, Noboru and Moriya, Takehiro},
doi = {10.1145/2468356.2468541},
file = {:home/acmt/Dropbox/Documentos/Mendeley/CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13/2013/Sato et al/Sato et al. - 2013 - A playback system that synchronizes the musical phrases with listener's respiration phases.pdf:pdf},
isbn = {9781450319522},
journal = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
pages = {1035},
publisher = {ACM Press},
title = {{A playback system that synchronizes the musical phrases with listener's respiration phases}},
url = {http://dl.acm.org/citation.cfm?doid=2468356.2468541},
year = {2013}
}
@article{Peck2013,
address = {New York, New York, USA},
author = {Peck, Evan M M. and Yuksel, Beste F. and Ottley, Alvitta and Jacob, Robert J.K. and Chang, Remco},
doi = {10.1145/2470654.2470723},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {473},
publisher = {ACM Press},
title = {{Using fNIRS brain sensing to evaluate information visualization interfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470723},
year = {2013}
}
@book{Hartley2003a,
abstract = {A basic problem in computer vision is to understand the structure of a real world scene. This book covers relevant geometric principles and how to represent objects algebraically so they can be computed and applied. Recent major developments in the theory and practice of scene reconstruction are described in detail in a unified framework. Richard Hartley and Andrew Zisserman provide comprehensive background material and explain how to apply the methods and implement the algorithms. First Edition HB (2000): 0-521-62304-9},
author = {Hartley, Richard},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2003/Hartley/Hartley - 2003 - Multiple View Geometry in Computer Vision.pdf:pdf},
isbn = {1139449141},
pages = {655},
publisher = {Cambridge University Press},
title = {{Multiple View Geometry in Computer Vision}},
url = {http://books.google.com/books?id=si3R3Pfa98QC&pgis=1},
year = {2003}
}
@misc{Majumder2011,
author = {Majumder, Aditi},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{View-Perspective Projection}},
url = {http://www.ics.uci.edu/~majumder/CG/classes/wk3-cls1-persp.pdf},
urldate = {2013-07-22},
year = {2011}
}
@inproceedings{Santella2004,
abstract = {Characterizing the location and extent of a viewer's interest, in terms of eye movement recordings, informs a range of investigations in image and scene viewing. We present an automatic data-driven method for accomplishing this, which clusters visual point-of-regard (POR) measurements into gazes and regions-of-interest using the mean shift procedure. Clusters produced using this method form a structured representation of viewer interest, and at the same time are replicable and not heavily influenced by noise or outliers. Thus, they are useful in answering fine-grained questions about where and how a viewer examined an image.},
address = {New York, New York, USA},
author = {Santella, Anthony and DeCarlo, Doug},
booktitle = {Proceedings of the Eye tracking research \& applications symposium on Eye tracking research \& applications - ETRA'2004},
doi = {10.1145/968363.968368},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Eye tracking research \& applications symposium on Eye tracking research \& applications - ETRA'2004/2004/Santella, DeCarlo/Santella, DeCarlo - 2004 - Robust clustering of eye movement recordings for quantification of visual interest.pdf:pdf},
isbn = {1581138253},
keywords = {eye movement,gaze analysis},
mendeley-tags = {eye movement,gaze analysis},
pages = {27--34},
publisher = {ACM Press},
title = {{Robust clustering of eye movement recordings for quantification of visual interest}},
url = {http://dl.acm.org/citation.cfm?id=968368 http://portal.acm.org/citation.cfm?doid=968363.968368},
year = {2004}
}
@misc{Adobe,
author = {Adobe},
title = {{Adobe Flash}},
url = {http://www.adobe.com/products/flashplayer.html},
urldate = {17/01/2012}
}
@inproceedings{Faugeras,
abstract = {This article deals with the problem of recovering the three trifocal tensors between three views from a set of point correspondences. We give a new way of deriving the trifocal tensor based on Grassmann-Cayley algebra that sheds some new light on its structure and leads to a complete characterization of its geometric and algebraic properties which is fairly institute, i.e. geometric. We give a set of algebraic constraints satisfied by the 27 coefficients of the trifocal tensor which allow to parameterize it minimally with 18 coefficients. We then describe a robust method for estimating the trifocal tensor from point and line correspondences that uses this minimal parameterization. Experimental results show that this method as superior to the linear methods which had been previously published},
author = {Faugeras, O. and Papadopoulo, T.},
booktitle = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
doi = {10.1109/ICCV.1998.710761},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)/Unknown/Faugeras, Papadopoulo/Faugeras, Papadopoulo - Unknown - A nonlinear method for estimating the projective geometry of 3 views.pdf:pdf},
isbn = {81-7319-221-9},
pages = {477--484},
publisher = {Narosa Publishing House},
title = {{A nonlinear method for estimating the projective geometry of 3 views}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=710761&contentType=Conference+Publications&searchField=Search_All&queryText=.QT.projective+geometry.QT.}
}
@article{Abreu2011,
author = {Abreu, Priscilla F. De and Werneck, Vera Maria B. and Costa, Rosa Maria E. Moreira Da and Carvalho, Luis Alfredo V. De},
doi = {10.1109/SVR.2011.32},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Abreu et al/Abreu et al. - 2011 - Employing Multi-agents in 3-D Game for Cognitive Stimulation.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
keywords = {an automated control,can be integrated into,cognitive stimulation,different applications and provide,games,mas,multi-agents systems,serious,the multi-agent systems,virtual reality},
month = may,
pages = {73--78},
publisher = {Ieee},
title = {{Employing Multi-agents in 3-D Game for Cognitive Stimulation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951837},
year = {2011}
}
@misc{Lindeijer2013,
author = {Lindeijer, Thorbj\o rn},
keywords = {sbgames},
mendeley-tags = {sbgames},
title = {{Tiled}},
url = {http://www.mapeditor.org/},
urldate = {2013/07/26},
year = {2013}
}
@article{Schmalstieg2007e,
author = {Schmalstieg, Dieter and Wagner, Daniel},
isbn = {9781424417506},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
keywords = {augmented reality games,cultural heritage,mobile augmented reality,wearable computing},
month = nov,
pages = {1--13},
publisher = {IEEE Computer Society Press},
title = {{Experiences with Handheld Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538819},
year = {2007}
}
@inproceedings{Machado2006,
abstract = {The goal of virtual reality applications to support medical procedures is the planning, the training or the assistance of medical procedures. Some features as reduction of costs, availability and safety can be related to realism and quality procedure assessment to provide several benefits of medical applications of virtual reality.},
address = {Bel\'{e}m-PA},
author = {Machado, Liliane Santos and Moraes, Ronei Marcos},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {358--365},
publisher = {SBC},
title = {{Realidade Virtual Aplicada \`{a} Medicina}},
year = {2006}
}
@article{Wenzel2003,
author = {Wenzel, S. and Bernhard, J. and Jessen, U.},
doi = {10.1109/WSC.2003.1261489},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693)/2003/Wenzel, Bernhard, Jessen/Wenzel, Bernhard, Jessen - 2003 - A taxonomy of visualization techniques for simulation in production and logistics.pdf:pdf},
isbn = {0-7803-8131-9},
journal = {Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693)},
pages = {729--736},
publisher = {Ieee},
title = {{A taxonomy of visualization techniques for simulation in production and logistics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1261489},
year = {2003}
}
@inproceedings{Henrysson2005,
author = {Henrysson, Anders and Billinghurst, Mark and Ollila, Mark},
booktitle = {Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)},
doi = {10.1109/ISMAR.2005.32},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)/2005/Henrysson, Billinghurst, Ollila/Henrysson, Billinghurst, Ollila - 2005 - Face to face collaborative AR on mobile phones.pdf:pdf},
isbn = {0-7695-2459-1},
pages = {80--89},
publisher = {IEEE},
title = {{Face to face collaborative AR on mobile phones}},
url = {http://portal.acm.org/citation.cfm?id=1105185 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544667},
year = {2005}
}
@book{Kalra2006,
address = {Berlin, Heidelberg},
doi = {10.1007/11949619},
editor = {Kalra, Prem K. and Peleg, Shmuel},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2006/Unknown/Unknown - 2006 - Computer Vision, Graphics and Image Processing.pdf:pdf},
isbn = {978-3-540-68301-8},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Computer Vision, Graphics and Image Processing}},
url = {http://www.springerlink.com/index/10.1007/11949619},
volume = {4338},
year = {2006}
}
@article{Nov2013,
address = {New York, New York, USA},
author = {Nov, Oded and Arazy, Ofer and L\'{o}pez, Claudia and Brusilovsky, Peter},
doi = {10.1145/2470654.2470707},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {361},
publisher = {ACM Press},
title = {{Exploring personality-targeted UI design in online social participation systems}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470707},
year = {2013}
}
@article{Spakov2007,
abstract = {Eye tracking devices generate enormous amount of data, which requires a well-balanced approach to selective visualization of the data. This approach involves employing some data clustering algorithm. Most of the tradi- tional algorithms, however, are too slow as well as inadequately deterministic to be applied to eye gaze data. This paper describes our software implementation of two modifications of the clustering algorithm suitable for visualization of eye gaze data. Such a visualization greatly facilitates data analysis by grouping the individual samples into more meaningful units referred to as gaze fixations.},
annote = {- cited by: 3
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {\v{S}pakov, O and Miniotas, D},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Information Technology and Control/2007/\v{S}pakov, Miniotas/\v{S}pakov, Miniotas - 2007 - Application of clustering algorithms in eye gaze visualizations.pdf:pdf},
journal = {Information Technology and Control},
keywords = {clustering algorithms,data clusters,eye tracking,gaze analysis,information visualization,pie charts.},
mendeley-tags = {gaze analysis},
number = {2},
pages = {213--216},
title = {{Application of clustering algorithms in eye gaze visualizations}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.116.1091&rep=rep1&type=pdf},
volume = {36},
year = {2007}
}
@misc{Wiering2012,
author = {Wiering, Mike},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{TileStudio}},
url = {http://tilestudio.sourceforge.net/},
urldate = {2013/07/26},
year = {2012}
}
@article{Torricelli2009,
author = {Torricelli, Diego and Goffredo, Michela and Conforto, Silvia and Schmid, Maurizio},
doi = {10.1016/j.patrec.2009.05.014},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Pattern Recognition Letters/2009/Torricelli et al/Torricelli et al. - 2009 - An adaptive blink detector to initialize and update a view-basedremote eye gaze tracking system in a natural.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = sep,
number = {12},
pages = {1144--1150},
title = {{An adaptive blink detector to initialize and update a view-basedremote eye gaze tracking system in a natural scenario}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865509001329 http://linkinghub.elsevier.com/retrieve/pii/S0167865509001329},
volume = {30},
year = {2009}
}
@inproceedings{Komarov2013,
abstract = {Online labor markets, such as Amazon's Mechanical Turk (MTurk), provide an attractive platform for conducting human subjects experiments because the relative ease of recruitment, low cost, and a diverse pool of potential participants enable larger-scale experimentation and faster experimental revision cycle compared to lab-based settings. However, because the experimenter gives up the direct control over the participants' environments and behavior, concerns about the quality of the data collected in online settings are pervasive. In this paper, we investigate the feasibility of conducting online performance evaluations of user interfaces with anonymous, unsupervised, paid participants recruited via MTurk. We implemented three performance experiments to re-evaluate three previously well-studied user interface designs. We conducted each experiment both in lab and online with participants recruited via MTurk. The analysis of our results did not yield any evidence of significant or substantial differences in the data collected in the two settings: All statistically significant differences detected in lab were also present on MTurk and the effect sizes were similar. In addition, there were no significant differences between the two settings in the raw task completion times, error rates, consistency, or the rates of utilization of the novel interaction mechanisms introduced in the experiments. These results suggest that MTurk may be a productive setting for conducting performance evaluations of user interfaces providing a complementary approach to existing methodologies.},
address = {New York, New York, USA},
author = {Komarov, Steven and Reinecke, Katharina and Gajos, Krzysztof Z.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470684},
isbn = {9781450318990},
pages = {207--216},
publisher = {ACM Press},
title = {{Crowdsourcing performance evaluations of user interfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470684},
year = {2013}
}
@inproceedings{Sukthankar2001,
abstract = {Standard presentation systems consisting of a laptop connected to a projector suffer from two problems: (1) the projected image appears distorted (keystoned) unless the projector is precisely aligned to the projection screen; (2) the speaker is forced to interact with the computer rather than the audience. This paper shows how the addition of an uncalibrated camera, aimed at the screen, solves both problems. Although the locations, orientations and optical parameters of the camera and projector are unknown, the projector-camera system calibrates itself by exploiting the homography between the projected slide and the camera image. Significant improvements are possible over passively calibrating systems since the projector actively manipulates the environment by placing feature points into the scene. For instance, using a low-resolution (160×120) camera, we can achieve an accuracy of ±3 pixels in a 1024×768 presentation slide. The camera-projector system infers models for the projector-to-camera and projector-to-screen mappings in order to provide two major benefits},
annote = {        From Duplicate 1 (                   Smarter Presentations : Exploiting Homography in Camera-Projector Systems                 - Sukthankar, Rahul; Stockton, Robert G; Mullin, Matthew D )
                
        
        
      },
author = {Sukthankar, Rahul and Stockton, R.G. and Mullin, M.D.},
booktitle = {Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},
doi = {10.1109/ICCV.2001.937525},
isbn = {0-7695-1143-0},
pages = {247--253},
publisher = {IEEE Comput. Soc},
title = {{Smarter presentations: exploiting homography in camera-projector systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=937525},
volume = {1},
year = {2001}
}
@inproceedings{Koyama2003,
abstract = {This paper proposes a method to realize a 3D video display system that can capture video from multiple cameras, reconstruct 3D models and transmit 3D video data in real time. We represent a target object with a simplified 3D model consisting of a single plane and a 2D texture extracted from multiple cameras. This 3D model is simple enough to be transmitted via a network. We have developed a prototype system that can capture multiple videos, reconstruct 3D models, transmit the models via a network, and display 3D video in real time. A 3D video of a typical soccer scene that includes a dozen players was processed at 26 frames per second.},
address = {Tokyo},
annote = {
        From Duplicate 1 ( 
        
        
          Live mixed-reality 3D video in soccer stadium
        
        
         - Koyama, T; Kitahara, I; Ohta, Y )

        
        

        

        

      },
author = {Koyama, T. and Kitahara, I. and Ohta, Y.},
booktitle = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
doi = {10.1109/ISMAR.2003.1240701},
isbn = {0-7695-2006-5},
keywords = {2D texture,3D model,3D reconstruction,3D video data,3D video display system,Cameras,Data engineering,Image reconstruction,Intelligent robots,Layout,Prototypes,Real time systems,Space technology,Three dimensional displays,Virtual reality,computer vision,image media,image representation,mixed reality,multiple cameras,prototype system,real time system,reconstruction,soccer scene,soccer stadium,sport,target object,three-dimensional displays,video capture,visual information},
mendeley-tags = {reconstruction},
pages = {178--186},
publisher = {IEEE Comput. Soc},
shorttitle = {Mixed and Augmented Reality, 2003. Proceedings. Th},
title = {{Live mixed-reality 3D video in soccer stadium}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1240701 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240701},
year = {2003}
}
@article{Delphenich2005a,
abstract = {Some concepts of real and complex projective geometry are applied to the fundamental physical notions that relate to Minkowski space and the Lorentz group. In particular, it is shown that the transition from an infinite speed of propagation for light waves to a finite one entails the replacement of a hyperplane at infinity with a light cone and the replacement of an affine hyperplane - or rest space - with a proper time hyperboloid. The transition from the metric theory of electromagnetism to the pre-metric theory is discussed in the context of complex projective geometry, and ultimately it is proposed that the geometrical issues are more general than electromagnetism, namely, they pertain to the transition from point mechanics to wave mechanics.},
author = {Delphenich, David},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Philosophy of Science/2005/Delphenich/Delphenich - 2005 - Projective geometry and special relativity.pdf:pdf},
journal = {Philosophy of Science},
pages = {41},
title = {{Projective geometry and special relativity}},
url = {http://arxiv.org/abs/gr-qc/0512125},
volume = {46},
year = {2005}
}
@inproceedings{Noonan2011,
abstract = {Robust motion correction in medical imaging requires accurate and reliable motion tracking. Current systems use devices such as the Polaris Vicra position sensor to monitor the position and orientation of a tracking tool which is fixed to the subject. Although in principle these methods offer high positional accuracy this is lost if the tool slips. Markerless motion tracking aims to track the object directly without the use of markers or a tracking tool. To date these methods have either been unsuccessful or too expensive to have been widely implemented. The Microsoft Kinect is a low cost RGB+D (colour plus depth) video camera. We have used the Kinect to perform motion tracking of a head phantom using a CT of the head as a high resolution template. We present initial results that show the Kinect can track rigid body motion to within <;2 mm of that measured by a Polaris system. We use the PointCloudLibrary open project [1] algorithm implementations to register the CT template to the Kinect frames.},
author = {Noonan, Philip J. and Cootes, Tim F. and Hallett, William A. and Hinz, Rainer},
booktitle = {2011 IEEE Nuclear Science Symposium Conference Record},
doi = {10.1109/NSSMIC.2011.6153680},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 IEEE Nuclear Science Symposium Conference Record/2011/Noonan et al/Noonan et al. - 2011 - The design and initial calibration of an optical tracking system using the Microsoft Kinect.pdf:pdf},
isbn = {978-1-4673-0120-6},
month = oct,
pages = {3614--3617},
publisher = {IEEE},
title = {{The design and initial calibration of an optical tracking system using the Microsoft Kinect}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6153680&contentType=Conference+Publications&searchField%3DSearch_All%26queryText%3Dkinect+calibration http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6153680},
year = {2011}
}
@book{Tiffin2001,
author = {Tiffin, John and Terashima, Nobuyoshi},
isbn = {041526104X},
pages = {192},
publisher = {Routledge},
title = {{HyperReality: Paradigm for the Third Millennium}},
url = {http://www.amazon.com/HyperReality-Paradigm-Millenium-Nobuyoshi- Terashima/dp/041526104X},
year = {2001}
}
@inproceedings{Quintella2010,
address = {Natal},
author = {Quintella, Felipe and Vicente, R M S and Soares, Luciano and Raposo, Alberto},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2010/Quintella et al/Quintella et al. - 2010 - DWeb3D Um toolkit para facilitar a cri\c{c}\~{a}o e manipula\c{c}\~{a}o de cenas 3D em X3D.pdf:pdf},
pages = {1--4},
publisher = {SBC},
title = {{DWeb3D: Um toolkit para facilitar a cri\c{c}\~{a}o e manipula\c{c}\~{a}o de cenas 3D em X3D}},
year = {2010}
}
@article{Leao2011,
author = {Le\~{a}o, Crystian Wendel M. and Lima, Jo\~{a}o Paulo and Teichrieb, Veronica and Kelner, Judith and Albuquerque, Eduardo S.},
doi = {10.1109/SVR.2011.29},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Le\~{a}o et al/Le\~{a}o et al. - 2011 - Geometric Modifications Applied to Real Elements in Augmented Reality.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
keywords = {-augmented reality,mixed reality,physically-based},
month = may,
pages = {96--101},
publisher = {Ieee},
title = {{Geometric Modifications Applied to Real Elements in Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951840},
year = {2011}
}
@unpublished{Chesnet2011,
abstract = {The decomposition of the movement of the eye into different categories is critical to their study. Ac- cording to the algorithm used, some movements may significantly be over or under estimated. The two most important movements (saccade, swift movement and fixation, when the eye remains on the same position to capture information) are well characterized and usually properly identified by most algorithms, however in the context of writing, some other movements cannot be characterized as fixations or saccades. These movements may either be considered as microsaccades or slow movements which are actually close to saccades of fixations respectively but without completely sharing their characteristics. None of the algorithms available for eye movements classification can handle all the four movements. Some of them tend to first identify fixations by the barycenter method while others first identify saccades by the mean of speed. The approach used here is different as movements are first decomposed into elementary move- ments according to the acceleration scheme before they are merged. This new approach allows a better identification of each of the 4 kinds of movements.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Alamargot, Denis and Caporossi, Gilles and Chesnet, David},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2011/Alamargot, Caporossi, Chesnet/Alamargot, Caporossi, Chesnet - 2011 - An Algorithm for Qualifying Eye Movements During Handwriting.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {12},
title = {{An Algorithm for Qualifying Eye Movements During Handwriting}},
url = {http://www.gerad.ca/fichiers/cahiers/G-2011-41.pdf},
year = {2011}
}
@article{Voelker2013,
address = {New York, New York, USA},
author = {Voelker, Simon and Wacharamanotham, Chat and Borchers, Jan},
doi = {10.1145/2470654.2470759},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {745},
publisher = {ACM Press},
title = {{An evaluation of state switching methods for indirect touch systems}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470759},
year = {2013}
}
@article{Wallace2013a,
address = {New York, New York, USA},
author = {Wallace, Jayne and McCarthy, John and Wright, Peter C. and Olivier, Patrick},
doi = {10.1145/2470654.2466473},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3441},
publisher = {ACM Press},
title = {{Making design probes work}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466473},
year = {2013}
}
@article{Malacria2013,
address = {New York, New York, USA},
author = {Malacria, Sylvain and Bailly, Gilles and Harrison, Joel and Cockburn, Andy and Gutwin, Carl},
doi = {10.1145/2470654.2470735},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Hotkeys, keyboard shortcuts, rehearsal, menus, com},
pages = {573},
publisher = {ACM Press},
title = {{Promoting Hotkey use through rehearsal with ExposeHK}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470735},
year = {2013}
}
@article{McMillan2013,
address = {New York, New York, USA},
author = {McMillan, Donald and Morrison, Alistair and Chalmers, Matthew},
doi = {10.1145/2470654.2466245},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1853},
publisher = {ACM Press},
title = {{Categorised ethical guidelines for large scale mobile HCI}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466245},
year = {2013}
}
@inproceedings{Sugimoto2007,
author = {Sugimoto, Maki and Kodama, Kazuki and Nakamura, Akihiro and Kojima, Minoru and Inami, Masahiko},
booktitle = {17th International Conference on Artificial Reality and Telexistence (ICAT 2007)},
doi = {10.1109/ICAT.2007.50},
file = {:home/acmt/Dropbox/Documentos/Mendeley/17th International Conference on Artificial Reality and Telexistence (ICAT 2007)/2007/Sugimoto et al/Sugimoto et al. - 2007 - A Display-Based Tracking System Display-Based Computing for Measurement Systems.pdf:pdf},
isbn = {0-7695-3056-7},
month = nov,
pages = {31--38},
publisher = {IEEE},
title = {{A Display-Based Tracking System: Display-Based Computing for Measurement Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4414613},
year = {2007}
}
@article{Livingstone2002,
author = {Livingstone, M and Hubel, DH},
file = {::},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Vision and art: The biology of seeing}},
url = {http://great-humanities-textbooks.info/wp-content/uploads/pdfs/Vision and Art The Biology of Seeing by Margaret S Livingstone - Finally  A Book Offering Ideas For An Age-Old Question.pdf},
year = {2002}
}
@article{Kujala2013,
address = {New York, New York, USA},
author = {Kujala, Sari and Miron-Shatz, Talya},
doi = {10.1145/2470654.2466135},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1061},
publisher = {ACM Press},
title = {{Emotions, experiences and usability in real-life mobile phone use}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466135},
year = {2013}
}
@article{Juhola2006,
abstract = {Eye movements have been investigated in several areas of medicine and also elsewhere, such as in psychology or even in the development of human-computer interfaces. In the last few years we have designed a technique to stimulate, measure and analyze vestibulo-ocular reflex eye movements. In the otoneurological literature these are seen as a novel and promising means of revealing certain disorders and diseases associated with vertigo. Vestibulo-ocular reflex is stimulated by impulsive head movements. We developed the present pattern recognition technique to detect the stimulus (impulsive head movements) and the vestibulo-ocular reflex (response eye movements) generated from signals and to compute the latency and the gain values between them. Using our technique to calculate these attributes, we obtained clearly different results for a group of 22 dizzy patients than for a group of 30 healthy subjects.},
author = {Juhola, Martti and Aalto, Heikki and Hirvonen, Timo},
doi = {10.1007/s10439-006-9129-1},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Annals of biomedical engineering/2006/Juhola, Aalto, Hirvonen/Juhola, Aalto, Hirvonen - 2006 - A signal analysis technique of vestibulo-ocular reflex stimulated with impulsive head movements.pdf:pdf},
issn = {0090-6964},
journal = {Annals of biomedical engineering},
keywords = {Automated,Automated: methods,Computer-Assisted,Computer-Assisted: instrumentation,Dizziness,Dizziness: diagnosis,Eye Movements,Female,Head Movements,Humans,Male,Pattern Recognition,Reflex,Signal Processing,Vertigo,Vertigo: diagnosis,Vestibulo-Ocular,gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
month = jul,
number = {7},
pages = {1213--25},
pmid = {16786396},
title = {{A signal analysis technique of vestibulo-ocular reflex stimulated with impulsive head movements.}},
url = {http://link.springer.com/article/10.1007/s10439-006-9129-1 http://www.ncbi.nlm.nih.gov/pubmed/16786396},
volume = {34},
year = {2006}
}
@inproceedings{Shic2008a,
abstract = {The analysis of eye-tracking data hinges on the ability of automated algorithms to separate rapid saccadic eye movements from stable eye fixations. However, though it has long been known that changing the parameters of fixationidentification algorithms can lead to very different qualitative impressions, less is known about how algorithmic parameters interact with quantitative eye-tracking measures. In this study we show that by manipulating aspects of fixation identification, we can completely reverse the patterns of observed results for mean fixation duration, a measure traditionally associated with cognitive load. However, by linearly mapping mean fixation duration over its parameter space, we obtain a new formulation which addresses many of the deficits of the standard analysis. We use our methods to analyze the gaze patterns of toddlers with autism spectrum disorder and control populations and discuss the observed differences in terms of the physical and cognitive ramifications of our methodology.},
annote = {- cited by: 9
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Shic, F and Chawarska, K and Scassellati, B},
booktitle = {30th Annual Meeting of the Cognitive Science Society},
doi = {10.1.1.145.8123},
file = {:home/acmt/Dropbox/Documentos/Mendeley/30th Annual Meeting of the Cognitive Science Society/2008/Shic, Chawarska, Scassellati/Shic, Chawarska, Scassellati - 2008 - The amorphous fixation measure revisited with applications to autism.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {1--6},
title = {{The amorphous fixation measure revisited: with applications to autism}},
url = {http://scazlab.yale.edu/sites/default/files/files/Shic-CogSci-2008.pdf http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.145.8123},
year = {2008}
}
@book{brannan2011geometry,
author = {Brannan, D A and Esplen, M F and Gray, J J},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2011/Brannan, Esplen, Gray/Brannan, Esplen, Gray - 2011 - Geometry.pdf:pdf},
isbn = {9781107647831},
publisher = {Cambridge University Press},
title = {{Geometry}},
url = {http://books.google.com.br/books?id=UlrmKjIjrzQC},
year = {2011}
}
@inproceedings{Kinnunen2010,
abstract = {We propose a person authentication system using eye movement signals. In security scenarios, eye-tracking has earlier been used for gaze-based password entry. A few authors have also used physical features of eye movement signals for authentication in a task-dependent scenario with matched training and test samples. We propose and implement a task-independent scenario whereby the training and test samples can be arbitrary. We use short-term eye gaze direction to construct feature vectors which are modeled using Gaussian mixtures. The results suggest that there are personspecific features in the eye movements that can be modeled in a task-independent manner. The range of possible applications extends beyond the security-type of authentication to proactive and user-convenience systems.},
address = {New York, New York, USA},
annote = {- cited by: 13
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Kinnunen, Tomi and Sedlak, Filip and Bednarik, Roman},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743712},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Kinnunen, Sedlak, Bednarik/Kinnunen, Sedlak, Bednarik - 2010 - Towards task-independent person authentication using eye movement signals.pdf:pdf},
isbn = {9781605589947},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {187},
publisher = {ACM Press},
title = {{Towards task-independent person authentication using eye movement signals}},
url = {http://dl.acm.org/citation.cfm?id=1743712 http://portal.acm.org/citation.cfm?doid=1743666.1743712},
year = {2010}
}
@phdthesis{Larsson2010,
abstract = {A new method of evaluating eye movement classification algorithms using Precision and Recall is proposed. The method involves recording test subjects looking at known stimuli and then testing various algo- rithms’ ability to classify the eye movements that are anticipated. This method is then used to evaluate the performance of different off-line algorithms. The algorithms I-DT, I-VT and an HMM-based method were tested, as well as eye tracking company Tobii Technology’s algorithms Clear- View and Tobii Fixation Filter. An analysis tool, which is available freely to the public, was developed in order to facilitate the process of developing and evaluating classification algorithms. Precision and Recall gave a clear profile of how accurately different algorithms could identify fixations. The implementations of I-VT and ClearView are essentially the same, and so were the results. The HMM offered no improvements, but should not be dismissed completely. To- bii Fixation Filter performed well due to filtering of the data. Most significantly, I-DT performed better than I-VT for fixation identification, while the reverse was true for extracting accurate sac- cadic information.},
author = {Larsson, G},
booktitle = {nada.kth.se},
file = {:home/acmt/Dropbox/Documentos/Mendeley/nada.kth.se/2010/Larsson/Larsson - 2010 - Evaluation methodology of eye movement classification algorithms.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {56},
school = {Royal Institute of Technology},
title = {{Evaluation methodology of eye movement classification algorithms}},
url = {http://www.nada.kth.se/utbildning/grukth/exjobb/rapportlistor/2010/rapporter10/larsson_gustav_10064.pdf},
year = {2010}
}
@article{Norman1999,
author = {Norman, Donald A},
doi = {10.1145/301153.301168},
file = {:home/acmt/Dropbox/Documentos/Mendeley/interactions/1999/Norman/Norman - 1999 - Affordance, conventions, and design.pdf:pdf},
issn = {10725520},
journal = {interactions},
month = may,
number = {3},
pages = {38--43},
title = {{Affordance, conventions, and design}},
url = {http://portal.acm.org/citation.cfm?doid=301153.301168},
volume = {6},
year = {1999}
}
@article{Poynter2013,
abstract = {The purpose of this study was to examine individual differences in eye-movement behavior. Six metrics (Fixation Rate, Duration, and Size; Saccade Amplitude; Micro-Saccade Rate and Amplitude) were used to measure individuals' eye-movement behavior profiles (EmBP). We replicate previous research (Andrews \& Coppola, 1999; Castelhano \& Henderson, 2008) by finding consistent individual differences in fixation duration and saccade amplitude across tasks, and present new findings of stable idiosyncrasies in measures of fixational eye-movement (Fixation Size, Micro-Saccade Rate and Amplitude). Moreover, we observed consistent inter-metric correlations across tasks (e.g., individuals that exhibited relatively high Fixation Rates also presented relative low Micro-Saccade Rates and relatively high Micro-Saccade Amplitudes). Factor Analysis linked the six EmBP metrics together with a single factor, which we speculate might be related to the operational effectiveness of the attentional system, given that individual factor scores were correlated with scores on a self-report measure of attentional function. Normal subjects with relatively high scores on this attention-deficit measure exhibited relatively frequent fixations of short duration and large spatial extent, and relatively infrequent micro-saccades of large amplitude. This EmBP is similar to a general pattern of eye-movement behavior observed with ADHD individuals - difficulty controlling eye movements, maintaining fixation, and inhibiting intrusive saccades. Results of this study indicate that normal individuals exhibit idiosyncratic EmBPs that are quite stable across tasks and are related to attentional ability.},
author = {Poynter, William and Barber, Megan and Inman, Jason and Wiggins, Coral},
doi = {10.1016/j.visres.2013.07.002},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Vision Research/2013/Poynter et al/Poynter et al. - 2013 - Individuals exhibit idiosyncratic eye-movement behavior profiles across tasks.pdf:pdf},
issn = {1878-5646},
journal = {Vision Research},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = aug,
pages = {32--8},
pmid = {23867568},
title = {{Individuals exhibit idiosyncratic eye-movement behavior profiles across tasks.}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698913001685 http://www.ncbi.nlm.nih.gov/pubmed/23867568},
volume = {89},
year = {2013}
}
@article{Spakov2012,
author = {\v{S}pakov, O},
journal = {Proceedings of the Symposium on Eye Tracking  \ldots},
keywords = {Gaze analysis},
mendeley-tags = {Gaze analysis},
title = {{Comparison of eye movement filters used in HCI}},
url = {http://dl.acm.org/citation.cfm?id=2168616},
year = {2012}
}
@article{Gregory1997,
author = {Gregory, RL},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Eye and brain: The psychology of seeing .}},
url = {http://psycnet.apa.org/psycinfo/1998-07123-000},
year = {1997}
}
@article{Li2011,
abstract = {Keystone correction is an essential operation for projector-based applications, especially in mobile scenarios. In this paper, we propose a handheld movable projection method that can freely project keystone-free content on a general flat surface without adding any markings or boundary on it. Such a projection system can give the user greater freedom of display control (such as viewing angle, distance, etc.), without suffering from keystone distortion. To achieve this, we attach a camera to the projector to form a camera-projector pair. A green frame with the same resolution as the projector screen is projected onto the screen. Particle filter is employed to track the green frame and the correction of the display content is then achieved by rectifying the projection region of interest into a rectangular area. We built a prototype system to validate the effectiveness of the method. Experimental results show that our method can continuously project distortion free content in real time with good performance.},
annote = {
        From Duplicate 1 ( 
        
          An Effective Method for Movable Projector Keystone Correction
        
         - Li, Zhaorong; Wong, Kin-Hong; Gong, Yibo; Chang, Ming-Yuen )

        
        
- Coletar keywords

        

      },
author = {Li, Zhaorong and Wong, Kin-Hong and Gong, Yibo and Chang, Ming-Yuen},
doi = {10.1109/TMM.2010.2092421},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
keywords = {Accuracy,Calibration,Cameras,Keystone correction,Mobile communication,Pixel,Three dimensional displays,Tracking,anamorphism,camera-projector pair,display control,display instrumentation,flat surface,handheld movable projection method,image resolution,keystone,keystone-free content,mobile projection,movable projector keystone correction,optical projectors,particle filter,particle filtering (numerical methods),projector screen},
mendeley-tags = {anamorphism,keystone},
month = feb,
number = {1},
pages = {155--160},
shorttitle = {Multimedia, IEEE Transactions on},
title = {{An Effective Method for Movable Projector Keystone Correction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5635340 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5635340},
volume = {13},
year = {2011}
}
@inproceedings{Sarim2010,
address = {New York, New York, USA},
author = {Sarim, Muhammad and Hilton, Adrian and Guillemaut, Jean-Yves and Kim, Hansung and Takai, Takeshi},
booktitle = {Proceedings of the 1st international workshop on 3D video processing - 3DVP '10},
doi = {10.1145/1877791.1877795},
isbn = {9781450301596},
keywords = {multi-view,reconstruction,segmentation,silhouette,wide-baseline},
mendeley-tags = {reconstruction},
month = oct,
pages = {13},
publisher = {ACM Press},
title = {{Wide-baseline multi-view video segmentation for 3D reconstruction}},
url = {http://dl.acm.org/citation.cfm?id=1877791.1877795},
year = {2010}
}
@article{Junior2012,
author = {Junior, Antonio Jose Melo Leite and Gomes, George Allan Menezes and Junior, Natal Anacleto Chicca and Santos, Alysson Diniz Dos and Vidal, Creto Augusto and Cavalcante-Neto, Joaquim Bento and Gattass, Marcelo},
doi = {10.1109/SVR.2012.12},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Junior et al/Junior et al. - 2012 - System Model for Shooting Training Based on Interactive Video, Three-Dimensional Computer Graphics and Laser Ray.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {dimensional computer graphics,shooting training},
month = may,
pages = {254--260},
publisher = {Ieee},
title = {{System Model for Shooting Training Based on Interactive Video, Three-Dimensional Computer Graphics and Laser Ray Capture}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297537},
year = {2012}
}
@inproceedings{Pinho2006,
abstract = {This chapter presents a study on the relative aspects to the interaction in atmospheres virtual immersed. General considerations are presented on atmospheres virtual immersed with focus in the basic forms of interaction, metaphors and interaction parameters, for soon afterwards to present the selection techniques and manipulation of objects, as well as tha navigation in atmospheres three-dimensional immersed.},
address = {Bel\'{e}m-PA},
author = {Pinho, M\'{a}rcio Serolli and Rebelo, Irla Bocianoski},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {149--172},
publisher = {SBC},
title = {{Intera\c{c}\~{a}o em Ambientes Virtuais Imersivos}},
year = {2006}
}
@inproceedings{Sandin2005,
abstract = {Virtual reality (VR) has long been hampered by the gear needed to make the experience possible; specifically, stereo glasses and tracking devices. Autostereoscopic display devices are gaining popularity by freeing the user from stereo glasses, however few qualify as VR displays. The Electronic Visualization Laboratory (EVL) at the University of Illinois at Chicago (UIC) has designed and produced a large scale, high resolution head-tracked barrier-strip autostereoscopic display system that produces a VR immersive experience without requiring the user to wear any encumbrances. The resulting system, called Varrier, is a passive parallax barrier 35-panel tiled display that produces a wide field of view, head-tracked VR experience. This paper presents background material related to parallax barrier autostereoscopy, provides system configuration and construction details, examines Varrier interleaving algorithms used to produce the stereo images, introduces calibration and testing, and discusses the camera-based tracking subsystem.},
address = {New York, New York, USA},
author = {Sandin, Daniel J. and Margolis, Todd and Ge, Jinghua and Girado, Javier and Peterka, Tom and DeFanti, Thomas A.},
booktitle = {ACM SIGGRAPH 2005 Papers on - SIGGRAPH '05},
doi = {10.1145/1186822.1073279},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM SIGGRAPH 2005 Papers on - SIGGRAPH '05/2005/Sandin et al/Sandin et al. - 2005 - The Varrier TM autostereoscopic virtual reality display.pdf:pdf},
pages = {894},
publisher = {ACM Press},
title = {{The Varrier TM autostereoscopic virtual reality display}},
url = {http://dl.acm.org/citation.cfm?id=1073279 http://portal.acm.org/citation.cfm?doid=1186822.1073279},
year = {2005}
}
@article{Muczynski2013,
abstract = {The following paper provides information about eye-tracking techniques and methodology. It is focused on introducing eye movement metrics in human factor research in maritime domain, explaining basic methodo- logy and describing the types of data analysis, thus providing the background and guidelines for simple eye- tracking studies.},
author = {Muczyński, B and Gucma, M},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Scientific Journals Maritime \ldots/2013/Muczyński, Gucma/Muczyński, Gucma - 2013 - Application of eye-tracking techniques in human factor research in marine operations. Challenges and methodol.pdf:pdf},
journal = {Scientific Journals Maritime \ldots},
keywords = {data analy-,eye-tracking,gaze analysis,human factor research,maritime operations,sis,technique methodology},
mendeley-tags = {gaze analysis},
number = {1},
pages = {116--120},
title = {{Application of eye-tracking techniques in human factor research in marine operations. Challenges and methodology}},
url = {http://repository.am.szczecin.pl/handle/123456789/541},
volume = {36},
year = {2013}
}
@article{Rutherford2008,
abstract = {Typical adults use predictable scan patterns while observing faces. Some research suggests that people with autism spectrum disorders (ASD) instead attend to eyes less, and perhaps to the mouth more. The current experiment was designed as a direct measure of scan paths that people with and without ASD use when identifying simple and complex emotions. Participants saw photos of emotions and chose emotion labels. Scan paths were measured via infrared corneal reflectance. Both groups looked significantly longer at eyes than mouth, and neither overall looking time at eyes nor first fixations distinguished the groups. These results are contrary to suggestions that those with ASD attend preferentially to the mouth and avoid the eyes. Furthermore, there was no interaction between group and area of the face: the ratio of attention between eyes and mouth did not differ between the ASD and control groups. However, those with ASD looked at the eyes less than the control group when viewing complex emotions.},
author = {Rutherford, M D and Towns, Ashley M},
doi = {10.1007/s10803-007-0525-7},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of autism and developmental disorders/2008/Rutherford, Towns/Rutherford, Towns - 2008 - Scan path differences and similarities during emotion perception in those with and without autism spectrum di.pdf:pdf},
issn = {0162-3257},
journal = {Journal of autism and developmental disorders},
keywords = {Adult,Attention,Autistic Disorder,Autistic Disorder: diagnosis,Autistic Disorder: psychology,Emotions,Eye Movements,Facial Expression,Female,Fixation,Humans,Male,Ocular,Pattern Recognition,Reference Values,Visual,Young Adult,eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
month = aug,
number = {7},
pages = {1371--81},
pmid = {18297386},
title = {{Scan path differences and similarities during emotion perception in those with and without autism spectrum disorders.}},
url = {http://link.springer.com/article/10.1007/s10803-007-0525-7 http://www.ncbi.nlm.nih.gov/pubmed/18297386},
volume = {38},
year = {2008}
}
@article{Woolard2006,
author = {Woolard, a. and Laliodati, V. and Hedley, N. and Carrigan, N. and Hammond, M. and Julien, J.},
doi = {10.1109/ISMAR.2003.1240727},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings/2006/Woolard et al/Woolard et al. - 2006 - Case studies in application of augmented reality in future media production.pdf:pdf},
isbn = {0-7695-2006-5},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {294--295},
publisher = {IEEE Comput. Soc},
title = {{Case studies in application of augmented reality in future media production}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240727},
year = {2006}
}
@article{Yoo2013,
address = {New York, New York, USA},
author = {Yoo, Daisy and Zimmerman, John and Hirsch, Tad},
doi = {10.1145/2470654.2470714},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {409},
publisher = {ACM Press},
title = {{Probing bus stop for insights on transit co-design}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470714},
year = {2013}
}
@misc{Castro2001,
author = {Castro, Aldemar Ara\'{u}jo},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2001/Castro/Castro - 2001 - Revis\~{a}o Sistem\'{a}tica e Meta-an\'{a}lise.PDF:PDF},
keywords = {RBS},
mendeley-tags = {RBS},
title = {{Revis\~{a}o Sistem\'{a}tica e Meta-an\'{a}lise}},
url = {http://metodologia.org/},
urldate = {2013-11-22},
year = {2001}
}
@inproceedings{Tsuruta2007,
author = {Tsuruta, Seiya and Kawauchi, Yamato and Choi, Woong and Hachimura, Kozaburo},
booktitle = {17th International Conference on Artificial Reality and Telexistence (ICAT 2007)},
doi = {10.1109/ICAT.2007.37},
file = {:home/acmt/Dropbox/Documentos/Mendeley/17th International Conference on Artificial Reality and Telexistence (ICAT 2007)/2007/Tsuruta et al/Tsuruta et al. - 2007 - Real-Time Recognition of Body Motion for Virtual Dance Collaboration System.pdf:pdf},
isbn = {0-7695-3056-7},
month = nov,
pages = {23--30},
publisher = {IEEE},
title = {{Real-Time Recognition of Body Motion for Virtual Dance Collaboration System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4414612},
year = {2007}
}
@inproceedings{Russo2006,
abstract = {This chapter presents some of the main challenges related to the definition and construction of virtual environments for the oil exploration and production (E\&P) industry. Initially the main E\&P processes that may make good use of Virtual Reality technology are presented. Then, the main related challenges are discussed.},
address = {Bel\'{e}m},
author = {Russo, Enio Emanuel Ramos and Raposo, Alberto Barbosa and Fernando, Terrence and Gattass, Marcelo},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {313--318},
publisher = {SBC},
title = {{A Realidade Virtual na Ind\'{u}stria de Explora\c{c}\~{a}o e Produ\c{c}\~{a}o de Petr\'{o}leo}},
year = {2006}
}
@article{Wachs2011,
author = {Wachs, Juan Pablo and K\"{o}lsch, Mathias and Stern, Helman and Edan, Yael},
doi = {10.1145/1897816.1897838},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Communications of the ACM/2011/Wachs et al/Wachs et al. - 2011 - Vision-based hand-gesture applications.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = feb,
number = {2},
pages = {60},
title = {{Vision-based hand-gesture applications}},
url = {http://portal.acm.org/citation.cfm?doid=1897816.1897838},
volume = {54},
year = {2011}
}
@inproceedings{II2001,
abstract = {The Virtual-Reality Peripheral Network (VRPN) system provides a device-independent and network-transparent interface to virtual-reality peripherals. VRPN's application of factoring by function and of layering in the context of devices produces an interface that is novel and powerful. VRPN also integrates a wide range of known advanced techniques into a publicly-available system. These techniques benefit both direct VRPN users and those who implement other applications that make use of VR peripherals.},
address = {New York, New York, USA},
author = {Taylor, Russell M. and Hudson, Thomas C. and Seeger, Adam and Weber, Hans and Juliano, Jeffrey and Helser, Aron T.},
booktitle = {Proceedings of the ACM symposium on Virtual reality software and technology - VRST '01},
doi = {10.1145/505008.505019},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the ACM symposium on Virtual reality software and technology - VRST '01/2001/Taylor et al/Taylor et al. - 2001 - VRPN a device-independent, network-transparent VR peripheral system.pdf:pdf},
isbn = {1581134274},
pages = {55},
publisher = {ACM Press},
title = {{VRPN: a device-independent, network-transparent VR peripheral system}},
url = {http://dl.acm.org/citation.cfm?id=505019 http://portal.acm.org/citation.cfm?doid=505008.505019},
year = {2001}
}
@article{Okatani2005,
abstract = {This paper presents a method for calibrating a projector-camera system that consists of multiple projectors (or multiple poses of a single projector), a camera, and a planar screen. We consider the problem of estimating the homography between the screen and the image plane of the camera or the screen-camera homography, in the case where there is no prior knowledge regarding the screen surface that enables the direct computation of the homography. It is assumed that the pose of each projector is unknown while its internal geometry is known. Subsequently, it is shown that the screen-camera homography can be determined from only the images projected by the projectors and then obtained by the camera, up to a transformation with four degrees of freedom. This transformation corresponds to arbitrariness in choosing a two-dimensional coordinate system on the screen surface and when this coordinate system is chosen in some manner, the screen-camera homography as well as the unknown poses of the projectors can be uniquely determined. A noniterative algorithm is presented, which computes the homography from three or more images. Several experimental results on synthetic as well as real images are shown to demonstrate the effectiveness of the method.},
author = {Okatani, Takayuki and Deguchi, Koichiro},
doi = {10.1109/TPAMI.2005.235},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on pattern analysis and machine intelligence/2005/Okatani, Deguchi/Okatani, Deguchi - 2005 - Autocalibration of a projector-camera system.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Calibration,Computer-Assisted,Computer-Assisted: methods,Computer-Assisted: standards,Data Display,Image Enhancement,Image Enhancement: methods,Image Enhancement: standards,Image Interpretation,Imaging,Photography,Photography: methods,Three-Dimensional,Three-Dimensional: methods,User-Computer Interface,anamorphism},
mendeley-tags = {anamorphism},
month = dec,
number = {12},
pages = {1845--55},
pmid = {16355654},
title = {{Autocalibration of a projector-camera system.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1524979 http://www.ncbi.nlm.nih.gov/pubmed/16355654},
volume = {27},
year = {2005}
}
@article{Pang2013,
address = {New York, New York, USA},
author = {Pang, Carolyn E. and Neustaedter, Carman and Riecke, Bernhard E. and Oduor, Erick and Hillman, Serena},
doi = {10.1145/2470654.2466232},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Personal health informatics, families, social supp},
pages = {1759},
publisher = {ACM Press},
title = {{Technology preferences and routines for sharing health information during the treatment of a chronic illness}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466232},
year = {2013}
}
@article{Rusu2010,
author = {Rusu, RB},
journal = {KI-K\"{u}nstliche Intelligenz},
title = {{Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments}},
url = {http://link.springer.com/article/10.1007/s13218-010-0059-6},
year = {2010}
}
@misc{Khronos2012,
author = {Khronos},
title = {{WebGL Specification}},
url = {http://www.khronos.org/registry/webgl/specs/latest/},
urldate = {26/02/2012},
year = {2012}
}
@article{Liston2012,
annote = {- keyword coletado},
author = {Liston, Dorion B. and Krukowski, Anton E. and Stone, Leland S.},
doi = {10.1016/j.displa.2012.10.002},
issn = {01419382},
journal = {Displays},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = apr,
number = {2},
pages = {171--176},
title = {{Saccade detection during smooth tracking}},
url = {http://www.sciencedirect.com/science/article/pii/S0141938212000777 http://linkinghub.elsevier.com/retrieve/pii/S0141938212000777},
volume = {34},
year = {2013}
}
@inproceedings{Garstka2011,
abstract = {Simulation and modelling are key techniques used by computational scientists in many disciplines. Teaching students how to best use these methods is assisted by highly interactive, visual and motivational technology. Recent commodity pricing of depth ﬁeld cameras such as the Kinect makes an integrated approach to real time interactive teaching and learning of simulation and modelling feasible and exciting to students. We describe some of the techniques, software prototypes we have developed for teaching interactive simulation methods using devices such as the MS Kinect. We discuss examples including a discrete lattice model like the Ising model of a magnet, and continuous equation models such as ﬂuid ﬂow and speculate on the implications of ubiquitous depth-of-ﬁeld devices for highly interactive simulations for learning.},
address = {Colorado},
author = {Garstka, J and Peters, G},
booktitle = {8th IEEE Int. Workshop on Projector-Camera Sytems},
file = {:home/acmt/Dropbox/Documentos/Mendeley/8th IEEE Int. Workshop on Projector-Camera Sytems/2011/Garstka, Peters/Garstka, Peters - 2011 - View-dependent 3d projection using depth-image-based head tracking.pdf:pdf},
keywords = {Kinect,computational science education.,depth-of-ﬁeld,interative simulation,teaching technologies,visualisation technology},
pages = {52--58},
publisher = {IEEE Computer Society Press},
title = {{View-dependent 3d projection using depth-image-based head tracking}},
url = {http://lds62-112-144-233.my-simplyroot.de/wp-content/uploads/downloads/2011/12/0008.pdf},
year = {2011}
}
@article{Kitamura2002,
address = {New York, New York, USA},
author = {Kitamura, Yoshifumi and Ogata, Susumu and Kishino, Fumio},
doi = {10.1145/585771.585774},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the ACM symposium on Virtual reality software and technology - VRST '02/2002/Kitamura, Ogata, Kishino/Kitamura, Ogata, Kishino - 2002 - A manipulation environment of virtual and real objects using a magnetic metaphor.pdf:pdf},
isbn = {1581135300},
journal = {Proceedings of the ACM symposium on Virtual reality software and technology - VRST '02},
pages = {201},
publisher = {ACM Press},
title = {{A manipulation environment of virtual and real objects using a magnetic metaphor}},
url = {http://portal.acm.org/citation.cfm?doid=585740.585774},
year = {2002}
}
@article{Sundareswaran2006,
author = {Sundareswaran, V. and Wang, K. and Chen, S. and Behringer, R. and McGee, J. and Tam, C. and Zahorik, P.},
doi = {10.1109/ISMAR.2003.1240728},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings/2006/Sundareswaran et al/Sundareswaran et al. - 2006 - 3D audio augmented reality implementation and experiments.pdf:pdf},
isbn = {0-7695-2006-5},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {296--297},
publisher = {IEEE Comput. Soc},
title = {{3D audio augmented reality: implementation and experiments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240728},
year = {2006}
}
@article{Nadeau1999,
abstract = {VRML makes it easy to create virtual worlds. The article reviews VRML's syntax and features as well as its world construction and animation abilities. In 1995, VRML 1.0 began primarily as a shape description language. The following year, VRML 2.0 redefined the language, extending it to support sound, fog, backgrounds, animation, and user interaction. Today, the designers of VRML are in the midst of designing the next generation of VRML, code-named “VRML NG”. A first draft specification should be ready in early 1999, with a final specification and VRML browser implementations by the end of the year},
author = {Nadeau, D.R.},
doi = {10.1109/38.749119},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Computer Graphics and Applications/1999/Nadeau/Nadeau - 1999 - Building virtual worlds with VRML.pdf:pdf},
isbn = {0471165077},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {2},
pages = {18--29},
title = {{Building virtual worlds with VRML}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=749119},
volume = {19},
year = {1999}
}
@article{DiVerdi2006,
author = {{Di Verdi}, S. and Nurmi, D. and Hollerer, T.},
doi = {10.1109/ISMAR.2003.1240729},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings/2006/Di Verdi, Nurmi, Hollerer/Di Verdi, Nurmi, Hollerer - 2006 - ARWin - a desktop augmented reality Window Manager.pdf:pdf},
isbn = {0-7695-2006-5},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {298--299},
publisher = {IEEE Comput. Soc},
title = {{ARWin - a desktop augmented reality Window Manager}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240729},
year = {2006}
}
@article{Takahashi1983,
author = {Takahashi, Masahiro and Uemura, Takuya and Fujishiro, Takehisa},
doi = {10.1007/BF00453933},
issn = {0302-9530},
journal = {Archives of Oto-Rhino-Laryngology},
keywords = {gaze analysis,smooth pursuit},
mendeley-tags = {gaze analysis,smooth pursuit},
month = oct,
number = {3},
pages = {225--232},
title = {{Quantitative analysis of pursuit eye movements by unidirectional target motion}},
url = {http://link.springer.com/10.1007/BF00453933},
volume = {238},
year = {1983}
}
@article{Behrens2010,
abstract = {This analysis of time series of eye movements is a saccade-detection algorithm that is based on an earlier algorithm. It achieves substantial improvements by using an adaptive-threshold model instead of fixed thresholds and using the eye-movement acceleration signal. This has four advantages: (1) Adaptive thresholds are calculated automatically from the preceding acceleration data for detecting the beginning of a saccade, and thresholds are modified during the saccade. (2) The monotonicity of the position signal during the saccade, together with the acceleration with respect to the thresholds, is used to reliably determine the end of the saccade. (3) This allows differentiation between saccades following the main-sequence and non-main-sequence saccades. (4) Artifacts of various kinds can be detected and eliminated. The algorithm is demonstrated by applying it to human eye movement data (obtained by EOG) recorded during driving a car. A second demonstration of the algorithm detects microsleep episodes in eye movement data.},
annote = {- keyword coletado},
author = {Behrens, F and Mackeben, M and Schr\"{o}der-Preikschat, W},
doi = {10.3758/BRM.42.3.701},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2010/Behrens, Mackeben, Schr\"{o}der-Preikschat/Behrens, Mackeben, Schr\"{o}der-Preikschat - 2010 - An improved algorithm for automatic detection of saccades in eye movement data and for.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Adaptation,Algorithms,Automation,Automobile Driving,Automobile Driving: psychology,Calibration,Data Collection,Data Collection: methods,Data Interpretation,Electrooculography,Eye Tracking,Fixation,Humans,Ocular,Physiological,Physiological: physiology,Saccades,Saccades: physiology,Segmentation,Sleep,Sleep: physiology,Statistical},
mendeley-tags = {Eye Tracking,Segmentation},
month = aug,
number = {3},
pages = {701--8},
pmid = {20805592},
title = {{An improved algorithm for automatic detection of saccades in eye movement data and for calculating saccade parameters.}},
url = {http://link.springer.com/article/10.3758/BRM.42.3.701 http://www.ncbi.nlm.nih.gov/pubmed/20805592},
volume = {42},
year = {2010}
}
@inproceedings{Kumar2007,
abstract = {We present a practical technique for pointing and selection using a combination of eye gaze and keyboard triggers. EyePoint uses a two-step progressive refinement process fluidly stitched together in a look-press-look-release action, which makes it possible to compensate for the accuracy limitations of the current state-of-the-art eye gaze trackers. While research in gaze-based pointing has traditionally focused on disabled users, EyePoint makes gaze-based pointing effective and simple enough for even able-bodied users to use for their everyday computing tasks. As the cost of eye gaze tracking devices decreases, it will become possible for such gaze-based techniques to be used as a viable alternative for users who choose not to use a mouse depending on their abilities, tasks and preferences.},
address = {New York, New York, USA},
author = {Kumar, Manu and Paepcke, Andreas and Winograd, Terry},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '07},
doi = {10.1145/1240624.1240692},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '07/2007/Kumar, Paepcke, Winograd/Kumar, Paepcke, Winograd - 2007 - EyePoint practical pointing and selection using gaze and keyboard.pdf:pdf},
isbn = {9781595935939},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {421},
publisher = {ACM Press},
title = {{EyePoint: practical pointing and selection using gaze and keyboard}},
url = {http://dl.acm.org/citation.cfm?id=1240692 http://portal.acm.org/citation.cfm?doid=1240624.1240692},
year = {2007}
}
@inproceedings{Matsuda2011,
abstract = {Few previous eye-tracking studies incorporated the psychological notion of chunking, a meaningful cognitive unit of information. In the present work, we constructed fixation sequence lists nesting chunks, using isolated saccades as a delimiter. Chunks were extracted from the time-stamped records of the fixation sequences that were coded according to the 5x5 segments imposed on the display. The overwhelming majority chunks consisted of one or two fixations. Most within-chunk distances were zero or one, while the between-chunk distance was relatively dispersed with the modal distance at one, followed by zero. There was good agreement between the rankings of between- and within-chunk loops among the primary and secondary segments on the total number of loops. We found some indications about the layout effect, possible attributable to the presence of sub-area on the right most segments.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Matsuda, N and Takeuchi, H},
booktitle = {Proceedings of IADIS-IHCI},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of IADIS-IHCI/2011/Matsuda, Takeuchi/Matsuda, Takeuchi - 2011 - Cognitive Chunks Extracted From Eye-Tracking Records of Web Page Readers, Using Isolated Saccades as a Delimi.pdf:pdf},
keywords = {chunking,eye-tracking,fixations,gaze analysis,loops,saccades},
mendeley-tags = {gaze analysis},
pages = {169--176},
title = {{Cognitive Chunks Extracted From Eye-Tracking Records of Web Page Readers, Using Isolated Saccades as a Delimiter}},
url = {http://infoshako.sk.tsukuba.ac.jp/~mazda/dPapers/IHCI11.pdf},
year = {2011}
}
@article{Filho2011,
author = {Filho, Ronaldo Ferreira Dos Anjos and Teichrieb, Veronica and Kelner, Judith},
doi = {10.1109/SVR.2011.22},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Filho, Teichrieb, Kelner/Filho, Teichrieb, Kelner - 2011 - Hydra Virtual Environments Development Platform.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
keywords = {customization,development,fast,virtual environments development platform},
month = may,
pages = {102--111},
publisher = {Ieee},
title = {{Hydra: Virtual Environments Development Platform}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951841},
year = {2011}
}
@article{Marple-Horvat1996,
annote = {- keyword coletado},
author = {Marple-Horvat, DE and Gilbey, SL and Hollands, MA},
doi = {10.1016/0165-0270(96)00049-0},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Neuroscience Methods/1996/Marple-Horvat, Gilbey, Hollands/Marple-Horvat, Gilbey, Hollands - 1996 - A method for automatic identification of saccades from eye movement recordings.pdf:pdf},
issn = {01650270},
journal = {Journal of Neuroscience Methods},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = aug,
number = {2},
pages = {191--195},
title = {{A method for automatic identification of saccades from eye movement recordings}},
url = {http://www.sciencedirect.com/science/article/pii/0165027096000490 http://linkinghub.elsevier.com/retrieve/pii/0165027096000490},
volume = {67},
year = {1996}
}
@article{Wu2011,
author = {Wu, Qiong and Boulanger, Pierre},
doi = {10.1109/SVR.2011.35},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Wu, Boulanger/Wu, Boulanger - 2011 - Real-Time Estimation of Missing Markers for Reconstruction of Human Motion.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
month = may,
pages = {161--168},
publisher = {Ieee},
title = {{Real-Time Estimation of Missing Markers for Reconstruction of Human Motion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951848},
year = {2011}
}
@misc{XJTek2010a,
author = {XJTek},
title = {{AnyLogic}},
url = {http://www.xjtek.com},
year = {2010}
}
@phdthesis{Cao2009,
abstract = {The recent trend towards miniaturization of projection technology indicates that handheld devices will soon have the ability to project information onto any surface, thus enabling interaction and applications that are not possible with current handheld devices. This opens up an emerging research area on interaction using handheld projectors. With the ability to project information, a handheld device can surmount the limitations of its small internal screen by creating a larger information display on an external surface. By doing so, the display and interaction space can be expanded to cover almost an entire physical environment. Large amounts of data can be displayed, a rich interaction vocabulary can be supported, and multiple co-located people can share the viewing experience at the same time. In this thesis, I investigate research issues involved in the design, implementation, and user performance and behaviors regarding the usage of interactive handheld projectors. I create a handheld projector interaction prototype platform, and explore interaction concepts and techniques to support both single and multi-user interaction using one or several handheld projectors. I also empirically investigate the user behaviors related to handheld projector usage, in terms of both quantitative interaction performance with pointing tasks, and qualitative social behaviors that emerge from a game application. This work is a multi-faceted investigation on handheld projector interaction, and will provide the groundwork for future research and development of interactive handheld projectors.},
author = {Cao, X},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2009/Cao/Cao - 2009 - Handheld projector interaction.pdf:pdf},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {180},
school = {University of Toronto},
title = {{Handheld projector interaction}},
url = {http://www.cs.toronto.edu/~caox/XiangCao_PhD_thesis.pdf},
year = {2009}
}
@book{Zeigler2000,
author = {Zeigler, Bernard P. and Praehofer, Herbert and Kim, Tag Gon},
edition = {2},
isbn = {0127784551},
pages = {510},
publisher = {Academic Press},
title = {{Theory of Modeling and Simulation, Second Edition}},
year = {2000}
}
@article{Diaz2013a,
abstract = {Despite the growing popularity of virtual reality environments, few laboratories are equipped to investigate eye movements within these environments. This primer is intended to reduce the time and effort required to incorporate eye-tracking equipment into a virtual reality environment. We discuss issues related to the initial startup and provide algorithms necessary for basic analysis. Algorithms are provided for the calculation of gaze angle within a virtual world using a monocular eye-tracker in a three-dimensional environment. In addition, we provide algorithms for the calculation of the angular distance between the gaze and a relevant virtual object and for the identification of fixations, saccades, and pursuit eye movements. Finally, we provide tools that temporally synchronize gaze data and the visual stimulus and enable real-time assembly of a video-based record of the experiment using the Quicktime MOV format, available at http://sourceforge.net/p/utdvrlibraries/. This record contains the visual stimulus, the gaze cursor, and associated numerical data and can be used for data exportation, visual inspection, and validation of calculated gaze movements.},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Diaz, Gabriel and Cooper, Joseph and Kit, Dmitry and Hayhoe, Mary},
doi = {10.1167/13.12.5},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of vision/2013/Diaz et al/Diaz et al. - 2013 - Real-time recording and classification of eye movements in an immersive virtual environment.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {eye movements,gaze,gaze analysis,methods,virtual reality},
mendeley-tags = {gaze analysis},
month = jan,
number = {12},
pages = {1--14},
pmid = {24113087},
title = {{Real-time recording and classification of eye movements in an immersive virtual environment.}},
url = {http://w.journalofvision.org/content/13/12/5.short http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3795427&tool=pmcentrez&rendertype=abstract},
volume = {13},
year = {2013}
}
@article{LeMeunier2003,
author = {{Le Meunier}, L. and Mathy, F. and Fagret, D.},
doi = {10.1109/TNS.2003.818369},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Nuclear Science/2003/Le Meunier, Mathy, Fagret/Le Meunier, Mathy, Fagret - 2003 - Validation of a pet monte-carlo simulator with random events and dead time modeling.pdf:pdf},
isbn = {0780376366},
issn = {0018-9499},
journal = {IEEE Transactions on Nuclear Science},
month = oct,
number = {5},
pages = {1462--1468},
title = {{Validation of a pet monte-carlo simulator with random events and dead time modeling}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1236950},
volume = {50},
year = {2003}
}
@inproceedings{Dietz2004,
abstract = {Recent advances in computer video projection open up new possibilities for real-time interactive, persuasive displays. Now a display can continuously adapt to a viewer so as to maximize its effectiveness. However, by the very nature of persuasion, these displays must be both immersive and subtle. We have been working on technologies that support this application including multi-projector and implicit interaction techniques. These technologies have been used to create a series of interactive persuasive displays that are described.},
address = {New York, New York, USA},
author = {Dietz, Paul and Raskar, Ramesh and Booth, Shane and van Baar, Jeroen and Wittenburg, Kent and Knep, Brian},
booktitle = {Proceedings of the working conference on Advanced visual interfaces - AVI '04},
doi = {10.1145/989863.989898},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the working conference on Advanced visual interfaces - AVI '04/2004/Dietz et al/Dietz et al. - 2004 - Multi-projectors and implicit interaction in persuasive public displays.pdf:pdf},
isbn = {1581138679},
keywords = {anamorphism},
mendeley-tags = {anamorphism},
pages = {209},
publisher = {ACM Press},
title = {{Multi-projectors and implicit interaction in persuasive public displays}},
url = {http://dl.acm.org/citation.cfm?id=989898 http://portal.acm.org/citation.cfm?doid=989863.989898},
year = {2004}
}
@misc{Wikipedia2012,
author = {Wikipedia},
title = {{Teoria de Sistemas}},
url = {http://pt.wikipedia.org/wiki/Teoria_de_sistemas},
urldate = {10/02/2012},
year = {2012}
}
@book{Pullum2001,
author = {Pullum, Laura L.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2001/Pullum/Pullum - 2001 - Software Fault Tolerance Techniques and Implementation (Artech House Computing Library).pdf:pdf},
isbn = {1580531377},
pages = {360},
publisher = {Artech House},
title = {{Software Fault Tolerance Techniques and Implementation (Artech House Computing Library)}},
url = {http://www.amazon.com/Software-Tolerance-Techniques-Implementation- Computing/dp/1580531377},
year = {2001}
}
@article{Cassidy2013,
address = {New York, New York, USA},
author = {Cassidy, Brendan and Antani, Dipti Saurabh and Read, Janet C C.},
doi = {10.1145/2470654.2481315},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13/2013/Cassidy, Antani, Read/Cassidy, Antani, Read - 2013 - Using an open card sort with children to categorize games in a mobile phone application store.pdf:pdf},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
number = {2287},
pages = {2287},
publisher = {ACM Press},
title = {{Using an open card sort with children to categorize games in a mobile phone application store}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481315},
year = {2013}
}
@article{Tam2013,
address = {New York, New York, USA},
author = {Tam, Diane and MacLean, Karon E. and McGrenere, Joanna and Kuchenbecker, Katherine J.},
doi = {10.1145/2470654.2466223},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1689},
publisher = {ACM Press},
title = {{The design and field observation of a haptic notification system for timing awareness during oral presentations}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466223},
year = {2013}
}
@inproceedings{rbi,
abstract = {We are in the midst of an explosion of emerging human-computer interaction techniques that redefine our understanding of both computers and interaction. We propose the notion of Reality-Based Interaction (RBI) as a unifying concept that ties together a large subset of these emerging interaction styles. Based on this concept of RBI, we provide a framework that can be used to understand, compare, and relate current paths of recent HCI research as well as to analyze specific interaction designs. We believe that viewing interaction through the lens of RBI provides insights for design and uncovers gaps or opportunities for future research.},
address = {New York, New York, USA},
author = {Jacob, Robert J.K. and Girouard, Audrey and Hirshfield, Leanne M. and Horn, Michael S. and Shaer, Orit and Solovey, Erin Treacy and Zigelbaum, Jamie},
booktitle = {Proceeding of the twenty-sixth annual CHI conference on Human factors in computing systems - CHI '08},
doi = {10.1145/1357054.1357089},
isbn = {9781605580111},
keywords = {SBGames},
mendeley-tags = {SBGames},
organization = {ACM},
pages = {201},
publisher = {ACM Press},
title = {{Reality-based interaction: : a framework for post-WIMP interfaces}},
url = {http://dl.acm.org/citation.cfm?id=1357089 http://portal.acm.org/citation.cfm?doid=1357054.1357089},
year = {2008}
}
@article{Lanir2013,
address = {New York, New York, USA},
author = {Lanir, Joel and Stone, Ran and Cohen, Benjamin and Gurevich, Pavel},
doi = {10.1145/2470654.2481309},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13/2013/Lanir et al/Lanir et al. - 2013 - Ownership and control of point of view in remote assistance.pdf:pdf},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2243},
publisher = {ACM Press},
title = {{Ownership and control of point of view in remote assistance}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481309},
year = {2013}
}
@article{Savelsbergh2010,
abstract = {The aim of the study was to improve the estimation of the direction of the ball during penalty kicks by changing the visual search behaviour. Inexperienced goalkeepers divided into three groups moved a joystick in response to penalty kick situations presented on a large screen in pre-test, training and post-test phases of an experiment. The perceptual learning group practised with film clips that were edited to highlight relevant information in the run-up sequence of the kicker. The training group practised with the same film clips but without any highlights. A third group served as control and only performed the pre- and post-tests. The results showed that the visual search behaviour of the perceptual training group changed significantly and improved the initiation of the joystick movement. This initiation coincided with the timing of the most important visual information and led to significantly better performance than the other two groups (i.e. more penalties were stopped).},
author = {Savelsbergh, GJP and van Gastel, P.J. and van Kampen, P.M.},
journal = {International Journal of Sport Psychology},
pages = {24--41},
title = {{Anticipation of penalty kicking direction can be improved by directing attention through perceptual learning.}},
url = {http://www.cabdirect.org/abstracts/20113055154.html},
volume = {41},
year = {2010}
}
@inproceedings{Dow2013,
abstract = {Industry relies on higher education to prepare students for careers in innovation. Fulfilling this obligation is especially difficult in classroom settings, which often lack authentic interaction with the outside world. Online crowdsourcing has the potential to change this. Our research explores if and how online crowds can support student learning in the classroom. We explore how scalable, diverse, immediate (and often ambiguous and conflicting) input from online crowds affects student learning and motivation for project-based innovation work. In a pilot study with three classrooms, we explore interactions with the crowd at four key stages of the innovation process: needfinding, ideating, testing, and pitching. Students reported that online crowds helped them quickly and inexpensively identify needs and uncover issues with early-stage prototypes, although they favored face-to-face interactions for more contextual feed-back. We share early evidence and discuss implications for creating a socio-technical infrastructure to more effectively use crowdsourcing in education.},
address = {New York, New York, USA},
author = {Dow, Steven and Gerber, Elizabeth and Wong, Audris},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470686},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13/2013/Dow, Gerber, Wong/Dow, Gerber, Wong - 2013 - A pilot study of using crowds in the classroom.pdf:pdf},
isbn = {9781450318990},
pages = {227--236},
publisher = {ACM Press},
title = {{A pilot study of using crowds in the classroom}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470686},
year = {2013}
}
@article{Hacisalihzade1993,
abstract = {An interactive program package for the acquisition, analysis and plotting of human eye movements is introduced. It is shown that the programs described in this paper can be used by scientists in a wide range of disciplines in spite of their different data analysis requirements. An example dealing with smooth pursuit tracking is given.},
author = {Hacisalihzade, Selim S. and Allen, John S. and Stark, Lawrence W.},
doi = {10.1016/0169-2607(93)90056-Q},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Computer Methods and Programs in Biomedicine/1993/Hacisalihzade, Allen, Stark/Hacisalihzade, Allen, Stark - 1993 - Computer analysis of eye movements.pdf:pdf},
issn = {01692607},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
month = jul,
number = {3},
pages = {181--187},
title = {{Computer analysis of eye movements}},
url = {http://www.sciencedirect.com/science/article/pii/016926079390056Q http://linkinghub.elsevier.com/retrieve/pii/016926079390056Q},
volume = {40},
year = {1993}
}
@inproceedings{Legg2011,
abstract = {In this paper we investigate the challenge of 3D reconstruction from Snooker video data. We propose a system pipeline for intelligent filtering based on semantic importance in Snooker. The system can be divided into table detection and correction, followed by ball detection, classification and tracking. It is apparent from previous work that there are several challenges presented here. Firstly, previous methods tend to use a fixed top-down camera mounted above the table. To capture a full table view from this is challenging due to space limitations above the table. Instead, we capture video data from a tripod and correct the viewpoint through processing. Secondly, previous methods tend to simply detect the balls without considering other interfering objects such as player and cue. This becomes even more apparent when the player strikes the cue ball. Our intelligent filtering avoids such issues to give accurate 3D table reconstruction.},
author = {Legg, Philip A. and Parry, Matthew L. and Chung, David H. S. and Jiang, Richard M. and Morris, Adrian and Griffiths, Iwan W. and Marshall, David and Chen, Min},
booktitle = {2011 18th IEEE International Conference on Image Processing},
doi = {10.1109/ICIP.2011.6116122},
isbn = {978-1-4577-1303-3},
issn = {1522-4880},
keywords = {3D table reconstruction,Cameras,Computer vision,Conferences,Image color analysis,Image reconstruction,Snooker video,Three dimensional displays,ball classification,ball detection,ball tracking,filtering theory,fixed top-down camera,image analysis,image processing,intelligent filtering,morphological operations,object detection,object recognition,object tracking,reconstruction,semantic importance,single-view 3D reconstruction,table detection,video signal processing},
mendeley-tags = {reconstruction},
month = sep,
pages = {2385--2388},
publisher = {IEEE},
shorttitle = {Image Processing (ICIP), 2011 18th IEEE Internatio},
title = {{Intelligent filtering by semantic importance for single-view 3D reconstruction from Snooker video}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6116122},
year = {2011}
}
@article{Wang2009b,
author = {Wang, Chaoli and Yu, Hongfeng and Ma, Kwan-Liu},
doi = {10.1109/MCG.2009.104},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Computer Graphics and Applications/2009/Wang, Yu, Ma/Wang, Yu, Ma - 2009 - Application-Driven Compression for Visualizing Large-Scale Time-Varying Volume Data.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
keywords = {bit-wise texture,deferred filtering,importance-based compression,large data visualization,packing,time-varying data visualization},
pages = {1--19},
title = {{Application-Driven Compression for Visualizing Large-Scale Time-Varying Volume Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5232779},
volume = {D},
year = {2009}
}
@article{Nicholson2013,
address = {New York, New York, USA},
author = {Nicholson, James and Coventry, Lynne and Briggs, Pam},
doi = {10.1145/2470654.2470701},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {323--332},
publisher = {ACM Press},
title = {{Age-related performance issues for PIN and face-based authentication systems}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470701},
year = {2013}
}
@article{Gama2012,
author = {Gama, Alana Da and Chaves, Thiago and Figueiredo, Lucas and Teichrieb, Veronica},
doi = {10.1109/SVR.2012.15},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Gama et al/Gama et al. - 2012 - Guidance and Movement Correction Based on Therapeutics Movements for Motor Rehabilitation Support Systems.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {rehabilitation},
month = may,
pages = {191--200},
publisher = {Ieee},
title = {{Guidance and Movement Correction Based on Therapeutics Movements for Motor Rehabilitation Support Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297576},
year = {2012}
}
@article{Macvean2013,
address = {New York, New York, USA},
author = {Macvean, Andrew and Robertson, Judy},
doi = {10.1145/2470654.2466163},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1251},
publisher = {ACM Press},
title = {{Understanding exergame users' physical activity, motivation and behavior over time}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466163},
year = {2013}
}
@article{Tuch2013,
address = {New York, New York, USA},
author = {Tuch, Alexandre N. and Trusell, Rune and Hornb\ae k, Kasper},
doi = {10.1145/2470654.2481285},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2079},
publisher = {ACM Press},
title = {{Analyzing users' narratives to understand experience with interactive products}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481285},
year = {2013}
}
@book{Wolfe2009,
author = {Wolfe, Jeremy M. and Kluender, Keith R. and Levi, Dennis M. and Bartoshuk, Linda M. and Herz, Rachel S. and Klatzky, Roberta L. and Lederman, Susan J. and Merfeld, Daniel M.},
edition = {2},
isbn = {9780878939534},
keywords = {SBGames},
mendeley-tags = {SBGames},
pages = {450},
publisher = {Sinauer Associates},
title = {{Sensation \& Perception}},
url = {http://www.amazon.com/Sensation-Perception-second-Jeremy-Wolfe/dp/B006OMH66E},
year = {2009}
}
@article{Ashdown2003,
abstract = {We present a robust calibration method for aligning a camera-projector system to multiple planar surfaces. Un- like prior work, we do not recover the 3D scene geometry, nor do we assume knowledge of projector or camera posi- tion. We recover the mapping between the projector and each surface in three stages. In the first stage, we recover pla- nar homographies between the projector and the camera through each surface using an uncalibrated variant of struc- tured light. In the second stage, we express the homogra- phies from the camera to each display surface as the com- position of a metric rectification and a similarity transform. Our metric rectification algorithm uses several images of a rectangular object. In the third stage, we obtain the homo- graphies between the projector and each surface by combin- ing the results of the previous two stages. Inconsistencies appear along the boundaries between adjacent surfaces; we eliminate them through a process of iterative refinement. Standard techniques for recovering homographies from line correspondences and performing metric rectification are very sensitive to image processing outliers. We present robust algorithms for both tasks, and confirm that accuracy is maintained in the presence of outliers, both in simulation and on our interactive application that spans a table and ad- jacent wall. Our calibration method enables users to quickly set up multi-planar displays as they are needed, using any avail- able projector and camera. These displays could be applied to visualization tasks in medical imaging, architecture and geographic information systems.},
author = {Ashdown, M and Sukthankar, R},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Laboratories Tech Report HPL-2003-24/2003/Ashdown, Sukthankar/Ashdown, Sukthankar - 2003 - Robust calibration of camera-projector system for multi-planar displays.pdf:pdf},
journal = {Laboratories Tech Report HPL-2003-24},
keywords = {anamorphism},
mendeley-tags = {anamorphism},
title = {{Robust calibration of camera-projector system for multi-planar displays}},
url = {http://www.cse.iitb.ac.in/graphics/~rocky/website/mtp/papers/Ashdown-HPL-2003-24.pdf},
year = {2003}
}
@article{Warnock2013,
address = {New York, New York, USA},
author = {Warnock, David and McGee-Lennon, Marilyn and Brewster, Stephen},
doi = {10.1145/2470654.2466139},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Multimodal, Older Users, Notifications, Reminders},
pages = {1091},
publisher = {ACM Press},
title = {{Multiple notification modalities and older users}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466139},
year = {2013}
}
@article{Akpan2013,
address = {New York, New York, USA},
author = {Akpan, Imeh and Marshall, Paul and Bird, Jon and Harrison, Daniel},
doi = {10.1145/2470654.2481306},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2213},
publisher = {ACM Press},
title = {{Exploring the effects of space and place on engagement with an interactive installation}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481306},
year = {2013}
}
@inproceedings{Martinez2006,
abstract = {This paper describes the tasks carried out to develop a control tool using the changes detected in gaze, which are captured in the electrooculogram signal. The objective is to use these changes to control a user interface such as Dasher. A software tool for generating visual stimuli and acquiring the eye signal has been developed. These signals were later processed with a first derivative-based algorithm in order to detect the changes. The optimal parameters for the algorithm have been determined, and also the sensitivity (S>97\%) and the predictive positive value (+PV>90\%) of the detector have also been calculated. The preliminary results are promising, but a study with a greater number of individuals should be made to check the on-line performance with longer registers.},
address = {Tenerife, Canary Islands, Spain},
author = {Martinez, M and Soria, E and Magdalena, R},
booktitle = {Proceedings of the 6th WSEAS international conference on Applied computer science},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 6th WSEAS international conference on Applied computer science/2006/Martinez, Soria, Magdalena/Martinez, Soria, Magdalena - 2006 - Identification of saccades in Electrooculograms and their use as a control tool.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {291--295},
title = {{Identification of saccades in Electrooculograms and their use as a control tool}},
url = {http://www.wseas.us/e-library/conferences/2006tenerife/papers/541-212.pdf},
year = {2006}
}
@article{Davis2013,
address = {New York, New York, USA},
author = {Davis, Nicholas and Zook, Alexander and O'Neill, Brian and Headrick, Brandon and Riedl, Mark and Grosz, Ashton and Nitsche, Michael},
doi = {10.1145/2470654.2470747},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {651},
publisher = {ACM Press},
title = {{Creativity support for novice digital filmmaking}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470747},
year = {2013}
}
@techreport{Wangenheim2005,
address = {Florian\'{o}polis},
author = {Wangenheim, A.V. and Wagner, H.M.},
institution = {UFSC},
pages = {87--114},
title = {{Curvas Param\'{e}tricas}},
url = {http://www.inf.ufsc.br/~grafica/CG4.pdf},
year = {2005}
}
@article{Buchau2009,
author = {Buchau, Andr\'{e} and Rucker, Wolfgang M. and W\"{o}ssner, Uwe and Becker, Martin},
doi = {10.1108/03321640910959026},
file = {:home/acmt/Dropbox/Documentos/Mendeley/COMPEL The International Journal for Computation and Mathematics in Electrical and Electronic Engineering/2009/Buchau et al/Buchau et al. - 2009 - Augmented reality in teaching of electrodynamics.pdf:pdf},
issn = {0332-1649},
journal = {COMPEL: The International Journal for Computation and Mathematics in Electrical and Electronic Engineering},
number = {4},
pages = {948--963},
title = {{Augmented reality in teaching of electrodynamics}},
url = {http://www.emeraldinsight.com/10.1108/03321640910959026},
volume = {28},
year = {2009}
}
@inproceedings{Tan2000,
abstract = {Three efficient techniques are presented for modelling the shape of 3-D objects employing uncalibrated cameras, The first technique employing multiple video cameras is proposed for recovering the 3-D shape of non-rigid objects by factorization. The second technique employing pairs of facing cameras which surround a rigid object reconstructs an entire shape of the object by collecting all the projected feature points around the object into a single measurement matrix, which is factorized to yield an entire 3-D model of the object. The first and the second technique are combined to yield the third technique which not only models 3-D shape of a non-rigid object at each time but also recovers its deformation process during observation all at once. Satisfactory performance of these techniques are shown by the performed experiments. The present study is expected to contribute to various fields which have interests in 3-D shape/deformation recovery, modelling, and analysis, such as 3-D modelling of characters in video games, 3-D modelling of excavated objects in archaeology, human motion analysis in sports, dancing, or rehabilitation, etc},
author = {Tan, J.K. and Ishikawa, S.},
booktitle = {2000 TENCON Proceedings. Intelligent Systems and Technologies for the New Millennium (Cat. No.00CH37119)},
doi = {10.1109/TENCON.2000.893540},
isbn = {0-7803-6355-8},
keywords = {3-D shape,Cameras,Control engineering,Deformable models,Games,Humans,Motion analysis,Shape control,Shape measurement,Streaming media,Three dimensional displays,archaeology,dancing,deformation process,excavated objects,factorization,human motion analysis,image motion analysis,image reconstruction,matrix decomposition,measurement matrix,modelling,multiple video cameras,nonrigid objects,projected feature points,reconstruction,rehabilitation,sport,three-dimensional objects,uncalibrated cameras,video games,video signal processing},
mendeley-tags = {reconstruction},
pages = {59--63},
publisher = {IEEE},
shorttitle = {TENCON 2000. Proceedings},
title = {{On modelling three-dimensional objects by uncalibrated cameras}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=893540},
volume = {1},
year = {2000}
}
@incollection{Hayhoe2007,
address = {Amsterdam},
author = {Hayhoe, Mary and Droll, J. and Mennie, N.},
booktitle = {Eye Movements: A Window on Mind and Brain},
isbn = {9780080474915},
pages = {642--659},
publisher = {Elsevier Science},
title = {{Learning where to look}},
year = {2007}
}
@article{Schmidt2013,
address = {New York, New York, USA},
author = {Schmidt, Dominik and Sas, Corina and Gellersen, Hans},
doi = {10.1145/2470654.2466457},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Multi-touch surfaces,clipboards,copy-and-paste},
pages = {3335},
publisher = {ACM Press},
title = {{Personal clipboards for individual copy-and-paste on shared multi-user surfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466457},
year = {2013}
}
@article{Peffers2007,
author = {Peffers, K and Tuunanen, T},
file = {::},
journal = {\ldots  information systems},
title = {{A design science research methodology for information systems research}},
url = {http://mesharpe.metapress.com/index/276818W6PN4T5483.pdf},
year = {2007}
}
@article{Abernethy1996,
author = {Abernethy, B},
journal = {American Journal of sports medicine},
title = {{Training the visual-perceptual skills of athletes: Insights from the study of motor expertise}},
url = {http://cat.inist.fr/?aModele=afficheN&cpsidt=2517359},
year = {1996}
}
@article{Agapie2013,
address = {New York, New York, USA},
author = {Agapie, Elena and Golovchinsky, Gene and Qvarfordt, Pernilla},
doi = {10.1145/2470654.2481418},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {3,4,although users,documents in exploratory search,effective at retrieving useful,information needs,keyword queries are more,longer,queries are a familiar,research literature shows that,way of representing},
pages = {3019},
publisher = {ACM Press},
title = {{Leading people to longer queries}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481418},
year = {2013}
}
@inproceedings{Gu2011,
abstract = {This research demo describes the implementation of a mobile AR-supported educational course application, AR Circuit, which is designed to promote the effectiveness of remote collaborative learning for physics. The application employs the TCP/IP protocol enabling multiplayer functionality in a mobile AR environment. One phone acts as the server and the other acts as the client. The server phone will capture the video frames, process the video frame, and send the current frame and the markers transformation matrices to the client phone.},
address = {Singapore},
author = {Gu, Jian and Li, Nai and Duh, Henry Been-Lirn},
booktitle = {2011 IEEE Virtual Reality Conference},
doi = {10.1109/VR.2011.5759496},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 IEEE Virtual Reality Conference/2011/Gu, Li, Duh/Gu, Li, Duh - 2011 - A remote mobile collaborative AR system for learning in physics.pdf:pdf},
isbn = {978-1-4577-0039-2},
keywords = {Collaboration,Collaborative work,Games,Mobile communication,Mobile handsets,Physics,Servers},
mendeley-tags = {Collaboration,Collaborative work,Games,Mobile communication,Mobile handsets,Physics,Servers},
month = mar,
pages = {257--258},
publisher = {IEEE},
title = {{A remote mobile collaborative AR system for learning in physics}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5759496 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5759496},
year = {2011}
}
@book{Sanders2007,
author = {Sanders, William and Cumaranatunge, Chandima},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2007/Sanders, Cumaranatunge/Sanders, Cumaranatunge - 2007 - ActionScript 3.0 Design Patterns Object Oriented Programming Techniques (Adobe Developer Library).pdf:pdf},
isbn = {0596528469},
pages = {530},
publisher = {Adobe Developer Library},
title = {{ActionScript 3.0 Design Patterns: Object Oriented Programming Techniques (Adobe Developer Library)}},
url = {http://www.amazon.com/ActionScript-3-0-Design-Patterns-Programming/dp /0596528469},
year = {2007}
}
@article{Cesarelli2000,
abstract = {Visual acuity in congenital nystagmus has proven to be primarily related to the duration of foveation periods, during which the image of a target falls onto the fovea and eye velocity slows down. It was found that the longer the foveation time the higher the visual acuity. However, the cycle-to-cycle variability of the eye position and velocity during foveation periods also contribute to visual acuity. A high variability of the eye position during the foveations hinders a stable placement of the target image on the centralmost fovea and consequently decreases visual acuity. To investigate the relationship between different nystagmus features and visual acuity, infrared- oculographic and electro-oculographic eye position recordings of 20 patients affected by congenital nystagmus were analysed in different gaze positions. In several patients' recordings, a high variability of the eye position during foveations (i.e. greater than 0.5°) was detected. Correspondingly, low visual acuity was measured, in spite of sufficiently long foveation periods. The standard deviation of eye positions during foveation periods was used to measure this variability and it was found to be correlated to visual acuity, in conjunction with the mean duration of the foveation periods. On the basis of the data analysis, an exponential relationship is proposed to relate visual acuity and the standard deviation of the eye position during foveations.},
author = {Cesarelli, M and Bifulco, P and Loffredo, L and Bracale, M},
doi = {10.1023/A:1002702609387},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Documenta Ophthalmologica/2000/Cesarelli et al/Cesarelli et al. - 2000 - Relationship between visual acuity and eye position variability during foveations in congenital nystagmus.pdf:pdf},
journal = {Documenta Ophthalmologica},
keywords = {gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
number = {1},
pages = {59--72},
title = {{Relationship between visual acuity and eye position variability during foveations in congenital nystagmus}},
url = {http://link.springer.com/article/10.1023/A:1002702609387},
volume = {101},
year = {2000}
}
@inproceedings{Tien2012,
abstract = {For gaze-based training in surgery to be meaningful, the similarity between a trainee's gaze and an expert's gaze during performance of surgical tasks must be assessed. As it is difficult to record two people's gaze simultaneously, we produced task videos made by experts, and measured the amount of overlap between the gaze path of the expert surgeon and third-party observers while watching the videos. For this investigation, we developed a new, simple method for displaying and summarizing the proportion of time during which two observers' points of gaze on a common stimulus were separated by no more than a specified visual angle. In a study of single-observer self-review and multiple-observer initial view of a laparoscopic training task, we predicted that self-review would produce the highest overlap. We found relatively low overlap between watchers and the task performer; even operators with detailed task knowledge produce low overlap when watching their own videos. Conversely, there was a high overlap among all watchers. Results indicate that it may be insufficient to improve trainees' eye-hand coordination by just watching a video. Gaze training will need to be integrated with other teaching methods to be effective.},
address = {New York, New York, USA},
author = {Tien, Geoffrey and Atkins, M. Stella and Zheng, Bin},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12},
doi = {10.1145/2168556.2168623},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12/2012/Tien, Atkins, Zheng/Tien, Atkins, Zheng - 2012 - Measuring gaze overlap on videos between multiple observers.pdf:pdf},
isbn = {9781450312219},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
pages = {309},
publisher = {ACM Press},
title = {{Measuring gaze overlap on videos between multiple observers}},
url = {http://dl.acm.org/citation.cfm?id=2168623 http://dl.acm.org/citation.cfm?doid=2168556.2168623},
year = {2012}
}
@article{Hirooka2006,
abstract = {In this paper, we propose a novel virtual display system for a real object surface by using a video projector, so that the viewer can feel as if digital images are printed on the real surface with arbitrary shape. This system consists of an uncalibrated camera and video projector connected to a same PC and creates a virtual object by rendering 2D contents preserved beforehand onto a white object in a real world via a projector. For geometry registration between the rendered image and the object surface correctly, we regard the object surface as a set of a number of small rectangular regions and perform geometry registration by calculating homographies between the projector image plane and the each divided regions. By using such a homography-based method, we can avoid calibration of a camera and a projector that is necessary in a conventional method. In this system, we perform following two processes. First of all, we acquire the status of the object surface from images which capture the scene that color-coded checker patterns are projected on it and generate image rendered on it without distortion by calculating homographies. After once the projection image is generated, the rendered image can be updated if the object surface moves, or refined when it is stationary by observing the object surface. By this second process, the system always offers more accurate display. In implementation, we demonstrate our system in various conditions. This system enables it to project them as if it is printed on a real paper surface of a book. By using this system, we expect the realization of a virtual museum or other industrial application.},
author = {Hirooka, S and Saito, H},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEICE transactions on information and systems/2006/Hirooka, Saito/Hirooka, Saito - 2006 - Calibration free virtual display system using video projector onto real object surface.pdf:pdf},
journal = {IEICE transactions on information and systems},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
number = {1},
pages = {88--97},
title = {{Calibration free virtual display system using video projector onto real object surface}},
url = {http://search.ieice.org/bin/summary.php?id=e89-d_1_88},
volume = {E89-D},
year = {2006}
}
@article{Kamuro2009,
author = {Kamuro, Sho and Minamizawa, Kouta and Kawakami, Naoki and Tachi, Susumu},
doi = {10.1109/ROMAN.2009.5326217},
isbn = {978-1-4244-5081-7},
journal = {RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication},
month = sep,
pages = {436--441},
publisher = {Ieee},
title = {{Ungrounded kinesthetic pen for haptic interaction with virtual environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5326217},
year = {2009}
}
@article{Anthony2013,
address = {New York, New York, USA},
author = {Anthony, Lisa and Kim, YooJin and Findlater, Leah},
doi = {10.1145/2470654.2466158},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Touchscreen,YouTube,assistive technology,iPad,iPhone,motor impairments,physical disabilities},
pages = {1223},
publisher = {ACM Press},
title = {{Analyzing user-generated youtube videos to understand touchscreen use by people with motor impairments}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466158},
year = {2013}
}
@article{Schall1999,
abstract = {We review neural correlates of perceptual and motor decisions, examining whether the time they occupy explains the duration and variability of behavioral reaction times. The location of a salient target is identified through a spatiotemporal evolution of visually evoked activation throughout the visual system. Selection of the target leads to stochastic growth of movement-related activity toward a fixed threshold to generate the gaze shift. For a given image, the neural concomitants of perceptual processing occupy a relatively constant interval so that stochastic variability in response generation introduces additional variability in reaction times.},
author = {Schall, J D and Thompson, K G},
doi = {10.1146/annurev.neuro.22.1.241},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {Animals,Eye Movements,Eye Movements: physiology,Humans,Nervous System Physiological Phenomena,Ocular,Ocular: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Saccades,Saccades: physiology,Vision},
month = jan,
pages = {241--59},
pmid = {10202539},
title = {{Neural selection and control of visually guided eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10202539},
volume = {22},
year = {1999}
}
@phdthesis{Kasprowski2004a,
annote = {- cited by: 19- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Kasprowski, P},
booktitle = {Faculty of Automatic Control, Electronics and \ldots},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Faculty of Automatic Control, Electronics and \ldots/2004/Kasprowski/Kasprowski - 2004 - Human identification using eye movements.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {111},
school = {Silesian University of Technology},
title = {{Human identification using eye movements}},
url = {http://www.kasprowski.pl/phd/PhD_Kasprowski.pdf},
year = {2004}
}
@article{Goshtasby1993,
author = {Goshtasby, A},
doi = {10.1007/BF01539537},
file = {::},
journal = {International Journal of Computer Vision},
title = {{Design and recovery of 2-D and 3-D shapes using rational Gaussian curves and surfaces}},
url = {http://link.springer.com/article/10.1007/BF01539537},
year = {1993}
}
@article{Grasset2006,
author = {Grasset, R. and Gascuel, J.-D.},
doi = {10.1109/ISMAR.2003.1240731},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings/2006/Grasset, Gascuel/Grasset, Gascuel - 2006 - Interactive mediated reality.pdf:pdf},
isbn = {0-7695-2006-5},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {302--303},
publisher = {IEEE Comput. Soc},
title = {{Interactive mediated reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240731},
year = {2006}
}
@article{Foulsham2012,
abstract = {Complex stimuli and tasks elicit particular eye movement sequences. Previous research has focused on comparing between these scanpaths, particularly in memory and imagery research where it has been proposed that observers reproduce their eye movements when recognizing or imagining a stimulus. However, it is not clear whether scanpath similarity is related to memory performance and which particular aspects of the eye movements recur. We therefore compared eye movements in a picture memory task, using a recently proposed comparison method, MultiMatch, which quantifies scanpath similarity across multiple dimensions including shape and fixation duration. Scanpaths were more similar when the same participant’s eye movements were compared from two viewings of the same image than between different images or different participants viewing the same image. In addition, fixation durations were similar within a participant and this similarity was associated with memory performance.},
author = {Foulsham, T and Dewhurst, R and Nystr\"{o}m, M},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Eye Movement Research/2012/Foulsham, Dewhurst, Nystr\"{o}m/Foulsham, Dewhurst, Nystr\"{o}m - 2012 - Comparing scanpaths during scene encoding and recognition A multi-dimensional approach.pdf:pdf},
journal = {Journal of Eye Movement Research},
keywords = {eye tracking,memory,scanpath,scanpaths,scene perception,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
number = {3},
pages = {1--12},
title = {{Comparing scanpaths during scene encoding and recognition: A multi-dimensional approach}},
url = {http://dspace.ou.nl/handle/1820/4627},
volume = {5},
year = {2012}
}
@book{fitts1979human,
author = {Fitts, P M and Posner, M I},
publisher = {Greenwood Press},
series = {Basic Concepts in Psychology Series},
title = {{Human performance}},
url = {http://books.google.com.br/books?id=6msbAQAAMAAJ},
year = {1979}
}
@article{Sko2013,
address = {New York, New York, USA},
author = {Sko, Torben and Gardner, Henry J. and Martin, Michael},
doi = {10.1145/2470654.2481288},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Classification,Decision Trees,Games,Non-parametric,Online Studies,Parametric,Regression},
pages = {2103},
publisher = {ACM Press},
title = {{Non-parametric decision trees and online HCI}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481288},
year = {2013}
}
@inproceedings{Duchowski2010,
abstract = {The scanpath comparison framework based on string editing is revisited. The previous method of clustering based on k-means "preevaluation" is replaced by the mean shift algorithm followed by elliptical modeling via Principal Components Analysis. Ellipse intersection determines cluster overlap, with fast nearest-neighbor search provided by the kd-tree. Subsequent construction of Y - matrices and parsing diagrams is fully automated, obviating prior interactive steps. Empirical validation is performed via analysis of eye movements collected during a variant of the Trail Making Test, where participants were asked to visually connect alphanumeric targets (letters and numbers). The observed repetitive position similarity index matches previously published results, providing ongoing support for the scanpath theory (at least in this situation). Task dependence of eye movements may be indicated by the global position index, which differs considerably from past results based on free viewing.},
address = {New York, New York, USA},
author = {Duchowski, Andrew T. and Driver, Jason and Jolaoso, Sheriff and Tan, William and Ramey, Beverly N. and Robbins, Ami},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743719},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Duchowski et al/Duchowski et al. - 2010 - Scanpath comparison revisited.pdf:pdf},
isbn = {9781605589947},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
pages = {219},
publisher = {ACM Press},
title = {{Scanpath comparison revisited}},
url = {http://dl.acm.org/citation.cfm?id=1743719 http://portal.acm.org/citation.cfm?doid=1743666.1743719},
year = {2010}
}
@article{Anderson2013,
address = {New York, New York, USA},
author = {Anderson, Fraser and Bischof, Walter F.},
doi = {10.1145/2470654.2466143},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1109},
publisher = {ACM Press},
title = {{Learning and performance with gesture guides}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466143},
year = {2013}
}
@inproceedings{Eichner,
abstract = {Salvucci \& Goldberg (2000) described dispersion algorithms (I-DT) as a robust way for fixation detection in low-speed-eytrackers. Never the less Shic, Chawarska and Scassellati (2008) found that changing settings for thresholds in the used I-DT altered the relation between independent and dependent variables significantly. Furthermore they concluded that it could be more important to find the relationships between measured variables and threshold settings than finding the “right” settings for thresholds. This work used eye- tracking data from reading and motivational research (N=280; 50 Hz) to find answers to this question. The findings show that dispersion thresholds are not crucial for relationship changes in variables, but temporal thresholds are. The theoretical approach separates physiological from psychological temporal thresholds. Findings indicate that psychological thresholds can be applied to fixation data outside the I-DT parameters to find meaningful relationships.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Eichner, M},
booktitle = {EyeTrackBehavior Conference},
file = {:home/acmt/Dropbox/Documentos/Mendeley/EyeTrackBehavior Conference/2011/Eichner/Eichner - 2011 - Do thresholds in dispersion-algorithms matter in applied eye movement studies.pdf:pdf},
keywords = {Eye movements,dispersion algorithm,fixation detection,gaze analysis,reading,threshold},
mendeley-tags = {gaze analysis},
pages = {1--2},
title = {{Do thresholds in dispersion-algorithms matter in applied eye movement studies?}},
url = {http://www.uni-giessen.de/~g61314/eyetracking/EichnerM_Dispersion_Algs_Tobii_EyeTrackingBehavior2011_rev1.pdf},
year = {2011}
}
@incollection{Moreira,
address = {Bauru-SP},
author = {Moreira, Glaudiney and Junior, Mendon\c{c}a and Vidal, Creto Augusto and Jos\'{e}, Antonio and Leite, Melo and Allan, George and Gomes, Menezes},
booktitle = {Intera\c{c}\~{a}o em Realidade Virtual e Aumentada},
chapter = {3},
edition = {1},
editor = {Brega, Jos\'{e} Remo Ferreira and Kelner, Judith},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Intera\c{c}\~{a}o em Realidade Virtual e Aumentada/2010/Moreira et al/Moreira et al. - 2010 - Intera\c{c}\~{a}o e Comportamento de Entidades em Ambientes Virtuais.pdf:pdf},
pages = {35--53},
publisher = {Canal6},
title = {{Intera\c{c}\~{a}o e Comportamento de Entidades em Ambientes Virtuais}},
year = {2010}
}
@inproceedings{Damasceno2011,
abstract = {This work shows an Augmented Reality System produced according to the needs for assessing the extent or angular motion's range, which may be used in health areas where this information is needed to ponder about the physical measuring or motor rehabilitation.},
author = {Damasceno, Eduardo Filgueiras and Cardoso, Alexandre and {Lamounier Jr.}, Edgard Afonso},
booktitle = {2011 XIII Symposium on Virtual Reality},
doi = {10.1109/SVR.2011.37},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Damasceno, Cardoso, Lamounier Jr/Damasceno, Cardoso, Lamounier Jr. - 2011 - Augmented Biophotogrammetry.pdf:pdf},
isbn = {978-1-4577-0661-5},
keywords = {augmented reality,photogrammetric analysis},
month = may,
pages = {48--55},
publisher = {IEEE},
title = {{Augmented Biophotogrammetry}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5951834 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951834},
year = {2011}
}
@article{Price2013,
address = {New York, New York, USA},
author = {Price, Sara and Jewitt, Carey},
doi = {10.1145/2470654.2481402},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2907},
publisher = {ACM Press},
title = {{Interview approaches to researching embodiment}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481402},
year = {2013}
}
@article{Smolic20111958,
abstract = {This paper gives an end-to-end overview of 3D video and free viewpoint video, which can be regarded as advanced functionalities that expand the capabilities of a 2D video. Free viewpoint video can be understood as the functionality to freely navigate within real world visual scenes, as it is known for instance from virtual worlds in computer graphics. 3D video shall be understood as the functionality that provides the user with a 3D depth impression of the observed scene, which is also known as stereo video. In that sense as functionalities, 3D video and free viewpoint video are not mutually exclusive but can very well be combined in a single system. Research in this area combines computer graphics, computer vision and visual communications. It spans the whole media processing chain from capture to display and the design of systems has to take all parts into account, which is outlined in different sections of this paper giving an end-to-end view and mapping of this broad area. The conclusion is that the necessary technology including standard media formats for 3D video and free viewpoint video is available or will be available in the future, and that there is a clear demand from industry and user for such advanced types of visual media. As a consequence we are witnessing these days how such technology enters our everyday life},
annote = {Computer Analysis of Images and Patterns },
author = {Smolic, Aljoscha},
doi = {10.1016/j.patcog.2010.09.005},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Pattern Recognition/2011/Smolic/Smolic - 2011 - 3D video and free viewpoint video—From capture to display.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {3D video,3DTV,Free viewpoint video,Stereo video},
number = {9},
pages = {1958--1968},
title = {{3D video and free viewpoint video—From capture to display}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320310004450},
volume = {44},
year = {2011}
}
@article{Kato2006,
author = {Kato, H. and Naemura, T. and Harashima, H.},
doi = {10.1109/ISMAR.2003.1240733},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings/2006/Kato, Naemura, Harashima/Kato, Naemura, Harashima - 2006 - Graphic shadow augmenting your shadow on the floor.pdf:pdf},
isbn = {0-7695-2006-5},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {306--307},
publisher = {IEEE Comput. Soc},
title = {{Graphic shadow: augmenting your shadow on the floor}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240733},
year = {2006}
}
@inproceedings{Sun2008,
abstract = {This paper presents a novel algorithm for calibrating multiple casually placed projectors, via a single uncalibrated camera, to produce a "wallpaper" projection, which is equivalent to printing a single image onto a flat sheet of paper and pasting it to the screen. Based on a piecewise planar model, the method described here combines the advantages of global surface fitting and homographies to generate high accuracy geometric correction independent of the camera position and viewing angle. Experimental results validate the approach, achieving seamless displays with various multi-projector arrangements. The proposed calibration mechanism is applicable to both curved and planar screen surfaces and to single as well as multiple projector displays.},
address = {New York, New York, USA},
author = {Sun, Wei and Sobel, Irwin and Culbertson, Bruce and Gelb, Dan and Robinson, Ian},
booktitle = {Proceedings of the 5th ACM/IEEE International Workshop on Projector camera systems - PROCAMS '08},
doi = {10.1145/1394622.1394624},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 5th ACMIEEE International Workshop on Projector camera systems - PROCAMS '08/2008/Sun et al/Sun et al. - 2008 - Calibrating multi-projector cylindrically curved displays for wallpaper projection.pdf:pdf},
isbn = {9781605582726},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {1},
publisher = {ACM Press},
title = {{Calibrating multi-projector cylindrically curved displays for "wallpaper" projection}},
url = {http://dl.acm.org/citation.cfm?id=1394624 http://portal.acm.org/citation.cfm?doid=1394622.1394624},
year = {2008}
}
@article{Nilsson2009a,
abstract = {This paper presents results from a study on using an AR application to support collaborative command and control activities requiring the collaboration of three different civil service organisations. The technology is used to create a common ground between the organisations and allows the users to interact, plan resources and react to the ongoing events on a digital map. The AR application was developed and evaluated in a study where a forest fire scenario was simulated. Participants from the involved organisations acted as command and control teams in the simulated scenario and both quantitative and qualitative results were obtained. The results show that AR can become a useful tool in these situations in the future.},
author = {Nilsson, Susanna and Johansson, Bj\"{o}rn J E and J\"{o}nsson, Arne},
doi = {10.1145/1670252.1670291},
isbn = {9781605589121},
journal = {Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry VRCAI 09},
pages = {179--184},
publisher = {ACM Press},
series = {VRCAI '09},
title = {{A co-located collaborative augmented reality application}},
url = {http://portal.acm.org/citation.cfm?doid=1670252.1670291},
year = {2009}
}
@article{Miller2008,
abstract = {Team Cornell's Skynet is an autonomous Chevrolet Tahoe built to compete in the 2007 DARPA Urban Challenge. Skynet consists of many unique subsystems, including actuation and power distribution designed in-house, a tightly coupled attitude and position estimator, a novel obstacle detection and tracking system, a system for augmenting position estimates with vision-based detection algorithms, a path planner based on physical vehicle constraints and a nonlinear optimization routine, and a state-based reasoning agent for obeying traffic laws. This paper describes these subsystems in detail before discussing the system's overall performance in the National Qualifying Event and the Urban Challenge. Logged data recorded at the National Qualifying Event and the Urban Challenge are presented and used to analyze the system's performance. © 2008 Wiley Periodicals, Inc.},
author = {Miller, Isaac and Campbell, Mark and Huttenlocher, Dan and Kline, Frank-Robert and Nathan, Aaron and Lupashin, Sergei and Catlin, Jason and Schimpf, Brian and Moran, Pete and Zych, Noah and Garcia, Ephrahim and Kurdziel, Mike and Fujishima, Hikaru},
doi = {10.1002/rob.20253},
issn = {15564959},
journal = {Journal of Field Robotics},
month = aug,
number = {8},
pages = {493--527},
title = {{Team Cornell's Skynet: Robust perception and planning in an urban environment}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/rob.20253/abstract http://doi.wiley.com/10.1002/rob.20253},
volume = {25},
year = {2008}
}
@article{Andersen2013,
address = {New York, New York, USA},
author = {Andersen, Erik and Gulwani, Sumit and Popovic, Zoran},
doi = {10.1145/2470654.2470764},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {games, procedural content generation},
pages = {773},
publisher = {ACM Press},
title = {{A trace-based framework for analyzing and synthesizing educational progressions}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470764},
year = {2013}
}
@article{Xu2013,
address = {New York, New York, USA},
author = {Xu, Wenchang and Yu, Chun and Zhao, Songmin and Liu, Jie and Shi, Yuanchun},
doi = {10.1145/2470654.2481297},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2167},
publisher = {ACM Press},
title = {{Facilitating parallel web browsing through multiple-page view}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481297},
year = {2013}
}
@article{Tavakoli2013,
abstract = {In this article, a novel technique for fixation prediction and saccade generation will be introduced. The proposed model simulates saccadic eye movement to incorporate the underlying eye movement mechanism into saliency estimation. To this end, a simple salience measure is introduced. Afterwards, we derive a system model for saccade generation and apply it in a stochastic filtering framework. The proposed model will dynamically make a saccade toward the next predicted fixation and produces saliency maps. Evaluation of the proposed model is carried out in terms of saccade generation performance and saliency estimation. Saccade generation evaluation reveals that the proposed model outperforms inhibition of return. Also, experiments signify integration of eye movement mechanism into saliency estimation boosts the results. Finally, comparison with several saliency models shows the proposed model performs aptly.},
author = {{Rezazadegan Tavakoli}, Hamed and Rahtu, Esa and Heikkil\"{a}, Janne},
doi = {10.1016/j.imavis.2013.06.006},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = sep,
number = {9},
pages = {686--693},
title = {{Stochastic bottom–up fixation prediction and saccade generation}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885613001017 http://linkinghub.elsevier.com/retrieve/pii/S0262885613001017},
volume = {31},
year = {2013}
}
@article{Lans2011,
abstract = {We propose a new fully automated velocity-based algorithm to identify fixations from eye-movement records of both eyes, with individual-specific thresholds. The algorithm is based on robust minimum determinant covariance estimators (MDC) and control chart procedures, and is conceptually simple and computationally attractive. To determine fixations, it uses velocity thresholds based on the natural within-fixation variability of both eyes. It improves over existing approaches by automatically identifying fixation thresholds that are specific to (a) both eyes, (b) x- and y- directions, (c) tasks, and (d) individuals. We applied the proposed Binocular-Individual Threshold (BIT) algorithm to two large datasets collected on eye-trackers with different sampling frequencies, and compute descriptive statistics of fixations for larger samples of individuals across a variety of tasks, including reading, scene viewing, and search on supermarket shelves. Our analysis shows that there are considerable differences in the characteristics of fixations not only between these tasks, but also between individuals.},
annote = {- cited by: 9
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {van der Lans, Ralf and Wedel, Michel and Pieters, Rik},
doi = {10.3758/s13428-010-0031-2},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2011/van der Lans, Wedel, Pieters/van der Lans, Wedel, Pieters - 2011 - Defining eye-fixation sequences across individuals and tasks the Binocular-Individual Threshold (B.pdf:pdf;:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2011/van der Lans, Wedel, Pieters/van der Lans, Wedel, Pieters - 2011 - Defining eye-fixation sequences across individuals and tasks the Binocular-Individual Threshold (.epub:epub},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Adolescent,Algorithms,Binocular,Binocular: physiology,Blinking,Data Interpretation,Female,Fixation,Functional Laterality,Functional Laterality: physiology,Humans,Male,Ocular,Ocular: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Reading,Saccades,Sensory Thresholds,Sensory Thresholds: physiology,Statistical,Vision,Young Adult,gaze analysis},
mendeley-tags = {gaze analysis},
month = mar,
number = {1},
pages = {239--57},
pmid = {21287116},
title = {{Defining eye-fixation sequences across individuals and tasks: the Binocular-Individual Threshold (BIT) algorithm.}},
url = {http://link.springer.com/article/10.3758/s13428-010-0031-2 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3048294&tool=pmcentrez&rendertype=abstract},
volume = {43},
year = {2011}
}
@article{Kumar2013a,
address = {New York, New York, USA},
author = {Kumar, Neha and Parikh, Tapan S.},
doi = {10.1145/2470654.2481396},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2863},
publisher = {ACM Press},
title = {{Mobiles, music, and materiality}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481396},
year = {2013}
}
@article{Malsburg2011,
abstract = {Which repair strategy does the language system deploy when it gets garden-pathed, and what can regressive eye movements in reading tell us about reanalysis strategies? Several influential eye-tracking studies on syntactic reanalysis (Frazier and Rayner, 1982, Meseguer et al., 2002 and Mitchell et al., 2008) have addressed this question by examining scanpaths, i.e., sequential patterns of eye fixations. However, in the absence of a suitable method for analyzing scanpaths, these studies relied on simplified dependent measures that are arguably ambiguous and hard to interpret. We address the theoretical question of repair strategy by developing a new method that quantifies scanpath similarity. Our method reveals several distinct fixation strategies associated with reanalysis that went undetected in a previously published data set (Meseguer et al., 2002). One prevalent pattern suggests re-parsing of the sentence, a strategy that has been discussed in the literature (Frazier \& Rayner, 1982); however, readers differed tremendously in how they orchestrated the various fixation strategies. Our results suggest that the human parsing system non-deterministically adopts different strategies when confronted with the disambiguating material in garden-path sentences.},
author = {von der Malsburg, Titus and Vasishth, Shravan},
doi = {10.1016/j.jml.2011.02.004},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Memory and Language/2011/von der Malsburg, Vasishth/von der Malsburg, Vasishth - 2011 - What is the scanpath signature of syntactic reanalysis.pdf:pdf},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
month = aug,
number = {2},
pages = {109--127},
title = {{What is the scanpath signature of syntactic reanalysis?}},
url = {http://www.sciencedirect.com/science/article/pii/S0749596X11000179 http://linkinghub.elsevier.com/retrieve/pii/S0749596X11000179},
volume = {65},
year = {2011}
}
@article{Besl1992,
author = {Besl, PJ and McKay, ND},
file = {::},
journal = {Robotics-DL tentative},
title = {{Method for registration of 3-D shapes}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=981454},
year = {1992}
}
@article{Chin2006,
abstract = {This paper outlines the development and initial testing of a new hybrid computer cursor control system based on Eye Gaze Tracking (EGT) and electromyogram (EMG) processing for hands-free control of the computer cursor. The ultimate goal of the system is to provide an efficient computer interaction mechanism for individuals with severe motor disabilities (or specialized operators whose hands are committed to other tasks, such as surgeons, pilots, etc.) The paper emphasizes the enhancements that have been made on different areas of the architecture, with respect to a previous prototype developed by our group, and demonstrates the performance improvement verified for some of the enhancements.},
annote = {- cited by: 6
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Chin, Craig A and Barreto, Armando},
doi = {10.1109/IEMBS.2006.259595},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Conference proceedings ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engine. Conference/2006/Chin, Barreto/Chin, Barreto - 2006 - Enhanced hybrid electromyogramEye Gaze Tracking cursor control system for hands-free computer interaction.pdf:pdf},
issn = {1557-170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Algorithms,Computer Peripherals,Data Display,Electromyography,Electromyography: methods,Eye Movement Measurements,Eye Movements,Eye Movements: physiology,Facial Muscles,Facial Muscles: physiology,Fixation,Humans,Ocular,Ocular: physiology,User-Computer Interface,gaze analysis},
mendeley-tags = {gaze analysis},
month = jan,
pages = {2296--9},
pmid = {17946102},
title = {{Enhanced hybrid electromyogram/Eye Gaze Tracking cursor control system for hands-free computer interaction.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4462251 http://www.ncbi.nlm.nih.gov/pubmed/17946102},
volume = {1},
year = {2006}
}
@inproceedings{Ortega2013,
abstract = {This paper presents IUCA (Interaction Using Camera Animations), a new interaction technique for 3D objects manipulation. IUCA allows efficient interaction in a full-resolution perspective view by integrating transients animated transitions to orthographic views into the manipulation task. This provides an interaction in context, with precise object positioning and alignment. An evaluation of the technique shows that, compared to the classical configurations, IUCA allows to reduce pointing time by 14\% on average. Testing with professional 3D designers and novice users indicate that IUCA is easy to use and to learn; and that users feel comfortable with it.},
address = {New York, New York, USA},
author = {Ortega, Michael},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470681},
isbn = {9781450318990},
pages = {193--196},
publisher = {ACM Press},
title = {{3D object position using automatic viewpoint transitions}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470681},
year = {2013}
}
@article{Chung1999,
author = {Chung, Kyung H. and Shewchuk, John P. and Williges, Robert C.},
doi = {10.1002/(SICI)1520-6564(199923)9:4<331::AID-HFM1>3.0.CO;2-3},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Human Factors and Ergonomics in Manufacturing/1999/Chung, Shewchuk, Williges/Chung, Shewchuk, Williges - 1999 - An application of augmented reality to thickness inspection.pdf:pdf},
issn = {1090-8471},
journal = {Human Factors and Ergonomics in Manufacturing},
number = {4},
pages = {331--342},
title = {{An application of augmented reality to thickness inspection}},
url = {http://doi.wiley.com/10.1002/%28SICI%291520-6564%28199923%299%3A4%3C331%3A%3AAID-HFM1%3E3.0.CO%3B2-3},
volume = {9},
year = {1999}
}
@article{Georgel2009,
author = {Georgel, Pierre and Schroeder, Pierre and Navab, Nassir},
doi = {10.1109/MCG.2009.110},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Computer Graphics and Applications/2009/Georgel, Schroeder, Navab/Georgel, Schroeder, Navab - 2009 - Navigation Tools for Augmented CAD Viewing.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
pages = {1--8},
title = {{Navigation Tools for Augmented CAD Viewing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5288521},
year = {2009}
}
@article{Kumar2013b,
address = {New York, New York, USA},
author = {Kumar, Neha and Rangaswamy, Nimmi},
doi = {10.1145/2470654.2466263},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1989},
publisher = {ACM Press},
title = {{The mobile media actor-network in urban India}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466263},
year = {2013}
}
@article{Holone2013,
address = {New York, New York, USA},
author = {Holone, Harald and Herstad, Jo},
doi = {10.1145/2470654.2481401},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2903},
publisher = {ACM Press},
title = {{Three tensions in participatory design for inclusion}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481401},
year = {2013}
}
@article{Juhola,
author = {Juhola, M and Aalto, H and Joutsijoki, H and Hirvonen, TP},
file = {:home/acmt/Dropbox/Documentos/Mendeley/downloads.hindawi.com/Unknown/Juhola et al/Juhola et al. - Unknown - The Classification of Valid and Invalid Beats of Three-Dimensional Nystagmus Eye Movement Signals Using Machin.pdf:pdf},
journal = {downloads.hindawi.com},
keywords = {gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
title = {{The Classification of Valid and Invalid Beats of Three-Dimensional Nystagmus Eye Movement Signals Using Machine Learning Methods}},
url = {http://downloads.hindawi.com/journals/aans/aip/972412.pdf}
}
@article{Wallace2013,
address = {New York, New York, USA},
author = {Wallace, Jayne and Wright, Peter C. and McCarthy, John and Green, David Philip and Thomas, James and Olivier, Patrick},
doi = {10.1145/2468356.2479560},
file = {:home/acmt/Dropbox/Documentos/Mendeley/CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13/2013/Wallace et al/Wallace et al. - 2013 - A design-led inquiry into personhood in dementia.pdf:pdf},
isbn = {9781450319522},
journal = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
pages = {2883},
publisher = {ACM Press},
title = {{A design-led inquiry into personhood in dementia}},
url = {http://dl.acm.org/citation.cfm?doid=2468356.2479560},
year = {2013}
}
@inproceedings{Hayashi2007,
author = {Hayashi, Kenichi and Kato, Hirokazu and Nishida, Shogo},
booktitle = {17th International Conference on Artificial Reality and Telexistence (ICAT 2007)},
doi = {10.1109/ICAT.2007.45},
file = {:home/acmt/Dropbox/Documentos/Mendeley/17th International Conference on Artificial Reality and Telexistence (ICAT 2007)/2007/Hayashi, Kato, Nishida/Hayashi, Kato, Nishida - 2007 - A New Framework for Tracking by Maintaining Multiple Global Hypotheses for Augmented Reality.pdf:pdf},
isbn = {0-7695-3056-7},
month = nov,
pages = {15--22},
publisher = {IEEE},
title = {{A New Framework for Tracking by Maintaining Multiple Global Hypotheses for Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4414611},
year = {2007}
}
@article{Pohl2013,
address = {New York, New York, USA},
author = {Pohl, Norman and Hodges, Steve and Helmes, John and Villar, Nicolas and Paek, Tim},
doi = {10.1145/2470654.2466194},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13/2013/Pohl et al/Pohl et al. - 2013 - An interactive belt-worn badge with a retractable string-based input mechanism.pdf:pdf},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1465},
publisher = {ACM Press},
title = {{An interactive belt-worn badge with a retractable string-based input mechanism}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466194},
year = {2013}
}
@book{Filho2008,
author = {Filho, Paulo Jos\'{e} Freitas},
edition = {2},
isbn = {9788575022283},
pages = {372},
publisher = {Visual Books},
title = {{Introdu\c{c}\~{a}o a Modelagem e Simula\c{c}\~{a}o de Sistemas com Aplica\c{c}\~{o}es Arena}},
year = {2008}
}
@misc{Ambierra2013,
author = {Ambierra},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{Ambierra irrEdit}},
url = {http://www.ambiera.com/irredit/},
urldate = {2013/07/26},
year = {2013}
}
@article{Oulasvirta2013,
address = {New York, New York, USA},
author = {Oulasvirta, Antti and Roos, Teemu and Modig, Arttu and Lepp\"{a}nen, Laura},
doi = {10.1145/2470654.2466169},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1289},
publisher = {ACM Press},
title = {{Information capacity of full-body movements}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466169},
year = {2013}
}
@article{Privitera2000,
author = {Privitera, CM and Stark, LW},
doi = {10.1109/34.877520},
file = {::},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
number = {9},
pages = {970--982},
title = {{Algorithms for defining visual regions-of-interest: comparison with eye fixations}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=877520 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=877520},
volume = {22},
year = {2000}
}
@inproceedings{Kirner2006,
address = {Bel\'{e}m},
author = {Kirner, Claudio and Tori, Romero},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {22--38},
publisher = {SBC},
title = {{Fundamentos de Realidade Aumentada}},
year = {2006}
}
@inproceedings{Shi2013,
abstract = {Although privacy problems in Social Network Sites (SNS) have become more salient than ever in recent years, interpersonal privacy issues in SNS remain understudied. This study aims to generate insights in understanding users' interpersonal privacy concerns by expounding interpersonal privacy boundaries in SNS. Through a case analysis of Friendship Pages on Facebook, this paper identifies users' interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity, as well as the tensions that occur within and cross these informational norms. This paper concludes with a discussion of design implications and future research.},
address = {New York, New York, USA},
author = {Shi, Pan and Xu, Heng and Chen, Yunan},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470660},
isbn = {9781450318990},
keywords = {a growing body of,and their behaviors on,co-owners of shared,e,has studied the,i,inability to monitor friends,information,privacy research in hci,sns},
pages = {35--38},
publisher = {ACM Press},
title = {{Using contextual integrity to examine interpersonal information boundary on social network sites}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470660},
year = {2013}
}
@inproceedings{Gibson2013,
abstract = {New mothers can experience social exclusion, particularly during the early weeks when infants are solely dependent on their mothers. We used ethnographic methods to investigate whether technology plays a role in supporting new mothers. Our research identified two core themes: (1) the need to improve confidence as a mother; and (2) the need to be more than ‘just’ a mother. We reflect on these findings both in terms of those interested in designing applications and services for motherhood and also the wider CHI community.},
address = {New York, New York, USA},
author = {Gibson, Lorna and Hanson, Vicki L},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470700},
isbn = {9781450318990},
pages = {313--322},
publisher = {ACM Press},
title = {{Digital motherhood: how does technology help new mothers?}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470700},
year = {2013}
}
@article{Chaves2012,
author = {Chaves, Thiago and Figueiredo, Lucas and Gama, Alana Da and Araujo, Cristiano De and Teichrieb, Veronica},
doi = {10.1109/SVR.2012.16},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Chaves et al/Chaves et al. - 2012 - Human Body Motion and Gestures Recognition Based on Checkpoints.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {body tracking,human motion analysis,rgb-d},
month = may,
pages = {271--278},
publisher = {Ieee},
title = {{Human Body Motion and Gestures Recognition Based on Checkpoints}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297539},
year = {2012}
}
@book{Anton2010,
author = {Anton, Howard and Rorres, Chris},
isbn = {0470432055},
pages = {773},
publisher = {Wiley},
title = {{Elementary Linear Algebra: Applications Version}},
url = {http://www.amazon.com/Elementary-Linear-Algebra-Applications-Version/dp/0470432055},
year = {2010}
}
@misc{Ulloa2010,
author = {Ulloa, Carlos and Grden, John and Knip, Tim and Zupko, Andy},
booktitle = {Papervision3D},
title = {{Papervision3D}},
url = {http://blog.papervision3d.org/},
urldate = {04/10/2011},
year = {2010}
}
@inproceedings{Jacobs2013,
abstract = {A study of an interactive artwork shows how artists engaged the public with scientific climate change data. The artwork visualised live environmental data collected from remote trees, alongside both historical and forecast global CO2 data. Visitors also took part in a mobile sensing experience in a nearby forest. Our study draws on the perspectives of the artists, visitors and a climate scientist to reveal how the work was designed and experienced. We show that the artists adopted a distinct approach that fostered an emotional engagement with data rather than an informative or persuasive one. We chart the performative strategies they used to achieve this including sensory engagement with data, a temporal structure that balanced liveness with slowness, and the juxtaposition of different treatments of the data to enable interpretation and dialogue.},
address = {New York, New York, USA},
author = {Jacobs, Rachel and Benford, Steve and Selby, Mark and Golembewski, Michael and Price, Dominic and Giannachi, Gabriella},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470673},
isbn = {9781450318990},
pages = {129--138},
publisher = {ACM Press},
title = {{A conversation between trees: what data feels like in the forest}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470673},
year = {2013}
}
@inproceedings{Radinsky2004,
abstract = {An improved algorithm for classification of nystagmus was designed allowing the sorting of response segments even in severely non-linear patients and subjects with abnormally large phase shifts. The algorithm employs a model-based approach that was developed by Rey and Galiana. The improved classification algorithm consists of two essential stages. In the first stage the eye velocity response is classified to obtain initial estimates of the slow phase eye velocity intervals. In the second stage, the slow phase estimates are used to identify a response phase shift and nonlinearity, and compensate for their effects. Multiple tests on simulated data and experimental data obtained from clinical subjects are presented. The results of the tests demonstrate that the algorithm is able to analyze the patient data with a high accuracy even in the presence of noise, eye-blinks and other artifacts.},
address = {San Francisco, CA},
author = {Radinsky, Iliya and Galiana, Henrietta L},
booktitle = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
doi = {10.1109/IEMBS.2004.1403212},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Conference proceedings ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engine. Conference/2004/Radinsky, Galiana/Radinsky, Galiana - 2004 - Improved algorithm for classification of ocular nystagmus.pdf:pdf},
issn = {1557-170X},
keywords = {gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
month = jan,
pages = {534--537},
pmid = {17271731},
title = {{Improved algorithm for classification of ocular nystagmus.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1403212 http://www.ncbi.nlm.nih.gov/pubmed/17271731},
volume = {1},
year = {2004}
}
@inproceedings{Divjak2008,
address = {Leeds, UK},
author = {Divjak, M and Bischof, H},
booktitle = {First International Workshop on Tracking Humans for the Evaluation of their Motion in Image Sequences - THEMIS},
file = {:home/acmt/Dropbox/Documentos/Mendeley/First International Workshop on Tracking Humans for the Evaluation of their Motion in Image Sequences - THEMIS/2008/Divjak, Bischof/Divjak, Bischof - 2008 - Real-time video-based eye blink analysis for detection of low blink-rate during computer use.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {99--107},
title = {{Real-time video-based eye blink analysis for detection of low blink-rate during computer use}},
url = {http://iselab.cvc.uab.es/themis2008/ProceedingsTHEMIS2008.pdf#page=107},
year = {2008}
}
@article{Trappenberg2001,
abstract = {Significant advances in cognitive neuroscience can be achieved by combining techniques used to measure behavior and brain activity with neural modeling. Here we apply this approach to the initiation of rapid eye movements (saccades), which are used to redirect the visual axis to targets of interest. It is well known that the superior colliculus (SC) in the midbrain plays a major role in generating saccadic eye movements, and physiological studies have provided important knowledge of the activity pattern of neurons in this structure. Based on the observation that the SC receives localized sensory (exogenous) and voluntary (endogenous) inputs, our model assumes that this information is integrated by dynamic competition across local collicular interactions. The model accounts well for the effects upon saccadic reaction time (SRT) due to removal of fixation, the presence of distractors, execution of pro-versus antisaccades, and variation in target probability, and suggests a possible mechanism for the generation of express saccades. In each of these cases, the activity patterns of “neurons” within the model closely resemble actual cell behavior in the intermediate layer of the SC. The interaction structure we employ is instrumental for producing a physiologically faithful model and results in new insights and hypotheses regarding the neural mechanisms underlying saccade initiation.},
author = {Trappenberg, Thomas P. and Dorris, Michael C. and Munoz, Douglas P. and Klein, Raymond M.},
doi = {10.1162/089892901564306},
file = {::},
issn = {0898-929X},
journal = {Journal of Cognitive Neuroscience},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = feb,
number = {2},
pages = {256--271},
title = {{A Model of Saccade Initiation Based on the Competitive Integration of Exogenous and Endogenous Signals in the Superior Colliculus}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089892901564306},
volume = {13},
year = {2001}
}
@inproceedings{Park2010,
abstract = {This paper presents a simple and active calibration technique of camera-projector systems based on planar homography. From the camera image of a planar calibration pattern, we generate a projector image of the pattern through the homography between the camera and the projector. To determine the coordinates of the pattern corners from the view of the projector, we actively project a corner marker from the projector to align the marker with the printed pattern corners. Calibration is done in two steps. First, four outer corners of the pattern are identified. Second, all other inner corners are identified. The pattern image from the projector is then used to calibrate the projector. Experimental results of two types of camera-projector systems show that the projection errors of both camera and projector are less than 1 pixel.},
author = {Park, Soon-Yong and Park, Go Gwang},
booktitle = {2010 20th International Conference on Pattern Recognition},
doi = {10.1109/ICPR.2010.87},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 20th International Conference on Pattern Recognition/2010/Park, Park/Park, Park - 2010 - Active Calibration of Camera-Projector Systems Based on Planar Homography.pdf:pdf},
isbn = {978-1-4244-7542-1},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
month = aug,
pages = {320--323},
publisher = {IEEE},
title = {{Active Calibration of Camera-Projector Systems Based on Planar Homography}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597796 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5597796},
year = {2010}
}
@inproceedings{Hradis2012,
abstract = {This paper discusses estimation of active speaker in multi-party video-mediated communication from gaze data of one of the participants. In the explored settings, we predict voice activity of participants in one room based on gaze recordings of a single participant in another room. The two rooms were connected by high definition, low delay audio and video links and the participants engaged in different activities ranging from casual discussion to simple problem-solving games. We treat the task as a classification problem. We evaluate several types of features and parameter settings in the context of Support Vector Machine classification framework. The results show that using the proposed approach vocal activity of a speaker can be correctly predicted in 89 \% of the time for which the gaze data are available.},
address = {New York, New York, USA},
author = {Hradis, Michal and Eivazi, Shahram and Bednarik, Roman},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12},
doi = {10.1145/2168556.2168628},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12/2012/Hradis, Eivazi, Bednarik/Hradis, Eivazi, Bednarik - 2012 - Voice activity detection from gaze in video mediated communication.pdf:pdf},
isbn = {9781450312219},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {329},
publisher = {ACM Press},
title = {{Voice activity detection from gaze in video mediated communication}},
url = {http://dl.acm.org/citation.cfm?id=2168628 http://dl.acm.org/citation.cfm?doid=2168556.2168628},
year = {2012}
}
@misc{Wikipedia2013,
author = {Wikipedia},
keywords = {rbs},
mendeley-tags = {rbs},
title = {{Systematic Review}},
url = {http://en.wikipedia.org/wiki/Systematic_review},
urldate = {22-11-2013},
year = {2013}
}
@article{Roberto2011,
author = {Roberto, Rafael and Freitas, Daniel and Lima, Jo\~{a}o Paulo and Teichrieb, Veronica and Kelner, Judith},
doi = {10.1109/SVR.2011.19},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Roberto et al/Roberto et al. - 2011 - ARBlocks A Concept for a Dynamic Blocks Platform for Educational Activities.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
keywords = {-augmented reality,design for children,education,face,tangible user inter-},
month = may,
pages = {28--37},
publisher = {Ieee},
title = {{ARBlocks: A Concept for a Dynamic Blocks Platform for Educational Activities}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951832},
year = {2011}
}
@inproceedings{Fuks2003,
address = {Salvador-BA},
author = {Fuks, Hugo and Raposo, Alberto Barbosa and Gerosa, Marco Aur\'{e}lio},
booktitle = {IX Simp\'{o}sio Brasileiro de Sistemas Multim\'{\i}dia e Web - WebMidia},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IX Simp\'{o}sio Brasileiro de Sistemas Multim\'{\i}dia e Web - WebMidia/2003/Fuks, Raposo, Gerosa/Fuks, Raposo, Gerosa - 2003 - Do Modelo de Colabora\c{c}\~{a}o 3C \`{a} Engenharia de Groupware.pdf:pdf},
pages = {445--452},
title = {{Do Modelo de Colabora\c{c}\~{a}o 3C \`{a} Engenharia de Groupware}},
volume = {2003},
year = {2003}
}
@inproceedings{Tohidi2006,
abstract = {We present a study comparing usability testing of a single interface versus three functionally equivalent but stylistically distinct designs. We found that when presented with a single design, users give significantly higher ratings and were more reluctant to criticize than when presented with the same design in a group of three. Our results imply that by presenting users with alternative design solutions, subjective ratings are less prone to inflation and give rise to more and stronger criticisms when appropriate. Contrary to our expectations, our results also suggest that usability testing by itself, even when multiple designs are presented, is not an effective vehicle for soliciting constructive suggestions about how to improve the design from end users. It is a means to identify problems, not provide solutions.},
address = {New York, New York, USA},
author = {Tohidi, Maryam and Buxton, William and Baecker, Ronald and Sellen, Abigail},
booktitle = {Proceedings of the SIGCHI conference on Human Factors in computing systems - CHI '06},
doi = {10.1145/1124772.1124960},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI conference on Human Factors in computing systems - CHI '06/2006/Tohidi et al/Tohidi et al. - 2006 - Getting the right design and the design right.pdf:pdf},
isbn = {1595933727},
pages = {1243--1252},
publisher = {ACM Press},
title = {{Getting the right design and the design right}},
url = {http://portal.acm.org/citation.cfm?doid=1124772.1124960},
year = {2006}
}
@article{Mohr_Triggs_1996,
author = {Mohr, Roger and Triggs, Bill and {Roger Mohr}, Bill Triggs},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Int Symp Photogrammetry and Remote Sensing/1996/Mohr, Triggs, Roger Mohr/Mohr, Triggs, Roger Mohr - 1996 - Projective Geometry for Image Analysis.pdf:pdf},
journal = {Int Symp Photogrammetry and Remote Sensing},
number = {July},
publisher = {Citeseer},
title = {{Projective Geometry for Image Analysis}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.3924 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.37.3924&rep=rep1&type=pdf},
year = {1996}
}
@article{Curmi2013,
abstract = {A number of studies in the literature have looked into the use of real-time biometric data to improve one's own physiological performance and wellbeing. However, there is limited research that looks into the effects that sharing biometric data with others could have on one's social network. Following a period of research on existing mobile applications and prototype testing, we developed a system, HeartLink, which collects real-time personal biometric data such as heart rate and broadcasts this data online. Insights gained on designing systems to broadcast real-time biometric data are presented. In this paper we also report emerging results from testing HeartLink in a pilot study and a user study that were conducted during sport events. The results showed that sharing heart rate data does influence the relationship of the persons involved and that the degree of influence seems related to the tie strength prior to visualizing the data.},
address = {New York, New York, USA},
author = {Curmi, Franco and Ferrario, Maria Angela and Southern, Jen and Whittle, Jon},
doi = {10.1145/2470654.2466231},
isbn = {9781450319522},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {4503},
publisher = {ACM Press},
title = {{HeartLink: open broadcast of live biometric data to social networks}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466231},
year = {2013}
}
@article{Almansa2003,
abstract = {Even though vanishing points in digital images result from parallel lines in the 3D scene, most of the proposed detection algorithms are forced to rely heavily either on additional properties (like orthogonality or coplanarity and equal distance) of the underlying 3D lines, or on knowledge of the camera calibration parameters, in order to avoid spurious responses. In this work, we develop a new detection algorithm that relies on the Helmoltz principle recently proposed for computer vision by Desolneux et al (2001; 2003), both at the line detection and line grouping stages. This leads to a vanishing point detector with a low false alarms rate and a high precision level, which does not rely on any a priori information on the image or calibration parameters, and does not require any parameter tuning.},
annote = {        From Duplicate 2 (                           Vanishing point detection without any a priori information                         - Almansa, A; Desolneux, A; Vamech, S )
                
        
        
      },
author = {Almansa, a. and Desolneux, a. and Vamech, S.},
doi = {10.1109/TPAMI.2003.1190575},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = apr,
number = {4},
pages = {502--507},
title = {{Vanishing point detection without any a priori information}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1190575 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190575},
volume = {25},
year = {2003}
}
@article{Kapps2012,
author = {Kapps, Graziele Weinchutz and Oliveira, Jauvane Cavalcante De},
doi = {10.1109/SVR.2012.19},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Kapps, Oliveira/Kapps, Oliveira - 2012 - PraCiMA A Training System for Cardiopulmonary Resuscitation Procedure.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {-cardiopulmonary arrest,cardiopulmonary resus-,citation,cpr,wii fit},
month = may,
pages = {219--226},
publisher = {Ieee},
title = {{PraCiMA: A Training System for Cardiopulmonary Resuscitation Procedure}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297533},
year = {2012}
}
@article{Li2009,
abstract = {We present a framework and algorithms for robust geometry and motion reconstruction of complex deforming shapes. Our method makes use of a smooth template that provides a crude approximation of the scanned object and serves as a geometric and topological prior for reconstruction. Large-scale motion of the acquired object is recovered using a novel space-time adaptive, non-rigid registration method. Fine-scale details such as wrinkles and folds are synthesized with an efficient linear mesh deformation algorithm. Subsequent spatial and temporal filtering of detail coefficients allows transfer of persistent geometric detail to regions not observed by the scanner. We show how this two-scale process allows faithful recovery of small-scale shape and motion features leading to a high-quality reconstruction. We illustrate the robustness and generality of our algorithm on a variety of examples composed of different materials and exhibiting a large range of dynamic deformations.},
author = {Li, Hao and Adams, Bart and Guibas, Leonidas J. and Pauly, Mark},
doi = {10.1145/1618452.1618521},
isbn = {978-1-60558-858-2},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {3D scanning,animation reconstruction,geometry synthesis,non-rigid registration,partial scans,reconstruction,template tracking},
mendeley-tags = {reconstruction},
month = dec,
number = {5},
pages = {1},
publisher = {ACM},
title = {{Robust single-view geometry and motion reconstruction}},
url = {http://dl.acm.org/citation.cfm?id=1618452.1618521 http://portal.acm.org/citation.cfm?doid=1618452.1618521},
volume = {28},
year = {2009}
}
@inproceedings{Toker2013,
abstract = {There is increasing evidence that users' characteristics such as cognitive abilities and personality have an impact on the effectiveness of information visualization techniques. This paper investigates the relationship between such characteristics and fine-grained user attention patterns. In particular, we present results from an eye tracking user study involving bar graphs and radar graphs, showing that a user's cognitive abilities such as perceptual speed and verbal working memory have a significant impact on gaze behavior, both in general and in relation to task difficulty and visualization type. These results are discussed in view of our long-term goal of designing information visualisation systems that can dynamically adapt to individual user characteristics.},
address = {New York, New York, USA},
author = {Toker, Dereck and Conati, Cristina and Steichen, Ben and Carenini, Giuseppe},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470696},
isbn = {9781450318990},
pages = {295--304},
publisher = {ACM Press},
title = {{Individual user characteristics and information visualization}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470696},
year = {2013}
}
@article{Pasman2006a,
author = {Woodward, Charles and Pasman, W.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings/2006/Woodward, Pasman/Woodward, Pasman - 2006 - Implementation of an Augmented Reality System on a PDA.pdf:pdf},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {276--277},
publisher = {IEEE Comput. Soc},
title = {{Implementation of an Augmented Reality System on a PDA}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240718},
year = {2006}
}
@book{Coxeter2003,
abstract = {In Euclidean geometry, constructions are made with ruler and compass. Projective geometry is simpler: its constructions require only a ruler. In projective geometry one never measures anything, instead, one relates one set of points to another by a projectivity. The first two chapters of this book introduce the important concepts of the subject and provide the logical foundations. The third and fourth chapters introduce the famous theorems of Desargues and Pappus. Chapters 5 and 6 make use of projectivities on a line and plane, respectively. The next three chapters develop a self-contained account of von Staudt's approach to the theory of conics. The modern approach used in that development is exploited in Chapter 10, which deals with the simplest finite geometry that is rich enough to illustrate all the theorems nontrivially. The concluding chapters show the connections among projective, Euclidean, and analytic geometry.},
author = {Coxeter, Harold S. M.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2003/Coxeter/Coxeter - 2003 - Projective geometry.pdf:pdf},
isbn = {0387406239},
pages = {162},
publisher = {Springer},
title = {{Projective geometry}},
url = {http://books.google.com/books?id=gjAAI4FW0tsC&pgis=1},
year = {2003}
}
@inproceedings{Schnyder2011,
abstract = {Given video from a single camera, conversion to two-view stereoscopic 3D is a challenging problem. We present a system to automatically create high quality stereoscopic video from monoscopic footage of field-based sports by exploiting context-specific priors, such as the ground plane, player size and known background. Our main contribution is a novel technique that constructs per-shot panoramas to ensure temporally consistent stereoscopic depth in video reconstructions. Players are rendered as billboards at correct depths on the ground plane. Our method uses additional sports priors to disambiguate segmentation artifacts and produce synthesized 3D shots that are in most cases, indistinguishable from stereoscopic ground truth footage.},
author = {Schnyder, Lars and Wang, Oliver and Smolic, Aljoscha},
booktitle = {2011 18th IEEE International Conference on Image Processing},
doi = {10.1109/ICIP.2011.6115857},
isbn = {978-1-4577-1303-3},
issn = {1522-4880},
keywords = {2D to 3D conversion,2D-3D conversion,3D Reconstruction,Cameras,Conferences,Image segmentation,Mosaicing,Segmentation,Sports Visualization,Stability analysis,Stereo image processing,Stereo vision,Streaming media,Three dimensional displays,high quality stereoscopic video,monoscopic footage,panoramas,per shot panoramas,reconstruction,segmentation artifacts,sport,sports content,stereoscopic ground truth footage,two view stereoscopic 3D,video reconstructions,video signal processing},
mendeley-tags = {reconstruction},
month = sep,
pages = {1961--1964},
publisher = {IEEE},
shorttitle = {Image Processing (ICIP), 2011 18th IEEE Internatio},
title = {{2D to 3D conversion of sports content using panoramas}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6115857},
year = {2011}
}
@inproceedings{Shic2008,
abstract = {In this paper we evaluate several of the most popular algorithms for segmenting fixations from saccades by testing these algorithms on the scanning patterns of toddlers. We show that by changing the parameters of these algorithms we change the reported fixation durations in a systematic fashion. However, we also show how choices in analysis can lead to very different interpretations of the same eye-tracking data. Methods for reconciling the disparate results of different algorithms as well as suggestions for the use of fixation identification algorithms in analysis, are presented.},
address = {New York, New York, USA},
annote = {- keyword coletado
- cited by: 28
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Shic, Frederick and Scassellati, Brian and Chawarska, Katarzyna},
booktitle = {Proceedings of the 2008 symposium on Eye tracking research \& applications - ETRA '08},
doi = {10.1145/1344471.1344500},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2008 symposium on Eye tracking research \& applications - ETRA '08/2008/Shic, Scassellati, Chawarska/Shic, Scassellati, Chawarska - 2008 - The incomplete fixation measure.pdf:pdf},
isbn = {9781595939821},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
pages = {111},
publisher = {ACM Press},
title = {{The incomplete fixation measure}},
url = {http://dl.acm.org/citation.cfm?id=1344500 http://portal.acm.org/citation.cfm?doid=1344471.1344500},
year = {2008}
}
@inproceedings{Munn2008,
abstract = {Video-based eye trackers produce an output video showing where a subject is looking, the subject's point-of-regard (POR), for each frame of a video of the scene. Fixation-identification algorithms simplify the long list of POR data into a more manageable set of data, especially for further analysis, by grouping PORs into fixations. Most current fixation-identification algorithms assume that the POR data are defined in static two-dimensional scene images and only use these raw POR data to identify fixations. The applicability of these algorithms to gaze data in dynamic scene videos is largely unexplored. We implemented a simple velocity-based, duration-sensitive fixation-identification algorithm and compared its performance to results obtained by three experienced users manually coding the eye tracking data displayed within the scene video such that these manual coders had knowledge of the scene motion. We performed this comparison for eye tracking data collected during two different tasks involving different types of scene motion. These two tasks included a subject walking around a building for about 100 seconds (Task 1) and a seated subject viewing a computer animation (approximately 90 seconds long, Task 2). It took our manual coders on average 75 minutes (stdev = 28) and 80 minutes (17) to code results from the first and second tasks, respectively. The automatic fixation-identification algorithm, implemented in MATLAB and run on an Apple 2.16 GHz MacBook, produced results in 0.26 seconds for Task 1 and 0.21 seconds for Task 2. For the first task (walking), the average percent difference among the three human manual coders was 9\% (3.5) and the average percent difference between the automatically generated results and the three coders was 11\% (2.0). For the second task (animation), the average percent difference among the three human coders was 4\% (0.75) and the average percent difference between the automatically generated results and the three coders was 5\% (0.9).},
address = {New York, New York, USA},
annote = {- cited by: 14
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Munn, SM Susan M. and Stefano, Leanne and Pelz, Jeff B. JB},
booktitle = {Proceedings of the 5th symposium on Applied perception in graphics and visualization - APGV '08},
doi = {10.1145/1394281.1394287},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 5th symposium on Applied perception in graphics and visualization - APGV '08/2008/Munn, Stefano, Pelz/Munn, Stefano, Pelz - 2008 - Fixation-identification in dynamic scenes Comparing an automated algorithm to manual coding.pdf:pdf},
isbn = {9781595939814},
keywords = {fixation,gaze analysis},
mendeley-tags = {fixation,gaze analysis},
pages = {33},
publisher = {ACM Press},
title = {{Fixation-identification in dynamic scenes: Comparing an automated algorithm to manual coding}},
url = {http://dl.acm.org/citation.cfm?id=1394287 http://portal.acm.org/citation.cfm?doid=1394281.1394287},
year = {2008}
}
@article{Inchingolo1985,
author = {Inchingolo, P and Spanio, M},
journal = {\ldots  Engineering, IEEE Transactions on},
title = {{On the identification and analysis of saccadic eye movements-A quantitative study of the processing procedures}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4122143},
year = {1985}
}
@inproceedings{Hammer2013,
abstract = {This paper presents a system for real-time analysis of 3D gaze data arising in mobile applications. Our system allows users to freely move in a known 3D environment while their gaze is computed on arbitrarily shaped objects. The scanpath is analysed fully automatically using fixations and areas-of-interest -- all in 3D and real time. Furthermore, the scanpath can be visualized in parallel in a 3D model of the environment. This enables to observe the scanning behaviour of a subject. We describe how this has been realized for a commercial off-the-shelf mobile eye tracker utilizing an inside-out tracking mechanism for head pose estimation. Moreover, we show examples of real gaze data collected in a museum.},
address = {New York, New York, USA},
author = {Hammer, Jan Hendrik and Maurus, Michael and Beyerer, J\"{u}rgen},
booktitle = {Proceedings of the 2013 Conference on Eye Tracking South Africa - ETSA '13},
doi = {10.1145/2509315.2509333},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2013 Conference on Eye Tracking South Africa - ETSA '13/2013/Hammer, Maurus, Beyerer/Hammer, Maurus, Beyerer - 2013 - Real-time 3D gaze analysis in mobile applications.pdf:pdf},
isbn = {9781450321105},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {75--78},
publisher = {ACM Press},
title = {{Real-time 3D gaze analysis in mobile applications}},
url = {http://dl.acm.org/citation.cfm?id=2509333 http://dl.acm.org/citation.cfm?doid=2509315.2509333},
year = {2013}
}
@inproceedings{Bednarik2005,
abstract = {Eye-movement tracking proved its potentials in many areas of human-computer interaction. Resting on a hypothesis that eye-direction and mind are linked, some of the HCI researchers have employed eye-movement trackers to investigate the visual attention focus of the participants completing their tasks. Others have used the eye-movement tracking in real-time applications, either as a direct interaction device or as an input to gaze-aware interfaces. Inspired by the previous HCI applications, we propose to utilize eye- movement trackers in adaptive systems research and development in two ways. First, the evaluations of adaptive systems could get an access to the information otherwise unavailable, as for instance to how the visual attention and cognitive processing are influenced by an adaptivity implemented into the evaluated system. Second, we propose to employ the eye-movement tracking technologies for a real-time registration of users’ loci of visual attention, therefore increasing the awareness of the adaptive systems about their current users. We discuss possible potentials, difficulties and pitfalls of eye-movement tracking when applied to adaptive systems. We argue that a methodological framework of applying eye-tracking into adaptive systems shall be developed.},
address = {Edinburgh, UK},
annote = {- cited by: 9
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Bednarik, R},
booktitle = {Proceedings of the Fourth Workshop on the Evaluation of Adaptive Systems},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Fourth Workshop on the Evaluation of Adaptive Systems/2005/Bednarik/Bednarik - 2005 - Potentials of eye-movement tracking in adaptive systems.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {1--8},
title = {{Potentials of eye-movement tracking in adaptive systems}},
url = {http://www.cs.joensuu.fi/pages/int/pub/bednarik05a.pdf},
year = {2005}
}
@article{Khaled2013,
address = {New York, New York, USA},
author = {Khaled, Rilla and Nelson, Mark J. and Barr, Pippin},
doi = {10.1145/2470654.2466201},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {your keywords},
pages = {1509},
publisher = {ACM Press},
title = {{Design metaphors for procedural content generation in games}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466201},
year = {2013}
}
@article{Holland2011,
author = {Holland, C and Komogortsev, OV},
file = {::},
journal = {Biometrics (IJCB), 2011  \ldots},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Biometric identification via eye movement scanpaths in reading}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6117536},
year = {2011}
}
@article{Williams2002,
abstract = {. Skilled (n = 12) and less skilled (n = 12) billiards players participated in 2 experiments in which the relationship between quiet eye duration, expertise, and task complexity was examined in a near and a far aiming task. Quiet eye was defined as the final fixation on the target prior to the initiation of movement. In Experiment 1, skilled performers exhibited longer fixations on the target (quiet eye) during the preparation phase of the action than their less skilled counterparts did. Quiet eye duration increased as a function of shot difficulty and was proportionally longer on successful than on unsuccessful shots for both groups of participants. In Experiment 2, participants executed shots under 3 different time-constrained conditions in which quiet eye periods were experimentally manipulated. Shorter quiet eye periods resulted in poorer performance, irrespective of participant skill level. The authors argue that quiet eye duration represents a critical period for movement programming in the aiming response.},
author = {Williams, A Mark and Singer, Robert N and Frehlich, Shane G},
doi = {10.1080/00222890209601941},
issn = {0022-2895},
journal = {Journal of motor behavior},
keywords = {Adult,Blinking,Eye Movements,Eye Movements: physiology,Fixation,Humans,Motor Skills,Ocular,Random Allocation,Time Factors,Visual Perception},
month = jun,
number = {2},
pages = {197--207},
pmid = {12057892},
title = {{Quiet eye duration, expertise, and task complexity in near and far aiming tasks.}},
url = {http://www.tandfonline.com/doi/full/10.1080/00222890209601941 http://www.ncbi.nlm.nih.gov/pubmed/12057892},
volume = {34},
year = {2002}
}
@article{Collewijn1984,
author = {Collewijn, H and Tamminga, EP},
file = {::},
journal = {The Journal of physiology},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Human smooth and saccadic eye movements during voluntary pursuit of different target motions on different backgrounds.}},
url = {http://jp.physoc.org/content/351/1/217.short},
year = {1984}
}
@article{Lin2013,
address = {New York, New York, USA},
author = {Lin, Sharon and Hanrahan, Pat},
doi = {10.1145/2470654.2466424},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3101},
publisher = {ACM Press},
title = {{Modeling how people extract color themes from images}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466424},
year = {2013}
}
@inproceedings{Byeon2004,
abstract = {UML cannot meet all the requirements offered in different software system for diverse application domain. GNSS (Global Navigation Satellite System) application domain is an especial environment that requires precise measurement and precision calculation of real-world geographical entities with the help of GPS (Global Position System) in both temporal and spatial factor. Therefore in the paper new extended iconic stereotypes for better modeling GNSS application in the UML diagram are proposed, and the implementation of a program called StereotypeCreator, which is able to create iconic stereotypes used in one of the most popular visual modeling tools for software development, Rational Rose, will be also proposed.},
author = {Byeon, WS and Wang, B and Jeong, SK},
booktitle = {2004 International Conference on Cyberworlds},
doi = {10.1109/CW.2004.32},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2004 International Conference on Cyberworlds/2004/Byeon, Wang, Jeong/Byeon, Wang, Jeong - 2004 - Extension and Implementation of Iconic Stereotype for GNSS Application in the UML Class Diagram.pdf:pdf},
isbn = {0-7695-2140-1},
pages = {162--169},
publisher = {IEEE},
title = {{Extension and Implementation of Iconic Stereotype for GNSS Application in the UML Class Diagram}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1366169 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1366169},
year = {2004}
}
@article{Howley2013,
address = {New York, New York, USA},
author = {Howley, Iris and Newman, Todd},
doi = {10.1145/2470654.2481314},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13/2013/Howley, Newman/Howley, Newman - 2013 - Factors impacting community response in an interest-sharing network.pdf:pdf},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2283},
publisher = {ACM Press},
title = {{Factors impacting community response in an interest-sharing network}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481314},
year = {2013}
}
@inproceedings{Soares2006,
abstract = {To achieve higher realism and interaction levels, every time more powerful resources are developed and available for the community. This chapter is going to discuss about techniques to produce high quality imagery based in supercomputers, specially commodity computer graphic cluster (VR-Cluster). It is also going to be covered immersive high-resolution multiprojection systems, tracking systems and development libraries for virtual reality application.},
address = {Bel\'{e}m},
author = {Soares, Luciano Pereira and Cabral, Marcio Calixto and Zuffo, Marcelo Knorich},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {51--58},
publisher = {SBC},
title = {{Sistemas Avan\c{c}ados de Realidade Virtual}},
year = {2006}
}
@inproceedings{Liu2012a,
abstract = {Keystone distortion is a long-standing problem in stereoscopic cinematography. Keystone distortion occurs when a stereoscopic camera toes in to achieve a desirable disparity distribution. One particular problem from keystone distortion is vertical disparity, which often compromises stereoscopic 3D viewing experience. Keystone distortion can be corrected by applying a proper homography; however, this damages the desirable disparity distribution. This paper presents an approach to keystone correction for stereoscopic cinematography that both corrects keystone distortion and preserves the original disparity distribution. Our method formulates keystone correction as a spatially-varying warping problem. Our method eliminates the vertical disparities and preserves the original horizontal disparities by encoding them as data terms in the warping problem. The energy terms are designed to be quadratic and thus the keystone correction problem can be quickly solved using a sparse linear solver. Our experiment shows that our method can effectively solve the keystone problem while preserving desirable horizontal disparities.},
author = {Liu, Feng and Niu, Yuzhen and Jin, Hailin},
booktitle = {2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
doi = {10.1109/CVPRW.2012.6238901},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops/2012/Liu, Niu, Jin/Liu, Niu, Jin - 2012 - Keystone correction for stereoscopic cinematography.pdf:pdf},
isbn = {978-1-4673-1612-5},
issn = {2160-7508},
keywords = {Adaptive optics,Cameras,Cinematography,Optical distortion,Optical imaging,Stereo image processing,Videos,anamorphism,disparity distribution,distortion,homography,horizontal disparity preservation,keystone,keystone correction problem,keystone distortion,sparse linear solver,sparse matrices,spatially-carving warping problem,stereoscopic 3D viewing experience,stereoscopic camera,stereoscopic cinematography,vertical disparity elimination},
mendeley-tags = {anamorphism,keystone},
month = jun,
pages = {1--7},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition Workshops},
title = {{Keystone correction for stereoscopic cinematography}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6238901},
year = {2012}
}
@article{Sicilia2007,
abstract = {The term systematic review is used to refer to a specific methodology of research, developed in order to gather and evaluate the available evidence pertaining to a focused topic. It represents a secondary study that depends on primary study results to be accomplished. Several primary studies have been conducted in the field of Software Engineering in the last years, determining an increasing improvement in methodology. However, in most cases software is built with technologies and processes for which developers have insufficient evidence to confirm their suitability, limits, qualities, costs, and inherent risks. Conducting systematic reviews in Software Engineering consists in a major methodological tool to scientifically improve the validity of assertions that can be made in the field and, as a consequence, the reliability degree of the methods that are employed for developing software technologies and supporting software processes. This paper aims at discussing the significance of experimental studies, particularly systematic reviews, and their use in supporting software processes. A template designed to support systematic reviews in Software Engineering is presented, and the development of ontologies to describe knowledge regarding such experimental studies is also introduced.},
author = {Biolchini, Jorge Calmon de Almeida and Mian, Paula Gomes and Natali, Ana Candida Cruz and Conte, Tayana Uch\^{o}a and Travassos, Guilherme Horta},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Advanced Engineering Informatics/2007/Biolchini et al/Biolchini et al. - 2007 - Scientific research ontology to support systematic review in software engineering.pdf:pdf},
journal = {Advanced Engineering Informatics},
keywords = {Experimental software engineering,Experimental study,Ontology,Scientific method,Systematic review,rbs},
mendeley-tags = {rbs},
number = {2},
pages = {133--151},
title = {{Scientific research ontology to support systematic review in software engineering}},
url = {http://www.sciencedirect.com/science/article/pii/S147403460600070X},
volume = {21},
year = {2007}
}
@article{Obrist2013,
address = {New York, New York, USA},
author = {Obrist, Marianna and Seah, Sue Ann and Subramanian, Sriram},
doi = {10.1145/2470654.2466220},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1659},
publisher = {ACM Press},
title = {{Talking about tactile experiences}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466220},
year = {2013}
}
@book{Ashby1999,
address = {London},
author = {Ashby, W Ross},
booktitle = {Director},
edition = {2},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Director/1999/Ashby/Ashby - 1999 - An Introduction to Cybernetics.pdf:pdf},
isbn = {0416683002},
pages = {312},
publisher = {Chapman \& Hall Ltd},
title = {{An Introduction to Cybernetics}},
url = {http://pcp.vub.ac.be/books/IntroCyb.pdf},
year = {1999}
}
@inproceedings{Kinsman2010,
abstract = {The classification of a large number of images is a familiar problem to the image processing community. It occurs in consumer photography, bioinformatics, biomedical imaging, surveillance, and in the field of mobile eye-tracking studies. During eye-tracking studies, what a person looks at is recorded, and for each frame what the person looked at must then be analyzed and classified. In many cases the data analysis time restricts the scope of the studies. This paper describes the initial use of hierarchical clustering of these images to minimize the time required during analysis. Pre-clustering the images allows the user to classify a large number of images simultaneously. The success of this method is dependent on meeting requirements for human-computer-interactions, which are also discussed.},
address = {Rochester, NY},
annote = {- cited by: 2
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Kinsman, Thomas and Bajorski, Peter and Pelz, Jeff B.},
booktitle = {2010 Western New York Image Processing Workshop},
doi = {10.1109/WNYIPW.2010.5649742},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 Western New York Image Processing Workshop/2010/Kinsman, Bajorski, Pelz/Kinsman, Bajorski, Pelz - 2010 - Hierarchical image clustering for analyzing eye tracking videos.pdf:pdf},
isbn = {978-1-4244-9298-5},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = nov,
pages = {58--61},
publisher = {IEEE},
title = {{Hierarchical image clustering for analyzing eye tracking videos}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5649742 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5649742},
year = {2010}
}
@article{Lee2013a,
address = {New York, New York, USA},
author = {Lee, Jaebong and Choi, Seungmoon},
doi = {10.1145/2470654.2481354},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2567},
publisher = {ACM Press},
title = {{Real-time perception-level translation from audio signals to vibrotactile effects}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481354},
year = {2013}
}
@article{Yetim2013,
address = {New York, New York, USA},
author = {Yetim, Fahri},
doi = {10.1145/2470654.2466454},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3327},
publisher = {ACM Press},
title = {{Critical perspective on persuasive technology reconsidered}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466454},
year = {2013}
}
@misc{Eugene,
author = {Eugene},
title = {{In2AR}},
url = {http://www.in2ar.com},
urldate = {17/01/2012}
}
@article{Kittur2013,
address = {New York, New York, USA},
author = {Kittur, Aniket and Peters, Andrew M. and Diriye, Abdigani and Telang, Trupti and Bove, Michael R.},
doi = {10.1145/2470654.2481415},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {1,180 mil-,3 million users and,5,60 systems,alone reported more than,com,delicious,for notetaking and organ-,in 2008,izational tools,lion unique bookmarked urls,tags for web pages,wikipedia lists more than},
pages = {2989},
publisher = {ACM Press},
title = {{Costs and benefits of structured information foraging}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481415},
year = {2013}
}
@book{opencv,
annote = {"This library is useful for practitioners, and is an excellent tool for those entering the field: it is a set of computer vision algorithms that work as advertised."
-William T. Freeman, Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology 
        
Learning OpenCV puts you in the middle of the rapidly expanding field of computer vision. Written by the creators of the free open source OpenCV library, this book introduces you to computer vision and demonstrates how you can quickly build applications that enable computers to "see" and make decisions based on that data. 
        
Computer vision is everywhere-in security systems, manufacturing inspection systems, medical image analysis, Unmanned Aerial Vehicles, and more. It stitches Google maps and Google Earth together, checks the pixels on LCD screens, and makes sure the stitches in your shirt are sewn properly. OpenCV provides an easy-to-use computer vision framework and a comprehensive library with more than 500 functions that can run vision code in real time. 
        
Learning OpenCV will teach any developer or hobbyist to use the framework quickly with the help of hands-on exercises in each chapter. This book includes:
A thorough introduction to OpenCV
Getting input from cameras
Transforming images
Segmenting images and shape matching
Pattern recognition, including face detection
Tracking and motion in 2 and 3 dimensions
3D reconstruction from stereo vision
Machine learning algorithms
Getting machines to see is a challenging but entertaining goal. Whether you want to build simple or sophisticated vision applications, Learning OpenCV is the book you need to get started.
      },
author = {Kaehler, Adrian and Bradski, Gary},
edition = {1},
isbn = {978-0-596-51613-0},
keywords = {SBGames},
mendeley-tags = {SBGames},
pages = {580},
publisher = {O'Reilly Media},
title = {{Learning OpenCV: Computer Vision with the OpenCV Library}},
url = {http://shop.oreilly.com/product/9780596516130.do},
year = {2008}
}
@inproceedings{Newman2004,
abstract = {Augmented Reality (AR) provides a natural interface to the "calm" pervasive technology anticipated in large-scale Ubiquitous Computing environments. However, the range of classic AR applications has been limited by the scope, range and cost of sensors used for tracking. Hybrid tracking approaches can go some way to extending this range. We propose an approach, called Ubiquitous Tracking, in which data from widespread and diverse heterogeneous tracking sensors is automatically and dynamically fused, and then transparently provided to applications. A formal model represents spatial relationships between objects as a graph attributed with quality-of-service parameters. This paper presents a software implementation, in which a dynamic data flow network of distributed software components is thereby constructed in response to queries and optimisation criteria specified by applications. This implementation is demonstrated using a small laboratory example, and larger setups modelled in a simulation environment.},
address = {Arlington},
author = {Newman, Joseph and Wagner, Martin and Bauer, Martin and MacWilliams, A. and Pintaric, Thomas and Beyer, Dagmar and Pustka, Daniel and Strasser, Franz and Schmalstieg, Dieter and Klinker, Gudrun},
booktitle = {Third IEEE and ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2004.62},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Third IEEE and ACM International Symposium on Mixed and Augmented Reality/2004/Newman et al/Newman et al. - 2004 - Ubiquitous Tracking for Augmented Reality.pdf:pdf},
isbn = {0-7695-2191-6},
number = {Ismar},
pages = {192--201},
publisher = {IEEE},
title = {{Ubiquitous Tracking for Augmented Reality}},
url = {http://portal.acm.org/citation.cfm?id=1033716 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1383056},
year = {2004}
}
@inproceedings{Smisek2011,
abstract = {We analyze Kinect as a 3D measuring device, experimentally investigate depth measurement resolution and error properties and make a quantitative comparison of Kinect accuracy with stereo reconstruction from SLR cameras and a 3D-TOF camera. We propose Kinect geometrical model and its calibration procedure providing an accurate calibration of Kinect 3D measurement and Kinect cameras. We demonstrate the functionality of Kinect calibration by integrating it into an SfM pipeline where 3D measurements from a moving Kinect are transformed into a common coordinate system by computing relative poses from matches in color camera.},
author = {Smisek, Jan and Jancosek, Michal and Pajdla, Tomas},
booktitle = {2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)},
doi = {10.1109/ICCVW.2011.6130380},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)/2011/Smisek, Jancosek, Pajdla/Smisek, Jancosek, Pajdla - 2011 - 3D with Kinect.pdf:pdf},
isbn = {978-1-4673-0063-6},
month = nov,
pages = {1154--1160},
publisher = {IEEE},
title = {{3D with Kinect}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6130380&contentType=Conference+Publications&searchField%3DSearch_All%26queryText%3Dkinect+calibration http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6130380},
year = {2011}
}
@article{Veneri2011,
abstract = {Eye movement is the simplest and repetitive movement that enables humans to interact with the environment. The common daily activities, such as reading a book or watching television, involve this natural activity, which consists of rapidly shifting our gaze from one region to another. In clinical application, the identification of the main components of eye movement during visual exploration, such as fixations and saccades, is the objective of the analysis of eye movements: however, in patients affected by motor control disorder the identification of fixation is not banal. This work presents a new fixation identification algorithm based on the analysis of variance and covariance: the main idea was to use bivariate statistical analysis to compare variance over x and y to identify fixation. We describe the new algorithm, and we compare it with the common fixations algorithm based on dispersion. To demonstrate the performance of our approach, we tested the algorithm in a group of healthy subjects and patients affected by motor control disorder.},
annote = {- cited by: 2
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Veneri, Giacomo and Piu, Pietro and Rosini, Francesca and Federighi, Pamela and Federico, Antonio and Rufa, Alessandra},
doi = {10.1016/j.patrec.2011.06.012},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Pattern Recognition Letters/2011/Veneri et al/Veneri et al. - 2011 - Automatic eye fixations identification based on analysis of variance and covariance.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = oct,
number = {13},
pages = {1588--1593},
title = {{Automatic eye fixations identification based on analysis of variance and covariance}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865511001887 http://linkinghub.elsevier.com/retrieve/pii/S0167865511001887},
volume = {32},
year = {2011}
}
@article{Sauter1991,
abstract = {A simple but efficient algorithm has been developed for computer analysis of eye tracking movements. The program separates smooth pursuit and saccadic eye movements. Separation of the two components is achieved using a twostep process of saccade detection. First, an AR model of the velocity of the smooth component is identified and used to determine a Kalman filter. Secondly the innovation sequence generated by this filter allows saccade detection. The precise beginning and end of each saccade are found using a Hinkley algorithm. Examples are given of analysis procedure for eye tracking of a random moving target. The method proved to be highly reliable and could be easily extended to other eye movements such as nystagmus.},
author = {Sauter, D and Martin, B. J. and Renzo, N. and Vomscheid, C.},
doi = {10.1007/BF02446297},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Medical \& Biological Engineering \& Computing/1991/Sauter et al/Sauter et al. - 1991 - Analysis of eye tracking movements using innovations generated by a Kalman filter.pdf:pdf},
issn = {0140-0118},
journal = {Medical \& Biological Engineering \& Computing},
keywords = {gaze analysis,saccade,smooth pursuit},
mendeley-tags = {gaze analysis,saccade,smooth pursuit},
month = jan,
number = {1},
pages = {63--69},
title = {{Analysis of eye tracking movements using innovations generated by a Kalman filter}},
url = {http://link.springer.com/article/10.1007/BF02446297 http://link.springer.com/10.1007/BF02446297},
volume = {29},
year = {1991}
}
@article{Mathot2012,
author = {Math\^{o}t, S and Cristino, F and Gilchrist, ID and Theeuwes, J},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Eye Movement \ldots/2012/Math\^{o}t et al/Math\^{o}t et al. - 2012 - A simple way to estimate similarity between pairs of eye movement sequences.pdf:pdf},
journal = {Journal of Eye Movement  \ldots},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
title = {{A simple way to estimate similarity between pairs of eye movement sequences}},
url = {http://www.cs.vu.nl/~cogsci/cogpsy/theeuwes/JoER_1.pdf},
year = {2012}
}
@inproceedings{Liu2012,
abstract = {In this paper, we present a method that can calibrates color camera and depth camera of Kinect simultaneously, and finally get the relative pose between them. The calibration process for color camera and depth camera is designed by taking advantage of two different method respectively. As we know, the depth information can be acquired readily from the depth image, however, under the consideration of the fuzzy boundary and the overlapping of object in depth image, we choose using one-dimensional object for calibrating depth camera and propose a nonlinear method to optimize its intrinsic parameter. As for color camera calibration, we design a cross shape object for calibration and validation. Both methods are strongly robust to noise and much easier to implement. The experiment result shows a better accuracy in comparison with the proprietary calibration procedure of the manufacturer.},
author = {Liu, Weihua and Fan, Yangyu and Zhong, Zhang and Lei, Tao},
booktitle = {2012 International Conference on Audio, Language and Image Processing},
doi = {10.1109/ICALIP.2012.6376614},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 International Conference on Audio, Language and Image Processing/2012/Liu et al/Liu et al. - 2012 - A new method for calibrating depth and color camera pair based on Kinect.pdf:pdf},
isbn = {978-1-4673-0174-9},
month = jul,
pages = {212--217},
publisher = {IEEE},
title = {{A new method for calibrating depth and color camera pair based on Kinect}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6376614&contentType=Conference+Publications&searchField%3DSearch_All%26queryText%3Dkinect+calibration http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6376614},
year = {2012}
}
@article{Galvao2004,
abstract = {A revis\~{a}o sistem\'{a}tica \'{e} um recurso importante da pr\'{a}tica baseada em evid\^{e}ncias, que consiste em uma forma de s\'{\i}ntese dos resultados de pesquisas relacionados com um problema espec\'{\i}fico. O presente artigo tem como objetivo oferecer subs\'{\i}dios que proporcionem reflex\~{o}es para a constru\c{c}\~{a}o e/ou aplica\c{c}\~{a}o de revis\~{o}es sistem\'{a}ticas no cen\'{a}rio da enfermagem. Fundamentados na literatura, apresentamos as fases que comp\~{o}em uma revis\~{a}o sistem\'{a}tica e aspectos relevantes a serem considerados para a utiliza\c{c}\~{a}o desse recurso.},
author = {Galv\~{a}o, CM and Sawada, NO and Trevizan, MA},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Revista Latino-Americana de enfermagem/2004/Galv\~{a}o, Sawada, Trevizan/Galv\~{a}o, Sawada, Trevizan - 2004 - Revis\~{a}o Sistem\'{a}tica Recurso que Proporciona a Incorpora\c{c}\~{a}o das Evid\^{e}ncias na Pr\'{a}tica da Enferma.pdf:pdf},
journal = {Revista Latino-Americana de enfermagem},
keywords = {RBS,enfermagem,metan\'{a}lise,pesquisa},
mendeley-tags = {RBS},
number = {3},
pages = {549--556},
title = {{Revis\~{a}o Sistem\'{a}tica: Recurso que Proporciona a Incorpora\c{c}\~{a}o das Evid\^{e}ncias na Pr\'{a}tica da Enfermagem}},
url = {http://www.scielo.br/pdf/rlae/v12n3/v12n3a14.pdf},
volume = {12},
year = {2004}
}
@misc{Raman2009,
author = {Raman, Assaf and Frydrych, Holger and Buck, Jim and Rogers, Dave and Furst, Mattan and Gat, Noam and Johnstone, Brian},
booktitle = {OGRE - Open Source Graphics Engine},
title = {{OGRE3D}},
url = {http://www.ogre3d.org/},
urldate = {04/10/2011},
year = {2009}
}
@article{Tanenbaum2013,
address = {New York, New York, USA},
author = {Tanenbaum, Joshua G. and Antle, Alissa N. and Robinson, John},
doi = {10.1145/2470654.2466464},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3389},
publisher = {ACM Press},
title = {{Three perspectives on behavior change for serious games}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466464},
year = {2013}
}
@inproceedings{Lee2004,
abstract = {Projection technology typically places several constraints on the geometric relationship between the projector and the projection surface to obtain an undistorted, properly sized image. In this paper we describe a simple, robust, fast, and low-cost method for automatic projector calibration that eliminates many of these constraints. We embed light sensors in the target surface, project Gray-coded binary patterns to discover the sensor locations, and then prewarp the image to accurately fit the physical features of the projection surface. This technique can be expanded to automatically stitch multiple projectors, calibrate onto non-planar surfaces for object decoration, and provide a method for simple geometry acquisition.},
address = {New York, New York, USA},
author = {Lee, Johnny C. and Dietz, Paul H. and Maynes-Aminzade, Dan and Raskar, Ramesh and Hudson, Scott E.},
booktitle = {Proceedings of the 17th annual ACM symposium on User interface software and technology - UIST '04},
doi = {10.1145/1029632.1029653},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 17th annual ACM symposium on User interface software and technology - UIST '04/2004/Lee et al/Lee et al. - 2004 - Automatic projector calibration with embedded light sensors.pdf:pdf},
isbn = {1581139578},
keywords = {anamorphism},
mendeley-tags = {anamorphism},
pages = {123},
publisher = {ACM Press},
title = {{Automatic projector calibration with embedded light sensors}},
url = {http://dl.acm.org/citation.cfm?id=1029653 http://portal.acm.org/citation.cfm?doid=1029632.1029653},
year = {2004}
}
@incollection{Goldberg2014,
author = {Goldberg, JH and Helfman, JI},
booktitle = {Handbook of Human Centric Visualization},
doi = {10.1007/978-1-4614-7485-2\_13},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Handbook of Human Centric Visualization/2014/Goldberg, Helfman/Goldberg, Helfman - 2014 - Eye Tracking on Visualizations Progressive Extraction of Scanning Strategies.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {337--372},
title = {{Eye Tracking on Visualizations: Progressive Extraction of Scanning Strategies}},
url = {http://link.springer.com/chapter/10.1007/978-1-4614-7485-2_13},
year = {2014}
}
@article{Chang2007,
abstract = {In recent years, the success of single-robot SLAM has led to more multi-robot SLAM (MR-SLAM) research. A team of robots with MR-SLAM can explore an environment more efficiently and reliably; however, MR-SLAM also raises many challenging problems, including map fusion, unknown robot poses and scalability issues. The first two problems can be considered as an optimization problem of finding a consistent joint map based on robots\&x2019; relative poses and sensory data. This optimization problem exhibits a similar property of a singlerobot topological/metric mapping. To exploit this property, we propose a multi-robot SLAM (MR-SLAM) algorithm, which builds a graph-like topological map with vertices representing local metric maps and edges describing relative positions of adjacent local maps. In this MR-SLAM algorithm, the map fusion between two robots can be naturally done by adding an edge that connects two topological maps, and the estimation of relative robot pose is simply performed by optimizing this edge. For the third scalable problem, the proposed algorithm is also scalable to the number of robots and the size of an environment. Computer simulations with a public data set and experimental work on Pioneer 3-DX robots have been conducted to validate the performance of the proposed MR-SLAM algorithm.},
author = {Chang, H Jacky and Lee, C S George and Hu, Y Charlie and {Yung-Hsiang Lu}, A Yung-Hsiang Lu},
journal = {2007 IEEERSJ International Conference on Intelligent Robots and Systems},
pages = {1467--1472},
publisher = {Ieee},
title = {{Multi-robot SLAM with topological/metric maps}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4399142},
year = {2007}
}
@inproceedings{Kelner2007,
abstract = {Software usability is highly dependent on the supported interaction at the interface level. A number of techniques have been described in the literature, and some of those used in the context of virtual and augmented realities together with implementation aspects are presented in this chapter.},
address = {Petropolis},
author = {Kelner, Judith and Teichrieb, Veronica},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2007/Machado/Machado - 2007 - Dispositivos H\'{a}pticos para Interfaces de Realidade Virtual e Aumentada.pdf:pdf},
pages = {52--70},
publisher = {SBC},
title = {{T\'{e}cnicas de Intera\c{c}\~{a}o para Ambientes de Realidade Virtual e Aumentada}},
year = {2007}
}
@article{Grindinger2010,
abstract = {A novel method for distinguishing classes of viewers from their aggregated eye movements is described. The probabilistic framework accumulates uniformly sampled gaze as Gaussian point spread functions (heatmaps), and measures the distance of unclassified scanpaths to a previously classified set (or sets). A similarity measure is then computed over the scanpath durations. The approach is used to compare human observers’s gaze over video to regions of interest (ROIs) automatically predicted by a computational saliency model. Results show consistent discrimination between human and artificial ROIs, regardless of either of two differing instructions given to human observers (free or tasked viewing).},
author = {Grindinger, Thomas J. and Murali, Vidya N. and Tetreault, Stephen and Duchowski, Andrew T. and Birchfield, Stan T. and Orero, Pilar},
doi = {10.1007/978-3-642-22822-3\_39},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Computer Vision - ACCV/2010/Grindinger et al/Grindinger et al. - 2010 - Algorithm for Discriminating Aggregate Gaze Points Comparison with Salient Regions-Of-Interest.pdf:pdf},
journal = {Computer Vision - ACCV},
pages = {390--399},
title = {{Algorithm for Discriminating Aggregate Gaze Points: Comparison with Salient Regions-Of-Interest}},
volume = {6468},
year = {2010}
}
@inproceedings{Sung2010,
author = {Sung, Chang Ho and Moon, Il-chul and Kim, Tag Gon},
booktitle = {2010 19th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises},
doi = {10.1109/WETICE.2010.31},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 19th IEEE International Workshops on Enabling Technologies Infrastructures for Collaborative Enterprises/2010/Sung, Moon, Kim/Sung, Moon, Kim - 2010 - Collaborative Work in Domain-Specific Discrete Event Simulation Software Development Fleet Anti-air Defense Sim.pdf:pdf},
isbn = {978-1-4244-7216-1},
keywords = {-modeling and simulation,collaborative work,m,opment process,s,s stakeholders,software devel-},
pages = {160--165},
publisher = {IEEE},
title = {{Collaborative Work in Domain-Specific Discrete Event Simulation Software Development: Fleet Anti-air Defense Simulation Software}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5541948},
year = {2010}
}
@inproceedings{Tanriverdi2000,
abstract = {Eye movement-based interaction offers the potential of easy, natural, and fast ways of interacting in virtual environments. However, there is little empirical evidence about the advantages or disadvantages of this approach. We developed a new interaction technique for eye movement interaction in a virtual environment and compared it to more conventional 3-D pointing. We conducted an experiment to compare performance of the two interaction types and to assess their impacts on spatial memory of subjects and to explore subjects' satisfaction with the two types of interactions. We found that the eye movement-based interaction was faster than pointing, especially for distant objects. However, subjects' ability to recall spatial information was weaker in the eye condition than the pointing one. Subjects reported equal satisfaction with both types of interactions, despite the technology limitations of current eye tracking equipment.},
author = {Tanriverdi, Vildan and Jacob, RJK Robert J K and Science, Computer},
booktitle = {Proceedings of the SIGCHI conference on \ldots},
doi = {10.1.1.24.3243},
keywords = {Eye,Gaze,IHC,Tracking,and fast ways of,based interaction can provide,easy,in its infancy,interacting in virtual environments,natural,the field is still,we believe eye movement-,work on eye},
mendeley-tags = {Eye,Gaze,IHC,Tracking},
pages = {265--272},
title = {{Interacting with eye movements in virtual environments}},
url = {http://dl.acm.org/citation.cfm?id=332443},
year = {2000}
}
@article{Wu2008,
author = {Wu, Tai-Pang and Sun, Jian and Tang, Chi-Keung and Shum, Heung-Yeung},
doi = {10.1145/1409060.1409072},
isbn = {978-1-4503-1831-0},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {reconstruction},
mendeley-tags = {reconstruction},
month = dec,
number = {5},
pages = {1},
publisher = {ACM},
title = {{Interactive normal reconstruction from a single image}},
url = {http://dl.acm.org/citation.cfm?id=1409060.1409072},
volume = {27},
year = {2008}
}
@article{Land2000,
abstract = {In cricket, a batsman watches a fast bowler's ball come toward him at a high and unpredictable speed, bouncing off ground of uncertain hardness. Although he views the trajectory for little more than half a second, he can accurately judge where and when the ball will reach him. Batsmen's eye movements monitor the moment when the ball is released, make a predictive saccade to the place where they expect it to hit the ground, wait for it to bounce, and follow its trajectory for 100-200 ms after the bounce. We show how information provided by these fixations may allow precise prediction of the ball's timing and placement. Comparing players with different skill levels, we found that a short latency for the first saccade distinguished good from poor batsmen, and that a cricket player's eye movement strategy contributes to his skill in the game.},
author = {Land, M F and McLeod, P},
doi = {10.1038/81887},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Nature neuroscience/2000/Land, McLeod/Land, McLeod - 2000 - From eye movements to actions how batsmen hit the ball.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Adult,Baseball,Baseball: physiology,Head Movements,Head Movements: physiology,Humans,Male,Motion Perception,Motion Perception: physiology,Motor Skills,Motor Skills: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Pursuit,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Smooth,Smooth: physiology,Sports,Sports: physiology},
month = dec,
number = {12},
pages = {1340--5},
pmid = {11100157},
title = {{From eye movements to actions: how batsmen hit the ball.}},
url = {http://www.nature.com/neuro/journal/v3/n12/abs/nn1200_1340.html http://www.ncbi.nlm.nih.gov/pubmed/11100157},
volume = {3},
year = {2000}
}
@article{Gustafson2013,
address = {New York, New York, USA},
author = {Gustafson, Sean G. and Rabe, Bernhard and Baudisch, Patrick M.},
doi = {10.1145/2470654.2466114},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {889},
publisher = {ACM Press},
title = {{Understanding palm-based imaginary interfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466114},
year = {2013}
}
@article{Yun2013,
address = {New York, New York, USA},
author = {Yun, Tae-Jung and Arriaga, Rosa I.},
doi = {10.1145/2470654.2466233},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1769},
publisher = {ACM Press},
title = {{A text message a day keeps the pulmonologist away}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466233},
year = {2013}
}
@article{Jokela2013,
address = {New York, New York, USA},
author = {Jokela, Tero and Lucero, Andr\'{e}s},
doi = {10.1145/2470654.2466459},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3355},
publisher = {ACM Press},
title = {{A comparative evaluation of touch-based methods to bind mobile devices for collaborative interactions}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466459},
year = {2013}
}
@inproceedings{Cruz-Neira1993,
address = {New York, New York, USA},
author = {Cruz-Neira, Carolina and Sandin, Daniel J. and DeFanti, Thomas A.},
booktitle = {Proceedings of the 20th annual conference on Computer graphics and interactive techniques - SIGGRAPH '93},
doi = {10.1145/166117.166134},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 20th annual conference on Computer graphics and interactive techniques - SIGGRAPH '93/1993/Cruz-Neira, Sandin, DeFanti/Cruz-Neira, Sandin, DeFanti - 1993 - Surround-screen projection-based virtual reality.pdf:pdf},
isbn = {0897916018},
pages = {135--142},
publisher = {ACM Press},
title = {{Surround-screen projection-based virtual reality}},
url = {http://dl.acm.org/citation.cfm?id=166134 http://portal.acm.org/citation.cfm?doid=166117.166134},
year = {1993}
}
@article{Larsson2013,
abstract = {A novel algorithm for detection of saccades and postsaccadic oscillations in the presence of smooth pursuit movements is proposed. The method combines saccade detection in the acceleration domain with specialized on- and offset criteria for saccades and postsaccadic oscillations. The performance of the algorithm is evaluated by comparing the detection results to those of an existing velocity-based adaptive algorithm and a manually annotated database. The results show that there is a good agreement between the events detected by the proposed algorithm and those in the annotated database with Cohen's kappa around 0.8 for both a development and a test database. In conclusion, the proposed algorithm accurately detects saccades and postsaccadic oscillations as well as intervals of disturbances.},
author = {Larsson, Linn\'{e}a and Nystr\"{o}m, Marcus and Stridh, Martin},
doi = {10.1109/TBME.2013.2258918},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on bio-medical engineering/2013/Larsson, Nystr\"{o}m, Stridh/Larsson, Nystr\"{o}m, Stridh - 2013 - Detection of saccades and postsaccadic oscillations in the presence of smooth pursuit.pdf:pdf},
issn = {1558-2531},
journal = {IEEE transactions on bio-medical engineering},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = sep,
number = {9},
pages = {2484--93},
pmid = {23625350},
title = {{Detection of saccades and postsaccadic oscillations in the presence of smooth pursuit.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6504734 http://www.ncbi.nlm.nih.gov/pubmed/23625350},
volume = {60},
year = {2013}
}
@article{Roedl2013,
address = {New York, New York, USA},
author = {Roedl, David J. and Stolterman, Erik},
doi = {10.1145/2470654.2466257},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1951},
publisher = {ACM Press},
title = {{Design research at CHI and its applicability to design practice}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466257},
year = {2013}
}
@article{Hagemann2006,
abstract = {A major element in expert sports performance, particularly racket-and-ball games, is excellent anticipatory skill. A prestudy combined the temporal and spatial occlusion paradigms to ascertain which key stimuli badminton players use for anticipating the direction of overhead shots. The main study then evaluated a program for training anticipatory skills; 200 video clips were employed to orient attention toward these key stimuli. Participants were 63 badminton novices, 20 national league players, and 21 local league players. A transparent red patch (exogenous orienting) was used to orient attention toward the trunk up to 160 ms before racket-shuttle contact; the arm, from 160 ms to 80 ms before contact; and the racket, from 80 ms before to actual contact. Results showed that badminton novices who trained with this program signifi cantly improved their anticipatory skill between post- and retention test compared with controls. Whereas local league players improved from pre- to posttest, training had no effect on expert national league players. It is concluded that using red transparent patches to highlight the most informative cues in perceptual training programs is a promising way to improve anticipatory skill.},
author = {Hagemann, N},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Sport \& Exercise Psychology/2006/Hagemann/Hagemann - 2006 - Training perceptual skill by orienting visual attention.pdf:pdf},
journal = {Journal of Sport \& Exercise Psychology},
number = {2},
pages = {143--158},
title = {{Training perceptual skill by orienting visual attention}},
url = {http://dialnet.unirioja.es/servlet/articulo?codigo=2261317&info=resumen&idioma=ENG},
volume = {28},
year = {2006}
}
@phdthesis{Karrsgard2003,
abstract = {Vision is the most complex human sense and a very important instrument for communication. A lot of knowledge about a person can be obtained by studying her eyes and it is possible to trace her true intent by observing her eye movements. In the same way as speech or handwriting analysis require accurate interpretation of the speech or the pen movements, visual impression analysis require accurate interpretation of the eye movements. In this thesis the gaze tracking system Smart Eye Pro, developed by Smart Eye AB, is evaluated in terms of its use in distinguishing small eye movements. The large amount of data obtained from the gaze tracker is refined and the thesis aims at evaluating the gain of interpreting the eye movements using hidden Markov models. An eye typing application is developed to facilitate the evaluation. In this application, the user forms a word by fixating characters on a screen in front of her. Eye typing is an interesting application since the quality of the interpretation is easy to determine and the application may be an important aid for people with a handicap that impair their ability to write.},
author = {K\"{a}rrsg\aa rd, I and Lindholm, A},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2003/K\"{a}rrsg\aa rd, Lindholm/K\"{a}rrsg\aa rd, Lindholm - 2003 - Eye movement tracking using hidden Markov models.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {40},
title = {{Eye movement tracking using hidden Markov models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.125.5895&rep=rep1&type=pdf},
year = {2003}
}
@inproceedings{Mohammadi2011,
abstract = {Pupil center localization is fundamental to calculate eye orientation and gaze direction in video-based systems. In previous techniques, either it is assumed that the pupil center is same as iris center or active illumination is utilized. In this paper, we have developed a new technique which utilizes eye geometry to localize pupil center without requiring special lighting. The main idea in the proposed technique is to restrict search space of the pupil center to the minor diameter of the iris ellipse proved from the geometrical model of eye proposed in this paper. In the proposed technique, we fit an ellipse to iris boundary, which is very simpler than ellipse fitting for pupil boundary in images on the common illumination, and then estimate pupil center by searching minor diameter of the iris ellipse. The performance of the method has been evaluated on both synthetic and real images.},
author = {Mohammadi, Mohammad Reza and Raie, Abolghasem},
booktitle = {2011 7th Iranian Conference on Machine Vision and Image Processing},
doi = {10.1109/IranianMVIP.2011.6121561},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 7th Iranian Conference on Machine Vision and Image Processing/2011/Mohammadi, Raie/Mohammadi, Raie - 2011 - A Novel Technique for Pupil Center Localization Based on Projective Geometry.pdf:pdf},
isbn = {978-1-4577-1535-8},
month = nov,
pages = {1--5},
publisher = {IEEE},
title = {{A Novel Technique for Pupil Center Localization Based on Projective Geometry}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6121561&contentType=Conference+Publications&searchField=Search_All&queryText=.QT.projective+geometry.QT.},
year = {2011}
}
@article{Lee2013c,
abstract = {Encoders are generally used to track the motion of industrial mechanisms. However, the information obtained by encoders may have errors due to encoder aging or mechanism-design problem. Therefore, information by visual feedback is a better way to track the movement of industrial mechanisms. However, image information costs lots of computing effort so it is not easy to be used in real-time control applications. This manuscript derives a simple but effective visual feedback method to follow the target and the image information is obtained only by a general handy camcorder. Besides, the proposed method can track multi-locations in a meantime. Fast image pattern recognition and localisation of the colour histogram by using a moving tracking block is applied to increase the calculation speed. Finally, the obtained locations information by the proposed visual feedback method is applied in an industrial crane control system to verify the effectiveness.},
author = {Lee, Lun-Hui and Huang, Pei-Hsiang and Pan, Shing-Tai and Lie, Handra Wijaya and Chiang, Tung-Chien and Chang, Cheng-Yuan},
doi = {10.1080/00207721.2013.779762},
file = {:home/acmt/Dropbox/Documentos/Mendeley/International Journal of Systems Science/2013/Lee et al/Lee et al. - 2013 - Applying vision feedback to crane controller design.pdf:pdf},
issn = {0020-7721},
journal = {International Journal of Systems Science},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
month = mar,
pages = {1--9},
title = {{Applying vision feedback to crane controller design}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00207721.2013.779762},
year = {2013}
}
@inproceedings{Lee2008,
address = {New York, New York, USA},
author = {Lee, Sangwon and Feng, David and Gooch, Bruce},
booktitle = {Proceedings of the 2008 symposium on Interactive 3D graphics and games - SI3D '08},
doi = {10.1145/1342250.1342269},
isbn = {9781595939838},
keywords = {perception,reconstruction,single-view reconstruction},
mendeley-tags = {reconstruction},
month = feb,
pages = {123},
publisher = {ACM Press},
title = {{Automatic construction of 3D models from architectural line drawings}},
url = {http://dl.acm.org/citation.cfm?id=1342250.1342269},
year = {2008}
}
@inproceedings{Willis2013,
abstract = {HideOut is a mobile projector-based system that enables new applications and interaction techniques with tangible objects and surfaces. HideOut uses a device mounted camera to detect hidden markers applied with infrared-absorbing ink. The obtrusive appearance of fiducial markers is avoided and the hidden marker surface doubles as a functional projection surface. We present example applications that demonstrate a wide range of interaction scenarios, including media navigation tools, interactive storytelling applications, and mobile games. We explore the design space enabled by the HideOut system and describe the hidden marker prototyping process. HideOut brings tangible objects to life for interaction with the physical world around us.},
address = {New York, New York, USA},
author = {Willis, Karl D. D. and Shiratori, Takaaki and Mahler, Moshe},
booktitle = {Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction - TEI '13},
doi = {10.1145/2460625.2460682},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction - TEI '13/2013/Willis, Shiratori, Mahler/Willis, Shiratori, Mahler - 2013 - HideOut.pdf:pdf},
isbn = {9781450318983},
keywords = {anamorphism},
mendeley-tags = {anamorphism},
pages = {331},
publisher = {ACM Press},
title = {{HideOut}},
url = {http://dl.acm.org/citation.cfm?id=2460682 http://dl.acm.org/citation.cfm?doid=2460625.2460682},
year = {2013}
}
@incollection{Regis2012,
abstract = {This paper focuses on ocular measurement to detect the human operator’s particular state of “attentional tunnelling” during a robot supervisory task. After a survey of the existing ocular metrics, an innovative fixation detection algorithm is proposed. Then the metrics derived from the ocular parameters calculated by the algorithm are tested in a human-robot experiment. Among the metrics calculated, 3 of them appear to be able to statisticaly discrimintate the operators who faced attentional tunnelling.},
address = {Toulouse, France.},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Regis, N and Dehais, F and Tessier, C and Giagnon, J. F.},
booktitle = {Human Factors and Ergonomics Society},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Human Factors and Ergonomics Society/2012/Regis et al/Regis et al. - 2012 - Ocular metrics for detecting attentional tunnelling.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {121--132},
title = {{Ocular metrics for detecting attentional tunnelling}},
url = {http://www.hfes-europe.org/books/proceedings2012/regis.pdf},
year = {2012}
}
@article{Oliveira2008,
author = {de Oliveira, Rita F. and Oudejans, Ra\^{o}ul R. D. and Beek, Peter J.},
doi = {10.1080/02701367.2008.10599504},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Research Quarterly for Exercise and Sport/2008/de Oliveira, Oudejans, Beek/de Oliveira, Oudejans, Beek - 2008 - Gaze Behavior in Basketball Shooting.pdf:pdf},
issn = {0270-1367},
journal = {Research Quarterly for Exercise and Sport},
month = sep,
number = {3},
pages = {399--404},
title = {{Gaze Behavior in Basketball Shooting}},
url = {http://www.tandfonline.com/doi/pdf/10.1080/02701367.2008.10599504},
volume = {79},
year = {2008}
}
@article{Fuchs2013,
address = {New York, New York, USA},
author = {Fuchs, Johannes and Fischer, Fabian and Mansmann, Florian and Bertini, Enrico and Isenberg, Petra},
doi = {10.1145/2470654.2466443},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3237},
publisher = {ACM Press},
title = {{Evaluation of alternative glyph designs for time series data in a small multiple setting}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466443},
year = {2013}
}
@article{Alper2013,
address = {New York, New York, USA},
author = {Alper, Basak and Bach, Benjamin and {Henry Riche}, Nathalie and Isenberg, Tobias and Fekete, Jean-Daniel},
doi = {10.1145/2470654.2470724},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Graph comparison,brain connectivity analysis,brain connectivity visualization.},
pages = {483},
publisher = {ACM Press},
title = {{Weighted graph comparison techniques for brain connectivity analysis}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470724},
year = {2013}
}
@misc{Heda2004,
author = {Heda, N},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2004/Heda/Heda - 2004 - Projector-camera Based Solutions for Simulation System.pdf:pdf},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {24},
title = {{Projector-camera Based Solutions for Simulation System}},
url = {http://www.cse.iitb.ac.in/~sharat/talks/nil.pdf},
year = {2004}
}
@inproceedings{Neto2006,
abstract = {There are several approaches for the treatment of phobias. The most effective, known as cognitive-behavior therapy, it bases on the gradual disensibility of the phobical individual through the exhibition to the stimulus cause of the fear. The idea of applying Interactive Systems in the phobias treatment it is promising for allowing the patient to access environments, objects or situations phobia causes with larger easiness, safety and low cost in relation to the traditional treatments. Taking as example phobias as airplane, height or driving, where the access and control of the environment are difficult and expensive, it can be elucidated the advantages of this tool. It is known that don't seek help about 60\% to 85\% of the people that suffer of these upset. The main reason is the enormous fear that they have to confront the object or the phobical situation. In spite of the traditional therapy to get good results. it is shown necessary the development of new tools that it encourage these people to seek the treatment, as, for example, interactive systems with virtual environment, that possess features that can exceed the results obtained by the conventional treatments.},
address = {Bel\'{e}m-PA},
author = {Neto, Ant\^{o}nio Val\'{e}rio},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {343--352},
publisher = {SBC},
title = {{Realidade Aumentada Aplicada ao Tratamento de Fobias}},
year = {2006}
}
@article{Hartley2000a,
author = {Hartley, R and Zisserman, A},
file = {::},
keywords = {computer vision,geometry,multiple view,perspective},
mendeley-tags = {computer vision,geometry,multiple view,perspective},
title = {{Multiple view geometry in computer vision}},
url = {http://journals.cambridge.org/production/action/cjoGetFulltext?fulltextid=289189},
year = {2000}
}
@incollection{Oyekoya2006a,
abstract = {The best interfaces are the most natural ones. They are unobtrusive and provide relevant information quickly and in ways that do not interfere with the task itself.},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Oyekoya, OK and Stentiford, FWM},
booktitle = {Intelligent Spaces},
doi = {10.1007/978-1-84628-429-8\_17},
edition = {17},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Intelligent Spaces/2006/Oyekoya, Stentiford/Oyekoya, Stentiford - 2006 - Eye Tracking as a New Interface for Image Retrieval.pdf:pdf},
isbn = {978-1-84628-429-8},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {273--286},
publisher = {Springer London},
title = {{Eye Tracking as a New Interface for Image Retrieval}},
url = {http://link.springer.com/content/pdf/10.1007/978-1-84628-429-8_17.pdf},
year = {2006}
}
@article{Komogortsev2013,
abstract = {Ternary eye movement classification, which separates fixations, saccades, and smooth pursuit from the raw eye positional data, is extremely challenging. This article develops new and modifies existing eye-tracking algorithms for the purpose of conducting meaningful ternary classification. To this end, a set of qualitative and quantitative behavior scores is introduced to facilitate the assessment of classification performance and to provide means for automated threshold selection. Experimental evaluation of the proposed methods is conducted using eye movement records obtained from 11 subjects at 1000 Hz in response to a step-ramp stimulus eliciting fixations, saccades, and smooth pursuits. Results indicate that a simple hybrid method that incorporates velocity and dispersion thresholding allows producing robust classification performance. It is concluded that behavior scores are able to aid automated threshold selection for the algorithms capable of successful classification.},
author = {Komogortsev, Oleg V and Karpov, Alex},
doi = {10.3758/s13428-012-0234-9},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2013/Komogortsev, Karpov/Komogortsev, Karpov - 2013 - Automated classification and scoring of smooth pursuit eye movements in the presence of fixations and sacca.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Adolescent,Adult,Algorithms,Automated,Automated: methods,Biological,Eye Movement Measurements,Fixation,Humans,Models,Ocular,Pattern Recognition,Pursuit,Reaction Time,Reference Values,Saccades,Smooth,Young Adult,gaze analysis,smooth pursuit},
mendeley-tags = {gaze analysis,smooth pursuit},
month = mar,
number = {1},
pages = {203--15},
pmid = {22806708},
title = {{Automated classification and scoring of smooth pursuit eye movements in the presence of fixations and saccades.}},
url = {http://link.springer.com/article/10.3758/s13428-012-0234-9 http://www.ncbi.nlm.nih.gov/pubmed/22806708},
volume = {45},
year = {2013}
}
@book{Ribeiro2011,
address = {Uberl\^{a}ndia},
author = {Ribeiro, Marcos Wagner S. and Zorzal, Ezequiel Roberto},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2011/Ribeiro, Zorzal/Ribeiro, Zorzal - 2011 - Pre-Symposium SVR 2011.pdf:pdf},
publisher = {SBC},
title = {{Pre-Symposium SVR 2011}},
year = {2011}
}
@article{postwimp,
author = {van Dam, Andries},
doi = {10.1145/253671.253708},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {SBGames},
mendeley-tags = {SBGames},
month = feb,
number = {2},
pages = {63--67},
publisher = {ACM},
title = {{Post-WIMP user interfaces}},
url = {http://portal.acm.org/citation.cfm?doid=253671.253708},
volume = {40},
year = {1997}
}
@article{Wagner2013,
address = {New York, New York, USA},
author = {Wagner, Julie and Nancel, Mathieu and Gustafson, Sean G. and Huot, Stephane and Mackay, Wendy E.},
doi = {10.1145/2470654.2466170},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1299},
publisher = {ACM Press},
title = {{Body-centric design space for multi-surface interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466170},
year = {2013}
}
@inproceedings{Meiguins2006,
abstract = {The goal of this chapter is to provide the reader a brief introduction on the necessary characteristics of a good information visualization tool, as well as the tasks the user may perform in this type of tool. Data types for visualization and the more adequate technique for each data type are also discussed. Finally, we present some information visualization techniques applied to three-dimensional virtual environments.},
address = {Bel\'{e}m-PA},
author = {Meiguins, Bianchi Serique and Gon\c{c}alves, Aruanda Sim\~{o}es and Garcia, Marcelo de Brito and Godinho, Paulo Igor Alves and J\'{u}nior, Rosevaldo Dias de Souza},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {319--326},
publisher = {SBC},
title = {{Realidade Virtual e Aumentada em Visualiza\c{c}\~{a}o de Informa\c{c}\~{a}o}},
year = {2006}
}
@article{Lauckner2013,
address = {New York, New York, USA},
author = {Lauckner, Carolyn and Hsieh, Gary},
doi = {10.1145/2470654.2470702},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {333--342},
publisher = {ACM Press},
title = {{The presentation of health-related search results and its impact on negative emotional outcomes}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470702},
year = {2013}
}
@article{Bowman2012,
abstract = {Electronic games are starting to incorporate in-game telemetry that collects data about player, team, and community performance on a massive scale, and as data begins to accumulate, so does the demand for effectively analyzing this data. In this paper, we use examples from both old and new games of different genres to explore the theory and design space of visualization for games. Drawing on these examples, we define a design space for this novel research topic and use it to formulate design patterns for how to best apply visualization technology to games. We then discuss the implications that this new framework will potentially have on the design and development of game and visualization technology in the future.},
author = {Bowman, B. and Elmqvist, N. and Jankun-Kelly, T. J.},
doi = {10.1109/TVCG.2012.77},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Communities,Computer games,Data visualization,Games,Real time systems,SBGames,Telemetry,Three dimensional displays,community performance,data analysis,data visualisation,design patterns,design space,electronic games,entertainment,game analytics,in-game telemetry,interactive entertainment,video games,visualization,visualization technology},
language = {English},
mendeley-tags = {SBGames},
month = nov,
number = {11},
pages = {1956--1968},
publisher = {IEEE},
title = {{Toward Visualization for Games: Theory, Design Space, and Patterns}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6165280},
volume = {18},
year = {2012}
}
@incollection{Bevington2002,
author = {Bevington, Philip},
booktitle = {Data Reduction and Error Analysis for the Physical Sciences},
chapter = {6},
title = {{Least-Squares Fit to a Straight Line}},
year = {2002}
}
@inproceedings{Rakprayoon2011,
abstract = {This paper presents a method to distinguish between obstacles and manipulator when they share the same workspace. Microsoft Kinect is used as a capturing device. A Kinect calibration method is explained. Furthermore, calibration between Kinect and the manipulator is addressed by iterative least-square method. 3D model of manipulator is generated using OpenGL library. Finally, the manipulator surface is deleted from the scene by intersection of data between the manipulator model and its corresponding point cloud.},
author = {Rakprayoon, Panjawee and Ruchanurucks, Miti and Coundoul, Ada},
booktitle = {2011 IEEE/SICE International Symposium on System Integration (SII)},
doi = {10.1109/SII.2011.6147421},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 IEEESICE International Symposium on System Integration (SII)/2011/Rakprayoon, Ruchanurucks, Coundoul/Rakprayoon, Ruchanurucks, Coundoul - 2011 - Kinect-based obstacle detection for manipulator.pdf:pdf},
isbn = {978-1-4577-1524-2},
month = dec,
pages = {68--73},
publisher = {IEEE},
title = {{Kinect-based obstacle detection for manipulator}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6147421&contentType=Conference+Publications&searchField=Search_All&queryText=kinect+calibration},
year = {2011}
}
@inproceedings{Lu2013,
abstract = {The prevalence of multi-touch devices opens the space for rich interactions. However, the complexity for creating multi-touch interactions hinders this potential. In this paper, we present Gesture Studio, a tool for creating multi-touch interaction behaviors by combining the strength of two distinct but complementary approaches: programming by demonstration and declaration. We employ an intuitive video-authoring metaphor for developers to demonstrate touch gestures, compose complicated behaviors, test these behaviors in the tool and export them as source code that can be integrated into the developers' project.},
address = {New York, New York, USA},
author = {L\"{u}, Hao and Li, Yang},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470690},
isbn = {9781450318990},
pages = {257--266},
publisher = {ACM Press},
title = {{Gesture studio: authoring multi-touch interactions through demonstration and declaration}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470690},
year = {2013}
}
@inproceedings{Hoiem2005,
address = {New York, New York, USA},
author = {Hoiem, Derek and Efros, Alexei A. and Hebert, Martial},
booktitle = {ACM SIGGRAPH 2005 Papers on - SIGGRAPH '05},
doi = {10.1145/1186822.1073232},
issn = {0730-0301},
keywords = {image segmentation,image-based rendering,machine learning,reconstruction,single-view reconstruction},
mendeley-tags = {reconstruction},
month = jul,
number = {3},
pages = {577},
publisher = {ACM Press},
title = {{Automatic photo pop-up}},
url = {http://dl.acm.org/citation.cfm?id=1186822.1073232 http://portal.acm.org/citation.cfm?doid=1186822.1073232},
volume = {24},
year = {2005}
}
@article{Hayhoe2005,
abstract = {The classic experiments of Yarbus over 50 years ago revealed that saccadic eye movements reflect cognitive processes. But it is only recently that three separate advances have greatly expanded our understanding of the intricate role of eye movements in cognitive function. The first is the demonstration of the pervasive role of the task in guiding where and when to fixate. The second has been the recognition of the role of internal reward in guiding eye and body movements, revealed especially in neurophysiological studies. The third important advance has been the theoretical developments in the fields of reinforcement learning and graphic simulation. All of these advances are proving crucial for understanding how behavioral programs control the selection of visual information.},
author = {Hayhoe, Mary and Ballard, Dana},
doi = {10.1016/j.tics.2005.02.009},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Trends in cognitive sciences/2005/Hayhoe, Ballard/Hayhoe, Ballard - 2005 - Eye movements in natural behavior.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Ambulatory,Ambulatory: instrumentation,Ambulatory: methods,Behavior,Behavior: physiology,Cognition,Cognition: physiology,Eye Movements,Eye Movements: physiology,Humans,Monitoring,Ocular,Ocular: physiology,Vision},
month = apr,
number = {4},
pages = {188--94},
pmid = {15808501},
title = {{Eye movements in natural behavior.}},
url = {http://www.sciencedirect.com/science/article/pii/S1364661305000598 http://www.ncbi.nlm.nih.gov/pubmed/15808501},
volume = {9},
year = {2005}
}
@article{DanielHerreraC2012,
abstract = {We present an algorithm that simultaneously calibrates two color cameras, a depth camera, and the relative pose between them. The method is designed to have three key features: accurate, practical, and applicable to a wide range of sensors. The method requires only a planar surface to be imaged from various poses. The calibration does not use depth discontinuities in the depth image, which makes it flexible and robust to noise. We apply this calibration to a Kinect device and present a new depth distortion model for the depth sensor. We perform experiments that show an improved accuracy with respect to the manufacturer's calibration.},
author = {{Daniel Herrera C} and {Juho Kannala} and {Janne Heikkil\"{a}}},
doi = {10.1109/TPAMI.2012.125},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on pattern analysis and machine intelligence/2012/Daniel Herrera C, Juho Kannala, Janne Heikkil\"{a}/Daniel Herrera C, Juho Kannala, Janne Heikkil\"{a} - 2012 - Joint depth and color camera calibration with distortion correction.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = oct,
number = {10},
pages = {2058--64},
pmid = {22641701},
title = {{Joint depth and color camera calibration with distortion correction.}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6205765&contentType=Journals+%26+Magazines&searchField%3DSearch_All%26queryText%3Dkinect+calibration http://www.ncbi.nlm.nih.gov/pubmed/22641701},
volume = {34},
year = {2012}
}
@article{Carvalho2011,
author = {Carvalho, Felipe and Trindade, Daniel R. and Dam, Peter F. and Raposo, Alberto and Santos, Ismael H. F. Dos},
doi = {10.1109/SVR.2011.30},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Carvalho et al/Carvalho et al. - 2011 - Dynamic Adjustment of Stereo Parameters for Virtual Reality Tools.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
keywords = {-virtual},
month = may,
pages = {66--72},
publisher = {Ieee},
title = {{Dynamic Adjustment of Stereo Parameters for Virtual Reality Tools}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951836},
year = {2011}
}
@inproceedings{Klein2007,
abstract = {This paper presents a method of estimating camera pose in an unknown scene. While this has previously been attempted by adapting SLAM algorithms developed for robotic exploration, we propose a system specifically designed to track a hand-held camera in a small AR workspace. We propose to split tracking and mapping into two separate tasks, processed in parallel threads on a dual-core computer: one thread deals with the task of robustly tracking erratic hand-held motion, while the other produces a 3D map of point features from previously observed video frames. This allows the use of computationally expensive batch optimisation techniques not usually associated with real-time operation: The result is a system that produces detailed maps with thousands of landmarks which can be tracked at frame-rate, with an accuracy and robustness rivalling that of state-of-the-art model-based systems.},
address = {Oxford},
annote = {
        From Duplicate 1 ( 
        
        
          Parallel Tracking and Mapping for Small AR Workspaces
        
        
         - Klein, Georg; Murray, David )
And  Duplicate 2 ( 
        
        
          Parallel Tracking and Mapping for Small AR Workspaces
        
        
         - Klein, Georg; Murray, David )

        
        

        

        

      },
author = {Klein, Georg and Murray, David},
booktitle = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2007.4538852},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality/2007/Klein, Murray/Klein, Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspaces.pdf:pdf},
isbn = {978-1-4244-1749-0},
keywords = {Algorithm design and analysis,Cameras,Concurrent computing,Handheld computers,Layout,Robot vision systems,Robustness,Simultaneous localization and mapping,Tracking,Yarn},
month = nov,
pages = {1--10},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping for Small AR Workspaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538852},
year = {2007}
}
@inproceedings{Rzeszotarski2013,
address = {New York, New York, USA},
author = {Rzeszotarski, Jeffrey M. and Kittur, Aniket},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
doi = {10.1145/2468356.2468675},
isbn = {9781450319522},
pages = {1779},
publisher = {ACM Press},
title = {{TouchViz}},
url = {http://dl.acm.org/citation.cfm?doid=2468356.2468675},
year = {2013}
}
@article{Tan2006,
abstract = {The proposed method performs the determination of eye blink states by tracking iris and eyelids. Two novelties of this method are the simultaneous exploitation of intensity and edge information for detecting the eye state as well as the record of the patterns of eyelids before closing for tracking the reopened eyes. Experiments show the efficiency of the proposed method.},
author = {Tan, Huachun and Zhang, Yu-Jin},
doi = {10.1016/j.patrec.2005.10.005},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Pattern Recognition Letters/2006/Tan, Zhang/Tan, Zhang - 2006 - Detecting eye blink states by tracking iris and eyelids.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = apr,
number = {6},
pages = {667--675},
title = {{Detecting eye blink states by tracking iris and eyelids}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865505002953 http://linkinghub.elsevier.com/retrieve/pii/S0167865505002953},
volume = {27},
year = {2006}
}
@inproceedings{Jung2004,
author = {Jung, Chang-Yun and Kim, Jin-Sung and Yoo, Chun-Sik and Kim, Yong-Sung},
booktitle = {2004 International Conference on Cyberworlds},
doi = {10.1109/CW.2004.13},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2004 International Conference on Cyberworlds/2004/Jung et al/Jung et al. - 2004 - A SMIL Document Generating System Using Temporal Scripts of Animation Component.pdf:pdf},
isbn = {0-7695-2140-1},
pages = {188--193},
publisher = {IEEE},
title = {{A SMIL Document Generating System Using Temporal Scripts of Animation Component}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/CW.2004.13 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1366173},
year = {2004}
}
@article{Phillips2013,
abstract = {PURPOSE: To develop an eye-tracking method applicable to three-dimensional (3D) images, where the abnormality is both moving and changing in size. MATERIALS AND METHODS: Research ethics committee approval was granted to record eye-tracking data from six inexperienced readers who inspected eight short (<30 seconds) endoluminal fly-through videos extracted from computed tomographic (CT) colonography examinations. Cases included true-positive and false-positive polyp detections from a previous study (polyp diameters, 5-25 mm). Eye tracking was performed with a desk-mounted tracker, and readers indicated when they saw a polyp with a mouse click. The polyp location on each video frame was quantified subsequently by using a circular mask. Gaze data related to each video frame were calculated relative to the visible polyp boundary and used to identify eye movements that pursue a polyp target as it changes size and position during fly-through. Gaze data were then related to positive polyp detections by readers. RESULTS: Tracking eye gaze on moving 3D images was technically feasible. Gaze was successfully classified by using pursuit analysis, and pursuit-based gaze metrics were able to help discriminate different reader search behaviors and methods of allocating visual attention during polyp identification. Of a total of 16 perceptual errors, 15 were recognition errors. There was only one visual search error. The largest polyp (25 mm) was seen but not recognized by five of six readers. CONCLUSION: Tracking a reader's gaze during endoluminal interpretation of 3D data sets is technically feasible and can be described with pursuit-based metrics. Perceptual errors can be classified into visual search errors and recognition errors. Recognition errors are more frequent in inexperienced readers.},
author = {Phillips, Peter and Boone, Darren and Mallett, Susan and Taylor, Stuart A and Altman, Douglas G and Manning, David and Gale, Alastair and Halligan, Steve},
doi = {10.1148/radiol.12120062},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Radiology/2013/Phillips et al/Phillips et al. - 2013 - Method for tracking eye gaze during interpretation of endoluminal 3D CT colonography technical description and.pdf:pdf},
issn = {1527-1315},
journal = {Radiology},
keywords = {Clinical Competence,Colonic Polyps,Colonic Polyps: radiography,Colonography,Computed Tomographic,Computer-Assisted,Diagnostic Errors,Eye Movements,Humans,Imaging,Radiographic Image Interpretation,Three-Dimensional,gaze analysis},
mendeley-tags = {gaze analysis},
month = jun,
number = {3},
pages = {924--31},
pmid = {23382289},
title = {{Method for tracking eye gaze during interpretation of endoluminal 3D CT colonography: technical description and proposed metrics for analysis.}},
url = {http://radiology.rsna.org/content/267/3/924.short http://www.ncbi.nlm.nih.gov/pubmed/23382289},
volume = {267},
year = {2013}
}
@inproceedings{Macal2009,
author = {Macal, Charles M and North, Michael J},
booktitle = {Proceedings of the 2009 Winter Simulation Conference (WSC)},
doi = {10.1109/WSC.2009.5429318},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2009 Winter Simulation Conference (WSC)/2009/Macal, North/Macal, North - 2009 - Agent-based modeling and simulation.pdf:pdf},
isbn = {978-1-4244-5770-0},
month = dec,
pages = {86--98},
publisher = {IEEE},
title = {{Agent-based modeling and simulation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5429318},
year = {2009}
}
@inproceedings{Song2008,
address = {New York, New York, USA},
author = {Song, Peng and Yu, Hang and Winkler, Stefan},
booktitle = {Proceedings of The 7th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry - VRCAI '08},
doi = {10.1145/1477862.1477871},
isbn = {9781605583358},
keywords = {finger interaction,finger tracking,mixed reality},
number = {June 2008},
pages = {1},
publisher = {ACM Press},
title = {{Vision-based 3D finger interactions for mixed reality games with physics simulation}},
url = {http://portal.acm.org/citation.cfm?doid=1477862.1477871},
volume = {8},
year = {2008}
}
@book{Russel1995,
address = {New Jersey},
author = {Russel, Stuart J and Norvig, Peter},
editor = {Pompilli, Mona and Chavez, Sondra and McGuire, Shirley},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/1995/Russel, Norvig/Russel, Norvig - 1995 - Artificial Intelligence A Modern Approach.pdf:pdf},
isbn = {0131038052},
issn = {1682-8658},
number = {2},
pages = {946},
pmid = {21560649},
publisher = {Prentice-Hall},
title = {{Artificial Intelligence A Modern Approach}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21932643},
year = {1995}
}
@inproceedings{Gong2009,
abstract = {This paper has summarized the conceptions of human-machine systems and human-computer interface,studied and analyzed the ways of human-computer interaction. Under these instructions, it proposed the design process and methods of human-computer interface,as well as some attentive points and the basic principles to be abided by during the design process, which gives some interface designation basis for the design of human machine systems and has certain guidance significance.The major ideas of this paper are to explain how to improve the human-machine systems, how to make machines adapt to and serve humans effectively and better,thereby brings the humans, machines and environment into a harmonious relationship.},
address = {Bangkok},
author = {Gong, Chaohua},
booktitle = {2009 International Conference on Computer and Automation Engineering},
doi = {10.1109/ICCAE.2009.23},
isbn = {978-0-7695-3569-2},
month = mar,
pages = {230--233},
publisher = {IEEE},
title = {{Human-Computer Interaction: Process and Principles of Human-Computer Interface Design}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4804523},
year = {2009}
}
@article{Urruty2007a,
abstract = {Eye movements are certainly the most natural and repetitive movement of a human being. The most mundane activity, such as watching television or reading a newspaper, involves this automatic activity which consists of shifting our gaze from one point to another. Identification of the components of eye movements (fixations and saccades) is an essential part in the analysis of visual behavior because these types of movements provide the basic elements used by further investigations of human vision. However, many of the algorithms that detect fixations present a number of problems. In this article, we present a new fixation identification technique that is based on clustering of eye positions, using projections and projection aggregation applied to static pictures. We also present a new method that computes dispersion of eye fixations in videos considering a multiuser environment. To demonstrate the performance and usefulness of our approach we discuss our experimental work with two different applications: on fixed image and video.},
annote = {
        From Duplicate 1 ( 
        
        
          Detecting eye fixations by projection clustering
        
        
         - Urruty, T; Lew, S )

        
        
- cited by: 13
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000

        

      },
author = {Urruty, Thierry and Lew, Stanislas and Ihadaddene, Nacim and Simovici, Dan A.},
doi = {10.1145/1314303.1314308},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM Transactions on Multimedia Computing, Communications, and Applications/2007/Urruty et al/Urruty et al. - 2007 - Detecting eye fixations by projection clustering.pdf:pdf},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = dec,
number = {4},
pages = {1--20},
title = {{Detecting eye fixations by projection clustering}},
url = {http://dl.acm.org/citation.cfm?id=1314308 http://portal.acm.org/citation.cfm?doid=1314303.1314308},
volume = {3},
year = {2007}
}
@book{Wainer2009,
address = {New York, New York, USA},
author = {Wainer, Gabriel A.},
edition = {2},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2009/Wainer/Wainer - 2009 - Discrete-Event Modeling and Simulation A Practitioner's Approach (Computational Analysis, Synthesis, and Design of Dynam.pdf:pdf},
isbn = {9781420053364},
pages = {486},
publisher = {CRC Press},
title = {{Discrete-Event Modeling and Simulation: A Practitioner's Approach (Computational Analysis, Synthesis, and Design of Dynamic Systems)}},
url = {http://www.amazon.com/Discrete-Event-Modeling-Simulation-Practitioners- Computational/dp/1420053361},
year = {2009}
}
@inproceedings{Lee2013,
abstract = {A video see-through head mounted display (HMD) has a different viewing point than does the real eye, resulting in visual displacement (VD). VD deteriorates visuomotor performance due to sensory conflict. Previous work has investigated this deterioration and human adaptation by comparing fixed VD and real eye conditions. In this study we go a step further to investigate whether any differences in visuomotor and adaptation trends exist across 16 distinct VD conditions. The performance tasks studied were of two types: foot placement and finger touch. In contrast to our initial prediction, the results showed equal task performance levels and adaptation within about 5 minutes regardless of VD conditions. We found that human adaptation covered a variety of VDs --- up to 55 mm in the X, Y direction; up to 125mm in the Z direction; and up to 140mm of interocular distance (IOD). In addition, we found that partial adaptation gave participants the interesting experience of a sense of body structure distortion for a few minutes.},
address = {New York, New York, USA},
author = {Lee, Joong Ho and Kim, Sei-young and Yoon, Hae Cheol and Huh, Bo Kyung and Park, Ji-Hyung},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470698},
isbn = {9781450318990},
pages = {309--312},
publisher = {ACM Press},
title = {{A preliminary investigation of human adaptations for various virtual eyes in video see-through HMDS}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470698},
year = {2013}
}
@article{Rolland2002,
author = {Rolland, J. and Davis, L. and Meyer, C. and Shaoulov, V. and Akcay, a. and Banks, R. and {Del Vento}, B.},
doi = {10.1109/38.974512},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Computer Graphics and Applications/2002/Rolland et al/Rolland et al. - 2002 - 3D visualization and imaging in distributed collaborative environments.pdf:pdf},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {1},
pages = {11--13},
title = {{3D visualization and imaging in distributed collaborative environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=974512},
volume = {22},
year = {2002}
}
@article{Hong2013,
address = {New York, New York, USA},
author = {Hong, Hwajung and Yarosh, Svetlana and Kim, Jennifer G. and Abowd, Gregory D. and Arriaga, Rosa I.},
doi = {10.1145/2470654.2466439},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3207},
publisher = {ACM Press},
title = {{Investigating the use of circles in social networks to support independence of individuals with autism}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466439},
year = {2013}
}
@article{Caldara2011,
abstract = {Eye movement data analyses are commonly based on the probability of occurrence of saccades and fixations (and their characteristics) in given regions of interest (ROIs). In this article, we introduce an alternative method for computing statistical fixation maps of eye movements--iMap--based on an approach inspired by methods used in functional magnetic resonance imaging. Importantly, iMap does not require the a priori segmentation of the experimental images into ROIs. With iMap, fixation data are first smoothed by convolving Gaussian kernels to generate three-dimensional fixation maps. This procedure embodies eyetracker accuracy, but the Gaussian kernel can also be flexibly set to represent acuity or attentional constraints. In addition, the smoothed fixation data generated by iMap conform to the assumptions of the robust statistical random field theory (RFT) approach, which is applied thereafter to assess significant fixation spots and differences across the three-dimensional fixation maps. The RFT corrects for the multiple statistical comparisons generated by the numerous pixels constituting the digital images. To illustrate the processing steps of iMap, we provide sample analyses of real eye movement data from face, visual scene, and memory processing. The iMap MATLAB toolbox is editable and freely available for download online (www.unifr.ch/psycho/ibmlab/).},
annote = {crossRef(Jarodzka 2010)},
author = {Caldara, Roberto and Miellet, S\'{e}bastien},
doi = {10.3758/s13428-011-0092-x},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2011/Caldara, Miellet/Caldara, Miellet - 2011 - iMap a novel method for statistical fixation mapping of eye movement data.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Algorithms,Biometry,Biometry: methods,Data Interpretation, Statistical,Eye Movement Measurements,Eye Movement Measurements: statistics \& numerical ,Eye Movements,Humans,Software,eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
month = sep,
number = {3},
pages = {864--78},
pmid = {21512875},
title = {{iMap: a novel method for statistical fixation mapping of eye movement data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21512875},
volume = {43},
year = {2011}
}
@inproceedings{Behzadan2008,
author = {Behzadan, Amir H. and Kamat, Vineet R},
booktitle = {2008 Winter Simulation Conference},
doi = {10.1109/WSC.2008.4736353},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2008 Winter Simulation Conference/2008/Behzadan, Kamat/Behzadan, Kamat - 2008 - Simulation and visualization of traffic operations in Augmented Reality for improved planning and design of roa.pdf:pdf},
isbn = {978-1-4244-2707-9},
month = dec,
pages = {2447--2454},
publisher = {IEEE},
title = {{Simulation and visualization of traffic operations in Augmented Reality for improved planning and design of road construction projects}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4736353},
year = {2008}
}
@inproceedings{Raskar2006,
abstract = {Projectors are currently undergoing a transformation as they evolve from static output devices to portable, environment-aware, com- municating systems. An enhanced projector can determine and re- spond to the geometry of the display surface, and can be used in an ad-hoc cluster to create a self-configuring display. Information display is such a prevailing part of everyday life that new and more flexible ways to present data are likely to have significant impact. This paper examines geometrical issues for enhanced projectors, re- lating to customized projection for different shapes of display sur- face, object augmentation, and co-operation between multiple units. We introduce a new technique for adaptive projection on non- planar surfaces using conformal texture mapping. We describe ob- ject augmentation with a hand-held projector, including interaction techniques. We describe the concept of a display created by an ad-hoc cluster of heterogeneous enhanced projectors, with a new global alignment scheme, and new parametric image transfer meth- ods for quadric surfaces, to make a seamless projection. The work is illustrated by several prototypes and applications.},
address = {New York, New York, USA},
author = {Raskar, Ramesh and van Baar, Jeroen and Beardsley, Paul and Willwacher, Thomas and Rao, Srinivas and Forlines, Clifton},
booktitle = {ACM SIGGRAPH 2006 Courses on - SIGGRAPH '06},
doi = {10.1145/1185657.1185802},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM SIGGRAPH 2006 Courses on - SIGGRAPH '06/2006/Raskar et al/Raskar et al. - 2006 - iLamps geometrically aware and self-configuring projectors.pdf:pdf},
isbn = {1595933646},
keywords = {ad-hoc clusters,anamorphism,augmented reality,calibration,keystone,projector,quadric transfer,seamless display},
mendeley-tags = {anamorphism,keystone},
month = jul,
pages = {7},
publisher = {ACM Press},
title = {{iLamps: geometrically aware and self-configuring projectors}},
url = {http://dl.acm.org/citation.cfm?id=1185657.1185802 http://portal.acm.org/citation.cfm?doid=1185657.1185802},
year = {2006}
}
@book{Wedel2008,
abstract = {In the last decade there has been a rapid growth in commercial applications of eye-tracking technology to assess the effectiveness of visual marketing efforts. Eye-movements are tightly coupled with visual attention which makes them eminent indicators of the covert visual attention process. Now a sizable and growing body of literature exists on attention to visual marketing stimuli. Eye-Tracking for Visual Marketing provides: 1. The foundations of visual attention and eye-tracking; 2. A conceptual framework for eyetracking research in marketing; 3. A review of the marketing literature within this conceptual framework. Motivated from its rising importance in marketing practice and its potential for theoretical contribution, Eye-Tracking for Visual Marketing examines the structure of the eye, the visual brain, eye-movements, and methods for recording and analyzing them. Next, it describes the authors' theory and reviews eye-tracking applications in marketing based on this theory. It conclude with an outlook on future theory and method development and recommendations for practice.},
annote = {- cited by: 35
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Wedel, M and Pieters, R},
doi = {10.1561/9781601981554},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2008/Wedel, Pieters/Wedel, Pieters - 2008 - Eye tracking for visual marketing.pdf:pdf},
isbn = {9781601981547},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {93},
publisher = {Now Publishers Inc},
title = {{Eye tracking for visual marketing}},
url = {http://books.google.com.br/books?hl=pt-BR&lr=&id=_yjIeqbC8fMC&oi=fnd&pg=PA1&dq=identification+fixation+eye&ots=ohmt0F8jvc&sig=hAnJXqqRZC0NbTNsBDJxKuMrdrM},
year = {2008}
}
@article{Butz1999,
author = {Butz, A and H\"{o}llerer, T and Feiner, S and MacIntyre, B and Beshers, C},
doi = {10.1109/IWAR.1999.803804},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality IWAR99/1999/Butz et al/Butz et al. - 1999 - Enveloping users and computers in a collaborative 3D augmented reality.pdf:pdf},
isbn = {0769503594},
journal = {Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality IWAR99},
pages = {35--44},
publisher = {IEEE Comput. Soc},
title = {{Enveloping users and computers in a collaborative 3D augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=803804},
volume = {99},
year = {1999}
}
@article{Ferreira2012,
author = {Ferreira, Alessandro Luiz Stamatto and Santos, Selan Rodrigues Dos and Miranda, Leonardo Cunha De},
doi = {10.1109/SVR.2012.14},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Ferreira, Santos, Miranda/Ferreira, Santos, Miranda - 2012 - TrueSight A Pedestrian Navigation System Based in Automatic Landmark Detection and Extraction on Andr.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {-landmark,Android,Landmark Recognition,Localization,Mobile Device,Navigation},
month = may,
pages = {91--99},
publisher = {Ieee},
title = {{TrueSight A Pedestrian Navigation System Based in Automatic Landmark Detection and Extraction on Android Smartphone}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297564},
year = {2012}
}
@article{Papadopoulos2013,
abstract = {In this paper, a gaze-based Relevance Feedback (RF) approach to region-based image retrieval is presented. Fundamental idea of the proposed method comprises the iterative estimation of the real-world objects (or their constituent parts) that are of interest to the user and the subsequent exploitation of this information for refining the image retrieval results. Primary novelties of this work are: a) the introduction of a new set of gaze features for realizing user’s relevance assessment prediction at region-level, and b) the design of a time-efficient and effective object-based RF framework for image retrieval. Regarding the interpretation of the gaze signal, a novel set of features is introduced by formalizing the problem under a mathematical perspective, contrary to the exclusive use of explicitly defined features that are in principle derived from the psychology domain. Apart from the temporal attributes, the proposed features also represent the spatial characteristics of the gaze signal, which have not been extensively studied in the literature so far. On the other hand, the developed object-based RF mechanism aims at overcoming the main limitation of region-based RF approaches, i.e. the frequently inaccurate estimation of the regions of interest in the retrieved images. Moreover, the incorporation of a single-camera image processing-based gaze tracker makes the overall system cost efficient and portable. As it is shown by the experimental evaluation, the proposed method outperforms representative global- and region-based explicit RF approaches, using a challenging general-purpose image dataset.},
annote = {- cited by: 0
- kw: identification I-DT eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Papadopoulos, G. and Apostolakis, K. and Daras, P.},
doi = {10.1109/TMM.2013.2291535},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Multimedia/2013/Papadopoulos, Apostolakis, Daras/Papadopoulos, Apostolakis, Daras - 2013 - Gaze-Based Relevance Feedback for Realizing Region-Based Image Retrieval.pdf:pdf},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
keywords = {Relevance feedback,gaze analysis,gaze-tracking,image retrieval},
mendeley-tags = {gaze analysis},
number = {99},
pages = {1},
shorttitle = {Multimedia, IEEE Transactions on},
title = {{Gaze-Based Relevance Feedback for Realizing Region-Based Image Retrieval}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6671553&tag=1},
volume = {PP},
year = {2013}
}
@article{Lee2013b,
address = {New York, New York, USA},
author = {Lee, Uichin and Kim, Jihyoung and Yi, Eunhee and Sung, Juyup and Gerla, Mario},
doi = {10.1145/2470654.2470730},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {533},
publisher = {ACM Press},
title = {{Analyzing crowd workers in mobile pay-for-answer q\&a}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470730},
year = {2013}
}
@inproceedings{Chabbi,
abstract = {The planar surfaces (3-D faces) of the objects of a polyhedral scene are built using a trinocular stereovision system. Before the reconstruction step and after the step of matching, a search is conducted among the set of triplets of matched 2-D faces (supposed to be the projection of 3-D faces) for the triplets which really correspond to planar 3-D surfaces. To accurately reconstruct the surface, a check is conducted in 2-D space for the classes of triplets of faces which correspond to 3-D coplanar structures. It is shown how these 3-D properties are checked in the 2-D space, using tools of projective geometry, allowing the constraint of the 3-D reconstruction in order to maintain these 3-D properties},
author = {Chabbi, H. and Berger, M.-O.},
booktitle = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.1993.341045},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of IEEE Conference on Computer Vision and Pattern Recognition/Unknown/Chabbi, Berger/Chabbi, Berger - Unknown - Recovering planar surfaces by stereovision based on projective geometry.pdf:pdf},
isbn = {0-8186-3880-X},
pages = {649--650},
publisher = {IEEE Comput. Soc. Press},
title = {{Recovering planar surfaces by stereovision based on projective geometry}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=341045&contentType=Conference+Publications&searchField=Search_All&queryText=.QT.projective+geometry.QT.}
}
@article{Qu2013,
address = {New York, New York, USA},
author = {Qu, Yan and Zhang, Jun},
doi = {10.1145/2470654.2470711},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Human Mobility,OPTICS,Regularly Visited Patches},
pages = {395},
publisher = {ACM Press},
title = {{Regularly visited patches in human mobility}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470711},
year = {2013}
}
@misc{Simlox2011,
author = {Simlox},
title = {{Simlox}},
url = {http://www.systecon.se/case/C3_SIMLOX/},
year = {2011}
}
@book{Tiller2001,
abstract = {The first book on Modelica, a modeling language that can be used to simulate both continuous and discrete behavior, Introduction to Physical Modeling with Modelica provides the necessary background to develop Modelica models of almost any physical system. The author starts with basic differential equations from several engineering domains and describes how these equations can be used to create reusable component models. Next, he describes techniques for modeling complex non-linear behavior, exploiting the powerful array handling features and mixing continuous and discrete behavior. The second part of the book focuses on effective use of all the language features provided by the Modelica modeling language. This includes, among other things, discussions on maximizing the reusability of component models being developed, managing the model development process, and making models as computationally efficient as possible. Introduction to Physical Modeling with Modelica includes online access to supplementary material containing the Modelica source code for all examples as well as an evaluation copy of Dymola. Using Dymola, readers can immediately begin to explore the dynamics of the models included with the book or to develop their own models. Nearly 100 examples of mechanical, electrical, biological, chemical, thermal and hydraulic models are included. Introduction to Physical Modeling with Modelica will be of interest to all professional engineers and university researchers developing physical models. Students studying control system development or modeling of physical systems will also find it useful.},
author = {Tiller, Michael},
edition = {1},
pages = {368},
publisher = {Springer},
title = {{Introduction to Physical Modeling with Modelica}},
url = {http://www.amazon.com/Introduction-Physical-Modeling-International- Engineering/dp/0792373677},
year = {2001}
}
@article{Heun2013,
address = {New York, New York, USA},
author = {Heun, Valentin and Group, Fluid Interfaces and Kasahara, Shunichi and Corporation, Sony and Maes, Pattie},
doi = {10.1145/2468356.2468528},
isbn = {9781450319522},
journal = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
pages = {2939--2942},
publisher = {ACM Press},
title = {{Smarter Objects: Using AR Technology to Program Physical Objects and their Interactions}},
url = {http://dl.acm.org/citation.cfm?doid=2468356.2468528},
year = {2013}
}
@article{McDonald2013,
address = {New York, New York, USA},
author = {McDonald, Sharon and Petrie, Helen},
doi = {10.1145/2470654.2481407},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2941},
publisher = {ACM Press},
title = {{The effect of global instructions on think-aloud testing}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481407},
year = {2013}
}
@inproceedings{West2006,
abstract = {Fixation sequence analysis can reveal the cognitive strategies that drive eye movements. Unfortunately this type of analysis is not as common as other popular eye movement measures, such as fixation duration and trace length, because the proper tools for fixation sequence analysis are not incorporated into most popular eye movement software. This paper describes eyePatterns, a new tool for discovering similarities in fixation sequences and identifying the experimental variables that may influence their characteristics.},
address = {New York, New York, USA},
author = {West, Julia M. and Haake, Anne R. and Rozanski, Evelyn P. and Karn, Keith S.},
booktitle = {Proceedings of the 2006 symposium on Eye tracking research \& applications - ETRA '06},
doi = {10.1145/1117309.1117360},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2006 symposium on Eye tracking research \& applications - ETRA '06/2006/West et al/West et al. - 2006 - eyePatterns software for identifying patterns and similarities across fixation sequences.pdf:pdf},
isbn = {1595933050},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
pages = {149},
publisher = {ACM Press},
title = {{eyePatterns: software for identifying patterns and similarities across fixation sequences}},
url = {http://dl.acm.org/citation.cfm?id=1117360 http://portal.acm.org/citation.cfm?doid=1117309.1117360},
year = {2006}
}
@article{Dorr2010,
abstract = {How similar are the eye movement patterns of different subjects when free viewing dynamic natural scenes? We collected a large database of eye movements from 54 subjects on 18 high-resolution videos of outdoor scenes and measured their variability using the Normalized Scanpath Saliency, which we extended to the temporal domain. Even though up to about 80\% of subjects looked at the same image region in some video parts, variability usually was much greater. Eye movements on natural movies were then compared with eye movements in several control conditions. "Stop-motion" movies had almost identical semantic content as the original videos but lacked continuous motion. Hollywood action movie trailers were used to probe the upper limit of eye movement coherence that can be achieved by deliberate camera work, scene cuts, etc. In a "repetitive" condition, subjects viewed the same movies ten times each over the course of 2 days. Results show several systematic differences between conditions both for general eye movement parameters such as saccade amplitude and fixation duration and for eye movement variability. Most importantly, eye movements on static images are initially driven by stimulus onset effects and later, more so than on continuous videos, by subject-specific idiosyncrasies; eye movements on Hollywood movies are significantly more coherent than those on natural movies. We conclude that the stimuli types often used in laboratory experiments, static images and professionally cut material, are not very representative of natural viewing behavior. All stimuli and gaze data are publicly available at http://www.inb.uni-luebeck.de/tools-demos/gaze.},
annote = {- cited by:71
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Dorr, Michael and Martinetz, Thomas and Gegenfurtner, Karl R and Barth, Erhardt},
doi = {10.1167/10.10.28},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of vision/2010/Dorr et al/Dorr et al. - 2010 - Variability of eye movements when viewing dynamic natural scenes.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {Eye Movements,Eye Movements: physiology,Fixation,Humans,Motion Perception,Motion Perception: physiology,Ocular,Ocular: physiology,Pattern Recognition,Photic Stimulation,Visual,Visual: physiology,gaze analysis},
mendeley-tags = {gaze analysis},
month = jan,
number = {10},
pages = {28},
pmid = {20884493},
title = {{Variability of eye movements when viewing dynamic natural scenes.}},
url = {http://ww.journalofvision.org/content/10/10/28.short http://www.ncbi.nlm.nih.gov/pubmed/20884493},
volume = {10},
year = {2010}
}
@book{bennett2011affine,
author = {Bennett, K},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2011/Bennett/Bennett - 2011 - Affine and Projective Geometry.pdf:pdf},
isbn = {9781118030820},
publisher = {Wiley},
title = {{Affine and Projective Geometry}},
url = {http://books.google.com.br/books?id=DF9Jb83ashUC},
year = {2011}
}
@inproceedings{Marin2008,
abstract = {In this study we have compared the subjective effect of distortions simulated ophthalmic lenses in a virtual lens simulator to the equivalent real ophthalmic test lenses, in static monocular and dynamic, monocular and binocular conditions, taking care of matching as best as possible virtual and real conditions. Though visual perception was found to be similar in static condition, distortions were judged to be exaggerated by the virtual lenses in dynamic conditions.},
address = {New York, New York, USA},
author = {Marin, Gildas and Terrenoire, Edith and Hernandez, Martha},
booktitle = {Proceedings of the 2008 ACM symposium on Virtual reality software and technology - VRST '08},
doi = {10.1145/1450579.1450648},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2008 ACM symposium on Virtual reality software and technology - VRST '08/2008/Marin, Terrenoire, Hernandez/Marin, Terrenoire, Hernandez - 2008 - Compared distortion effects between real and virtual ophthalmic lenses with a simulator.pdf:pdf},
isbn = {9781595939517},
pages = {271},
publisher = {ACM Press},
title = {{Compared distortion effects between real and virtual ophthalmic lenses with a simulator}},
url = {http://portal.acm.org/citation.cfm?id=1450648 http://portal.acm.org/citation.cfm?doid=1450579.1450648},
year = {2008}
}
@article{Thimbleby2013,
address = {New York, New York, USA},
author = {Thimbleby, Harold},
doi = {10.1145/2470654.2466190},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13/2013/Thimbleby/Thimbleby - 2013 - Reasons to question seven segment displays.pdf:pdf},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1431},
publisher = {ACM Press},
title = {{Reasons to question seven segment displays}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466190},
year = {2013}
}
@misc{Accattato,
author = {Accattato, Dominick},
title = {{Red5}},
url = {http://www.red5.org},
urldate = {17/01/2010}
}
@article{Nieuwenhuizen2009,
author = {Nieuwenhuizen, Karin and Liu, Lei and Liere, Robert Van and Martens, Jean-Bernard},
doi = {10.1109/MCG.2009.121},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Computer Graphics and Applications/2009/Nieuwenhuizen et al/Nieuwenhuizen et al. - 2009 - Insights from Dividing 3D Goal-Directed Movements into Meaningful Phases.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
month = nov,
number = {6},
pages = {44--53},
title = {{Insights from Dividing 3D Goal-Directed Movements into Meaningful Phases}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5307642},
volume = {29},
year = {2009}
}
@inproceedings{Bulling2013,
abstract = {In this work we present EyeContext, a system to infer high-level contextual cues from human visual behaviour. We conducted a user study to record eye movements of four participants over a full day of their daily life, totalling 42.5 hours of eye movement data. Participants were asked to self-annotate four non-mutually exclusive cues: social (interacting with somebody vs. no interaction), cognitive (concentrated work vs. leisure), physical (physically active vs. not active), and spatial (inside vs. outside a building). We evaluate a proof-of-concept EyeContext system that combines encoding of eye movements into strings and a spectrum string kernel support vector machine (SVM) classifier. Our results demonstrate the large information content available in long-term human visual behaviour and opens up new venues for research on eye-based behavioural monitoring and life logging.},
address = {New York, New York, USA},
author = {Bulling, Andreas and Weichel, Christian and Gellersen, Hans},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470697},
isbn = {9781450318990},
keywords = {Context Recognition,Electrooculography (EOG),Eye Movement Analysis,Visual Behaviour},
pages = {305--308},
publisher = {ACM Press},
title = {{EyeContext: recognition of high-level contextual cues from human visual behaviour}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470697},
year = {2013}
}
@inproceedings{Drusch2011,
abstract = {Eye-tracking studies have provided us with interesting findings regarding the way users explore Web pages. Usually, visual fixations are represented using gaze plots and heatmaps. Probably one of the most cited studies on Web page exploration is the one by Nielsen [15] who demonstrated that users often read Web pages in an F-shaped pattern. However, this conclusion is based on aggregated data that do not represent any real user. In order to characterize and to compare scanpaths so as to uncover possible scan-patterns, a clustering method based on the Hausdorff distance has been applied to the data from 113 users. The results have shown that scan-patterns could be identified. Groups of users have been identified and their behaviors have been described with diverse eye-tracking metrics. The contributions of this study are outlined as well as its drawbacks. Research perspectives are proposed.},
address = {New York, New York, USA},
author = {Drusch, Gautier and Bastien, J. M. Christian and Dinet, J\'{e}r\^{o}me},
booktitle = {23rd French Speaking Conference on Human-Computer Interaction - IHM '11},
doi = {10.1145/2044354.2044356},
file = {:home/acmt/Dropbox/Documentos/Mendeley/23rd French Speaking Conference on Human-Computer Interaction - IHM '11/2011/Drusch, Bastien, Dinet/Drusch, Bastien, Dinet - 2011 - From gaze plots to eye fixation patterns using a clustering method based on Hausdorff distances.pdf:pdf},
isbn = {9781450308229},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
pages = {1},
publisher = {ACM Press},
title = {{From gaze plots to eye fixation patterns using a clustering method based on Hausdorff distances}},
url = {http://dl.acm.org/citation.cfm?id=2044356 http://dl.acm.org/citation.cfm?doid=2044354.2044356},
year = {2011}
}
@article{Xu,
author = {Xu, W and Wang, Y and Liu, Y and Weng, D and Tan, M and Salzmann, M},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
title = {{REAL-TIME KEYSTONE CORRECTION FOR HAND-HELD PROJECTORS WITH AN RGBD CAMERA}},
url = {http://scholar.google.com.br/scholar?hl=pt-BR&q=REAL-TIME+KEYSTONE+CORRECTION+FOR+HAND-HELD+PROJECTORS+WITH+AN+RGBDCAMERA&btnG=&lr=#0}
}
@inproceedings{Raskar2001a,
abstract = {We describe a calibration and rendering technique for a projector that can render rectangular images under keystoned position. The projector utilizes a rigidly attached camera to form a stereo pair. We describe a very easy to use technique for calibration of the projector-camera pair using only black planar surfaces. We present an efficient rendering method to pre-warp images so that they appear correctly on the screen, and show experimental results.},
author = {Raskar, R. and Beardsley, P.},
booktitle = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
doi = {10.1109/CVPR.2001.991004},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001/2001/Raskar, Beardsley/Raskar, Beardsley - 2001 - A self-correcting projector.pdf:pdf},
isbn = {0-7695-1272-0},
issn = {1063-6919},
keywords = {Calibration,Cameras,Computational geometry,Computer vision,Displays,Laboratories,Lenses,Prototypes,Rendering (computer graphics),Stereo vision,anamorphism,black planar surfaces,homography,keystone,keystoned position,optical projectors,rectangular images,rendering,self-correcting projector,stereo pair},
mendeley-tags = {anamorphism,keystone},
pages = {II--504--II--508},
publisher = {IEEE Comput. Soc},
shorttitle = {Computer Vision and Pattern Recognition, 2001. CVP},
title = {{A self-correcting projector}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=991004},
volume = {2},
year = {2001}
}
@inproceedings{Wang2013a,
abstract = {Although both men and women communicate frequently on Facebook, we know little about what they talk about, whether their topics differ and how their network responds. Using Latent Dirichlet Allocation (LDA), we identify topics from more than half a million Facebook status updates and determine which topics are more likely to receive feedback, such as likes and comments. Women tend to share more personal topics (e.g., family matters), while men discuss more public ones (e.g., politics and sports). Generally, women receive more feedback than men, but "male" topics (those more often posted by men) receive more feedback, especially when posted by women.},
address = {New York, New York, USA},
author = {Wang, Yi-chia and Burke, Moira and Kraut, Robert E.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470659},
isbn = {9781450318990},
pages = {31--34},
publisher = {ACM Press},
title = {{Gender, topic, and audience response: an analysis of user-generated content on facebook}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470659},
year = {2013}
}
@article{Pijnappel2013,
address = {New York, New York, USA},
author = {Pijnappel, Sebastiaan and Mueller, Florian},
doi = {10.1145/2470654.2466165},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1271},
publisher = {ACM Press},
title = {{4 Design Themes for Skateboarding}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466165},
year = {2013}
}
@inproceedings{Pinhanez2006,
abstract = {This chapter discusses not commonly used technologies of interfaces for Virtual and Augmented Reality and their potential usage. The majority of the chapter is dedicated to exploring different input and output devices that are currently in use or in research phase which can help the creation of new interfaces for Virtual Reality, possibly solving some of the problems usually seen in traditional interface systems.},
address = {Bel\'{e}m-PA},
author = {Pinhanez, Claudio},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {173--197},
publisher = {SBC},
title = {{Interfaces N\~{a}o-Convencionais}},
year = {2006}
}
@book{duda2012pattern,
author = {Duda, Richard O and Hart, Peter E and Stork, David G},
publisher = {Wiley-interscience},
title = {{Pattern classification}},
year = {2012}
}
@article{Hermens2010,
abstract = {When making a saccadic eye movement to a peripheral target, a simultaneous stimulus onset at central fixation generally increases saccadic latency, while offsets reduce latency ('gap effect'). Visual onsets remote from fixation also increase latency ('remote distractor effect'); however, the influence of remote visual offsets is less clear. Previous studies, which used a search task, found that remote offsets either facilitated, inhibited, or did nothing to saccade latencies towards a peripheral target. It cannot be excluded, however, that the target selection process in such search tasks influenced the results. We therefore simplified the task and asked participants to make eye movements to a predictable target. Simultaneously with target onset, either one or multiple remote stimulus onsets and offsets were presented. It was found that peripheral onsets increased saccade latencies, but offsets did not influence the initiation of a saccade to the target. Moreover, the number of onsets and offsets did not affect the results. These results suggest that earlier effects of remote stimulus offsets and of the number of remote distractor onsets reside in the target identification process of the visual search task rather than the competition between possible saccade goals. The results are discussed in the context of models of saccade target selection.},
annote = {Ver o que est\'{a} relacionado \`{a} segmenta\c{c}\~{a}o de dados do olhar},
author = {Hermens, Frouke and Walker, Robin},
doi = {10.1068/i0392},
file = {:home/acmt/Dropbox/Documentos/Mendeley/i-Perception/2010/Hermens, Walker/Hermens, Walker - 2010 - The influence of onsets and offsets on saccade programming.pdf:pdf},
issn = {2041-6695},
journal = {i-Perception},
keywords = {eye tracking,segmentation},
mendeley-tags = {eye tracking,segmentation},
month = jan,
number = {2},
pages = {83--94},
pmid = {23397028},
publisher = {Pion Ltd},
title = {{The influence of onsets and offsets on saccade programming.}},
url = {http://i-perception.perceptionweb.com/journal/I/article/i0392 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3563056&tool=pmcentrez&rendertype=abstract},
volume = {1},
year = {2010}
}
@misc{Ho2013,
author = {Ho, Nghia},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{Finding Optimal Rotation and Translation Between Corresponding 3D Points}},
url = {http://nghiaho.com/?page_id=671},
urldate = {2013-07-23},
year = {2013}
}
@inproceedings{Heuel,
abstract = {We present a geometric method for (i) matching 2D line segments from multiple oriented images, (ii) optimally reconstructing 3D line segments and (iii) grouping 3D line segments to corners. The proposed algorithm uses two developments in combining projective geometry and statistics, which are described in this article: (i) the geometric entities points, lines and planes in 2D and 3D and their uncertainty are represented in homogeneous coordinates and new entities may be constructed including their propagated uncertainty. The construction can be performed directly or as an estimation. (ii) relations such as incidence, equality, parallelism and orthogonality between points, lines and planes can be tested statistically based on a given significance level. Using these tools, the resulting algorithm is straightforward and gives reasonable results. It is only based on geometric information and does not use any image intensities, though it can be extended to use other information. The matching of 3D lines does not need any thresholds other than a significance value for the hypotheses tests.},
author = {Heuel, S. and Forstner, W.},
booktitle = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
doi = {10.1109/CVPR.2001.991006},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001/Unknown/Heuel, Forstner/Heuel, Forstner - Unknown - Matching, reconstructing and grouping 3D lines from multiple views using uncertain projective geometry.pdf:pdf},
isbn = {0-7695-1272-0},
pages = {II--517--II--524},
publisher = {IEEE Comput. Soc},
title = {{Matching, reconstructing and grouping 3D lines from multiple views using uncertain projective geometry}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=991006&contentType=Conference+Publications&searchField=Search_All&queryText=.QT.projective+geometry.QT.},
volume = {2}
}
@article{Birnbaum2013,
address = {New York, New York, USA},
author = {Birnbaum, Benjamin and Borriello, Gaetano and Flaxman, Abraham D. and DeRenzi, Brian and Karlin, Anna R.},
doi = {10.1145/2470654.2481404},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2911},
publisher = {ACM Press},
title = {{Using behavioral data to identify interviewer fabrication in surveys}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481404},
year = {2013}
}
@inproceedings{Qiang,
abstract = {This paper addresses the vision-based self-localization of an indoor service robot worked with a single vehicular camera. Based on the principle of projective geometry and the extended virtual image plane, the transverse position and orientation of robot is calculated through considering the image plane and floor plane as a whole. The longitudinal position is acquired by using the monocular stereovision method based on distance constraint along feature points of nature or artificial landmark. After a simple off-line process about landmark, the service robot can work well in a building. The validity and feasibility of the approach have been demonstrated through experiments.},
author = {Qiang, Fang and Cunxi, Xie},
booktitle = {Proceedings 7th International Conference on Signal Processing, 2004. Proceedings. ICSP '04. 2004.},
doi = {10.1109/ICOSP.2004.1441468},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings 7th International Conference on Signal Processing, 2004. Proceedings. ICSP '04. 2004/Unknown/Qiang, Cunxi/Qiang, Cunxi - Unknown - The vision-based metric self-localization of indoor mobile robot using projective geometry.pdf:pdf},
isbn = {0-7803-8406-7},
pages = {914--917},
publisher = {IEEE},
title = {{The vision-based metric self-localization of indoor mobile robot using projective geometry}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1441468&contentType=Conference+Publications&searchField=Search_All&queryText=.QT.projective+geometry.QT.},
volume = {2}
}
@article{Blackmon1997,
author = {Blackmon, TT and Ho, YF},
journal = {\ldots  in Medicine and  \ldots},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Eye movements while viewing dynamic and static stimuli}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=756912},
year = {1997}
}
@article{Mould2012,
author = {Mould, MS and Foster, DH and Amano, K and Oakley, JP},
journal = {Vision Research},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
title = {{A simple nonparametric method for classifying eye fixations}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698911004214},
year = {2012}
}
@article{Kim2002,
author = {Kim, Taewoo and Lee, Jinho and Fishwick, Paul},
doi = {10.1145/643114.643118},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM Transactions on Modeling and Computer Simulation/2002/Kim, Lee, Fishwick/Kim, Lee, Fishwick - 2002 - A two-stage modeling and simulation process for web-based modeling and simulation.pdf:pdf},
issn = {10493301},
journal = {ACM Transactions on Modeling and Computer Simulation},
month = jul,
number = {3},
pages = {230--248},
title = {{A two-stage modeling and simulation process for web-based modeling and simulation}},
url = {http://portal.acm.org/citation.cfm?doid=643114.643118},
volume = {12},
year = {2002}
}
@article{Henderson2003,
abstract = {In human vision, acuity and color sensitivity are best at the point of fixation, and the visual-cognitive system exploits this fact by actively controlling gaze to direct fixation towards important and informative scene regions in real time as needed. How gaze control operates over complex real-world scenes has recently become of central concern in several core cognitive science disciplines including cognitive psychology, visual neuroscience, and machine vision. This article reviews current approaches and empirical findings in human gaze control during real-world scene perception.},
author = {Henderson, JM},
doi = {10.1016/j.tics.2003.09.006},
file = {::},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = nov,
number = {11},
pages = {498--504},
title = {{Human gaze control during real-world scene perception}},
url = {http://www.sciencedirect.com/science/article/pii/S1364661303002481 http://linkinghub.elsevier.com/retrieve/pii/S1364661303002481},
volume = {7},
year = {2003}
}
@phdthesis{Raskar2002,
abstract = {Light projectors can be arranged into electronic displays that offer large, bright, and high resolution images. However, despite their unique characteristics, projectors have been treated like any other two-dimensional display devices, e.g. CRT monitors or LCD panels, to create flat and usually rectangular images. Even the growth of three dimensional computer graphics has followed this limitation. To improve and widen the range of applications of projectors, in this dissertation I present a single unified geometric framework for projector-based graphics. It is based on the notion of the projector as the dual of a camera. The geometric framework is based on (i) the analytical projection model, (ii) the geometric representation of the display surface and (iii) the viewer location. The framework can be used for practically all the projector-based applications. For classic projector- based systems, such as tiled displays or immersive panoramic displays, the framework provides a fundamentally different approach that allows greater freedom and flexibility. In addition, it enables a new class of projector-based visualization methods.},
author = {Raskar, R},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2002/Raskar/Raskar - 2002 - Projector-based three dimensional graphics.pdf:pdf},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {133},
school = {University of North Carolina},
title = {{Projector-based three dimensional graphics}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.9008&rep=rep1&type=pdf},
year = {2002}
}
@incollection{Teichrieba,
abstract = {Evolution of man-machine interaction paradigms brought new challenges to HCI research. Along years HCI studies merged with en- gineers and IT professionals work bring a diversity of ways to interact. In this context, the natural interaction tendency explores human body movements to perform interaction, including users body, hands and face motion.},
address = {Bauru-SP},
author = {Teichrieb, Veronica and Figueiredo, Lucas Silva},
booktitle = {Intera\c{c}\~{a}o em Realidade Virtual e Aumentada},
chapter = {1},
edition = {1},
editor = {Kelner, Judith and Brega, Jos\'{e} Remo F.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Intera\c{c}\~{a}o em Realidade Virtual e Aumentada/2010/Teichrieb, Figueiredo/Teichrieb, Figueiredo - 2010 - Intera\c{c}\~{a}o Natural.pdf:pdf},
pages = {9--22},
publisher = {Canal6},
title = {{Intera\c{c}\~{a}o Natural}},
year = {2010}
}
@misc{Loureiro2012,
author = {Loureiro, S\'{e}rgio A.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2012/Loureiro/Loureiro - 2012 - Revis\~{a}o Sistem\'{a}tica da Literatura.pdf:pdf},
keywords = {RBS},
mendeley-tags = {RBS},
title = {{Revis\~{a}o Sistem\'{a}tica da Literatura}},
url = {http://vision.ime.usp.br/~acmt/revisao-sistematica-literatura.pdf},
urldate = {2013-11-22},
year = {2012}
}
@article{Sampaio2007,
abstract = {Introdu\c{c}\~{a}o: Agregar evid\^{e}ncias de pesquisa para guiar a pr\'{a}tica cl\'{\i}nica \'{e} uma das principais raz\~{o}es para se desenvolverem estudos que sintetizam a literatura, mas n\~{a}o \'{e} a \'{u}nica. As revis\~{o}es sistem\'{a}ticas s\~{a}o desenhadas para ser met\'{o}dicas, expl\'{\i}citas e pass\'{\i}veis de reprodu\c{c}\~{a}o. Esse tipo de estudo serve para nortear o desenvolvimento de projetos, indicando novos rumos para futuras investiga\c{c}\~{o}es e identificando quais m\'{e}todos de pesquisa foram utilizados em uma \'{a}rea. M\'{e}todos: Uma revis\~{a}o sistem\'{a}tica requer uma pergunta clara, a defini\c{c}\~{a}o de uma estrat\'{e}gia de busca, o estabelecimento de crit\'{e}rios de inclus\~{a}o e exclus\~{a}o dos artigos e, acima de tudo, uma an\'{a}lise criteriosa da qualidade da literatura selecionada. O processo de desenvolvimento desse tipo de estudo de revis\~{a}o inclui caracterizar cada estudo selecionado, avaliar a qualidade deles, identificar conceitos importantes, comparar as an\'{a}lises estat\'{\i}sticas apresentadas e concluir sobre o que a literatura informa em rela\c{c}\~{a}o a determinada interven\c{c}\~{a}o, apontando ainda problemas/quest\~{o}es que necessitam de novos estudos. Um trabalho de revis\~{a}o sistem\'{a}tica segue a estrutura de um artigo original. Conclus\~{a}o: Boas revis\~{o}es sistem\'{a}ticas s\~{a}o recursos importantes ante o crescimento acelerado da informa\c{c}\~{a}o cient\'{\i}fica. Esses estudos ajudam a sintetizar a evid\^{e}ncia dispon\'{\i}vel na literatura sobre uma interven\c{c}\~{a}o, podendo auxiliar profissionais cl\'{\i}nicos e pesquisadores no seu cotidiano de trabalho.},
author = {Sampaio, RF and Mancini, MC},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Revista Brasileira de Fisioterapia/2007/Sampaio, Mancini/Sampaio, Mancini - 2007 - Estudos de revis\~{a}o sistem\'{a}tica um guia para s\'{\i}ntese criteriosa da evid\^{e}ncia cient\'{\i}fica.pdf:pdf},
journal = {Revista Brasileira de Fisioterapia},
keywords = {ECA,RBS,revis\~{a}o sistem\'{a}tica,s\'{\i}ntese da literatura},
mendeley-tags = {RBS},
number = {1},
pages = {83--39},
title = {{Estudos de revis\~{a}o sistem\'{a}tica: um guia para s\'{\i}ntese criteriosa da evid\^{e}ncia cient\'{\i}fica}},
url = {http://bases.bireme.br/cgi-bin/wxislind.exe/iah/online/?IsisScript=iah/iah.xis&src=google&base=LILACS&lang=p&nextAction=lnk&exprSearch=446088&indexSearch=ID},
volume = {11},
year = {2007}
}
@article{Orji2013,
address = {New York, New York, USA},
author = {Orji, Rita and Mandryk, Regan L. and Vassileva, Julita and Gerling, Kathrin M.},
doi = {10.1145/2470654.2481341},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2467},
publisher = {ACM Press},
title = {{Tailoring persuasive health games to gamer type}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481341},
year = {2013}
}
@misc{TileMap,
author = {TileMap},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{Mappy}},
url = {http://www.tilemap.co.uk/mappy.php},
urldate = {2013/07/26}
}
@article{Vogl2006,
author = {Vogl, W. and Sitti, M.},
doi = {10.1109/TNANO.2006.877421},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions On Nanotechnology/2006/Vogl, Sitti/Vogl, Sitti - 2006 - Augmented reality user interface for an atomic force microscope-based nanorobotic system.pdf:pdf},
issn = {1536-125X},
journal = {IEEE Transactions On Nanotechnology},
month = jul,
number = {4},
pages = {397--406},
title = {{Augmented reality user interface for an atomic force microscope-based nanorobotic system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1652858},
volume = {5},
year = {2006}
}
@article{Oh2013,
address = {New York, New York, USA},
author = {Oh, Uran and Findlater, Leah},
doi = {10.1145/2470654.2466145},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1129},
publisher = {ACM Press},
title = {{The challenges and potential of end-user gesture customization}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466145},
year = {2013}
}
@misc{Worldskills2012,
author = {International, Worldskills},
title = {{Worldskills}},
url = {www.worldskills.com},
urldate = {14/03/2012}
}
@inproceedings{Salvucci2000a,
abstract = {This paper describes EyeTracer, an interactive environment for manipulating, viewing, and analyzing eye-movement protocols. EyeTracer augments the typical functionality of such systems by incorporating model-based tracing algorithms that interpret protocols with respect to the predictions of a cognitive process model. These algorithms provide robust strategy classification and fixation assignment that help to alleviate common difficulties with eye-movement data, such as equipment noise and individual variability. Using the tracing algorithms for analysis and visualization, EyeTracer facilitates both exploratory analysis for initial understanding of behavior and confirmatory analysis for model evaluation and refinement.},
address = {New York, New York, USA},
annote = {- cited by: 27
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Salvucci, Dario D.},
booktitle = {Proceedings of the symposium on Eye tracking research \& applications - ETRA '00},
doi = {10.1145/355017.355026},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the symposium on Eye tracking research \& applications - ETRA '00/2000/Salvucci/Salvucci - 2000 - An interactive model-based environment for eye-movement protocol analysis and visualization.pdf:pdf},
isbn = {1581132808},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {57--63},
publisher = {ACM Press},
title = {{An interactive model-based environment for eye-movement protocol analysis and visualization}},
url = {http://dl.acm.org/citation.cfm?id=355026 http://portal.acm.org/citation.cfm?doid=355017.355026},
year = {2000}
}
@article{Huggins1962,
author = {Huggins, William H.},
doi = {10.1109/TE.1962.4322249},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IRE Transactions on Education/1962/Huggins/Huggins - 1962 - System Theory.pdf:pdf},
issn = {0893-7141},
journal = {IRE Transactions on Education},
number = {2},
pages = {61--63},
title = {{System Theory}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4322249},
volume = {5},
year = {1962}
}
@article{Ullrich2007,
abstract = {In this article, we present two algorithms for precise collision detection between two potentially colliding objects. The first one uses axis-aligned bounding boxes (AABB) and is a typical representative of a computational geometry algorithm. The second one uses spherical distance fields originating in image processing. Both approaches addresses the following challenges of collision detection algorithms: just in time, little resources, inclusive etc. Thus both approaches are scalable in the information they give in collision determination and the analysis up to a fixed refinement level, the collision time depends on the granularity of the bounding volumes and it is also possible to estimate the time bounds for the collision test tightly},
author = {Ullrich, Torsten and Funfzig, Christoph and Fellner, Dieter},
doi = {10.1109/MP.2007.343037},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Potentials/2007/Ullrich, Funfzig, Fellner/Ullrich, Funfzig, Fellner - 2007 - Two different views on collision detection.pdf:pdf},
issn = {0278-6648},
journal = {IEEE Potentials},
month = jan,
number = {1},
pages = {26--30},
title = {{Two different views on collision detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4147707},
volume = {26},
year = {2007}
}
@article{Santosa2013,
address = {New York, New York, USA},
author = {Santosa, Stephanie and Chevalier, Fanny and Balakrishnan, Ravin and Singh, Karan},
doi = {10.1145/2470654.2466148},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1149},
publisher = {ACM Press},
title = {{Direct space-time trajectory control for visual media editing}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466148},
year = {2013}
}
@article{Urruty2007,
annote = {- keyword coletado},
author = {Urruty, Thierry and Lew, Stanislas and Ihadaddene, Nacim and Simovici, Dan A.},
doi = {10.1145/1314303.1314308},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = dec,
number = {4},
pages = {1--20},
title = {{Detecting eye fixations by projection clustering}},
url = {http://dl.acm.org/citation.cfm?id=1314308 http://portal.acm.org/citation.cfm?doid=1314303.1314308},
volume = {3},
year = {2007}
}
@book{Hart1999,
author = {Hart, Chris},
isbn = {0761959750},
keywords = {rbs},
mendeley-tags = {rbs},
pages = {230},
publisher = {SAGE Publications Ltd},
title = {{Doing a Literature Review: Releasing the Social Science Research Imagination (SAGE Study Skills Series)}},
url = {http://www.amazon.com/Doing-Literature-Review-Releasing-Imagination/dp/0761959750},
year = {1999}
}
@inproceedings{Fumarola2010,
abstract = {Animation techniques are used during simulation studies for verifying and validating the model, and for communication purposes to external parties. Including animation in a simulation model, often results in models that contain many references to animation specific code. Moreover, in the specific case of discrete event simulation, challenges arise due to the difference in time-bases with animation techniques that mostly have a discrete notion of time. Typical approaches to developing animation for simulation models provide tightly coupled simulation and animation components that are fine-tuned to provide acceptable results. Apart of the disadvantage of having entangled model and animation code, this also has the disadvantage of reduced flexibility that one would desire in order to be able to use other animation techniques: for instance going from 2D to 3D with modern visualization libraries. In this paper, we will present our approach for loosely coupled discrete event simulation models and animation components.},
annote = {Division between animation (view) and logic, like MVC (model-view-controller)

      },
author = {Fumarola, Michele and Seck, Mamadou and Verbraeck, Alexander},
booktitle = {Proceedings of the 2010 Winter Simulation Conference},
doi = {10.1109/WSC.2010.5678857},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Winter Simulation Conference/2010/Fumarola, Seck, Verbraeck/Fumarola, Seck, Verbraeck - 2010 - An approach for loosely coupled discrete event simulation models and animation components.pdf:pdf},
isbn = {978-1-4244-9866-6},
month = dec,
pages = {2161--2170},
publisher = {IEEE},
title = {{An approach for loosely coupled discrete event simulation models and animation components}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5678857},
year = {2010}
}
@inproceedings{Pierce2013,
abstract = {This paper offers new theoretical and design insights into nteractive technology. By initially considering electric technology broadly, our work informs how HCI approaches a range of specific interactive or digital things and materials. Theoretically, we contribute a rigorous analysis of electric technology using the experiential lens of phenomenology. A major result is to characterize electric technology by three forms of materiality: the electric object, its electric materiality, and electric power. In terms of design, we present and analyze novel interactive form prototypes. Our theoretical contributions offer new insight into design artifacts, just as our novel design artifacts help reveal new theoretical insight.},
address = {New York, New York, USA},
author = {Pierce, James and Paulos, Eric},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470672},
isbn = {9781450318990},
pages = {119--128},
publisher = {ACM Press},
title = {{Electric materialities and interactive technology}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470672},
year = {2013}
}
@inproceedings{Ban2013,
abstract = {The main contribution of this paper is to develop a method for alleviating fatigue during handling medium-weight objects and augmenting our endurance by affecting our weight perception with augmented reality technology. To assist people to lift medium-weight objects without a complex structure or various costs, we focus on the phenomenon that our weight perception during handling objects is affected by visual properties. Our hypothesis is that this illusionary effect in weight perception can be applied to reduce fatigue while handling medium-weight objects without mechatronics-based physical assistance. In this paper, we propose an augmented reality system that changes the brightness value of an object in order to reduce fatigue while handling the object. We conducted two fundamental experiments to investigate the effectiveness of the proposed system. Our results suggested that the system eliminates the need to use excess energy for handling objects and reduces fatigue during the handling task.},
address = {New York, New York, USA},
author = {Ban, Yuki and Narumi, Takuji and Fujii, Tatsuya and Sakurai, Sho and Imura, Jun and Tanikawa, Tomohiro and Hirose, Michitaka},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470665},
isbn = {9781450318990},
pages = {69--78},
publisher = {ACM Press},
title = {{Augmented endurance: controlling fatigue while handling objects by affecting weight perception using augmented reality}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470665},
year = {2013}
}
@article{Behzadan2010,
author = {Behzadan, Amir H. and Kamat, Vineet R.},
doi = {10.1111/j.1467-8667.2009.00601.x},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Computer-Aided Civil and Infrastructure Engineering/2010/Behzadan, Kamat/Behzadan, Kamat - 2010 - Scalable Algorithm for Resolving Incorrect Occlusion in Dynamic Augmented Reality Engineering Environments.pdf:pdf},
issn = {10939687},
journal = {Computer-Aided Civil and Infrastructure Engineering},
month = jan,
number = {1},
pages = {3--19},
title = {{Scalable Algorithm for Resolving Incorrect Occlusion in Dynamic Augmented Reality Engineering Environments}},
url = {http://doi.wiley.com/10.1111/j.1467-8667.2009.00601.x},
volume = {25},
year = {2010}
}
@article{Mishra2012,
abstract = {Attention is an integral part of the human visual system and has been widely studied in the visual attention literature. The human eyes fixate at important locations in the scene, and every fixation point lies inside a particular region of arbitrary shape and size, which can either be an entire object or a part of it. Using that fixation point as an identification marker on the object, we propose a method to segment the object of interest by finding the "optimal" closed contour around the fixation point in the polar space, avoiding the perennial problem of scale in the Cartesian space. The proposed segmentation process is carried out in two separate steps: First, all visual cues are combined to generate the probabilistic boundary edge map of the scene; second, in this edge map, the "optimal" closed contour around a given fixation point is found. Having two separate steps also makes it possible to establish a simple feedback between the mid-level cue (regions) and the low-level visual cues (edges). In fact, we propose a segmentation refinement process based on such a feedback process. Finally, our experiments show the promise of the proposed method as an automatic segmentation framework for a general purpose visual system.},
author = {Mishra, Ajay K and Aloimonos, Yiannis and Cheong, Loong-Fah and Kassim, Ashraf A},
doi = {10.1109/TPAMI.2011.171},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Computer-Assisted,Computer-Assisted: methods,Cues,Eye,Eye Tracking,Form Perception,Humans,Image Processing,Ocular,Ocular: physiology,Segmentation,Vision},
mendeley-tags = {Eye Tracking,Segmentation},
month = apr,
number = {4},
pages = {639--53},
pmid = {22383341},
title = {{Active visual segmentation.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5989830 http://www.ncbi.nlm.nih.gov/pubmed/22383341},
volume = {34},
year = {2012}
}
@article{Yamashita2013,
address = {New York, New York, USA},
author = {Yamashita, Naomi and Kuzuoka, Hideaki and Hirata, Keiji and Kudo, Takashi},
doi = {10.1145/2470654.2481365},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2637},
publisher = {ACM Press},
title = {{Understanding the conflicting demands of family caregivers caring for depressed family members}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481365},
year = {2013}
}
@inproceedings{Blythe2013,
abstract = {The paper reflects on three approaches to the dissemination and display of digital art. “s[edition]” is a novel, web-based service that offers limited editions of “digital prints”. Analysis of user comments suggests that the metaphor of a “limited digital edition” raises issues and to some extent is resisted. The second approach is the Flickr Brushes Gallery, where digital painters post images and comment on one another’s work. Analysis of comment boards indicates that the shared art and comments are a form of gift exchange. Finally, the paper discusses a field study in which artists exhibited their work as it develops over time in digital frames and also in an immersive digital projection room. Analysis of field notes and interviews indicate that the digital frame approach was unsuccessful because of aesthetic and environmental concerns. The immersive projection suggested that more experiential approaches may be more interesting. It is argued that there is an inherent resistance in digital media to previous models of art commoditization. None of the approaches discussed here resolve the dilemma but rather indicate the scope and complexity of the issues.},
address = {New York, New York, USA},
author = {Blythe, Mark and Briggs, Jo and Hook, Jonathan and Wright, Peter and Olivier, Patrick},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470674},
isbn = {9781450318990},
pages = {139--148},
publisher = {ACM Press},
title = {{Unlimited editions: three approaches to the dissemination and display of digital art}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470674},
year = {2013}
}
@inproceedings{Peinecke2007,
annote = {
        From Duplicate 1 ( 
        
        
          Generating Tactile Textures using Periodicity Analysis
        
        
         - Peinecke, Niklas; Allerkamp, Dennis; Wolter, Franz-erich )

        
        

        

        

      },
author = {Peinecke, Niklas and Allerkamp, Dennis and Wolter, Franz-erich},
booktitle = {2007 International Conference on Cyberworlds (CW'07)},
doi = {10.1109/CW.2007.50},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2007 International Conference on Cyberworlds (CW'07)/2007/Peinecke, Allerkamp, Wolter/Peinecke, Allerkamp, Wolter - 2007 - Generating Tactile Textures using Periodicity Analysis.pdf:pdf;:home/acmt/Dropbox/Documentos/Mendeley/2007 International Conference on Cyberworlds (CW'07)/2007/Peinecke, Allerkamp, Wolter/Peinecke, Allerkamp, Wolter - 2007 - Generating Tactile Textures using Periodicity Analysis(2).pdf:pdf},
isbn = {0-7695-3005-2},
month = oct,
pages = {308--313},
publisher = {IEEE},
title = {{Generating Tactile Textures using Periodicity Analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4390934},
year = {2007}
}
@article{Tausczik2013,
address = {New York, New York, USA},
author = {Tausczik, Yla R. and Pennebaker, James W.},
doi = {10.1145/2470654.2470720},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {459},
publisher = {ACM Press},
title = {{Improving teamwork using real-time language feedback}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470720},
year = {2013}
}
@article{Cardoso2010,
abstract = {This chapter presents some possibilities of using Virtual Reality (VR) and Augmented Reality (AR) in Medicine and phobia treatment, showing some successful experiment examples. The main objective is to highlight fundamental interaction techniques to support this kind of ap- plication. Furthermore, important concepts and the main reasons why using VR/AR technology in such area are discussed by the authors.},
author = {Cardoso, Alexandre and Jr, Edgard Lamounier},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Intera\c{c}\~{a}o em Realidade Virtual e Aumentada/2010/Cardoso, Jr/Cardoso, Jr - 2010 - T\'{e}cnicas de Intera\c{c}\~{a}o de RV e RA na Medicina.pdf:pdf},
journal = {Intera\c{c}\~{a}o em Realidade Virtual e Aumentada},
pages = {55--81},
title = {{T\'{e}cnicas de Intera\c{c}\~{a}o de RV e RA na Medicina}},
year = {2010}
}
@inproceedings{Kan2009,
address = {New York, New York, USA},
author = {Kan, Tai-Wei and Teng, Chin-Hung and Chou, Wen-Shou},
booktitle = {Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry - VRCAI '09},
doi = {10.1145/1670252.1670305},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry - VRCAI '09/2009/Kan, Teng, Chou/Kan, Teng, Chou - 2009 - Applying QR code in augmented reality applications.pdf:pdf},
isbn = {9781605589121},
keywords = {2d barcode,artoolkit,augmented reality,be decoded by a,cell phone or a,codes that need to,mainly used in,personal com-,puter with built-in camera,qr code,qr code can,small program in a,so far,specific scanner,the qr codes are},
number = {212},
pages = {253},
publisher = {ACM Press},
title = {{Applying QR code in augmented reality applications}},
url = {http://portal.acm.org/citation.cfm?id=1670305 http://portal.acm.org/citation.cfm?doid=1670252.1670305},
volume = {1},
year = {2009}
}
@misc{Technologies2013,
author = {Technologies, Unity},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{Unity3D}},
url = {http://www.unity.com},
urldate = {2013/07/26},
year = {2013}
}
@article{Pilet2005,
author = {Pilet, J. and Lepetit, V. and Fua, P.},
doi = {10.1109/ISMAR.2005.18},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)/2005/Pilet, Lepetit, Fua/Pilet, Lepetit, Fua - 2005 - Augmenting deformable objects in real-time.pdf:pdf},
isbn = {0-7695-2459-1},
journal = {Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)},
pages = {134--137},
publisher = {Ieee},
title = {{Augmenting deformable objects in real-time}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544675},
volume = {1},
year = {2005}
}
@article{Massung2013,
address = {New York, New York, USA},
author = {Massung, Elaine and Coyle, David and Cater, Kirsten F. and Jay, Marc and Preist, Chris},
doi = {10.1145/2470654.2470708},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {371},
publisher = {ACM Press},
title = {{Using crowdsourcing to support pro-environmental community activism}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470708},
year = {2013}
}
@book{van2007eye,
author = {van Gompel, R P G and Gompel, RPG Van},
isbn = {9780080474915},
publisher = {Elsevier Science},
series = {Educational psychology},
title = {{Eye Movements: A Window on Mind and Brain}},
url = {http://books.google.com.br/books?hl=en&lr=&id=d00Ie8ftEnwC&oi=fnd&pg=PP2&dq=Eye+Movements:+A+Window+on+Mind+and+Brain&ots=JxW6BUN6-F&sig=rOafx1OhLALBp4jM8FLqOAWJb6U http://books.google.com.br/books?id=d00Ie8ftEnwC},
year = {2007}
}
@inproceedings{Higa2007,
abstract = {There have been many implementations of virtual reality, using audio and visual senses. However, implementations of mixed reality (MR) have thus far only dealt with the visual sense. We have developed an MR system that merges real and virtual worlds in both the audio and visual senses, wherein the geometric consistency of the audio sense was fully coordinated with the visual sense. We tried two approaches for merging real and virtual worlds in the audio sense, using open-air and closed-air headphones.},
author = {Higa, Kyota and Nishiura, Takanobu and Kimura, Asako and Shibata, Fumihisa and Tamura, Hideyuki},
booktitle = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2007.4538847},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality/2007/Higa et al/Higa et al. - 2007 - A Two-by-Two Mixed Reality System That Merges Real and Virtual Worlds in Both Audio and Visual Senses.pdf:pdf},
isbn = {9781424417490},
keywords = {audio and visual senses,audio visual senses,closed air headphones,closed-air headphones,consistency,geometric,geometric consistency,mixed reality,open air headphones,open-air headphones},
month = nov,
pages = {1--4},
publisher = {Ieee},
title = {{A Two-by-Two Mixed Reality System That Merges Real and Virtual Worlds in Both Audio and Visual Senses}},
url = {http://dl.acm.org/citation.cfm?id=1514358 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538847},
year = {2007}
}
@article{Xu2013a,
address = {New York, New York, USA},
author = {Xu, Qianli and Li, Liyuan and Wang, Gang},
doi = {10.1145/2470654.2481308},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2233},
publisher = {ACM Press},
title = {{Designing engagement-aware agents for multiparty conversations}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481308},
year = {2013}
}
@article{Kr2013,
author = {Kr, Antonio and Gmbh, Dfki},
isbn = {9781450318990},
pages = {2137--2146},
title = {{A Study on Icon Arrangement by Smartphone Users ¨}},
year = {2013}
}
@article{Criminisi2000,
abstract = {The previous chapter has investigated how measurements can be taken on planar surfaces from uncalibrated images. However, the world is not just one big plane (as Cristoforo Colombo discovered five centuries ago); it is a complex three-dimensional structure. Therefore, a more general analysis of the threedimensional scene is required; this is achieved in this chapter. In particular, this chapter describes how aspects of the affine three-dimensional geometry of a scene may be measured from a single perspective image (see also [25, 26, 28]). The techniques described still concentrate on scenes containing planes and parallel lines, although the methods are not so restricted. The algorithms developed here extend and generalize previous results on single-view metrology [59, 68, 96, 100].},
author = {Criminisi, A and Reid, I and Zisserman, A},
doi = {10.1007/978-0-85729-327-5\_5},
file = {:home/acmt/Dropbox/Documentos/Mendeley/International Journal of Computer Vision/2000/Criminisi, Reid, Zisserman/Criminisi, Reid, Zisserman - 2000 - Single view metrology.pdf:pdf},
journal = {International Journal of Computer Vision},
number = {2},
pages = {69--105},
title = {{Single view metrology}},
url = {http://link.springer.com/article/10.1023/A:1026598000963},
volume = {40},
year = {2000}
}
@article{Hedegaard2013,
address = {New York, New York, USA},
author = {Hedegaard, Steffen and Simonsen, Jakob Grue},
doi = {10.1145/2470654.2481286},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2089},
publisher = {ACM Press},
title = {{Extracting usability and user experience information from online user reviews}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481286},
year = {2013}
}
@article{hcibook,
author = {Dix, Alan J and Finlay, Janet E and Abowd, Gregory D and Beale, Russell},
isbn = {9780130461094},
keywords = {SBGames},
mendeley-tags = {SBGames},
pages = {834},
publisher = {Pearson Education Limited},
title = {{Human-Computer Interaction}},
year = {2003}
}
@inproceedings{Li2012,
abstract = {Projective distortion caused by tilted camera brings great inconvenience to subsequent image processing and pattern recognition. In this paper, a method based on projective geometry is introduced to correct the projective distortion of infrared images. The dual conic in distortion image, which contains all the information of projective rectification, is identified firstly, and then the projective transformation matrix is derived by decomposing the dual conic. Finally, optimization is carried out to get the optimal result. Experimental results show that the method used in this paper can remove the projective distortion of infrared image effectively.},
author = {Li, Xiaolu and He, Tao and Xu, Lijun and Chen, Lulu and Guo, Zhanshe},
booktitle = {2012 IEEE International Conference on Imaging Systems and Techniques Proceedings},
doi = {10.1109/IST.2012.6295549},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 IEEE International Conference on Imaging Systems and Techniques Proceedings/2012/Li et al/Li et al. - 2012 - Projective rectification of infrared image based on projective geometry.pdf:pdf},
isbn = {978-1-4577-1775-8},
month = jul,
pages = {356--360},
publisher = {IEEE},
title = {{Projective rectification of infrared image based on projective geometry}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6295549&contentType=Conference+Publications&searchField=Search_All&queryText=.QT.projective+geometry.QT.},
year = {2012}
}
@article{Duchowski2007,
author = {Duchowski, AT},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Eye tracking methodology: Theory and practice}},
url = {http://books.google.com/books?hl=pt-BR&lr=&id=WtvVdNESRyIC&oi=fnd&pg=PR15&dq=Eye+Tracking:+A+comprehensive+guide+to+methods+and+measures&ots=8kze4tzVbx&sig=SxR4NlyF0UdIqTZ7F5-KeWVqV0M},
year = {2007}
}
@article{Foulsham2008,
abstract = {Saliency map models account for a small but significant amount of the variance in where people fixate, but evaluating these models with natural stimuli has led to mixed results. In the present study, the eye movements of participants were recorded while they viewed color photographs of natural scenes in preparation for a memory test (encoding) and when recognizing them later. These eye movements were then compared to the predictions of a well defined saliency map model (L. Itti \& C. Koch, 2000), in terms of both individual fixation locations and fixation sequences (scanpaths). The saliency model is a significantly better predictor of fixation location than random models that take into account bias toward central fixations, and this is the case at both encoding and recognition. However, similarity between scanpaths made at multiple viewings of the same stimulus suggests that repetitive scanpaths also contribute to where people look. Top-down recapitulation of scanpaths is a key prediction of scanpath theory (D. Noton \& L. Stark, 1971), but it might also be explained by bottom-up guidance. The present data suggest that saliency cannot account for scanpaths and that incorporating these sequences could improve model predictions.},
author = {Foulsham, Tom and Underwood, Geoffrey},
doi = {10.1167/8.2.6},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of vision/2008/Foulsham, Underwood/Foulsham, Underwood - 2008 - What can saliency models predict about eye movements Spatial and sequential aspects of fixations during enc.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {Analysis of Variance,Cognition,Cognition: physiology,Eye Movements,Eye Movements: physiology,Eye Tracking,Fixation,Form Perception,Form Perception: physiology,Humans,Ocular,Ocular: physiology,Pattern Recognition,Photic Stimulation,Segmentation,Semantics,Task Performance and Analysis,Visual,Visual: physiology,scanpath,similarity},
mendeley-tags = {Eye Tracking,scanpath,Segmentation,similarity},
month = jan,
number = {2},
pages = {6.1--17},
pmid = {18318632},
title = {{What can saliency models predict about eye movements? Spatial and sequential aspects of fixations during encoding and recognition.}},
url = {http://jov.highwire.org/content/8/2/6.short http://www.ncbi.nlm.nih.gov/pubmed/18318632},
volume = {8},
year = {2008}
}
@inproceedings{Behzadan2007,
abstract = {Visualization is a powerful method for verifying, validating, and communicating the results of a simulated model. Lack of visual understanding about a simulated model is one of the major reasons inhibiting contractors and engineers from using results obtained from discrete-event simulation to plan and design their construction processes and commit real resources on the job site. The fast emerging information technology makes the use of modern visualization applications more appealing to engineers and scientists in different domains. This paper presents the design and implementation of an augmented reality (AR) visualization application together with an authoring language that allows the creation of outdoor AR animated scenes of simulated operations while featuring complete user involvement and interaction. The application is based on the concept of scene graphs. It also uses a unique general purpose data transmission method to communicate with hardware components of the system.},
author = {Behzadan, Amir H and Kamat, Vineet R},
booktitle = {2007 Winter Simulation Conference},
doi = {10.1109/WSC.2007.4419851},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2007 Winter Simulation Conference/2007/Behzadan, Kamat/Behzadan, Kamat - 2007 - Enabling smooth and scalable dynamic 3D visualization of discrete-event construction simulations in outdoor aug.pdf:pdf},
isbn = {978-1-4244-1305-8},
month = dec,
pages = {2168--2176},
publisher = {IEEE},
title = {{Enabling smooth and scalable dynamic 3D visualization of discrete-event construction simulations in outdoor augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4419851},
year = {2007}
}
@article{Chen1996,
abstract = {An inverse eigenvalue problem, where a matrix is to be constructed from some or all of its eigenvalues, may not have a real-valued solution at all. An approximate solution in the sense of least squares is sometimes desirable. Two types of least squares problems are formulated and explored in this paper. In spite of their different appearance, the two problems are shown to be equivalent. Thus one new numerical method, modified from the conventional alternating projection method, is proposed. The method converges linearly and globally and can be used to generate good starting values for other faster but more expensive and locally convergent methods. The idea can be applied to multiplicative inverse eigenvalue problems for the purpose of preconditioning. Numerical examples are presented.},
annote = {        From Duplicate 2 (                   On the Least Squares Solution of Inverse Eigenvalue Problems                 - Chen, Xuzhou; Chu, Moody Ten-Chao )
                
        
        
      },
author = {Chen, Xuzhou and Chu, Moody Ten-Chao},
doi = {10.1137/S0036142994264742},
issn = {0036-1429},
journal = {SIAM Journal on Numerical Analysis},
keywords = {1,65f15,65h15,ams subject classifications,applications,are of great importance,as well as numerical,discussions on various aspects,iep,introduction,inverse eigenvalue problem,inverse eigenvalue problems,least squares,lift and projection,lift projection,of the existence theory,to many},
month = dec,
number = {6},
pages = {2417--2430},
title = {{On the Least Squares Solution of Inverse Eigenvalue Problems}},
url = {http://epubs.siam.org/doi/abs/10.1137/S0036142994264742 http://link.aip.org/link/SJNAAM/v33/i6/p2417/s1&Agg=doi},
volume = {33},
year = {1996}
}
@article{Hashiba1995,
abstract = {Abnormalities of smooth pursuit eye movement (SPEM) have been estimated, mainly using the wave form on an electro-oculogram, in a qualitative way. Many methods for quantitative analysis of SPEM have been designed, though most are still uncommon in present clinical use. Using a personal computer, we developed a method of automatic quantitative analysis of ocular tracking eye movement recorded by electro-oculography (EOG). The design concept of this method is based on the observation that eye movement during ocular tracking consists of two different kinds of eye movements, one is SPEM and the other is saccade. The combination of SPEM and saccade (composite eye movement: CEM) commonly appears during ocular tracking. These two kinds of eye movement are essentially different not only in behavior but also about involved neural pathway in the central nervous system. From this point of view, we believe that the two kinds of eye movements involved in ocular tracking should be evaluated separately. The analysis method is outlined as follows. A horizontal sinusoidally moving visual target was employed to elicit ocular tracking eye movements. The test frequencies were set at 0.1, 0.2, 0.4 and 0.8Hz, and the amplitude of target motion was 15 deg at each frequency. The 20 seconds of eye movement data measured by EOG were fed into the computer through a digital-analog converter for further analysis. Using our original saccade detection algorithm, based on the physiological behavior of saccades, the saccadic components were detected and removed from the eye movement wave. The remaining parts, fragments of SPEM, were connected by means of interpolating defective parts. The reconstructed wave was a slow cumulative eye position curve (SCEP). Sinusoidal target motion, CEM and SCEP were processed by the FFT (Fast Fourier Transformation) method. Bode plots were applied to summarize the gain and phase of responses to SCEP and the target motion wave. These processes enable us to estimate abnormalities of SPEM such as low gain, abnormal phase shift and large trends in tested duration. We conclude that the method described here is useful for quantitative estimation of SPEM in clinical neuro-otological examinations.},
author = {Hashiba, M and Yasui, K and Watabe, H and Matsuoka, T and Baba, S},
issn = {0030-6622},
journal = {Nihon Jibiinkoka Gakkai kaiho},
keywords = {Adult,Algorithms,Computers,Electrooculography,Humans,Pursuit,Smooth,Smooth: physiology,gaze analysis,smooth pursuit},
mendeley-tags = {gaze analysis,smooth pursuit},
month = apr,
number = {4},
pages = {681--96},
pmid = {7782976},
title = {{[Quantitative analysis of smooth pursuit eye movement].}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7782976},
volume = {98},
year = {1995}
}
@article{Lee2000,
author = {Lee, Edward A and Neuendorffer, Steve},
doi = {10.1.1.3.2696},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Language/2000/Lee, Neuendorffer/Lee, Neuendorffer - 2000 - MoML - A Modeling Markup Language in XML - Version 0 . 4.pdf:pdf},
journal = {Language},
pages = {1--14},
title = {{MoML - A Modeling Markup Language in XML - Version 0 . 4}},
year = {2000}
}
@article{Birkfellner2002,
abstract = {Computer-aided surgery (CAS), the intraoperative application of biomedical visualization techniques, appears to be one of the most promising fields of application for augmented reality (AR), the display of additional computer-generated graphics over a real-world scene. Typically a device such as a head-mounted display (HMD) is used for AR. However, considerable technical problems connected with AR have limited the intraoperative application of HMDs up to now. One of the difficulties in using HMDs is the requirement for a common optical focal plane for both the realworld scene and the computer-generated image, and acceptance of the HMD by the user in a surgical environment. In order to increase the clinical acceptance of AR, we have adapted the Varioscope (Life Optics, Vienna), a miniature, cost-effective head-mounted operating binocular, for AR. In this paper, we present the basic design of the modified HMD, and the method and results of an extensive laboratory study for photogrammetric calibration of the Varioscope's computer displays to a real-world scene. In a series of 16 calibrations with varying zoom factors and object distances, mean calibration error was found to be 1.24 +/- 0.38 pixels or 0.12 +/- 0.05 mm for a 640 x 480 display. Maximum error accounted for 3.33 +/- 1.04 pixels or 0.33 +/- 0.12 mm. The location of a position measurement probe of an optical tracking system was transformed to the display with an error of less than 1 mm in the real world in 56\% of all cases. For the remaining cases, error was below 2 mm. We conclude that the accuracy achieved in our experiments is sufficient for a wide range of CAS applications.},
author = {Birkfellner, Wolfgang and Figl, Michael and Huber, Klaus and Watzinger, Franz and Wanschitz, Felix and Hummel, Johann and Hanel, Rudolf and Greimel, Wolfgang and Homolka, Peter and Ewers, Rolf and Bergmann, Helmar},
doi = {10.1109/TMI.2002.803099},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on medical imaging/2002/Birkfellner et al/Birkfellner et al. - 2002 - A head-mounted operating binocular for augmented reality visualization in medicine--design and initial evalu.pdf:pdf},
issn = {0278-0062},
journal = {IEEE transactions on medical imaging},
keywords = {Calibration,Computer Graphics,Depth Perception,Equipment Design,Equipment Failure Analysis,Imaging, Three-Dimensional,Imaging, Three-Dimensional: instrumentation,Imaging, Three-Dimensional: methods,Microscopy, Video,Microscopy, Video: instrumentation,Microsurgery,Microsurgery: instrumentation,Reproducibility of Results,Sensitivity and Specificity,Subtraction Technique,Surgical Equipment,User-Computer Interface,Video Recording,Video Recording: instrumentation,Video Recording: methods},
month = aug,
number = {8},
pages = {991--7},
pmid = {12472271},
title = {{A head-mounted operating binocular for augmented reality visualization in medicine--design and initial evaluation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12472271},
volume = {21},
year = {2002}
}
@article{Overney2008,
abstract = {In tennis, as in many disciplines of sport, fine spatio-temporal resolution is required to reach optimal performance. While many studies on tennis have focused on anticipatory skills or decision making, fewer have investigated the underlying visual perception abilities. In this study, we used a battery of seven visual tests that allowed us to assess which kind of visual information processing is performed better by tennis players than other athletes (triathletes) and non-athletes. We found that certain time-related skills, such as speed discrimination, are superior in tennis players compared to non-athletes and triathletes. Such tasks might be used to improve tennis performance in the future.},
author = {Overney, Leila S and Blanke, Olaf and Herzog, Michael H},
doi = {10.1371/journal.pone.0002380},
issn = {1932-6203},
journal = {PloS one},
keywords = {Adult,Attention,Humans,Male,Movement,Reaction Time,Tennis,Tennis: physiology,Vision Tests},
month = jan,
number = {6},
pages = {e2380},
pmid = {18545661},
title = {{Enhanced temporal but not attentional processing in expert tennis players.}},
url = {http://dx.plos.org/10.1371/journal.pone.0002380 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2398771&tool=pmcentrez&rendertype=abstract},
volume = {3},
year = {2008}
}
@article{Hutto2013,
address = {New York, New York, USA},
author = {Hutto, C.J. and Yardi, Sarita and Gilbert, Eric},
doi = {10.1145/2470654.2470771},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Social networks,computer mediated communication,social media},
pages = {821},
publisher = {ACM Press},
title = {{A longitudinal study of follow predictors on twitter}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470771},
year = {2013}
}
@article{Silva2012,
author = {Silva, Danilo Assis Nobre Dos S. and Araujo, Tiago Maritan Ugulino De and Dantas, Leonardo and Nobrega, Yurika Sato and Lima, Hozana Raquel Gomes De and Filho, Guido Lemos De Souza},
doi = {10.1109/SVR.2012.25},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Silva et al/Silva et al. - 2012 - FleXLIBRAS Description and Animation of Signs in Brazilian Sign Language.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {deaf,formal language,generation,humanoid avatars,libras,sign language},
month = may,
pages = {227--236},
publisher = {Ieee},
title = {{FleXLIBRAS: Description and Animation of Signs in Brazilian Sign Language}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297534},
year = {2012}
}
@inproceedings{Waycott2013,
abstract = {Older adults are normally characterized as consumers, rather than producers, of digital content. Current research concerning the design of technologies for older adults typically focuses on providing access to digital resources. Access is important, but is often insufficient, especially when establishing new social relationships. This paper investigates the nature and role of digital content that has been created by older adults, for the purpose of forging new relationships. We present a unique field study in which seven older adults (aged 71-92 years), who did not know each other, used a prototype iPad application (Enmesh) to create and share photographs and messages. The findings demonstrate that older adults, even those in the $\backslash$'1c"oldest old$\backslash$'1d" age group, embraced opportunities to express themselves creatively through digital content production. We show that self-expression and social engagement with peers can be realized when socio-technical systems are suitably designed to allow older adults to create and share their own digital content.},
address = {New York, New York, USA},
author = {Waycott, Jenny and Vetere, Frank and Pedell, Sonja and Kulik, Lars and Ozanne, Elizabeth and Gruner, Alan and Downs, John},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470662},
isbn = {9781450318990},
pages = {39--48},
publisher = {ACM Press},
title = {{Older adults as digital content producers}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470662},
year = {2013}
}
@article{Yamazoe,
abstract = {This paper proposes a depth measurement error model of consumer depth cameras such as Microsoft KINECT, and its calibration method. These devices are originally designed for video game interface, thus, the obtained depth map are not enough accurate for 3D measurement. To decrease these depth errors, several models have been proposed, however, these models consider only camera-related parameters. Since the depth sensors are based on projector-camera systems, we should consider projector-related parameters. Therefore, we propose the error model of the consumer depth cameras especially the KINECT, considering both intrinsic parameters of the camera and the projector. To calibrate the error model, we also propose the parameter estimation method by only showing a planar board to the depth sensors. Our error model and its calibration are necessary step for using the KINECT as a 3D measuring device. Experimental results show the validity and effectiveness of the error model and its calibration.},
author = {Yamazoe, H. and Habe, H. and Mitsugami, I. and Yagi, Y.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/Unknown/Yamazoe et al/Yamazoe et al. - Unknown - Easy depth sensor calibration.pdf:pdf},
title = {{Easy depth sensor calibration}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6460172&contentType=Conference+Publications&searchField=Search_All&queryText=kinect+calibration}
}
@article{Platonov2006,
author = {Platonov, Juri and Heibel, Hauke and Meier, Peter},
doi = {10.1109/ISMAR.2006.297800},
file = {:home/acmt/Dropbox/Documentos/Mendeley/of the 5th IEEE and ACM/2006/Platonov, Heibel, Meier/Platonov, Heibel, Meier - 2006 - A mobile markerless AR system for maintenance and repair.pdf:pdf},
isbn = {1-4244-0650-1},
journal = {of the 5th IEEE and ACM},
keywords = {17,a laptop,and the user,augmented reality,augmented video stream are,computer,e,g,has been inspired by,lessly transmitted between a,maintenance,markerless tracking,our markerless tracking algorithm,solution both,the raw and the,wire-},
month = oct,
pages = {105--108},
publisher = {Ieee},
title = {{A mobile markerless AR system for maintenance and repair}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4079262 http://portal.acm.org/citation.cfm?id=1514222},
year = {2006}
}
@article{Park2006a,
abstract = {For projector-based augmented reality systems, geometric correction is a crucial function. There have been many researches on the geometric correction in the literature. However, most of them focused only on static projection surfaces and could not give us a solution for dynamic surfaces (with varying geometry in time). In this paper, we aim at providing a simple and robust framework for projecting augmented reality images onto dynamic surfaces without image distortion. For this purpose, a new technique for embedding pattern images into the augmented reality images, which allows simultaneous display and correction, is proposed and its validity is shown in experimental results.},
author = {Park, H and Lee, MH and Seo, BK and Park, JI},
doi = {10.1007/11949534\_58},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Advances in Image and Video Technology/2006/Park et al/Park et al. - 2006 - Undistorted projection onto dynamic surface.pdf:pdf},
journal = {Advances in Image and Video Technology},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {582--590},
title = {{Undistorted projection onto dynamic surface}},
url = {http://link.springer.com/chapter/10.1007/11949534_58},
volume = {4319},
year = {2006}
}
@article{Oyekoya2006,
abstract = {Eye-tracking technology offers a natural and immediate way of communicating human intentions to a computer. Eye movements reflect interests and may be analysed to drive computer functionality in games, image and video search, and other visual tasks. This paper examines current eye tracking technologies and their applications. Experiments are described that show that target images can be identified more rapidly by eye tracking than using a mouse interface. Further results show that an eye-tracking technology provides an efficient interface for locating images in a large database. Finally the paper speculates about how the technology may enter the mass market as costs decrease.},
author = {Oyekoya, O. K. and Stentiford, F. W. M.},
doi = {10.1007/s10550-006-0076-z},
file = {:home/acmt/Dropbox/Documentos/Mendeley/BT Technology Journal/2006/Oyekoya, Stentiford/Oyekoya, Stentiford - 2006 - Eye tracking — A new interface for visual exploration.pdf:pdf},
issn = {1358-3948},
journal = {BT Technology Journal},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = jul,
number = {3},
pages = {57--66},
title = {{Eye tracking — A new interface for visual exploration}},
url = {http://link.springer.com/article/10.1007/s10550-006-0076-z http://link.springer.com/10.1007/s10550-006-0076-z},
volume = {24},
year = {2006}
}
@article{Hara2013,
address = {New York, New York, USA},
author = {Hara, Kotaro and Le, Vicki and Froehlich, Jon},
doi = {10.1145/2470654.2470744},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {631},
publisher = {ACM Press},
title = {{Combining crowdsourcing and google street view to identify street-level accessibility problems}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470744},
year = {2013}
}
@article{Savelsbergh2002,
abstract = {We used a novel methodological approach to examine skill-based differences in anticipation and visual search behaviour during the penalty kick in soccer. Expert and novice goalkeepers were required to move a joystick in response to penalty kicks presented on film. The proportion of penalties saved was assessed, as well as the frequency and time of initiation of joystick corrections. Visual search behaviour was examined using an eye movement registration system. Expert goalkeepers were generally more accurate in predicting the direction of the penalty kick, waited longer before initiating a response and made fewer corrective movements with the joystick. The expert goalkeepers used a more efficient search strategy involving fewer fixations of longer duration to less disparate areas of the display. The novices spent longer fixating on the trunk, arms and hips, whereas the experts found the kicking leg, non-kicking leg and ball areas to be more informative, particularly as the moment of foot-ball contact approached. No differences in visual search behaviour were observed between successful and unsuccessful penalties. The results have implications for improving anticipation skill at penalty kicks.},
author = {Savelsbergh, Geert J P and Williams, A Mark and {Van der Kamp}, John and Ward, Paul},
doi = {10.1080/026404102317284826},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of sports sciences/2002/Savelsbergh et al/Savelsbergh et al. - 2002 - Visual search, anticipation and expertise in soccer goalkeepers.pdf:pdf},
issn = {0264-0414},
journal = {Journal of sports sciences},
keywords = {Adult,Attention,Attention: physiology,Eye Movements,Eye Movements: physiology,Fixation,Humans,Male,Motion Perception,Motion Perception: physiology,Multivariate Analysis,Ocular,Ocular: physiology,Probability,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Soccer,Soccer: physiology,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
month = mar,
number = {3},
pages = {279--87},
pmid = {11999482},
title = {{Visual search, anticipation and expertise in soccer goalkeepers.}},
url = {http://www.tandfonline.com/doi/full/10.1080/026404102317284826 http://www.ncbi.nlm.nih.gov/pubmed/11999482},
volume = {20},
year = {2002}
}
@article{Daly2007,
author = {Daly, Leonard and Brutzman, Don},
doi = {10.1109/MSP.2007.905889},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Signal Processing Magazine/2007/Daly, Brutzman/Daly, Brutzman - 2007 - X3D Extensible 3D Graphics Standard Standards in a Nutshell.pdf:pdf},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
month = nov,
number = {6},
pages = {130--135},
title = {{X3D: Extensible 3D Graphics Standard [Standards in a Nutshell]}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4387948},
volume = {24},
year = {2007}
}
@article{Rougier2013Text,
author = {Rougier, Nicolas P},
journal = {Journal of Computer Graphics Techniques (JCGT)},
number = {1},
pages = {50--64},
title = {{Higher Quality 2D Text Rendering}},
url = {http://jcgt.org/published/0002/01/04/},
volume = {2},
year = {2013}
}
@inproceedings{Kim2013,
abstract = {Prototyping of gestural interactions in the early phase of design is one of the most challenging tasks for designers without advanced programming skills. Relating users' input from gesture-based sensor values requires a great deal of effort on the designer's part and disturbs their reflective and creative thinking. To deal with this problem, we present EventHurdle, a visual gesture-authoring tool to support designers' explorative prototyping. It supports remote gestures from a camera, handheld gestures with physical sensors, and touch gestures by utilizing touch screens. EventHurdle allows designers to visually define and modify gestures through interaction workspace and graphical markup language with hurdles. Because the created gestures can be integrated into a prototype as programming code and automatically recognized, designers do not need to pay attention in sensor-related implementation. Two user studies and a recognition test are reported to discuss the acceptance and implications of explorative prototyping tools for designers.},
address = {New York, New York, USA},
author = {Kim, Ju-whan and Nam, Tek-jin},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470691},
isbn = {9781450318990},
pages = {267--276},
publisher = {ACM Press},
title = {{EventHurdle: supporting designers' exploratory interaction prototyping with gesture-based sensors}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470691},
year = {2013}
}
@article{Hirooka2004,
author = {Hirooka, S and Saito, H},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 14th International Conference on Artificial Reality and Telexistence/2004/Hirooka, Saito/Hirooka, Saito - 2004 - Virtual display system using video projector onto real object surface.pdf:pdf},
journal = {Proceedings of the 14th International Conference on Artificial Reality and Telexistence},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
title = {{Virtual display system using video projector onto real object surface}},
url = {http://hvrl.ics.keio.ac.jp/paper/pdf/international_Conference/2004/ICAT2004_shinichiro.pdf},
year = {2004}
}
@inproceedings{Zhao2013,
abstract = {The growing use of social media means that an increasing amount of people's lives are visible online. We draw from Goffman's theatrical metaphor and Hogan's exhibition approach to explore how people manage their personal collection of social media data over time. We conducted a qualitative study of 13 participants to reveal their day-to-day decision-making about producing and curating digital traces on Facebook. Their goals and strategies showed that people experience the Facebook platform as consisting of three different functional regions: a performance region for managing recent data and impression management, an exhibition region for longer term presentation of self-image, and a personal region for archiving meaningful facets of life. Further, users' need for presenting and archiving data in these three regions is mediated by temporality. These findings trigger a discussion of how to design social media that support these dynamic and sometimes conflicting needs.},
address = {New York, New York, USA},
author = {Zhao, Xuan and Salehi, Niloufar and Naranjit, Sasha and Alwaalan, Sara and Voida, Stephen and Cosley, Dan},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470656},
isbn = {9781450318990},
pages = {1--10},
publisher = {ACM Press},
title = {{The many faces of facebook: experiencing social media as performance, exhibition, and personal archive}},
url = {http://stephen.voida.com/uploads/Publications/Publications/zhao-chi13.pdf http://dl.acm.org/citation.cfm?doid=2470654.2470656},
year = {2013}
}
@article{Pai2004,
abstract = {Systematic reviews and meta-analyses synthesize data from existing primary research, and well-conducted reviews offer clinicians a practical solution to the problem of staying current in their fields of interest. A whole generation of secondary journals, pre-appraised evidence libraries and periodically updated elec- tronic texts are now available to clinicians. However, not all systematic reviews are of high quality, and it is important to be able to critically assess their validity and applicability. This article is an illustrated guide for conducting systematic reviews. A clear understanding of the process will provide clinicians with the tools to judiciously appraise reviews and interpret them. We hope that it will enable clinicians to conduct systematic reviews, generate high-quality evidence, and contribute to the evidence-based medicine movement.},
author = {Pai, M and McCulloch, M and Gorman, JD},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The National Medical Journal of India/2004/Pai, McCulloch, Gorman/Pai, McCulloch, Gorman - 2004 - Systematic reviews and meta-analyses an illustrated, step-by-step guide.pdf:pdf;:home/acmt/Dropbox/Documentos/Mendeley/The National Medical Journal of India/2004/Pai, McCulloch, Gorman/Pai, McCulloch, Gorman - 2004 - Systematic reviews and meta-analyses an illustrated, step-by-step guide(2).pdf:pdf},
journal = {The National Medical Journal of India},
keywords = {RBS},
mendeley-tags = {RBS},
number = {2},
pages = {86--95},
title = {{Systematic reviews and meta-analyses: an illustrated, step-by-step guide.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15141602},
volume = {17},
year = {2004}
}
@inproceedings{Prince2002,
abstract = {We present a complete system for live capture of 3D content and simultaneous presentation in augmented reality. The user sees the real world from his viewpoint, but modified so that the image of a remote collaborator is rendered into the scene. Fifteen cameras surround the collaborator, and the resulting video streams are used to construct a three-dimensional model of the subject using a shape-from-silhouette algorithm. Users view a two-dimensional fiducial marker using a video-see-through augmented reality interface. The geometric relationship between the marker and head-mounted camera is calculated, and the equivalent view of the subject is computed and drawn into the scene. Our system can generate 384 288 pixel images of the models at 25 fps, with a latency of < 100 ms. The result gives the strong impression that the subject is a real part of the 3D scene. We demonstrate applications of this system in 3D videoconferencing and entertainment.},
author = {Prince, Simon J D and Cheok, Adrian David and Farbiz, Farzam and Williamson, Todd and Johnson, Nik and Billinghurst, Mark and Kato, Hirokazu},
booktitle = {International Symposium on Mixed and Augmented Reality ISMAR},
doi = {10.1109/ISMAR.2002.1115062},
isbn = {0769517811},
keywords = {3-d reconstruction,appropriately,augmented reality,col-,laborator is three-dimensional and,mixed reality,present in the space,shape-from-,silhouette,stable percept that the,this results in the,video-conferencing,with},
pages = {7--13},
publisher = {IEEE Comput. Soc},
title = {3d live: real time captured content for mixed reality},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1115062},
year = {2002}
}
@article{Oikawa2012,
author = {Oikawa, Marina Atsumi and Taketomi, Takafumi and Yamamoto, Goshiro and Fujisawa, Makoto and Amano, Toshiyuki and Miyazaki, Jun and Kato, Hirokazu},
doi = {10.1109/SVR.2012.3},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Oikawa et al/Oikawa et al. - 2012 - Local Quadrics Surface Approximation for Real-Time Tracking of Textureless 3D Rigid Curved Objects.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {-model-based tracking,a,a coarse representation of,a sparse mesh is,b,camera pose estimation,figure 1,in,object resulting,quadrics,red lines,rendered on the target,rigid curved objects,the object contour},
month = may,
pages = {246--253},
publisher = {Ieee},
title = {{Local Quadrics Surface Approximation for Real-Time Tracking of Textureless 3D Rigid Curved Objects}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297536},
year = {2012}
}
@article{Reitmayr2005,
author = {Reitmayr, G. and Eade, E. and Drummond, T.},
doi = {10.1109/ISMAR.2005.39},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)/2005/Reitmayr, Eade, Drummond/Reitmayr, Eade, Drummond - 2005 - Localisation and interaction for augmented maps.pdf:pdf},
isbn = {0-7695-2459-1},
journal = {Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)},
keywords = {a control,a user interacting with,augmented,device to pick up,figure 1,maps using a pda,optical tracking,plays,projection dis-,spatially augmented reality,tangible user interfaces},
pages = {120--129},
publisher = {Ieee},
title = {{Localisation and interaction for augmented maps}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544673},
year = {2005}
}
@inproceedings{herrera,
author = {Herrera, Daniel and Kannala, Juho and Heikkil\"{a}, Janne},
booktitle = {Computer Analysis of Images and Patterns},
organization = {Springer},
pages = {437--445},
title = {{Accurate and practical calibration of a depth and color camera pair}},
year = {2011}
}
@article{Wang2013,
address = {New York, New York, USA},
author = {Wang, Yiran and Echenique, Andy and Shelton, Martin and Mark, Gloria},
doi = {10.1145/2470654.2481375},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2717},
publisher = {ACM Press},
title = {{A comparative evaluation of multiple chat stream interfaces for information-intensive environments}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481375},
year = {2013}
}
@misc{Herrlinger,
author = {Herrlinger, Sebastian},
title = {{OpenRTMFP/Cumulus}},
url = {https://github.com/OpenRTMFP/Cumulus},
urldate = {17/01/2012}
}
@article{Seo2007,
author = {Seo, Byung-Kuk and Lee, Moon-Hyun and Park, Hanhoon and Park, Jong-Il and {Soo Kim}, Young},
doi = {10.1109/ICAT.2007.42},
file = {:home/acmt/Dropbox/Documentos/Mendeley/17th International Conference on Artificial Reality and Telexistence (ICAT 2007)/2007/Seo et al/Seo et al. - 2007 - Direct-Projected AR Based Interactive User Interface for Medical Surgery.pdf:pdf},
isbn = {0-7695-3056-7},
journal = {17th International Conference on Artificial Reality and Telexistence (ICAT 2007)},
month = nov,
pages = {105--112},
publisher = {Ieee},
title = {{Direct-Projected AR Based Interactive User Interface for Medical Surgery}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4414622},
year = {2007}
}
@inproceedings{Kuksenok2013,
abstract = {Like most online content, user-generated content (UGC) poses accessibility barriers to users with disabilities. However, the accessibility difficulties pervasive in UGC warrant discussion and analysis distinct from other kinds of online content. Content authors, community culture, and the authoring tool itself all affect UGC accessibility. The choices, resources available, and strategies in use to ensure accessibility are different than for other types of online content. We contribute case studies of two UGC communities with accessible content: Wikipedia, where authors focus on access to visual materials and navigation, and an online health support forum where users moderate the cognitive accessibility of posts. Our data demonstrate real world moderation strategies and illuminate factors affecting success, such as community culture. We conclude with recommended strategies for creating a culture of accessibility around UGC.},
address = {New York, New York, USA},
author = {Kuksenok, Katie and Brooks, Michael and Mankoff, Jennifer},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470664},
isbn = {9781450318990},
pages = {59--68},
publisher = {ACM Press},
title = {{Accessible online content creation by end users}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470664},
year = {2013}
}
@article{Park2007,
abstract = {We modify a projected image so as to compensate for changes in the viewer’s location. We use the concept of a virtual camera in the viewing space to achieve a transformable display with improved visibility. The 3D space and virtual camera are initialized and then the image is translated, rotated, scaled and projected. The user can modify the position and size of the image freely within the allowable projection area. They can also change its orientation as seen from their viewpoint, which can be off the axis of projection.},
author = {Park, J and Kim, MH},
doi = {10.1007/978-3-540-73281-5\_75},
journal = {Universal Access in Human-Computer Interaction. \ldots},
keywords = {anamorphism},
mendeley-tags = {anamorphism},
pages = {691--698},
title = {{Controlling an anamorphic projected image for off-axis viewing}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-73281-5_75},
volume = {4555},
year = {2007}
}
@article{Huff2011,
author = {Huff, Rafael and Gierlinger, Thomas and Kuijper, Arjan and Stork, Andre and Fellner, Dieter},
doi = {10.1109/SVR.2011.18},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Huff et al/Huff et al. - 2011 - A Comparison of xPU Platforms Exemplified with Ray Tracing Algorithms.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
keywords = {-systems and software architectures,application study,cpus,hybrid computer systems,multi-core},
month = may,
pages = {1--8},
publisher = {Ieee},
title = {{A Comparison of xPU Platforms Exemplified with Ray Tracing Algorithms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951829},
year = {2011}
}
@inproceedings{Koh2009,
abstract = {This paper evaluates the input performance capabilities of Velocity Threshold (I-VT) and Kalman Filter (I-KF) eye movement detection models when employed for eye-gaze-guided interface control. I-VT is a common eye movement identification model employed by the eye tracking community, but it is neither robust nor capable of handling high levels of noise present in the eye position data. Previous research implies that use of a Kalman filter reduces the noise in the eye movement signal and predicts the signal during brief eye movement failures, but the actual performance of I-KF was never evaluated. We evaluated the performance of I-VT and I-KF models using guidelines for ISO 9241 Part 9 standard, which is designed for evaluation of non keyboard/mouse input devices with emphasis on performance, comfort, and effort. Two applications were implemented for the experiment: 1) an accuracy test 2) a photo viewing application specifically designed for eye-gaze-guided control. Twenty-one subjects participated in the evaluation of both models completing a series of tasks. The results indicates that I-KF allowed participants to complete more tasks with shorter completion time while providing higher general comfort, accuracy and operation speeds with easier target selection than the I-VT model. We feel that these results are especially important to the engineers of new assistive technologies and interfaces that employ eye-tracking technology in their design.},
address = {New York, New York, USA},
annote = {- cited by: 16- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Koh, Do Hyong and {Munikrishne Gowda}, Sandeep A. and Komogortsev, Oleg V.},
booktitle = {Proceedings of the 1st ACM SIGCHI symposium on Engineering interactive computing systems - EICS '09},
doi = {10.1145/1570433.1570470},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 1st ACM SIGCHI symposium on Engineering interactive computing systems - EICS '09/2009/Koh, Munikrishne Gowda, Komogortsev/Koh, Munikrishne Gowda, Komogortsev - 2009 - Input evaluation of an eye-gaze-guided interface.pdf:pdf},
isbn = {9781605586007},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {197},
publisher = {ACM Press},
title = {{Input evaluation of an eye-gaze-guided interface}},
url = {http://dl.acm.org/citation.cfm?id=1570470 http://portal.acm.org/citation.cfm?doid=1570433.1570470},
year = {2009}
}
@inproceedings{worldkit,
abstract = {Instant access to computing, when and where we need it, has long been one of the aims of research areas such as ubiquitous computing. In this paper, we describe the WorldKit system, which makes use of a paired depth camera and projector to make ordinary surfaces instantly interactive. Using this system, touch-based interactivity can, without prior calibration, be placed on nearly any unmodified surface literally with a wave of the hand, as can other new forms of sensed interaction. From a user perspective, such interfaces are easy enough to instantiate that they could, if desired, be recreated or modified "each time we sat down" by "painting" them next to us. From the programmer's perspective, our system encapsulates these capabilities in a simple set of abstractions that make the creation of interfaces quick and easy. Further, it is extensible to new, custom interactors in a way that closely mimics conventional 2D graphical user interfaces, hiding much of the complexity of working in this new domain. We detail the hardware and software implementation of our system, and several example applications built using the library.},
address = {New York, New York, USA},
author = {Xiao, Robert and Harrison, Chris and Hudson, Scott E},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2466113},
isbn = {9781450318990},
organization = {ACM},
pages = {879--888},
publisher = {ACM Press},
title = {{WorldKit: rapid and easy creation of ad-hoc interactive applications on everyday surfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466113},
year = {2013}
}
@inproceedings{Ashdown2004,
abstract = {We present a novel multi-planar display system based on an uncalibrated projector-camera pair. Our system exploits the juxtaposition of planar surfaces in a room to create ad-hoc visualization and display capabilities. In an office setting, for example, a desk pushed against a wall provides two perpendicular surfaces that can simultaneously display elevation and plan views of an architectural model. In contrast to previous room-level projector-camera systems, our method is based on a flexible calibration procedure that requires a minimum amount of information for the geometry of the multi-planar surface scenario. A number of display configurations can be created on any available planar surfaces using a single commodity projector and camera. The key to our calibration approach is an efficient technique for simultaneously localizing multiple planes and a robust planar metric rectification method, which can tolerate a restricted camera field-of-view and requires no special calibration objects. We demonstrate the robustness of our calibration method using real and synthetic images and present several applications of our display system.},
author = {Ashdown, M and Flagg, M and Sukthankar, R. and Rehg, J.M.},
booktitle = {Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
doi = {10.1109/CVPR.2004.1315159},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004/2004/Ashdown et al/Ashdown et al. - 2004 - A flexible projector-camera system for multi-planar displays.pdf:pdf},
isbn = {0-7695-2158-4},
keywords = {anamorphism},
mendeley-tags = {anamorphism},
pages = {165--172},
publisher = {IEEE},
title = {{A flexible projector-camera system for multi-planar displays}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1315159 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1315159},
volume = {2},
year = {2004}
}
@inproceedings{Modesto2006,
abstract = {The objective of this chapter is to present to the reader a brief introduction on the 3D representation 3D of human beings in virtual environments, the so called Virtual Avatars or Virtual Humans. Its basic characteristics and the ways of its movements generation are defined. In order to standardize the modeling and portability of the models created, the H-anim specification 1.1 and examples of its use are also presented.},
address = {Bel\'{e}m-PA},
author = {Modesto, F\'{a}bio Alexandre Caravieri and Brega, Jos\'{e} Remo Ferreira and Garcia, Marcelo de Brito and Meiguins, Bianchi Serique and Sementille, Ant\^{o}nio Carlos and Rodello, Ildeberto Aparecido and Junior, Rosevaldo dias de Souza},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {79--97},
publisher = {SBC},
title = {{Humanos Virtuais e Avatares}},
year = {2006}
}
@article{Sheng2011,
abstract = {We present an application of interactive global illumination and spatially augmented reality to architectural daylight modeling that allows designers to explore alternative designs and new technologies for improving the sustainability of their buildings. Images of a model in the real world, captured by a camera above the scene, are processed to construct a virtual 3D model. To achieve interactive rendering rates, we use a hybrid rendering technique, leveraging radiosity to simulate the interreflectance between diffuse patches and shadow volumes to generate per-pixel direct illumination. The rendered images are then projected on the real model by four calibrated projectors to help users study the daylighting illumination. The virtual heliodon is a physical design environment in which multiple designers, a designer and a client, or a teacher and students can gather to experience animated visualizations of the natural illumination within a proposed design by controlling the time of day, season, and climate. Furthermore, participants may interactively redesign the geometry and materials of the space by manipulating physical design elements and see the updated lighting simulation.},
author = {Sheng, Yu and Yapo, Theodore C and Young, Christopher and Cutler, Barbara},
doi = {10.1109/TVCG.2009.209},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on visualization and computer graphics/2011/Sheng et al/Sheng et al. - 2011 - A spatially augmented reality sketching interface for architectural daylighting design.pdf:pdf},
issn = {1941-0506},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Algorithms,Computer Graphics,Computer-Aided Design,Computer-Assisted,Computer-Assisted: methods,Environment Design,Humans,Image Interpretation,Image Processing,Imaging,Lighting,Three-Dimensional,Three-Dimensional: methods,User-Computer Interface,anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
month = jan,
number = {1},
pages = {38--50},
pmid = {21071786},
title = {{A spatially augmented reality sketching interface for architectural daylighting design.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5342415 http://www.ncbi.nlm.nih.gov/pubmed/21071786},
volume = {17},
year = {2011}
}
@book{Langton1995,
author = {Langton, Christopher G},
booktitle = {Artificial Life},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Artificial Life/1995/Langton/Langton - 1995 - Artificial Life An Overview.pdf:pdf},
isbn = {0262121891},
pages = {344},
publisher = {Bradford Books},
title = {{Artificial Life An Overview}},
year = {1995}
}
@article{Rayner1979,
author = {Rayner, K},
journal = {Perception},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Eye guidance in reading: Fixation locations within words}},
url = {http://www.perceptionweb.com/perception/fulltext/p08/p080021.pdf},
year = {1979}
}
@inproceedings{Findlater2013,
abstract = {Despite the apparent popularity of touchscreens for older adults, little is known about the psychomotor performance of these devices. We compared performance between older adults and younger adults on four desktop and touchscreen tasks: pointing, dragging, crossing and steering. On the touchscreen, we also examined pinch-to-zoom. Our results show that while older adults were significantly slower than younger adults in general, the touchscreen reduced this performance gap relative to the desktop and mouse. Indeed, the touchscreen resulted in a significant movement time reduction of 35\% over the mouse for older adults, compared to only 16\% for younger adults. Error rates also decreased.},
address = {New York, New York, USA},
author = {Findlater, Leah and Froehlich, Jon E. and Fattal, Kays and Wobbrock, Jacob O. and Dastyar, Tanya},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470703},
isbn = {9781450318990},
pages = {343--346},
publisher = {ACM Press},
title = {{Age-related differences in performance with touchscreens compared to traditional mouse input}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470703},
year = {2013}
}
@article{Kim2007,
author = {Kim, Sehwan and Diverdi, Stephen and Iltis, Ronald and Tobias, H},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Online/2007/Kim et al/Kim et al. - 2007 - Implicit 3D Modeling and Tracking for Anywhere Augmentation.pdf:pdf},
isbn = {9781595938633},
journal = {Online},
keywords = {based tracking,camera pose estimation,feature-,online modeling,outdoor augmented reality,ukf},
pages = {19--28},
title = {{Implicit 3D Modeling and Tracking for Anywhere Augmentation}},
year = {2007}
}
@book{Koch2011,
address = {Berlin, Heidelberg},
annote = {crossRef(Jarodzka2010)},
booktitle = {Computer Vision – ACCV 2010 Workshops},
doi = {10.1007/978-3-642-22822-3},
editor = {Koch, Reinhard and Huang, Fay},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Computer Vision – ACCV 2010 Workshops/2011/Unknown/Unknown - 2011 - Computer Vision – ACCV 2010 Workshops.pdf:pdf},
isbn = {978-3-642-22821-6},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Computer Vision – ACCV 2010 Workshops}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-22822-3},
volume = {6468},
year = {2011}
}
@article{Komogortsev2010a,
abstract = {In an effort towards standardization, this paper evaluates the performance of five eye movement classification algorithms in terms of their assessment of oculomotor fixation and saccadic behavior. The results indicate that performance of these five commonly used algorithms vary dramatically even in the case of a simple stimulus evoked task using a single, common threshold value. The important contributions of this paper are: 1) evaluation and comparison of performance of five algorithms to classify specific oculomotor behavior 2) introduction and comparison of new standardized scores to provide more reliable classification performance 3) logic for a reasonable threshold value selection for any eye movement classification algorithm based on the standardized scores and 4) logic for establishing a criterion-based baseline for performance comparison between any eye movement classification algorithms. Proposed techniques enable efficient and objective clinical applications providing means to assure meaningful automated eye movement classification.},
annote = {- cited by: 29
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Komogortsev, O V and Gobert, D V and Jayarathna, S and Koh, D-H and Gowda, S},
doi = {10.1109/TBME.2010.2057429},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on bio-medical engineering/2010/Komogortsev et al/Komogortsev et al. - 2010 - Standardization of automated analyses of oculomotor fixation and saccadic behaviors.pdf:pdf},
issn = {0018-9294},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Analysis,baseline,eye-movement classification,gaze analysis,oculomotor behavior.},
mendeley-tags = {gaze analysis},
month = nov,
number = {11},
pages = {2635--2645},
pmid = {20667803},
title = {{Standardization of automated analyses of oculomotor fixation and saccadic behaviors.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5523936 http://www.ncbi.nlm.nih.gov/pubmed/20667803},
volume = {57},
year = {2010}
}
@article{Conforto2011,
abstract = {A revis\~{a}o bibliogr\'{a}fica sistem\'{a}tica \'{e} um m\'{e}todo cient\'{\i}fico para busca e an\'{a}lise de artigos de uma determinada \'{a}rea da ci\^{e}ncia. \'{E} amplamente utilizada em pesquisas na medicina, psicologia e ci\^{e}ncias sociais, onde h\'{a} grandes massas de dados e fontes de informa\c{c}\~{o}es. Pesquisas na \'{a}rea de gest\~{a}o de opera\c{c}\~{o}es tamb\'{e}m necessitam analisar crescentes quantidades de artigos e informa\c{c}\~{o}es. No entanto, t\'{e}cnicas de revis\~{a}o sistem\'{a}tica s\~{a}o pouco difundidas nessa \'{a}rea, em especial em desenvolvimento de produtos e gerenciamento de projetos. O objetivo desse artigo \'{e} apresentar um roteiro para a condu\c{c}\~{a}o de revis\~{a}o bibliogr\'{a}fica sistem\'{a}tica (RBS) na \'{a}rea de gest\~{a}o de opera\c{c}\~{o}es com foco em pesquisas nos temas “desenvolvimento de produtos” e “gerenciamento de projetos”. O roteiro foi intitulado RBS Roadmap e foi criado a partir das melhores pr\'{a}ticas preconizadas em \'{a}reas pioneiras nesse tipo revis\~{a}o, combinada com uma pesquisa-a\c{c}\~{a}o em tr\^{e}s pesquisas na \'{a}rea de gest\~{a}o de opera\c{c}\~{o}es. A principal contribui\c{c}\~{a}o para a teoria e pr\'{a}tica \'{e} a sistematiza\c{c}\~{a}o do procedimento para revis\~{a}o sistem\'{a}tica voltado especificamente para pesquisas na \'{a}rea de desenvolvimento de produtos e gerenciamento de projetos, que pode ser utilizado como refer\^{e}ncia para pesquisadores nessa \'{a}rea.},
author = {Conforto, Edivandro Carlos and Amaral, Daniel Capaldo and da Silva, S\'{e}rgio Luis},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Congresso Brasileiro de Gest\~{a}o de Desenvolvimento de Produtos/2011/Conforto, Amaral, Silva/Conforto, Amaral, Silva - 2011 - Roteiro para revis\~{a}o bibliogr\'{a}fica sistem\'{a}tica aplica\c{c}\~{a}o no desenvolvimento de produtos e gerencia.pdf:pdf},
journal = {Congresso Brasileiro de Gest\~{a}o de Desenvolvimento de Produtos},
keywords = {Desenvolvimento de Produtos,Gerenciamento de Projetos.,RBS,RBS Roadmap,Roteiro para Revis\~{a}o Bibliogr\'{a}fica Sistem\'{a}tica},
mendeley-tags = {RBS},
number = {1998},
pages = {1--12},
publisher = {UFRGS},
title = {{Roteiro para revis\~{a}o bibliogr\'{a}fica sistem\'{a}tica: aplica\c{c}\~{a}o no desenvolvimento de produtos e gerenciamento de projetos}},
url = {http://vision.ime.usp.br/~acmt/conforto.pdf},
volume = {8},
year = {2011}
}
@book{Ponce2011,
abstract = {Computer Vision: A Modern Approach, 2e, is appropriate for upper-division undergraduate- and graduate-level courses in computer vision found in departments of Computer Science, Computer Engineering and Electrical Engineering. This textbook provides the most complete treatment of modern computer vision methods by two of the leading authorities in the field. This accessible presentation gives both a general view of the entire computer vision enterprise and also offers sufficient detail for students to be able to build useful applications. Students will learn techniques that have proven to be useful by first-hand experience and a wide range of mathematical methods},
author = {Ponce, Jean},
edition = {2},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2011/Ponce/Ponce - 2011 - Computer Vision A Modern Approach.pdf:pdf},
isbn = {013608592X},
pages = {761},
publisher = {Pearson Education, Limited},
title = {{Computer Vision: A Modern Approach}},
url = {http://books.google.com/books?id=gM63QQAACAAJ&pgis=1},
year = {2011}
}
@misc{Kooima2013,
author = {Kooima, Robert},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{Generalized Perspective Projection}},
url = {http://csc.lsu.edu/~kooima/articles/genperspective/index.html},
urldate = {2013-05-07},
year = {2013}
}
@inproceedings{Amrutur,
abstract = {A large fraction of scientific and engineering computations involve sparse matrices. While dense matrix computations can be parallelized relatively easily, sparse matrices with arbitrary or irregular structure pose a real challenge to designers of highly parallel machines. A recent paper by N.K. Karmarkar (1991) proposed a new parallel architecture for sparse matrix computations based on finite projective geometries. Mathematical structure of these geometries plays an important role in defining the interconnections between the processors and memories in this architecture, and also aids in efficiently solving several difficult problems (such as load balancing, data-routing, memory-access conflicts, etc.) that are encountered in the design of parallel systems. The authors discuss some of the key issues in the system design of such a machine, and show how exploiting the structure of the geometry results in an efficient hardware implementation of the machine. They also present circuit designs and simulation results for key elements of the system: a 200 MHz pipelined memory; a pipelined multiplier based on an adder unit with a delay of 2 ns; and a 500 Mbit/s CMOS input/output buffer},
author = {Amrutur, B.S. and Joshi, R. and Karmarkar, N.K.},
booktitle = {[1992] Proceedings of the International Conference on Application Specific Array Processors},
doi = {10.1109/ASAP.1992.218581},
file = {:home/acmt/Dropbox/Documentos/Mendeley/1992 Proceedings of the International Conference on Application Specific Array Processors/Unknown/Amrutur, Joshi, Karmarkar/Amrutur, Joshi, Karmarkar - Unknown - A projective geometry architecture for scientific computation.pdf:pdf},
isbn = {0-8186-2967-3},
pages = {64--80},
publisher = {IEEE Comput. Soc. Press},
title = {{A projective geometry architecture for scientific computation}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=218581&contentType=Conference+Publications&searchField=Search_All&queryText=.QT.projective+geometry.QT.}
}
@inproceedings{Sukthankar2005,
abstract = {Traditional desktop computing paradigms provide a poor interface for interacting with intelligent physical spaces. Although handheld devices are an important platform for interface agents, their displays are inadequate for many pervasive computing tasks and need to be supplemented by larger high-resolution displays. We propose the notion of augmenting indoor intelligent environments with ambient projection, where large numbers of projectors simultaneously illuminate the environment from multiple directions - analogous to the way in which ambient lighting permeates a room. Ambient projection could enable any suitable surface in an environment to be employed as a display device. Using such displays, the intelligent environment could present high-resolution information, proactively alert users who are not carrying handheld devices and annotate objects in the environment without instrumentation. Several challenges must be solved before such projected displays become a practical solution. This paper provides an overview of our research in computer vision for enabling interactive ambient projected displays.},
author = {Sukthankar, R},
booktitle = {Computer Vision for Interactive and Intelligent Environment (CVIIE'05)},
doi = {10.1109/CVIIE.2005.20},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Computer Vision for Interactive and Intelligent Environment (CVIIE'05)/2005/Sukthankar/Sukthankar - 2005 - Towards Ambient Projection for Intelligent Environments.pdf:pdf},
isbn = {0-7695-2524-5},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {162--172},
publisher = {IEEE},
title = {{Towards Ambient Projection for Intelligent Environments}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1623778 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1623778},
year = {2005}
}
@inproceedings{Hen2009,
abstract = {Vision-based techniques to estimate 3D human pose from single camera are important in many applications like entertainment and games industries, sports science, gait analysis and video surveillance. While de-facto optical-based motion capture system is highly accurate in estimating 3D human pose, vision-based techniques offer better alternative because the latter are far cheaper and non-intrusive. In this paper, we review recent significant advances made in single-camera 3D human pose estimation techniques. We discuss about challenges faced, typical image observations used, ways to address the challenges and highlighting limitations in state-of-the-art. We conclude this paper with speculation of future research directions as well as open research problems.},
author = {Hen, Yap Wooi and Paramesran, Raveendran},
booktitle = {2009 International Conference for Technical Postgraduates (TECHPOS)},
doi = {10.1109/TECHPOS.2009.5412094},
isbn = {978-1-4244-5223-1},
keywords = {3D human pose estimation,Application software,Biological system modeling,Cameras,Humans,Image reconstruction,Joints,Motion estimation,Skeleton,Toy industry,Video surveillance,pose estimation,reconstruction,single camera,vision-based techniques},
mendeley-tags = {reconstruction},
month = dec,
pages = {1--8},
publisher = {IEEE},
shorttitle = {Technical Postgraduates (TECHPOS), 2009 Internatio},
title = {{Single camera 3D human pose estimation: A Review of current techniques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5412094},
year = {2009}
}
@inproceedings{Zhu2010,
abstract = {In teleoperation, operators usually have to control multiple devices simultaneously, which requires frequent hand switches between different controllers. We designed and implemented two prototypes, one by applying head motion and the other by integrating eye gaze as intrinsic elements of teleoperation for remote camera control in a multi-control setting. We report a user study of a modeled multi-control experiment that compares the performance of head tracking control, eye tracking control and traditional joystick control. The results provide clear evidence that eye tracking control significantly outperforms joystick and head tracking control in both objective measures and subjective measures.},
address = {New York, New York, USA},
annote = {- cited by: 3
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Zhu, Dingyun and Gedeon, Tom and Taylor, Ken},
booktitle = {Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems - CHI EA '10},
doi = {10.1145/1753846.1753963},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems - CHI EA '10/2010/Zhu, Gedeon, Taylor/Zhu, Gedeon, Taylor - 2010 - Natural interaction enhanced remote camera control for teleoperation.pdf:pdf},
isbn = {9781605589305},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {3229--3234},
publisher = {ACM Press},
title = {{Natural interaction enhanced remote camera control for teleoperation}},
url = {http://dl.acm.org/citation.cfm?id=1753963 http://portal.acm.org/citation.cfm?doid=1753846.1753963},
year = {2010}
}
@inproceedings{Teather2013,
abstract = {We present a study of cursors for selecting 2D-projected 3D targets. We compared a stereo- and mono-rendered (one-eyed) cursor using two mouse-based and two remote pointing techniques in a 3D Fitts' law pointing experiment. The first experiment used targets at fixed depths. Results indicate that one-eyed cursors only improve screen-plane pointing techniques, and that constant target depth does not influence pointing throughput. A second experiment included pointing between targets at varying depths and used only "screen-plane" pointing techniques. Our results suggest that in the absence of stereo cue conflicts, screen-space projections of Fitts' law parameters (target size and distance) yield constant throughput despite target depth differences and produce better models of performance.},
address = {New York, New York, USA},
author = {Teather, Robert J. and Stuerzlinger, Wolfgang},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470677},
isbn = {9781450318990},
pages = {159--168},
publisher = {ACM Press},
title = {{Pointing at 3d target projections with one-eyed and stereo cursors}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470677},
year = {2013}
}
@article{Azuma1995,
abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
address = {Los Angeles},
author = {Azuma, Ronald T},
doi = {10.1.1.35.5387},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Presence Teleoperators and Virtual Environments/1995/Azuma/Azuma - 1995 - A Survey of Augmented Reality.pdf:pdf},
journal = {Presence: Teleoperators and Virtual Environments},
number = {4},
pages = {355--385},
publisher = {ACM},
title = {{A Survey of Augmented Reality}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.5387},
volume = {6},
year = {1995}
}
@inproceedings{Holland2013a,
abstract = {This paper presents an objective evaluation of previously unexplored biometric techniques utilizing patterns identifiable in human eye movements to distinguish individuals. The distribution of primitive eye movement features are compared between eye movement recordings using algorithms based on the following statistical tests: the Ansari-Bradley test, the Mann-Whitney U-test, the two-sample Kolmogorov-Smirnov test, the two-sample t-test, and the two-sample Cramer-von Mises test. Score-level information fusion is applied and evaluated by: weighted mean, support vector machine, random forest, and likelihood ratio. The accuracy of each comparison/jusion algorithm is evaluated, with results suggesting that, on high resolution eye tracking equipment, it is possible to obtain equal error rates of 16.5\% and rank-1 identification rates of 82.6\% using the two-sample Cramér-von Mises test and score-level information fusion by random forest, the highest accuracy results on the considered dataset.},
address = {Madrid},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Holland, Corey D. and Komogortsev, Oleg V.},
booktitle = {2013 International Conference on Biometrics (ICB)},
doi = {10.1109/ICB.2013.6612953},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2013 International Conference on Biometrics (ICB)/2013/Holland, Komogortsev/Holland, Komogortsev - 2013 - Complex eye movement pattern biometrics Analyzing fixations and saccades.pdf:pdf},
isbn = {978-1-4799-0310-8},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Complex eye movement pattern biometrics: Analyzing fixations and saccades}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6612953 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6612953},
year = {2013}
}
@book{Dunn2002,
address = {Plano-TX},
author = {Dunn, Fletcher and Parberry, Ian},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2002/Dunn, Parberry/Dunn, Parberry - 2002 - 3D Math Primer for Graphics and Game Development.pdf:pdf},
isbn = {1556229119},
keywords = {3D Math,Euler,Quaternions,Transforming matrix,Translation,rotation,scale,skew},
mendeley-tags = {3D Math,Euler,Quaternions,rotation,scale,skew,Transforming matrix,Translation},
pages = {448},
publisher = {Wordware Game Math Library},
title = {{3D Math Primer for Graphics and Game Development}},
year = {2002}
}
@article{Lasecki2013,
address = {New York, New York, USA},
author = {Lasecki, Walter S. and Miller, Christopher D. and Bigham, Jeffrey P.},
doi = {10.1145/2470654.2466269},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2033},
publisher = {ACM Press},
title = {{Warping time for more effective real-time crowdsourcing}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466269},
year = {2013}
}
@article{Bardzell2013,
address = {New York, New York, USA},
author = {Bardzell, Jeffrey and Bardzell, Shaowen},
doi = {10.1145/2470654.2466451},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3297},
publisher = {ACM Press},
title = {{What is "critical" about critical design?}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466451},
year = {2013}
}
@article{Ichino2013,
address = {New York, New York, USA},
author = {Ichino, Junko and Isoda, Kazuo and Hanai, Ayako and Ueda, Tetsuya},
doi = {10.1145/2470654.2481413},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2979},
publisher = {ACM Press},
title = {{Effects of the display angle in museums on user's cognition, behavior, and subjective responses}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481413},
year = {2013}
}
@phdthesis{Lee2008a,
abstract = {Today, the primary use of projection technology is for creating large flat displays that provide a shared viewing experience for presentations or entertainment applications. While research projects have explored the powerful ability for projected light to create illusions that can reshape our perception and our interaction with surfaces in the environment, very few of these systems have had success in terms of commercial and consumer adoption. Part of this limited adoption can be attributed to the lack of practicality in the cost-of-operation due to the complexity of installation and reliability of execution. Often these systems require expert knowledge to perform system setup and calibration between the projected image and the physical surfaces to make these illusions effective. In this thesis, I present a technique for inherently adding object location discovery and tracking capabilities to commercial projectors. This is accomplished by introducing light sensors into the projection area and then spatially encoding the image area using a series of structured light patterns. This delivers a unique pattern of light to every pixel in the projector’s screen space directly encoding the location data using the projector itself. By unifying the image projection and location tracking technologies, many of the difficult calibration and alignment issues related to interactive projection and projected spatial augmented reality applications can be eliminated simplifying their implementation and execution. Furthermore, by creating a hybrid visible light and infrared light projector, a single calibration-free device can perform invisible location tracking of input devices while simultaneously presenting visible application content. I present a detailed description of the projector-based location discovery and tracking technique, a description of three prototype implementations, and a demonstration of the effectiveness of this simplification by re-implementing, and in some cases improving upon, several location-sensitive projector applications that have been previously executed using external calibration and tracking technologies.},
author = {Lee, JC},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2008/Lee/Lee - 2008 - Projector-based location discovery and tracking.pdf:pdf},
keywords = {Image projection,anamorphism,augmented reality,high-speed projection,incremental tracking.,infrared projection,keystone,location tracking,motion capture,multi-projector applications,projector alignment,projector calibration},
mendeley-tags = {anamorphism,keystone},
pages = {106},
school = {Carnegie Mellon University},
title = {{Projector-based location discovery and tracking}},
url = {http://ra.adm.cs.cmu.edu/anon/usr/ftp/hcii/CMU-HCII-08-102.pdf},
year = {2008}
}
@article{Salojarvi2005,
abstract = {We organize a PASCAL EU Network of Excellence challenge for inferring relevance from eye movements, beginning 1 March 2005. The aim of this paper is to provide background material for the competitors: give references to related articles on eye movement modelling, describe the methods used for extracting the features used in the challenge, provide results of basic reference methods and to discuss open questions in the field.},
annote = {- cited by: 27
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Saloj\"{a}rvi, J and Puolam\"{a}ki, K and Simola, J and Kovanen, L},
doi = {10.1.1.96.6356},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2005/Saloj\"{a}rvi et al/Saloj\"{a}rvi et al. - 2005 - Inferring relevance from eye movements Feature extraction.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
title = {{Inferring relevance from eye movements: Feature extraction}},
url = {http://eprints.pascal-network.org/archive/00000963/},
year = {2005}
}
@book{Norman1988,
author = {Norman, Donald},
isbn = {0465067093},
pages = {257},
publisher = {Basic Books},
title = {{The psychology of everyday things}},
url = {http://www.livrariacultura.com.br/scripts/cultura/resenha/resenha.asp& nitem=255317},
year = {1988}
}
@article{Humphrey2010,
author = {Humphrey, K and Underwood, G},
journal = {Journal of Vision},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
title = {{The potency of people in pictures: Evidence from sequences of eye fixations}},
url = {http://w.journalofvision.org/content/10/10/19.short},
year = {2010}
}
@phdthesis{Bergstrand2008,
abstract = {The movement of a persons eyes is an interesting factor to study in different research areas where attention is important, for example driving. In 2004 the Swedish national road and transport research institute (VTI) introduced Simu- lator III – their third generation of driving simulators. Inside Simulator III a camera based eye tracking system is installed that records the eye movements of the driver. To be useful, the raw data from the eye tracking system needs to be analyzed and concentrated into a number of measures relevant for the research at VTI. This thesis presents methods to analyze the data from the eye tracker and transform it into something more useful. A world coordinate system is setup to connect the eye tracking system with the real world in a consistent way. A set of measures is collected, mainly from ISO and SAE standards, to be used as output from the analysis. Finally an application is developed for performing the analysis. The application reads the data from the eye tracker and the simulator, analyzes the data, and outputs a set of eye movement measures usable for the researchers at VTI.},
author = {Bergstrand, M},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2008/Bergstrand/Bergstrand - 2008 - Automatic analysis of eye tracker data from a driving simulator.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {63},
school = {Link\"{o}pings unversitet},
title = {{Automatic analysis of eye tracker data from a driving simulator}},
url = {http://www.diva-portal.org/smash/record.jsf?pid=diva2:636736},
year = {2008}
}
@article{Srivastava2005,
address = {New York, New York, USA},
author = {Srivastava, Deepti and Narasimhan, Priya},
doi = {10.1145/1083217.1083226},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2005 workshop on Architecting dependable systems - WADS '05/2005/Srivastava, Narasimhan/Srivastava, Narasimhan - 2005 - Architectural support for mode-driven fault tolerance in distributed applications.pdf:pdf},
isbn = {1595931244},
journal = {Proceedings of the 2005 workshop on Architecting dependable systems - WADS '05},
keywords = {corba,cots systems,distributed systems,erance,fault tol-,modes,nsf ca-,partially supported by the,replication,software architecture,this work has been},
pages = {1--7},
publisher = {ACM Press},
title = {{Architectural support for mode-driven fault tolerance in distributed applications}},
url = {http://portal.acm.org/citation.cfm?doid=1083217.1083226},
year = {2005}
}
@article{Ruiz2010,
author = {Ruiz, Marc and Szirmay-Kalos, L\'{a}zl\'{o} and Umenhoffer, Tam\'{a}s and Boada, Imma and Feixas, Miquel and Sbert, Mateu},
doi = {10.1007/s00371-010-0497-z},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The Visual Computer/2010/Ruiz et al/Ruiz et al. - 2010 - Volumetric ambient occlusion for volumetric models.pdf:pdf},
issn = {0178-2789},
journal = {The Visual Computer},
keywords = {gpu,importance sampling,obscurances,real-time ambient occlusion},
month = apr,
number = {6-8},
pages = {687--695},
title = {{Volumetric ambient occlusion for volumetric models}},
url = {http://www.springerlink.com/index/10.1007/s00371-010-0497-z},
volume = {26},
year = {2010}
}
@inproceedings{Steimle2013,
abstract = {Flexpad is an interactive system that combines a depth camera and a projector to transform sheets of plain paper or foam into flexible, highly deformable, and spatially aware handheld displays. We present a novel approach for tracking deformed surfaces from depth images in real time. It captures deformations in high detail, is very robust to occlusions created by the user's hands and fingers, and does not require any kind of markers or visible texture. As a result, the display is considerably more deformable than in previous work on flexible handheld displays, enabling novel applications that leverage the high expressiveness of detailed deformation. We illustrate these unique capabilities through three application examples: curved cross-cuts in volumetric images, deforming virtual paper characters, and slicing through time in videos. Results from two user studies show that our system is capable of detecting complex deformations and that users are able to perform them quickly and precisely.},
address = {New York, New York, USA},
author = {Steimle, J\"{u}rgen and Jordt, Andreas and Maes, Pattie},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470688},
isbn = {9781450318990},
keywords = {Flexible display,bending,deformation,depth camera,handheld display,projection,tracking,volumetric data},
pages = {237--246},
publisher = {ACM Press},
title = {{Flexpad: highly flexible bending interactions for projected handheld displays}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470688},
year = {2013}
}
@article{Kuttal2013,
address = {New York, New York, USA},
author = {Kuttal, Sandeep Kaur and Sarma, Anita and Rothermel, Gregg},
doi = {10.1145/2470654.2466213},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1609},
publisher = {ACM Press},
title = {{Debugging support for end user mashup programming}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466213},
year = {2013}
}
@article{Mantiuk2013,
abstract = {In this paper we model the process of temporal adaptation of the human visual system to varying luminance conditions. An eye tracker is used to capture the location of an observer’s gaze in a high dynamic range image displayed on the screen. We apply a novel technique of eye tracker data filtering to avoid flickering caused by incorrect gaze estimation. Temporary adaptation luminance is then determined in the area surrounding the gaze point. We use its value to compress the high dynamic range image and display it on the low dynamic range display. The applied tone mapping technique uses a global compression curve in which location is shifted along the luminance axis according to a value of the adaptation luminance. This technique models the natural process of adaptation occurring in the human eyes, also taking into account the time-dependent visual adaptation to dark and bright backgrounds.},
author = {Mantiuk, R and Markowski, M},
doi = {10.1007/978-3-642-39094-4\_48},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Image Analysis and Recognition/2013/Mantiuk, Markowski/Mantiuk, Markowski - 2013 - Gaze-Dependent Tone Mapping.pdf:pdf},
journal = {Image Analysis and Recognition},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {426--433},
title = {{Gaze-Dependent Tone Mapping}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-39094-4_48},
volume = {7950},
year = {2013}
}
@incollection{Kale2005,
address = {New York},
author = {Kale, A and Kwan, K and Jaynes, C},
booktitle = {Real-Time Vision for Human-Computer Interaction},
doi = {10.1007/0-387-27890-7\_12},
editor = {Kisa\v{c}anin, Branislav and Pavlovi\'{c}, Vladimir and Huang, Thomas S.},
isbn = {0-387-27697-1},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {201--214},
publisher = {Springer-Verlag},
title = {{Epipolar Constrained User Pushbutton Selection in Projected Interfaces}},
url = {http://link.springer.com/content/pdf/10.1007/0-387-27890-7_12.pdf http://link.springer.com/10.1007/0-387-27890-7},
year = {2005}
}
@article{Kusano2013,
address = {New York, New York, USA},
author = {Kusano, Koki and Nakatani, Momoko and Ohno, Takehiko},
doi = {10.1145/2470654.2470710},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {391},
publisher = {ACM Press},
title = {{Scenario-based interactive UI design}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470710},
year = {2013}
}
@inproceedings{Danisman2010,
abstract = {This paper presents an automatic drowsy driver monitoring and accident prevention system that is based on monitoring the changes in the eye blink duration. Our proposed method detects visual changes in eye locations using the proposed horizontal symmetry feature of the eyes. Our new method detects eye blinks via a standard webcam in real-time at 110fps for a 320×240 resolution. Experimental results in the JZU eye-blink database showed that the proposed system detects eye blinks with a 94\% accuracy with a 1\% false positive rate.},
author = {Danisman, Taner and Bilasco, Ian M and Djeraba, Chabane and Ihaddadene, Nacim},
booktitle = {2010 International Conference on Machine and Web Intelligence},
doi = {10.1109/ICMWI.2010.5648121},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 International Conference on Machine and Web Intelligence/2010/Danisman et al/Danisman et al. - 2010 - Drowsy driver detection system using eye blink patterns.pdf:pdf},
isbn = {978-1-4244-8608-3},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = oct,
pages = {230--233},
publisher = {IEEE},
title = {{Drowsy driver detection system using eye blink patterns}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5648121 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5648121},
year = {2010}
}
@article{Rashbass1961,
author = {Rashbass, C},
file = {::},
journal = {The Journal of Physiology},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{The relationship between saccadic and smooth tracking eye movements}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1359508/},
year = {1961}
}
@incollection{Fitts1975,
address = {Belmont},
booktitle = {Human Performance},
editor = {Fitts, P. and Posner, M.},
pages = {42--82},
publisher = {Greenwood Press},
title = {{Component processes and performance capacities}},
year = {1975}
}
@article{Crawford1998,
author = {Crawford, George},
doi = {10.1145/333151.333154},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Crossroads/1998/Crawford/Crawford - 1998 - Creating a 3D universe in Java3D.pdf:pdf},
issn = {15284972},
journal = {Crossroads},
month = nov,
number = {2},
pages = {4--10},
title = {{Creating a 3D universe in Java3D}},
url = {http://portal.acm.org/citation.cfm?doid=333151.333154},
volume = {5},
year = {1998}
}
@inproceedings{Levin2008,
abstract = {Modern geospatial data acquisition systems deliver vast amounts of multi-domain remotely sensed data such as multi/hyper spectral imagery and LIDAR point-clouds. Unfortunately geospatial products automatically derived from source geospatial data are burdened with residual errors and artifacts which should be manually inspected, cleaned and corrected. These tasks become critical in many large-scale projects that require real-time processing of immense amounts of visual information and usually require manual post-processing or visual inspection of the source and/or derived data. The process of visual inspection could be divided in two general phases: perception and reaction. Scene perception comprises several steps such as visual search, feature selection and identification. Reaction reflects a decision made by an operator and usually involves other types of modalities (e.g. physical action such as mouse movements or typing). Human analysts perceive visual data through intensive movements of eyes which subconsciously select the most distinctive features in an image in order to reduce our overall ambiguity about the observed scene. A sequence of eye movements may then be understood within a framework of sequential accumulation of information. Whether or not all informative points are detected depends on both the observer’s current knowledge of the stimulus and the particular task. Dynamics of this information accrual process can be documented and quantified using analysis of eye movements during the process of natural, active visual perception. This paper presents theoretical and practical investigations that have been made to illustrate the feasibility of 3D gaze tracking as a disambiguation tool in the process of visual search of a target in high resolution imagery.},
address = {Portland},
annote = {- cited by: 5
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Levin, E and Helton, W and Liimakka, R and Gienko, G},
booktitle = {Proceedings of ASPRS Annual Conference},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of ASPRS Annual Conference/2008/Levin et al/Levin et al. - 2008 - Eye movement analysis in visual inspection of geospatial data.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
title = {{Eye movement analysis in visual inspection of geospatial data}},
url = {http://www.asprs.org/a/publications/proceedings/portland08/0050.pdf},
year = {2008}
}
@article{Goyal2013,
address = {New York, New York, USA},
author = {Goyal, Nitesh and Leshed, Gilly and Fussell, Susan R.},
doi = {10.1145/2470654.2481376},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {2721},
publisher = {ACM Press},
title = {{Effects of visualization and note-taking on sensemaking and analysis}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481376},
year = {2013}
}
@article{Barnard1983a,
abstract = {Ce papier parle des contraintes perspective: notamment les points de fuite, l'angle etc. pas mal.},
author = {Barnard, S T},
journal = {Artificial Intelligence},
number = {4},
pages = {435--462},
title = {{Interpreting Perspective Images}},
url = {http://dx.doi.org/10.1016/S0004-3702(83)80021-6},
volume = {21},
year = {1983}
}
@article{Regenbrecht2006,
author = {Regenbrecht, H. and Ott, C. and Wagner, M. and Lum, T. and Kohler, P. and Wilke, W. and Mueller, E.},
doi = {10.1109/ISMAR.2003.1240725},
isbn = {0-7695-2006-5},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {290--291},
publisher = {IEEE Comput. Soc},
title = {{An augmented virtuality approach to 3D videoconferencing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240725},
year = {2006}
}
@misc{Rizzoli2009,
author = {Rizzoli, A E},
title = {{A Collection of Modelling and Simulation Resources on the Internet}},
url = {http://www.idsia.ch/~andrea/simtools.html},
year = {2009}
}
@techreport{Olsen2012,
abstract = {This document describes the general principles behind an I-VT fixation filter and they are implemented in the Tobii I-VT Fixation Filter.},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Olsen, A},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2012/Olsen/Olsen - 2012 - The Tobii I-VT Fixation Filter.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {21},
title = {{The Tobii I-VT Fixation Filter}},
url = {http://www.tobii.com/Global/Analysis/Training/WhitePapers/Tobii_WhitePaper_TobiiIVTFixationFilter.pdf},
year = {2012}
}
@article{Alexiadis2013,
abstract = {The problem of robust, realistic and especially fast 3-D reconstruction of objects, although extensively studied, is still a challenging research task. Most of the state-of-the-art approaches that target real-time applications, such as immersive reality, address mainly the problem of synthesizing intermediate views for given view-points, rather than generating a single complete 3-D surface. In this paper, we present a multiple-Kinect capturing system and a novel methodology for the creation of accurate, realistic, full 3-D reconstructions of moving foreground objects, e.g., humans, to be exploited in real-time applications. The proposed method generates multiple textured meshes from multiple RGB-Depth streams, applies a coarse-to-fine registration algorithm and finally merges the separate meshes into a single 3-D surface. Although the Kinect sensor has attracted the attention of many researchers and home enthusiasts and has already appeared in many applications over the Internet, none of the already presented works can produce full 3-D models of moving objects from multiple Kinect streams in real-time. We present the capturing setup, the methodology for its calibration and the details of the proposed algorithm for real-time fusion of multiple meshes. The presented experimental results verify the effectiveness of the approach with respect to the 3-D reconstruction quality, as well as the achieved frame rates.},
author = {Alexiadis, Dimitrios S. and Zarpalas, Dimitrios and Daras, Petros},
doi = {10.1109/TMM.2012.2229264},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Multimedia/2013/Alexiadis, Zarpalas, Daras/Alexiadis, Zarpalas, Daras - 2013 - Real-Time, Full 3-D Reconstruction of Moving Foreground Objects From Multiple Consumer Depth Cameras.pdf:pdf},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
month = feb,
number = {2},
pages = {339--358},
title = {{Real-Time, Full 3-D Reconstruction of Moving Foreground Objects From Multiple Consumer Depth Cameras}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6359953&contentType=Journals+&+Magazines&searchField=Search_All&queryText=kinect+calibration},
volume = {15},
year = {2013}
}
@article{Comport2006,
abstract = {Tracking is a very important research subject in a real-time augmented reality context. The main requirements for trackers are high accuracy and little latency at a reasonable cost. In order to address these issues, a real-time, robust, and efficient 3D model-based tracking algorithm is proposed for a "video see through" monocular vision system. The tracking of objects in the scene amounts to calculating the pose between the camera and the objects. Virtual objects can then be projected into the scene using the pose. Here, nonlinear pose estimation is formulated by means of a virtual visual servoing approach. In this context, the derivation of point-to-curves interaction matrices are given for different 3D geometrical primitives including straight lines, circles, cylinders, and spheres. A local moving edges tracker is used in order to provide real-time tracking of points normal to the object contours. Robustness is obtained by integrating an M-estimator into the visual control law via an iteratively reweighted least squares implementation. This approach is then extended to address the 3D model-free augmented reality problem. The method presented in this paper has been validated on several complex image sequences including outdoor environments. Results show the method to be robust to occlusion, changes in illumination, and mistracking.},
author = {Comport, A.I. and Marchand, \'{E}ric and Pressigout, Muriel and Chaumette, Fran\c{c}ois},
doi = {10.1109/TVCG.2006.78},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Visualization and Computer Graphics/2006/Comport et al/Comport et al. - 2006 - Real-time markerless tracking for augmented reality the virtual visual servoing framework.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithms,Computer Graphics,Computer Systems,Computer-Assisted,Computer-Assisted: methods,Feedback,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Signal Processing,Three-Dimensional,Three-Dimensional: methods,User-Computer Interface},
number = {4},
pages = {615--628},
pmid = {16805268},
publisher = {IEEE Computer Society},
title = {{Real-time markerless tracking for augmented reality: the virtual visual servoing framework}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16805268 http://www.computer.org/portal/web/csdl/doi/10.1109/tvcg.2006.78},
volume = {12},
year = {2006}
}
@article{Renshaw2004,
abstract = {We describe an experiment in which the eye movements of participants, carrying out tasks using two contrasting graph designs, were recorded by means of a remote eye tracking device. A variety of eye movement properties were measured and analysed both temporally and spatially. Both graph designs were based on specific psychological theories and established graph design guidelines. One incorporated attributes thought likely to enhance usability, the other included attributes likely to have the opposite effect. The results demonstrate that the design and location of a graph's legend and its spatial relationship to the data area are extremely important in determining a graph's usability. The incorporation of these and other design features may promote or detract from perceptual proximity and therefore influence a display's usability. The paper demonstrates that this influence is reflected in eye movement patterns, which can be readily monitored by means of a remote eye tracking system, and that a relatively simple temporal analysis of the results can give important insights as to how the usability of visual displays has been influenced.},
annote = {- cited by: 26
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Renshaw, J.A and Finlay, J.E and Tyfa, D and Ward, R.D},
doi = {10.1016/j.intcom.2004.03.001},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Interacting with Computers/2004/Renshaw et al/Renshaw et al. - 2004 - Understanding visual influence in graph design through temporal and spatial eye movement characteristics.pdf:pdf},
journal = {Interacting with Computers},
keywords = {Eye tracking,Graphs,Perception,Usability,gaze analysis},
mendeley-tags = {gaze analysis},
number = {3},
pages = {557--578},
title = {{Understanding visual influence in graph design through temporal and spatial eye movement characteristics}},
url = {http://www.sciencedirect.com/science/article/pii/S0953543804000360},
volume = {16},
year = {2004}
}
@inproceedings{Foster2013,
abstract = {We investigate the unique educational benefits of 1-on-1 competitive games, arguing that such games can be just as easy to design as single-player educational games, while yielding a more diverse and sustainable learning experience. We present a study of chess and StarCraft II in order to inform the design of similar educational games and their communities. We discuss a competitive game we designed to teach Java programming. We evaluate the game by discussing its user study. Our main contributions are 1) an argument that the use of 1-on-1 competition can solve two existing problems inherent to single-player games, 2) an analysis of the features that make competitive games effective learning environments, and 3) an early but encouraging description of the emergent learning environment one can expect from designing an educational game with these features.},
address = {New York, New York, USA},
author = {Foster, Stephen R and Esper, Sarah and Griswold, William G.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470669},
isbn = {9781450318990},
pages = {99--108},
publisher = {ACM Press},
title = {{From competition to metacognition: designing diverse, sustainable educational games}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470669},
year = {2013}
}
@inproceedings{Stellmach2013,
abstract = {We investigate how to seamlessly bridge the gap between users and distant displays for basic interaction tasks, such as object selection and manipulation. For this, we take advantage of very fast and implicit, yet imprecise gaze- and head-directed input in combination with ubiquitous smartphones for additional manual touch control. We have carefully elaborated two novel and consistent sets of gaze-supported interaction techniques based on touch-enhanced gaze pointers and local magnification lenses. These conflict-free sets allow for fluently selecting and positioning distant targets. Both sets were evaluated in a user study with 16 participants. Overall, users were fastest with a touch-enhanced gaze pointer for selecting and positioning an object after some training. While the positive user feedback for both sets suggests that our proposed gaze- and head-directed interaction techniques are suitable for a convenient and fluent selection and manipulation of distant targets, further improvements are necessary for more precise cursor control.},
address = {New York, New York, USA},
author = {Stellmach, Sophie and Dachselt, Raimund},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470695},
isbn = {9781450318990},
pages = {285--294},
publisher = {ACM Press},
title = {{Still looking: investigating seamless gaze-supported selection, positioning, and manipulation of distant targets}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470695},
year = {2013}
}
@inproceedings{Harpstead2013,
abstract = {The field of Educational Games has seen many calls for added rigor. One avenue for improving the rigor of the field is developing more generalizable methods for measuring student learning within games. Throughout the process of development, what is relevant to measure and assess may change as a game evolves into a finished product. The field needs an approach for game developers and researchers to be able to prototype and experiment with different measures that can stand up to rigorous scrutiny, as well as provide insight into possible new directions for development. We demonstrate a toolkit and analysis tools that capture and analyze students' performance within open educational games. The system records relevant events during play, which can be used for analysis of player learning by designers. The tools support replaying student sessions within the original game's environment, which allows researchers and developers to explore possible explanations for student behavior. Using this system, we were able to facilitate a number of analyses of student learning in an open educational game developed by a team of our collaborators as well as gain greater insight into student learning with the game and where to focus as we iterate.},
address = {New York, New York, USA},
author = {Harpstead, Erik and Myers, Brad A and Aleven, Vincent},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470667},
isbn = {9781450318990},
pages = {79--88},
publisher = {ACM Press},
title = {{In search of learning: facilitating data analysis in educational games}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470667},
year = {2013}
}
@inproceedings{Vatavu2013,
abstract = {We show that large consensus exists among users in the way they articulate stroke gestures at various scales (i.e., small, medium, and large), and formulate a simple rule that estimates the user-intended scale of input gestures with 87\% accuracy. Our estimator can enhance current gestural interfaces by leveraging scale as a natural parameter for gesture input, reflective of user perception (i.e., no training required). Gesture scale can simplify gesture set design, improve gesture-to-function mappings, and reduce the need for users to learn and for recognizers to discriminate unnecessary symbols.},
address = {New York, New York, USA},
author = {Vatavu, Radu-daniel and Casiez, G\'{e}ry and Grisoni, Laurent},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470692},
isbn = {9781450318990},
pages = {277--284},
publisher = {ACM Press},
title = {{Small, medium, or large?: estimating the user-perceived scale of stroke gestures}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470692},
year = {2013}
}
@article{Cristino2010,
abstract = {We present a novel approach to comparing saccadic eye movement sequences based on the Needleman-Wunsch algorithm used in bioinformatics to compare DNA sequences. In the proposed method, the saccade sequence is spatially and temporally binned and then recoded to create a sequence of letters that retains fixation location, time, and order information. The comparison of two letter sequences is made by maximizing the similarity score computed from a substitution matrix that provides the score for all letter pair substitutions and a penalty gap. The substitution matrix provides a meaningful link between each location coded by the individual letters. This link could be distance but could also encode any useful dimension, including perceptual or semantic space. We show, by using synthetic and behavioral data, the benefits of this method over existing methods. The ScanMatch toolbox for MATLAB is freely available online (www.scanmatch.co.uk).},
author = {Cristino, Filipe and Math\^{o}t, Sebastiaan and Theeuwes, Jan and Gilchrist, Iain D},
doi = {10.3758/BRM.42.3.692},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2010/Cristino et al/Cristino et al. - 2010 - ScanMatch a novel method for comparing fixation sequences.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Algorithms,Computational Biology,Fixation,Humans,Ocular,Ocular: physiology,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Reading,Saccades,Saccades: physiology,Semantics,Software,User-Computer Interface,Visual Perception,Visual Perception: physiology,eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
month = aug,
number = {3},
pages = {692--700},
pmid = {20805591},
title = {{ScanMatch: a novel method for comparing fixation sequences.}},
url = {http://link.springer.com/article/10.3758/BRM.42.3.692 http://www.ncbi.nlm.nih.gov/pubmed/20805591},
volume = {42},
year = {2010}
}
@misc{Oracle,
author = {Oracle},
title = {{MySQL}},
url = {http://www.mysql.com/},
urldate = {17/01/2012}
}
@inproceedings{Herbelin2007,
author = {Herbelin, Bruno and Grillon, Helena and {De Heras Ciechomski}, Pablo and Thalmann, Daniel},
booktitle = {17th International Conference on Artificial Reality and Telexistence (ICAT 2007)},
doi = {10.1109/ICAT.2007.28},
file = {:home/acmt/Dropbox/Documentos/Mendeley/17th International Conference on Artificial Reality and Telexistence (ICAT 2007)/2007/Herbelin et al/Herbelin et al. - 2007 - Coding gaze tracking data with chromatic gradients for VR Exposure Therapy.pdf:pdf},
isbn = {0-7695-3056-7},
month = nov,
pages = {7--14},
publisher = {IEEE},
title = {{Coding gaze tracking data with chromatic gradients for VR Exposure Therapy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4414610},
year = {2007}
}
@article{Komogortsev2009a,
abstract = {Our work addresses one of the core issues related to Human Computer Interaction (HCI) systems that use eye gaze as an input. This issue is the sensor, transmission and other delays that exist in any eye tracker-based system, reducing its performance. A delay effect can be compensated by an accurate prediction of the eye movement trajectories. This paper introduces a mathematical model of the human eye that uses anatomical properties of the Human Visual System to predict eye movement trajectories. The eye mathematical model is transformed into a Kalman filter form to provide continuous eye position signal prediction during all eye movement types. The model presented in this paper uses brainstem control properties employed during transitions between fast (saccade) and slow (fixations, pursuit) eye movements. Results presented in this paper indicate that the proposed eye model in a Kalman filter form improves the accuracy of eye movement prediction and is capable of a real-time performance. In addition to the HCI systems with the direct eye gaze input, the proposed eye model can be immediately applied for a bit-rate/computational reduction in real-time gaze-contingent systems.},
author = {Komogortsev, Oleg V. and Khan, Javed I.},
doi = {10.1007/s11768-009-7218-z},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Control Theory and Applications/2009/Komogortsev, Khan/Komogortsev, Khan - 2009 - Eye movement prediction by oculomotor plant Kalman filter with brainstem control.pdf:pdf},
issn = {1672-6340},
journal = {Journal of Control Theory and Applications},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = feb,
number = {1},
pages = {14--22},
title = {{Eye movement prediction by oculomotor plant Kalman filter with brainstem control}},
url = {http://link.springer.com/article/10.1007/s11768-009-7218-z http://link.springer.com/10.1007/s11768-009-7218-z},
volume = {7},
year = {2009}
}
@inproceedings{Divjak2009,
address = {Tokyo, Japan},
author = {Divjak, M and Bischof, H},
booktitle = {IAPR Conference on Machine Vision Applications - MVA},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IAPR Conference on Machine Vision Applications - MVA/2009/Divjak, Bischof/Divjak, Bischof - 2009 - Eye Blink Based Fatigue Detection for Prevention of Computer Vision Syndrome.pdf:pdf},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
pages = {350--353},
title = {{Eye Blink Based Fatigue Detection for Prevention of Computer Vision Syndrome.}},
url = {http://www.mva-org.jp/Proceedings/2009CD/papers/10-04.pdf},
year = {2009}
}
@inproceedings{Jarodzka2010,
address = {New York, New York, USA},
author = {Jarodzka, Halszka and Holmqvist, Kenneth and Nystr\"{o}m, Marcus},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743718},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Jarodzka, Holmqvist, Nystr\"{o}m/Jarodzka, Holmqvist, Nystr\"{o}m - 2010 - A vector-based, multidimensional scanpath similarity measure.pdf:pdf},
isbn = {9781605589947},
keywords = {eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
pages = {211},
publisher = {ACM Press},
title = {{A vector-based, multidimensional scanpath similarity measure}},
url = {http://dl.acm.org/citation.cfm?id=1743718 http://portal.acm.org/citation.cfm?doid=1743666.1743718},
year = {2010}
}
@inproceedings{Lamboray2004,
abstract = {Free-viewpoint video is a promising technology for next-generation virtual and augmented reality applications. Our goal is to enhance collaborative VR applications with 3D video-conferencing features. In this paper, we propose a 3D video streaming technique which can be deployed in telepresence environments. The streaming characteristics of real-time 3D video sequences are investigated under various system and networking conditions. We introduce several encoding techniques and analyze their behavior with respect to resolution, bandwidth and inter-frame jitter. Our 3D video pipeline uses point samples as basic primitives and is fully integrated with a communication framework handling acknowledgment information for reliable network transmissions and application control data. The 3D video reconstruction process dynamically adapts to processing and networking bottlenecks. Our results show that a reliable transmission of our pixel-based differential prediction encoding leads to the best performance in terms of bandwidth, but is also quite sensitive to packet losses. A redundantly encoded stream achieves better results in presence of burst losses and seamlessly adapts to varying network throughput.},
author = {Lamboray, Edouard and Gross, Markus and Wurmlin, S.},
booktitle = {IEEE Virtual Reality 2004},
doi = {10.1109/VR.2004.1310060},
isbn = {0-7803-8415-6},
pages = {91--99, 218},
publisher = {IEEE},
title = {{Real-time streaming of point-based 3D video}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1310060},
year = {2004}
}
@inproceedings{Heo2013,
abstract = {The possibility of using shear forces is being explored recently as a method to enrich touch screen interaction. However, most of the related studies are restricted to the case of single-point shear forces, possibly owing to the difficulty of independently sensing shear forces at multiple touch points. In this paper, we propose indirect methods to estimate shear forces using the movement of contact areas. These methods enable multi-point shear force estimation, where the estimation is done for each finger independently. We show the feasibility of these methods through an informal user study with a demo application utilizing these methods.},
address = {New York, New York, USA},
author = {Heo, Seongkook and Lee, Geehyuk},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
doi = {10.1145/2468356.2479536},
file = {:home/acmt/Dropbox/Documentos/Mendeley/CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13/2013/Heo, Lee/Heo, Lee - 2013 - Indirect shear force estimation for multi-point shear force operations.pdf:pdf},
isbn = {9781450319522},
pages = {2835},
publisher = {ACM Press},
title = {{Indirect shear force estimation for multi-point shear force operations}},
url = {http://dl.acm.org/citation.cfm?doid=2468356.2479536},
year = {2013}
}
@article{Knudsen2007,
abstract = {A mechanistic understanding of attention is necessary for the elucidation of the neurobiological basis of conscious experience. This chapter presents a framework for thinking about attention that facilitates the analysis of this cognitive process in terms of underlying neural mechanisms. Four processes are fundamental to attention: working memory, top-down sensitivity control, competitive selection, and automatic bottom-up filtering for salient stimuli. Each process makes a distinct and essential contribution to attention. Voluntary control of attention involves the first three processes (working memory, top-down sensitivity control, and competitive selection) operating in a recurrent loop. Recent results from neurobiological research on attention are discussed within this framework.},
author = {Knudsen, Eric I},
doi = {10.1146/annurev.neuro.30.051606.094256},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Annual review of neuroscience/2007/Knudsen/Knudsen - 2007 - Fundamental components of attention.pdf:pdf},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Attention,Attention: physiology,Brain,Brain: anatomy \& histology,Brain: physiology,Cognition,Cognition: physiology,Fixation,Humans,Memory,Neural Inhibition,Neural Inhibition: physiology,Neural Pathways,Neural Pathways: physiology,Ocular,Ocular: physiology,Parietal Lobe,Parietal Lobe: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology,Short-Term,Short-Term: physiology},
month = jan,
pages = {57--78},
pmid = {17417935},
title = {{Fundamental components of attention.}},
url = {http://www.annualreviews.org/doi/pdf/10.1146/annurev.neuro.30.051606.094256 http://www.ncbi.nlm.nih.gov/pubmed/17417935},
volume = {30},
year = {2007}
}
@inproceedings{Tori2006,
address = {Bel\'{e}m},
author = {Tori, Romero and Kirner, Claudio},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {2--21},
publisher = {SBC},
title = {{Fundamentos de Realidade Virtual}},
year = {2006}
}
@inproceedings{beyond,
address = {New York, New York, USA},
author = {Lee, Jinha and Ishii, Hiroshi},
booktitle = {Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems - CHI EA '10},
doi = {10.1145/1753846.1754081},
isbn = {9781605589305},
keywords = {SBGames},
mendeley-tags = {SBGames},
organization = {ACM},
pages = {3931--3936},
publisher = {ACM Press},
title = {{Beyond: collapsible tools and gestures for computational design}},
url = {http://dl.acm.org/citation.cfm?id=1754081 http://portal.acm.org/citation.cfm?doid=1753846.1754081},
year = {2010}
}
@inproceedings{Draelos2012,
abstract = {With proper calibration of its color and depth cameras, the Kinect can capture detailed color point clouds at up to 30 frames per second. This capability positions the Kinect for use in robotics as a low-cost navigation sensor. Thus, techniques for efficiently calibrating the Kinect depth camera and altering its optical system to improve suitability for imaging short-range obstacles are presented. To perform depth calibration, a calibration rig and software were developed to automatically map raw depth values to object depths. The calibration rig consisted of a traditional chessboard calibration target with easily locatable features in depth at its exterior corners that facilitated software extraction of corresponding object depths and raw depth values. To modify the Kinect's optics for improved short-range imaging, Nyko's Zoom adapter was used due to its simplicity and low cost. Although effective at reducing the Kinect's minimum range, these optics introduced pronounced distortion in depth. A method based on capturing depth images of planar objects at various depths produced an empirical depth distortion model for correcting such distortion in software. Together, the modified optics and the empirical depth undistortion procedure demonstrated the ability to improve the Kinect's resolution and decrease its minimum range by approximately 30\%.},
author = {Draelos, Mark and Deshpande, Nikhil and Grant, Edward},
booktitle = {2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)},
doi = {10.1109/MFI.2012.6343067},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)/2012/Draelos, Deshpande, Grant/Draelos, Deshpande, Grant - 2012 - The Kinect up close Adaptations for short-range imaging.pdf:pdf},
isbn = {978-1-4673-2512-7},
month = sep,
pages = {251--256},
publisher = {IEEE},
title = {{The Kinect up close: Adaptations for short-range imaging}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6343067&contentType=Conference+Publications&searchField=Search_All&queryText=kinect+calibration},
year = {2012}
}
@article{Tweed1990,
author = {Tweed, D and Vilis, T},
journal = {Vision research},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Geometric relations of eye position and velocity vectors during saccades}},
url = {http://www.sciencedirect.com/science/article/pii/0042698990901314},
year = {1990}
}
@inproceedings{Ohmori2009,
abstract = {For designing and modeling complicated and sophisticated systems such as cyberworlds, their mathematical foundation is critical. To realize it, two important properties called the homotopy lifting property and homotopy extension property are applied for designing and modeling a system in a bottom-up way and a top-down way, respectively. Activities of Internet Company are described by pi-calculus processes and a Petri net which are derived from system requirements in a bottom-up way and a top-down way using the homotopy lifting property and the homotopy extension property. Entities in both properties are specified by the incrementally modular abstraction hierarchy by climbing down the abstraction hierarchy from the most abstract homotopy level to the most specific view level, while keeping invariants such as homotopy equivalence or topological equivalence.},
address = {Bradford},
author = {Ohmori, Kenji and Kunii, Tosiyasu L.},
booktitle = {2009 International Conference on CyberWorlds},
doi = {10.1109/CW.2009.20},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2009 International Conference on CyberWorlds/2009/Ohmori, Kunii/Ohmori, Kunii - 2009 - Mathematical Foundation for Designing and Modeling Cyberworlds.pdf:pdf},
isbn = {978-1-4244-4864-7},
pages = {80--87},
publisher = {IEEE},
title = {{Mathematical Foundation for Designing and Modeling Cyberworlds}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5279683 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5279683},
year = {2009}
}
@article{Musthag2013,
address = {New York, New York, USA},
author = {Musthag, Mohamed and Ganesan, Deepak},
doi = {10.1145/2470654.2470745},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {641},
publisher = {ACM Press},
title = {{Labor dynamics in a mobile micro-task market}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470745},
year = {2013}
}
@inproceedings{Morris2013,
abstract = {An interactive system, PIXEE, was developed to promote greater emotional expression in image-based social media. Images shared on social media were projected onto a large interactive display at public events. A multimodal interface displayed the sentiment analysis of images and invited viewers to express their emotional responses. Viewers could adjust the emotional classification and thereby change the color and sound associated with a picture, and experiment with emotion-based composition. An interdisciplinary team deployed this system around the world to explore new ways for technology to catalyze emotional connectedness. This paper describes the system, design iterations, and observations about how people used it for self-expression and connection.},
address = {New York, New York, USA},
author = {Morris, Margaret E and Labs, Intel and Corporation, Intel and Haj, Murad Al and Marshall, Carl S and Calix, Mira and Macdougall, James S and Carmean, Douglas M},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
doi = {10.1145/2468356.2468750},
isbn = {9781450319522},
pages = {2277--2286},
publisher = {ACM Press},
title = {{PIXEE: Pictures, Interaction and Emotional Expression}},
url = {http://dl.acm.org/citation.cfm?doid=2468356.2468750},
year = {2013}
}
@article{Levy2006,
author = {Levy, Y and Ellis, TJ},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Informing Science Journal/2006/Levy, Ellis/Levy, Ellis - 2006 - A systems approach to conduct an effective literature review in support of information systems research.pdf:pdf},
journal = {Informing Science Journal},
keywords = {RBS},
mendeley-tags = {RBS},
pages = {181--212},
title = {{A systems approach to conduct an effective literature review in support of information systems research}},
url = {http://www.scs.ryerson.ca/aferworn/courses/CP8101/CLASSES/ConductingLiteratureReview.pdf},
volume = {9},
year = {2006}
}
@inproceedings{Kumar2007a,
abstract = {The GUIDe (Gaze-enhanced User Interface Design) project in the HCI Group at Stanford University explores how gaze information can be effectively used as an augmented input in addition to keyboard and mouse. We present three practical applications of gaze as an augmented input for pointing and selection, application switching, and scrolling. Our gaze-based interaction techniques do not overload the visual channel and present a natural, universally-accessible and general purpose use of gaze information to facilitate interaction with everyday computing devices.},
address = {New York, New York, USA},
author = {Kumar, Manu and Winograd, Terry},
booktitle = {CHI '07 extended abstracts on Human factors in computing systems - CHI '07},
doi = {10.1145/1240866.1240935},
file = {:home/acmt/Dropbox/Documentos/Mendeley/CHI '07 extended abstracts on Human factors in computing systems - CHI '07/2007/Kumar, Winograd/Kumar, Winograd - 2007 - GUIDe gaze-enhanced UI design.pdf:pdf},
isbn = {9781595936424},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {1977},
publisher = {ACM Press},
title = {{GUIDe: gaze-enhanced UI design}},
url = {http://dl.acm.org/citation.cfm?id=1240935 http://portal.acm.org/citation.cfm?doid=1240866.1240935},
year = {2007}
}
@inproceedings{wilson,
abstract = {We explore the application of depth-sensing cameras to detect touch on a tabletop. Limits of depth estimate resolution and line of sight requirements dictate that the determination of the moment of touch will not be as precise as that of more direct sensing techniques such as capacitive touch screens. However, using a depth-sensing camera to detect touch has significant advantages: first, the interactive surface need not be instrumented. Secondly, this approach allows touch sensing on non-flat surfaces. Finally, information about the shape of the users and their arms and hands above the surface may be exploited in useful ways, such as determining hover state, or that multiple touches are from same hand or from the same user. We present techniques and findings using Microsoft Kinect.},
address = {New York, New York, USA},
author = {Wilson, Andrew D},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces - ITS '10},
doi = {10.1145/1936652.1936665},
isbn = {9781450303996},
keywords = {SBGames},
mendeley-tags = {SBGames},
organization = {ACM},
pages = {69},
publisher = {ACM Press},
title = {{Using a depth camera as a touch sensor}},
url = {http://portal.acm.org/citation.cfm?doid=1936652.1936665},
year = {2010}
}
@article{Ince2009,
abstract = {The systems let user track their eye gaze information have been technologically possible for several decades. However, they are still very expensive. They have limited use of eye tracking and blink detection infra-structure. The purpose of this paper is to evaluate cost effects in the sector and explain our new approach in detail which reduces high costs of current systems apparently. This paper introduces an algorithm for fast and sub-pixel precise detection of eye blobs for extracting eye features. The algorithm is based on differential geometry and still exists in OpenCpV library as a class. Hence, blobs of arbitrary size that means eye size can be extracted by just adjusting the scale parameter in the class function. In addition, center point and boundary of an eye blob, also are extracted. These describe the specific eye location in the face boundary to run several algorithms to find the eye-ball location with its central coordinates. Several examples on real simple web-cam images illustrate the performance of the proposed algorithm and yield an efficient result on the idea of low-cost eye tracking, blink detection and drowsiness detection system.},
author = {Ince, IF and Yang, TC},
doi = {10.1007/978-3-642-04070-2\_58},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Emerging Intelligent Computing Technology and Applications/2009/Ince, Yang/Ince, Yang - 2009 - A new low-cost eye tracking and blink detection approach extracting eye features with blob extraction.pdf:pdf},
journal = {Emerging Intelligent Computing Technology and Applications},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
pages = {526--533},
title = {{A new low-cost eye tracking and blink detection approach: extracting eye features with blob extraction}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-04070-2_58},
volume = {5754},
year = {2009}
}
@inproceedings{Mahapatra2008,
abstract = {The importance of motion in attracting attention is well known. While watching videos, where motion is prevalent, how do we quantify the regions that are motion salient? In this paper, we investigate the role of motion in attention and compare it with the influence of other low-level features like image orientation and intensity. We propose a framework for motion saliency. In particular, we integrate motion vector information with spatial and temporal coherency to generate a motion attention map. The results show that our model achieves good performance in identifying regions that are moving and salient. We also find motion to have greater influence on saliency than other low-level features when watching videos.},
author = {Mahapatra, Dwarikanath and Winkler, Stefan and Yen, Shih-Cheng},
booktitle = {Human Vision and Electronic Imaging},
doi = {10.1117/12.766243},
editor = {Rogowitz, Bernice E. and Pappas, Thrasyvoulos N.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Human Vision and Electronic Imaging/2008/Mahapatra, Winkler, Yen/Mahapatra, Winkler, Yen - 2008 - Motion saliency outweighs other low-level features while watching videos.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = feb,
pages = {68060P--68060P--10},
title = {{Motion saliency outweighs other low-level features while watching videos}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=810996},
year = {2008}
}
@book{Westman2005,
author = {Westman, Hans},
booktitle = {ACM SIGGRAPH Computer Graphics},
doi = {10.1145/1080376.1080380},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM SIGGRAPH Computer Graphics/2005/Westman/Westman - 2005 - Computer graphics.pdf:pdf},
isbn = {1925884813},
issn = {00978930},
month = may,
number = {2},
pages = {4},
title = {{Computer graphics}},
url = {http://portal.acm.org/citation.cfm?doid=1080376.1080380},
volume = {39},
year = {2005}
}
@article{Abernethy1999,
author = {Abernethy, Bruce and Wood, Joanne M. and Parks, Sheri},
doi = {10.1080/02701367.1999.10608050},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Research Quarterly for Exercise and Sport/1999/Abernethy, Wood, Parks/Abernethy, Wood, Parks - 1999 - Can the Anticipatory Skills of Experts Be Learned by Novices.pdf:pdf},
issn = {0270-1367},
journal = {Research Quarterly for Exercise and Sport},
keywords = {anticipation,expertise,perception,training},
mendeley-tags = {anticipation,expertise,perception,training},
month = sep,
number = {3},
pages = {313--318},
title = {{Can the Anticipatory Skills of Experts Be Learned by Novices?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02701367.1999.10608050},
volume = {70},
year = {1999}
}
@inproceedings{Nunes2007,
address = {Petropolis},
author = {Nunes, F\'{a}tima L. S. and Costa, Rosa M. E. M. and Oliveira, Ana Cl\'{a}udia M. T. G. and Delfino, S\'{e}rgio R. and Pavarini, Larissa and Rodello, Ildeberto A. and Brega, Jos\'{e} Remo F. and Sementille, Antonio C.},
booktitle = {Symposium of Virtual Reality},
pages = {223--255},
publisher = {SBC},
title = {{Aplica\c{c}\~{o}es M\'{e}dicas usando Realidade Virtual e Realidade Aumentada}},
year = {2007}
}
@inproceedings{Galgani2009,
abstract = {Several studies have analyzed the link between mental dysfunctions and eye movements, using eye tracking techniques to determine where a person is looking, that is, the fixations. In this paper, we present a novel methodology to improve current diagnosis and evaluation methods of attention disorders. We have developed and tested several data-mining methodologies suitable for the automatic analysis and visualization of eye tracking data. In particular three novel methods of classification of subjects are proposed: (i) a method that uses expectation maximization to classify according to statistical likelihood of fixations locations; (ii) a procedure based on the Levenshtein distance method to compare sequences of fixations; and (iii) a method based on the analysis of the transitions frequencies of fixations between regions. Results of evaluation of classification accuracy are finally presented.},
address = {Nashville, TN},
author = {Galgani, Filippo and Sun, Yiwen and Lanzi, Pier Luca and Leigh, Jason},
booktitle = {2009 IEEE Symposium on Computational Intelligence and Data Mining},
doi = {10.1109/CIDM.2009.4938649},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2009 IEEE Symposium on Computational Intelligence and Data Mining/2009/Galgani et al/Galgani et al. - 2009 - Automatic analysis of eye tracking data for medical diagnosis.pdf:pdf},
isbn = {978-1-4244-2765-9},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = mar,
pages = {195--202},
publisher = {IEEE},
title = {{Automatic analysis of eye tracking data for medical diagnosis}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4938649 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4938649},
year = {2009}
}
@article{Sun1995,
author = {Sun, F and Chen, L},
file = {::},
journal = {Neural Networks, 1995. Proceedings., IEEE  \ldots},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Identification of fixations in reading eye movements by a multi-layer neural network}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=487721},
year = {1995}
}
@book{Huang2014,
address = {New York, NY},
doi = {10.1007/978-1-4614-7485-2},
editor = {Huang, Weidong},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2014/Unknown/Unknown - 2014 - Handbook of Human Centric Visualization.pdf:pdf},
isbn = {978-1-4614-7484-5},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
publisher = {Springer New York},
title = {{Handbook of Human Centric Visualization}},
url = {http://link.springer.com/10.1007/978-1-4614-7485-2},
year = {2014}
}
@inproceedings{Platonov2007,
abstract = {We present a solution for automatic extraction of contour models out of polygonal CAD models. Such contour models can be used for markerless initialization and tracking purposes. To create a contour model we synthesize different views of the object using its CAD model. During the view generation we alternate the camera pose as well as light conditions in order to extract the most stable contours in terms of illumination invariance and view independence. We project the extracted 2D edges back into the 3D space and accumulate for every 3D point statistics over different views describing its visibility and stability under different illumination conditions. After filtering out all 3D points with probability below a certain threshold value we use the Euclidean Minimum Spanning Tree algorithm to get the connected contours out of the 3D point cloud. The result is a B-Spline or VRML representation of the most stable contours.},
address = {Nara-JP},
author = {Platonov, Juri and Langer, Marion},
booktitle = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2007.4538829},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality/2007/Platonov, Langer/Platonov, Langer - 2007 - Automatic contour model creation out of polygonal CAD models for markerless Augmented Reality.pdf:pdf},
isbn = {978-1-4244-1749-0},
month = nov,
pages = {1--4},
publisher = {IEEE},
title = {{Automatic contour model creation out of polygonal CAD models for markerless Augmented Reality}},
url = {http://dl.acm.org/citation.cfm?id=1514340 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538829},
year = {2007}
}
@incollection{Bednarik2013,
abstract = {Inference about high-level cognitive states during interaction is a fundamental task in building proactive intelligent systems that would allow effective offloading of mental operations to a computational architecture. We introduce an improved machine-learning pipeline able to predict user interactive behavior and performance using real-time eye-tracking. The inference is carried out using a support-vector machine (SVM) on a large set of features computed from eye movement data that are linked to concurrent high-level behavioral codes based on think aloud protocols. The differences between cognitive states can be inferred from overt visual attention patterns with accuracy over chance levels, although the overall accuracy is still low. The system can also classify and predict performance of the problem-solving users with up to 79 \% accuracy. We suggest this prediction model as a universal approach for understanding of gaze in complex strategic behavior. The findings confirm that eye movement data carry important information about problem solving processes and that proactive systems can benefit from real-time monitoring of visual attention.},
address = {London},
author = {Bednarik, R and Eivazi, S and Vrzakova, H},
booktitle = {Eye Gaze in Intelligent User Interfaces},
chapter = {7},
doi = {10.1007/978-1-4471-4784-8\_7},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Eye Gaze in Intelligent User Interfaces/2013/Bednarik, Eivazi, Vrzakova/Bednarik, Eivazi, Vrzakova - 2013 - A Computational Approach for Prediction of Problem-Solving Behavior Using Support Vector Machines an.pdf:pdf},
isbn = {978-1-4471-4784-8},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {111--134},
publisher = {Springer London},
title = {{A Computational Approach for Prediction of Problem-Solving Behavior Using Support Vector Machines and Eye-Tracking Data}},
url = {http://link.springer.com/chapter/10.1007/978-1-4471-4784-8_7},
year = {2013}
}
@article{Nancel2013,
address = {New York, New York, USA},
author = {Nancel, Mathieu and Chapuis, Olivier and Pietriga, Emmanuel and Yang, Xing-Dong and Irani, Pourang P. and Beaudouin-Lafon, Michel},
doi = {10.1145/2470654.2470773},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Handheld Devices,Pointing,Wall Displays},
pages = {831},
publisher = {ACM Press},
title = {{High-precision pointing on large wall displays using small handheld devices}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470773},
year = {2013}
}
@article{Boulanger2013,
address = {New York, New York, USA},
author = {Boulanger, Cati and Boulanger, Adam and de Greef, Lilian and Kearney, Andy and Sobel, Kiley and Transue, Russell and Sweedyk, Z and Dietz, Paul H. and Bathiche, Steven},
doi = {10.1145/2470654.2466160},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1243},
publisher = {ACM Press},
title = {{Stroke rehabilitation with a sensing surface}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466160},
year = {2013}
}
@inproceedings{Rau2013,
abstract = {Designing interactive learning environments (ILEs; e.g., intelligent tutoring systems, educational games, etc.) is a challenging interdisciplinary process that needs to satisfy multiple stakeholders. ILEs need to function in real educational settings (e.g., schools) in which a number of goals interact. Several instructional design methodologies exist to help developers address these goals. However, they often lead to conflicting recommendations. Due to the lack of an established methodology to resolve such conflicts, developers of ILEs have to rely on ad-hoc solutions. We present a principled methodology to resolve such conflicts. We build on a well-established design process for creating Cognitive Tutors, a highly effective type of ILE. We extend this process by integrating methods from multiple disciplines to resolve design conflicts. We illustrate our methodology's effectiveness by describing the iterative development of the Fractions Tutor, which has proven to be effective in classroom studies with 3,000 4th-6th graders.},
address = {New York, New York, USA},
author = {Rau, Martina A and Aleven, Vincent and Rummel, Nikol and Rohrbach, Stacie},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470670},
isbn = {9781450318990},
pages = {109--118},
publisher = {ACM Press},
title = {{Why interactive learning environments can have it all}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470670},
year = {2013}
}
@inproceedings{Xiao-ming2001,
abstract = {Collaborative modeling and simulation take strong advantage of resource sharing across the Internet for an extended enterprise or a virtual enterprise. Collaborative graphical modeling is more attractive, but also more difficult, when applied on the World Wide Web. One solution for integrating 2D graphical modeling and a Web-based online analyzer is discussed, and a prototype is realized through a campus network. An order management model is designed collaboratively using the EXTEND modeling tool to map the operations involved in the scheduling, production and transportation of a geographically distributed iron-ore enterprise. The distributed managers can submit orders and then obtain the simulation results online from a Web online analyzer which is realized by an Apache Web server, PHP and mySQL tools. The prototype shows effective experimental results. It is intended to study the system further in creating a complete model base for a simulation server and a graphical user interface for browsers},
address = {London},
author = {Xiao-ming, Z. and Zi-qiong, D.},
booktitle = {Proceedings of the Sixth International Conference on Computer Supported Cooperative Work in Design (IEEE Cat. No.01EX472)},
doi = {10.1109/CSCWD.2001.942301},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Sixth International Conference on Computer Supported Cooperative Work in Design (IEEE Cat. No.01EX472)/2001/Xiao-ming, Zi-qiong/Xiao-ming, Zi-qiong - 2001 - Collaborative modeling and simulation for order management in virtual enterprise.pdf:pdf},
isbn = {0-660-18493-1},
pages = {444--448},
publisher = {NRC Res. Press},
title = {{Collaborative modeling and simulation for order management in virtual enterprise}},
url = {http://en.cnki.com.cn/Article_en/CJFDTOTAL-JSJZ200206019.htm http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=942301},
year = {2001}
}
@article{Szeliski2004,
abstract = {A new approach to computing a panoramic (360 degrees) depth map is presented in this paper. Our approach uses a large collection of images taken by a camera whose motion has been constrained to planar concentric circles. We resample regular perspective images to produce a set of multiperspective panoramas and then compute depth maps directly from these resampled panoramas. Our panoramas sample uniformly in three dimensions: rotation angle, inverse radial distance, and vertical elevation. The use of multiperspective panoramas eliminates the limited overlap present in the original input images and, thus, problems as in conventional multibaseline stereo can be avoided. Our approach differs from stereo matching of single-perspective panoramic images taken from different locations, where the epipolar constraints are sine curves. For our multiperspective panoramas, the epipolar geometry, to the first order approximation, consists of horizontal lines. Therefore, any traditional stereo algorithm can be applied to multiperspective panoramas with little modification. In this paper, we describe two reconstruction algorithms. The first is a cylinder sweep algorithm that uses a small number of resampled multiperspective panoramas to obtain dense 3D reconstruction. The second algorithm, in contrast, uses a large number of multiperspective panoramas and takes advantage of the approximate horizontal epipolar geometry inherent in multiperspective panoramas. It comprises a novel and efficient 1D multibaseline matching technique, followed by tensor voting to extract the depth surface. Experiments show that our algorithms are capable of producing comparable high quality depth maps which can be used for applications such as view interpolation.},
author = {Shum, Heung-Yeung and Tang, Chi-Keung and Szeliski, R.},
doi = {10.1109/TPAMI.2004.1261078},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Pattern Analysis and Machine Intelligence/2004/Shum, Tang, Szeliski/Shum, Tang, Szeliski - 2004 - Stereo reconstruction from multiperspective panoramas.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = jan,
number = {1},
pages = {45--62},
title = {{Stereo reconstruction from multiperspective panoramas}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1261078&contentType=Journals+&+Magazines&searchField=Search_All&queryText=Stereo+reconstruction+from+multiperspective+panoramas},
volume = {26},
year = {2004}
}
@article{B¿ottcher2007,
author = {B¿ottcher, Guido and Allerkamp, Dennis and Wolter, Franz-Erich},
doi = {10.1109/CW.2007.29},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2007 International Conference on Cyberworlds (CW'07)/2007/B¿ottcher, Allerkamp, Wolter/B¿ottcher, Allerkamp, Wolter - 2007 - Virtual Reality Systems Modelling Haptic Two-Finger Contact with Deformable Physical Surfaces.pdf:pdf},
isbn = {0-7695-3005-2},
journal = {2007 International Conference on Cyberworlds (CW'07)},
month = oct,
pages = {292--299},
publisher = {Ieee},
title = {{Virtual Reality Systems Modelling Haptic Two-Finger Contact with Deformable Physical Surfaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4390932},
year = {2007}
}
@article{Diaz2013,
author = {Diaz, G and Cooper, J and Rothkopf, C and Hayhoe, M},
journal = {Journal of vision},
title = {{Saccades to future ball location reveal memory-based prediction in a virtual-reality interception task}},
url = {http://171.67.113.220/content/13/1/20.short},
year = {2013}
}
@inproceedings{Holland2013,
address = {New York, New York, USA},
author = {Holland, Corey and Garza, Atenas and Kurtova, Elena and Cruz, Jose and Komogortsev, Oleg},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
doi = {10.1145/2468356.2468409},
isbn = {9781450319522},
pages = {295},
publisher = {ACM Press},
title = {{Usability evaluation of eye tracking on an unmodified common tablet}},
url = {http://dl.acm.org/citation.cfm?doid=2468356.2468409},
year = {2013}
}
@article{Junwen2008,
abstract = {We present a system that simultaneously tracks eyes and detects eye blinks. Two interactive particle filters are used for this purpose, one for the closed eyes and the other one for the open eyes. Each particle filter is used to track the eye locations as well as the scales of the eye subjects. The set of particles that gives higher confidence is defined as the primary set and the other one is defined as the secondary set. The eye location is estimated by the primary particle filter, and whether the eye status is open or closed is also decided by the label of the primary particle filter. When a new frame comes, the secondary particle filter is reinitialized according to the estimates from the primary particle filter. We use autoregression models for describing the state transition and a classification-based model for measuring the observation. Tensor subspace analysis is used for feature extraction which is followed by a logistic regression model to give the posterior estimation. The performance is carefully evaluated from two aspects: the blink detection rate and the tracking accuracy. The blink detection rate is evaluated using videos from varying scenarios, and the tracking accuracy is given by comparing with the benchmark data obtained using the Vicon motion capturing system. The setup for obtaining benchmark data for tracking accuracy evaluation is presented and experimental results are shown. Extensive experimental evaluations validate the capability of the algorithm.},
author = {Wu, Junwen and Trivedi, Mohan M},
doi = {10.1155/2008/823695},
file = {:home/acmt/Dropbox/Documentos/Mendeley/EURASIP Journal on Advances in Signal Processing/2008/Wu, Trivedi/Wu, Trivedi - 2008 - Simultaneous Eye Tracking and Blink Detection with Interactive Particle Filters.pdf:pdf},
issn = {1687-6180},
journal = {EURASIP Journal on Advances in Signal Processing},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
number = {1},
pages = {823695},
title = {{Simultaneous Eye Tracking and Blink Detection with Interactive Particle Filters}},
url = {http://scholar.google.com.br/scholar?start=10&q=morris+detection+blink+2002&hl=pt-BR&as_sdt=0,5#5 http://asp.eurasipjournals.com/content/2008/1/823695},
volume = {2008},
year = {2008}
}
@article{Wither2007,
author = {Wither, Jason and DiVerdi, Stephen and Hollerer, Tobias},
doi = {10.1109/ISMAR.2007.4538832},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality/2007/Wither, DiVerdi, Hollerer/Wither, DiVerdi, Hollerer - 2007 - Evaluating Display Types for AR Selection and Annotation.pdf:pdf},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = nov,
pages = {1--4},
publisher = {Ieee},
title = {{Evaluating Display Types for AR Selection and Annotation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538832},
year = {2007}
}
@inproceedings{O'Neill2013,
abstract = {This paper describes an ethnographic study of an outsourced business process - the digitization of healthcare forms. The aim of the study was to understand how the work is currently organized, with an eye to uncovering the research challenges which need to be addressed if that work is to be crowdsourced. The findings are organised under four emergent themes: Workplace Ecology, Data Entry Skills and Knowledge, Achieving Targets and Collaborative Working. For each theme a description of how the work is undertaken in the outsourcer's Indian office locations is given, followed by the implications for crowdsourcing that work. This research is a first step in understanding how crowdsourcing might be applied to BPO activities. The paper examines features specific to form digitization - extreme distribution and form decomposition - and lightly touches on the crowdsourcing of BPO work more generally.},
address = {New York, New York, USA},
author = {O'Neill, Jacki and Roy, Shourya and Grasso, Antonietta and Martin, David},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470683},
isbn = {9781450318990},
pages = {197--206},
publisher = {ACM Press},
title = {{Form digitization in BPO: from outsourcing to crowdsourcing?}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470683},
year = {2013}
}
@article{Moura2011,
author = {Moura, Guilherme De S. and Pessoa, Saulo a. and Lima, Jo\~{a}o Paulo S. Do M. and Teichrieb, Veronica and Kelner, Judith},
doi = {10.1109/SVR.2011.14},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Moura et al/Moura et al. - 2011 - RPR-SORS An Authoring Toolkit for Photorealistic AR.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
keywords = {-photorealism,augmented,computer graphics,pipeline,toolkit},
month = may,
pages = {178--187},
publisher = {Ieee},
title = {{RPR-SORS: An Authoring Toolkit for Photorealistic AR}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951850},
year = {2011}
}
@article{Karpov,
author = {Karpov, A and Komogortsev, O},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Behavioral Research Methods/2012/Karpov, Komogortsev/Karpov, Komogortsev - 2012 - Automated Classification and Scoring of Smooth Pursuit Eye Movements in Presence of Fixations and Saccades.pdf:pdf},
journal = {Journal of Behavioral Research Methods},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {1--13},
title = {{Automated Classification and Scoring of Smooth Pursuit Eye Movements in Presence of Fixations and Saccades}},
url = {http://cs.txstate.edu/~ok11/papers_published/TR2011_11_23_SP_Ka_Ko.pdf},
year = {2012}
}
@inproceedings{Machado2007,
abstract = {This chapter presents the main technologies related to the use of interaction devices for touch and force feedback in virtual and augmented reality systems. Thus, devices and control packages that compose haptic systems are presented, as well as their use in some applications.},
address = {Petropolis},
author = {Machado, Liliane dos Santos},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2007/Machado/Machado - 2007 - Dispositivos H\'{a}pticos para Interfaces de Realidade Virtual e Aumentada.pdf:pdf},
pages = {152--167},
publisher = {SBC},
title = {{Dispositivos H\'{a}pticos para Interfaces de Realidade Virtual e Aumentada}},
year = {2007}
}
@article{AntoniodaSilva2008,
abstract = {The process of teaching-learning based on lessons spoken-exposed, having the blackboard as the main didactic resource, does not currently brings attractiveness consistent and coherent with the environment in which elementary school students are involved with, full of technologies and innovations. Computers had and have a decisive role in changing this scenario. They had in education three generations, and the fourth generation begins to emerge with Virtual Reality (VR). The way of learning depends upon each person, some learn visually, other verbally, some explore and other deduct. An example of learning object that requires the student to make an abstraction or mentally to create a model for understanding is a three physiology. This area of knowledge covers the anatomy of plants, which can not only be taught with the use of traditional tools of education, since it presents complexity and dynamic ways that can only be viewed through simulations. In this context, the Augmented Reality (AR) fits as a tool for viewing, interaction and involvement with objects of learning. The purpose of this paper is to present an architecture for distribution of virtual environments of AR as a tool to support projects in education. A cognitive interface has been created to allow AR user interaction with a virtual environment through interaction menus and also through real markers. With this implementation, the interactions made in an virtual environment are replicated for other environments, creating a system strongly applied to support education, since it provides multiple views of virtual objects. It is understood that when one distributes the interactions made, users can make cooperate in an AR environment, enabling a greater level of understanding for the taught subject.},
author = {{Ant\^{o}nio da Silva}, Wender and Ribeiro, Marcos Wagner de Souza and J\'{u}nior, Edgard Lamounier and Cardoso, Alexandre},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Revista Brasileira de Inform\'{a}tica na Educa\c{c}\~{a}o/2008/Ant\^{o}nio da Silva et al/Ant\^{o}nio da Silva et al. - 2008 - Uma Arquitetura para Distribui\c{c}\~{a}o de Ambientes Virtuais de Realidade Aumentada Aplicada \`{a} Educa\c{c}\~{a}.pdf:pdf},
journal = {Revista Brasileira de Inform\'{a}tica na Educa\c{c}\~{a}o},
number = {3},
pages = {57--69},
title = {{Uma Arquitetura para Distribui\c{c}\~{a}o de Ambientes Virtuais de Realidade Aumentada Aplicada \`{a} Educa\c{c}\~{a}o}},
volume = {16},
year = {2008}
}
@article{Dementhon1995,
author = {Dementhon, Daniel F. and Davis, Larry S.},
doi = {10.1007/BF01450852},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = jun,
number = {1-2},
pages = {123--141},
publisher = {Kluwer Academic Publishers},
title = {{Model-based object pose in 25 lines of code}},
url = {http://dl.acm.org/citation.cfm?id=204005.204015},
volume = {15},
year = {1995}
}
@inproceedings{Chilana2013,
abstract = {We present a multi-site field study to evaluate LemonAid, a crowdsourced contextual help approach that allows users to retrieve relevant questions and answers by making selections within the interface. We deployed LemonAid on 4 different web sites used by thousands of users and collected data over several weeks, gathering over 1,200 usage logs, 168 exit surveys, and 36 one-on-one interviews. Our results indicate that over 70\% of users found LemonAid to be helpful, intuitive, and desirable for reuse. Software teams found LemonAid easy to integrate with their sites and found the analytics data aggregated by LemonAid a novel way of learning about users' popular questions. Our work provides the first holistic picture of the adoption and use of a crowdsourced contextual help system and offers several insights into the social and organizational dimensions of implementing such help systems for real-world applications.},
address = {New York, New York, USA},
author = {Chilana, Parmit K and Ko, Andrew J and Wobbrock, Jacob O and Grossman, Tovi},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470685},
isbn = {9781450318990},
pages = {217--226},
publisher = {ACM Press},
title = {{A multi-site field study of crowdsourced contextual help}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470685},
year = {2013}
}
@article{Nguyen2013,
address = {New York, New York, USA},
author = {Nguyen, Cuong and Niu, Yuzhen and Liu, Feng},
doi = {10.1145/2470654.2466150},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1169},
publisher = {ACM Press},
title = {{Direct manipulation video navigation in 3D}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466150},
year = {2013}
}
@article{Shaw1995,
abstract = {The formal literature review within the broader genre of academic writing remains problematic, and despite vigorous interest in other aspects of the genre, largely avoided by ESP researchers. Because such reviews are considered highly personal and interpretative, our reluctance to intervene is not surprising. However, the difficulties students are faced with are at least partially linguistic, and therefore the language teacher would seem to have something to offer. Recent developments in schema theory seem to offer a way out of the impasse, and the chance to develop language teaching technologies appropriate to language enhancement programs offered to graduate students in various fields, most particularly engineering. This paper presents results from classroom-initiated research into the use of text-graphing with engineering masters degree students working on their thesis proposals.},
author = {Shaw, Jonathan},
file = {:home/acmt/Dropbox/Documentos/Mendeley/System/1995/Shaw/Shaw - 1995 - A schema approach to the formal literature review in engineering theses.pdf:pdf},
journal = {System},
keywords = {rbs},
mendeley-tags = {rbs},
number = {3},
pages = {325--335},
title = {{A schema approach to the formal literature review in engineering theses}},
url = {http://www.sciencedirect.com/science/article/pii/0346251X9500020K},
volume = {23},
year = {1995}
}
@article{Munn2009,
abstract = {Video-based eye trackers produce an output video showing where a subject is looking, the subject's Point-of-Regard (POR), for each frame of a video of the scene. This information can be extremely valuable, but its analysis can be overwhelming. Analysis of eye-tracked data from portable (wearable) eye trackers is especially daunting, as the scene video may be constantly changing, rendering automatic analysis more difficult. A common way to begin analysis of POR data is to group these data into fixations. In a previous article, we compared the fixations identified (i.e., start and end marked) automatically by an algorithm to those identified manually by users (i.e., manual coders). Here, we extend this automatic identification of fixations to tagging each fixation to a Region-of-Interest (ROI). Our fixation tagging algorithm, FixTag, requires the relative 3D positions of the vertices of ROIs and calibration of the scene camera. Fixation tagging is performed by first calculating the camera projection matrices for keyframes of the scene video (captured by the eye tracker) via an iterative structure and motion recovery algorithm. These matrices are then used to project 3D ROI vertices into the keyframes. A POR for each fixation is matched to a point in the closest keyframe, which is then checked against the 2D projected ROI vertices for tagging. Our fixation tags were compared to those produced by three manual coders tagging the automatically identified fixations for two different scenarios. For each scenario, eight ROIs were defined along with the 3D positions of eight calibration points. Therefore, 17 tags were available for each fixation: 8 for ROIs, 8 for calibration points, and 1 for “other.” For the first scenario, a subject was tracked looking through products on four store shelves, resulting in 182 automatically identified fixations. Our automatic tagging algorithm produced tags that matched those produced by at least one manual coder for 181 out of the 182 fixations (99.5\% agreement). For the second scenario, a subject was tracked looking at two posters on adjoining walls of a room. Our algorithm matched at least one manual coder's tag for 169 fixations out of 172 automatically identified (98.3\% agreement).},
annote = {- cited by: 8
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Munn, Susan M. and Pelz, Jeff B.},
doi = {10.1145/1577755.1577759},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM Transactions on Applied Perception/2009/Munn, Pelz/Munn, Pelz - 2009 - FixTag An algorithm for identifying and tagging fixations to simplify the analysis of data collected by portable eye.pdf:pdf},
issn = {15443558},
journal = {ACM Transactions on Applied Perception},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = aug,
number = {3},
pages = {1--25},
title = {{FixTag: An algorithm for identifying and tagging fixations to simplify the analysis of data collected by portable eye trackers}},
url = {http://dl.acm.org/citation.cfm?id=1577759 http://portal.acm.org/citation.cfm?doid=1577755.1577759},
volume = {6},
year = {2009}
}
@article{Tafaj2013,
abstract = {Complex and hazardous driving situations often arise with the delayed perception of traffic objects. To automatically detect whether such objects have been perceived by the driver, there is a need for techniques that can reliably recognize whether the driver’s eyes have fixated or are pursuing the hazardous object (i.e., detecting fixations, saccades, and smooth pursuits from raw eye tracking data). This paper presents a system for analyzing the driver’s visual behavior based on an adaptive online algorithm for detecting and distinguishing between fixation clusters, saccades, and smooth pursuits.},
author = {Tafaj, E and K\"{u}bler, TC and Kasneci, G},
doi = {10.1007/978-3-642-40728-4\_56},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Artificial Neural Networks and Machine Learning - ICANN/2013/Tafaj, K\"{u}bler, Kasneci/Tafaj, K\"{u}bler, Kasneci - 2013 - Online Classification of Eye Tracking Data for Automated Analysis of Traffic Hazard Perception.pdf:pdf},
journal = {Artificial Neural Networks and Machine Learning - ICANN},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {442--450},
title = {{Online Classification of Eye Tracking Data for Automated Analysis of Traffic Hazard Perception}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-40728-4_56},
volume = {8131},
year = {2013}
}
@inproceedings{Geiger2012,
abstract = {As a core robotic and vision problem, camera and range sensor calibration have been researched intensely over the last decades. However, robotic research efforts still often get heavily delayed by the requirement of setting up a calibrated system consisting of multiple cameras and range measurement units. With regard to removing this burden, we present a toolbox with web interface for fully automatic camera-to-camera and camera-to-range calibration. Our system is easy to setup and recovers intrinsic and extrinsic camera parameters as well as the transformation between cameras and range sensors within one minute. In contrast to existing calibration approaches, which often require user intervention, the proposed method is robust to varying imaging conditions, fully automatic, and easy to use since a single image and range scan proves sufficient for most calibration scenarios. Experimentally, we demonstrate that the proposed checkerboard corner detector significantly outperforms current state-of-the-art. Furthermore, the proposed camera-to-range registration method is able to discover multiple solutions in the case of ambiguities. Experiments using a variety of sensors such as grayscale and color cameras, the Kinect 3D sensor and the Velodyne HDL-64 laser scanner show the robustness of our method in different indoor and outdoor settings and under various lighting conditions.},
author = {Geiger, Andreas and Moosmann, Frank and Car, Omer and Schuster, Bernhard},
booktitle = {2012 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2012.6224570},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 IEEE International Conference on Robotics and Automation/2012/Geiger et al/Geiger et al. - 2012 - Automatic camera and range sensor calibration using a single shot.pdf:pdf},
isbn = {978-1-4673-1405-3},
month = may,
pages = {3936--3943},
publisher = {IEEE},
title = {{Automatic camera and range sensor calibration using a single shot}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6224570&contentType=Conference+Publications&searchField=Search_All&queryText=kinect+calibration},
year = {2012}
}
@inproceedings{Akpan2005,
abstract = {This paper presents the results from surveying simulation practitioners from industry and academics who have used 2D or 3D software applications for discrete event simulation (DES) projects. The survey focused on the impacts of virtual reality (VR) on DES activities. The findings indicate the software used, the applications areas, the stages in the simulation modeling process where visual display is commonly used, and a comparative evaluation of the benefits and costs associated with modeling in 3D over 2D. Other results indicate possible influence of each of the two displays on simulation results, effects on users' understanding of the modeled system and any corresponding influence on decision making. The findings also incorporate the pitfalls to avoid when modeling in 3D, and speculations about the future of VR-based DES (VRSIM) practice.},
author = {Akpan, JI and Brooks, RJ},
booktitle = {Proceedings of the Winter Simulation Conference, 2005.},
doi = {10.1109/WSC.2005.1574476},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Winter Simulation Conference, 2005/2005/Akpan, Brooks/Akpan, Brooks - 2005 - Practitioners' Perception of the Impacts of Virtual Reality on Discrete-event Simulation.pdf:pdf},
isbn = {0-7803-9519-0},
pages = {1976--1984},
publisher = {IEEE},
title = {{Practitioners' Perception of the Impacts of Virtual Reality on Discrete-event Simulation}},
url = {http://eprints.lancs.ac.uk/30641/ http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1574476},
year = {2005}
}
@article{Drusch2012,
abstract = {In this paper, we propose a new method for comparing scanpaths in a bottom-up approach, and a test of the scanpath theory. To do so, we conducted a laboratory experiment in which 113 participants were invited to accomplish a set of tasks on two different websites. For each site, they had to perform two tasks that had to be repeated ounce. The data were analyzed using a procedure similar to the one used by Duchowski et al. [8]. The first step was to automatically identify, then label, AOIs with the mean-shift clustering procedure [19]. Then, scanpaths were compared two by two with a modified version of the string-edit method, which take into account the order of AOIs visualizations [2]. Our results show that scanpaths variability between tasks but within participants seems to be lower than the variability within task for a given participant. In other words participants seem to be more coherent when they perform different tasks, than when they repeat the same tasks. In addition, participants view more of the same AOI when they perform a different task on the same Web page than when they repeated the same task. These results are quite different from what predicts the scanpath theory.},
author = {Drusch, Gautier and Bastien, J M Christian},
doi = {10.3233/WOR-2012-0353-1559},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Work (Reading, Mass.)/2012/Drusch, Bastien/Drusch, Bastien - 2012 - Analyzing Web pages visual scanpaths between and within tasks variability.pdf:pdf},
issn = {1875-9270},
journal = {Work (Reading, Mass.)},
keywords = {eye tracking,scanpaty,similarity},
mendeley-tags = {eye tracking,scanpaty,similarity},
month = jan,
pages = {1559--66},
pmid = {22316937},
title = {{Analyzing Web pages visual scanpaths: between and within tasks variability.}},
url = {http://iospress.metapress.com/index/05J21W761850217T.pdf http://www.ncbi.nlm.nih.gov/pubmed/22316937},
volume = {41 Suppl 1},
year = {2012}
}
@inproceedings{Sodhi2013,
abstract = {We present BeThere, a proof-of-concept system designed to explore 3D input for mobile collaborative interactions. With BeThere, we explore 3D gestures and spatial input which al- lowremote users to perform a variety of virtual interactions in a local user’s physical environment. Our system is completely self-contained and uses depth sensors to track the location of a user’s fingers, as well as to capture the 3D shape of objects in front of the sensor. We illustrate the unique capabilities of our system through a series of interactions that allow users to control and manipulate 3D virtual content. We also pro- vide qualitative feedback from a preliminary user study which confirmed that users can complete a shared collaborative task using our system.},
address = {New York, New York, USA},
author = {Sodhi, Rajinder S and Jones, Brett R and Forsyth, David and Bailey, Brian P and Maciocci, Giuliano},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470679},
isbn = {9781450318990},
pages = {179--188},
publisher = {ACM Press},
title = {{BeThere: 3D mobile collaboration with spatial input}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470679},
year = {2013}
}
@inproceedings{Olsen2012a,
abstract = {Selecting values for fixation filters is a difficult task as not only the specifics of the selected filter algorithm has to be taken into account, but also what it is going to be used for and by whom. In this paper the selection and testing process of values for an I-VT fixation filter algorithm implementation is described.},
address = {New York, New York, USA},
annote = {- cited by: 2
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Olsen, Anneli and Matos, Ricardo},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12},
doi = {10.1145/2168556.2168625},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12/2012/Olsen, Matos/Olsen, Matos - 2012 - Identifying parameter values for an I-VT fixation filter suitable for handling data sampled with various sampling.pdf:pdf},
isbn = {9781450312219},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {317},
publisher = {ACM Press},
title = {{Identifying parameter values for an I-VT fixation filter suitable for handling data sampled with various sampling frequencies}},
url = {http://dl.acm.org/citation.cfm?id=2168625 http://dl.acm.org/citation.cfm?doid=2168556.2168625},
year = {2012}
}
@inproceedings{Raij2004,
abstract = {By treating projectors as pin-hole cameras, we show it is possible to calibrate the projectors of a casually-aligned, multi-projector display wall using the principles of planar auto-calibration. We also use a pose estimation technique for planar scenes to reconstruct the relative pose of a calibration camera, the projectors and the plane they project on. Together with assumptions about the pose of the camera, we use the reconstruction to automatically compute the projector-display homographies needed to render properly scaled and oriented imagery on the display wall. The main contribution of this paper is thus to provide a fully automated approach to calibrate a multi-projector display wall without the need for fiducials or interaction.},
author = {Raij, A and Pollefeys, M},
booktitle = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
doi = {10.1109/ICPR.2004.1333994},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004/2004/Raij, Pollefeys/Raij, Pollefeys - 2004 - Auto-calibration of multi-projector display walls.pdf:pdf},
isbn = {0-7695-2128-2},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {14--17 Vol.1},
publisher = {IEEE},
title = {{Auto-calibration of multi-projector display walls}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1333994 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1333994},
year = {2004}
}
@article{Kasprowski2004,
author = {Kasprowski, P and Ober, J},
journal = {Biometric Authentication},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Eye movements in biometrics}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-25976-3_23},
year = {2004}
}
@article{Mollers2013,
address = {New York, New York, USA},
author = {M\"{o}llers, Max and Dumont, Norbert and Ladwig, Stefan and Borchers, Jan},
doi = {10.1145/2470654.2470760},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {755},
publisher = {ACM Press},
title = {{Improving touch accuracy on large tabletops using predecessor and successor}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470760},
year = {2013}
}
@article{Steinicke2011,
abstract = {The display units integrated in today's head-mounted displays (HMDs) provide only a limited field of view (FOV) to the virtual world. In order to present an undistorted view to the virtual environment (VE), the perspective projection used to render the VE has to be adjusted to the limitations caused by the HMD characteristics. In particular, the geometric field of view (GFOV), which defines the virtual aperture angle used for rendering of the 3D scene, is set up according to the display field of view (DFOV). A discrepancy between these two fields of view distorts the geometry of the VE in a way that either minifies or magnifies the imagery displayed to the user. It has been shown that this distortion has the potential to affect a user's perception of the virtual space, sense of presence, and performance on visual search tasks. In this paper, we analyze the user's perception of a VE displayed in a HMD, which is rendered with different GFOVs. We introduce a psychophysical calibration method to determine the HMD's actual field of view, which may vary from the nominal values specified by the manufacturer. Furthermore, we conducted two experiments to identify perspective projections for HMDs, which are identified as natural by subjects--even if these perspectives deviate from the perspectives that are inherently defined by the DFOV. In the first experiment, subjects had to adjust the GFOV for a rendered virtual laboratory such that their perception of the virtual replica matched the perception of the real laboratory, which they saw before the virtual one. In the second experiment, we displayed the same virtual laboratory, but restricted the viewing condition in the real world to simulate the limited viewing condition in a HMD environment. We found that subjects evaluate a GFOV as natural when it is larger than the actual DFOV of the HMD--in some cases up to 50 percent--even when subjects viewed the real space with a limited field of view.},
author = {Steinicke, Frank and Bruder, Gerd and Kuhl, Scott and Willemsen, Pete and Lappe, Markus and Hinrichs, Klaus H},
doi = {10.1109/TVCG.2010.248},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on visualization and computer graphics/2011/Steinicke et al/Steinicke et al. - 2011 - Natural perspective projections for head-mounted displays.pdf:pdf},
isbn = {2010030060},
issn = {1941-0506},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Adult,Calibration,Computer-Assisted,Female,Head,Humans,Image Processing,Male,Man-Machine Systems,Middle Aged,Psychophysics,User-Computer Interface,Visual Fields,Visual Fields: physiology,Visual Perception,Visual Perception: physiology},
month = jul,
number = {7},
pages = {888--99},
pmid = {21546652},
title = {{Natural perspective projections for head-mounted displays.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5620907 http://www.ncbi.nlm.nih.gov/pubmed/21546652},
volume = {17},
year = {2011}
}
@inproceedings{Vouzounaras2010,
abstract = {In this paper, a novel method is proposed able to automatically generate accurate 3D models of both outdoor buildings and indoor scenes with perspective cues from line segments that are automatically extracted from a single image with an uncalibrated camera. The proposed method uses geometric constraints and knowledge of photography and achieves an accurate, real-time and fully automated 3D reconstruction of the scene without any intervention from the user.},
address = {New York, New York, USA},
author = {Vouzounaras, Georgios and {Perez-Moneo Agapito}, Juan Diego and Daras, Petros and Strintzis, Michael G.},
booktitle = {Proceedings of the 2010 ACM workshop on Surreal media and virtual cloning - SMVC '10},
doi = {10.1145/1878083.1878100},
isbn = {9781450301756},
keywords = {constraints,curvilinear modality,hierarchical,photorealistic,projective correction,reconstruction,single picture,single-view 3d reconstruction,vanishing point detection},
mendeley-tags = {reconstruction},
month = jun,
pages = {63},
publisher = {ACM Press},
title = {{3D reconstruction of indoor and outdoor building scenes from a single image}},
url = {http://dl.acm.org/citation.cfm?id=1082121.1082135 http://portal.acm.org/citation.cfm?doid=1878083.1878100 http://dl.acm.org/citation.cfm?id=1878083.1878100},
year = {2010}
}
@article{Rosner2013,
address = {New York, New York, USA},
author = {Rosner, Daniela K. and Ikemiya, Miwa and Kim, Diana and Koch, Kristin},
doi = {10.1145/2470654.2466218},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1649},
publisher = {ACM Press},
title = {{Designing with traces}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466218},
year = {2013}
}
@article{Cui2013,
address = {New York, New York, USA},
author = {Cui, Yanqing and Kangas, Jari and Holm, Jukka and Grassel, Guido},
doi = {10.1145/2470654.2466125},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {981},
publisher = {ACM Press},
title = {{Front-camera video recordings as emotion responses to mobile photos shared within close-knit groups}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466125},
year = {2013}
}
@book{Gutierrez2008,
address = {London},
author = {Guti\'{e}rrez, Mario a. a. and Vexo, Fr\'{e}d\'{e}ric and Thalmann, Daniel},
doi = {10.1007/978-1-84800-117-6},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2008/Guti\'{e}rrez, Vexo, Thalmann/Guti\'{e}rrez, Vexo, Thalmann - 2008 - Stepping into Virtual Reality.pdf:pdf},
isbn = {978-1-84800-116-9},
publisher = {Springer London},
title = {{Stepping into Virtual Reality}},
url = {http://www.springerlink.com/index/10.1007/978-1-84800-117-6},
year = {2008}
}
@book{hacking,
author = {Kramer, Jeff and Parker, Matt and Herrera, Daniel and Burrus, Nicolas and Echtler, Florian},
publisher = {Apress},
title = {{Hacking the Kinect}},
year = {2012}
}
@article{Nystrom2010,
abstract = {Event detection is used to classify recorded gaze points into periods of fixation, saccade, smooth pursuit, blink, and noise. Although there is an overall consensus that current algorithms for event detection have serious flaws and that a de facto standard for event detection does not exist, surprisingly little work has been done to remedy this problem. We suggest a new velocity-based algorithm that takes several of the previously known limitations into account. Most important, the new algorithm identifies so-called glissades, a wobbling movement at the end of many saccades, as a separate class of eye movements. Part of the solution involves designing an adaptive velocity threshold that makes the event detection less sensitive to variations in noise level and the algorithm settings-free for the user. We demonstrate the performance of the new algorithm on eye movements recorded during reading and scene perception and compare it with two of the most commonly used algorithms today. Results show that, unlike the currently used algorithms, fixations, saccades, and glissades are robustly identified by the new algorithm. Using this algorithm, we found that glissades occur in about half of the saccades, during both reading and scene perception, and that they have an average duration close to 24 msec. Due to the high prevalence and long durations of glissades, we argue that researchers must actively choose whether to assign the glissades to saccades or fixations; the choice affects dependent variables such as fixation and saccade duration significantly. Current algorithms do not offer this choice, and their assignments of each glissade are largely arbitrary.},
annote = {- keyword coletado
- cited by: 65
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000

        

      },
author = {Nystr\"{o}m, Marcus and Holmqvist, Kenneth},
doi = {10.3758/BRM.42.1.188},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2010/Nystr\"{o}m, Holmqvist/Nystr\"{o}m, Holmqvist - 2010 - An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Algorithms,Eye Tracking,Fixation,Humans,Models,Ocular,Psychological,Saccades,Saccades: physiology,Segmentation,Signal Detection,gaze analysis},
mendeley-tags = {Eye Tracking,gaze analysis,Segmentation},
month = feb,
number = {1},
pages = {188--204},
pmid = {20160299},
title = {{An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data.}},
url = {http://link.springer.com/article/10.3758/BRM.42.1.188 http://www.ncbi.nlm.nih.gov/pubmed/20160299},
volume = {42},
year = {2010}
}
@inproceedings{Kirner2007,
address = {Petropolis},
author = {Kirner, Claudio and Siscoutto, Robson A.},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2007/Machado/Machado - 2007 - Dispositivos H\'{a}pticos para Interfaces de Realidade Virtual e Aumentada.pdf:pdf},
pages = {2--21},
publisher = {SBC},
title = {{Fundamentos de Realidade Virtual e Aumentada}},
year = {2007}
}
@article{Beardsley2005,
abstract = {Handheld projection lets users create opportunistic displays on any suitable nearby surface. This projection method is a practical and useful addition to mobile computing. Incorporating a projector into a handheld device raises the issue of how to interact with a projection. The focus of the article is interactive projection: a technique for moving a cursor across a projection, allowing all the familiar mouse interactions from the desktop to be transposed to a handheld projector, and requiring only natural, one-handed pointing motion by the user. This article is available with a short video documentary on CD-ROM.},
author = {Beardsley, P and van Baar, J. and Raskar, R. and Forlines, C.},
doi = {10.1109/MCG.2005.12},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Computer Graphics and Applications/2005/Beardsley et al/Beardsley et al. - 2005 - Interaction using a handheld projector.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
month = jan,
number = {1},
pages = {39--43},
title = {{Interaction using a handheld projector}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1381223 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1381223},
volume = {25},
year = {2005}
}
@inproceedings{Bastos2006,
abstract = {This chapter presents some interaction techniques traditionally used in Virtual Reality environments. Beyond, some of these could be used in Augmented Reality ones. As Augmented Reality systems emerge, specially tailored techniques become available. These techniques are also presented in the text.},
address = {Petropolis},
author = {Bastos, Nacha Costa and Teichrieb, Ver\^{o}nica and Kelner, Judith},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {129--148},
publisher = {SBC},
title = {{Intera\c{c}\~{a}o com Realidade Virtual e Aumentada}},
year = {2006}
}
@inproceedings{Garbin2006,
abstract = {By Augmented Reality (RA) is possible to developing alternative systems to work with impairments needs children, allowing augmenting the sensorial channels and helping the perceptual process. This chapter presents interactive and alternative RA system for tasks with impairments needs children.},
address = {Bel\'{e}m-PA},
author = {Garbin, Tania Rossi and Dainese, Carlos Alberto and Kirner, Cl\'{a}udio (UNIFEI) and Dainesse, Carlos Alberto},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {289--297},
publisher = {SBC},
title = {{Sistema de Realidade Aumentada para Trabalho com Crian\c{c}as Portadoras de Necessidades Especiais}},
year = {2006}
}
@article{Engbert2003,
abstract = {Fixational eye movements are subdivided into tremor, drift, and microsaccades. All three types of miniature eye movements generate small random displacements of the retinal image when viewing a stationary scene. Here we investigate the modulation of microsaccades by shifts of covert attention in a classical spatial cueing paradigm. First, we replicate the suppression of microsaccades with a minimum rate about 150 ms after cue onset. Second, as a new finding we observe microsaccadic enhancement with a maximum rate about 350 ms after presentation of the cue. Third, we find a modulation of the orientation towards the cue direction. These multiple influences of visual attention on microsaccades accentuate their role for visual information processing. Furthermore, our results suggest that microsaccades can be used to map the orientation of visual attention in psychophysical experiments.},
author = {Engbert, Ralf and Kliegl, Reinhold},
doi = {10.1016/S0042-6989(03)00084-1},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Vision Research/2003/Engbert, Kliegl/Engbert, Kliegl - 2003 - Microsaccades uncover the orientation of covert attention.pdf:pdf},
issn = {00426989},
journal = {Vision Research},
keywords = {covert attention,gaze analysis,microsaccades},
mendeley-tags = {covert attention,gaze analysis,microsaccades},
month = apr,
number = {9},
pages = {1035--1045},
title = {{Microsaccades uncover the orientation of covert attention}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698903000841 http://linkinghub.elsevier.com/retrieve/pii/S0042698903000841},
volume = {43},
year = {2003}
}
@inproceedings{Bostanci2012,
abstract = {An algorithm for finding planar features from a 3D point cloud by Kinect's depth sensor is described in this paper. The algorithm uses the explicit definition of a plane which allows storing only four parameters per plane rather than storing thousands of points. Extraction of multiple planes from the same set of points is prevented using a rejection mechanism. Parallelism is used for an average speed-up of 2.3:1. Details of the algorithm and results are given along with a discussion of how the calibration of the sensor affects the projections.},
author = {Bostanci, Erkan and Kanwal, Nadia and Clark, Adrian F.},
booktitle = {2012 4th Computer Science and Electronic Engineering Conference (CEEC)},
doi = {10.1109/CEEC.2012.6375388},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 4th Computer Science and Electronic Engineering Conference (CEEC)/2012/Bostanci, Kanwal, Clark/Bostanci, Kanwal, Clark - 2012 - Extracting planar features from Kinect sensor.pdf:pdf},
isbn = {978-1-4673-2666-7},
month = sep,
pages = {111--116},
publisher = {IEEE},
title = {{Extracting planar features from Kinect sensor}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6375388&contentType=Conference+Publications&searchField=Search_All&queryText=kinect+calibration},
year = {2012}
}
@article{Cardoso2012,
author = {Cardoso, Alexandre and Junior, Edgard Afonso Lamounier and Faro, Andre De Mattos},
doi = {10.1109/SVR.2012.23},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Cardoso, Junior, Faro/Cardoso, Junior, Faro - 2012 - The Use of Virtual Reality for Simulation and Training of Bovine Artificial Insemination with Haptic Devi.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {artificial,simulation,training,virtual reality},
month = may,
pages = {66--73},
publisher = {Ieee},
title = {{The Use of Virtual Reality for Simulation and Training of Bovine Artificial Insemination with Haptic Devices}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297561},
year = {2012}
}
@article{perucia2005desenvolvimento,
author = {Perucia, Alexandre Souza and de Berth\^{e}m, Ant\^{o}nio C\'{o}rdova and Bertschinger, Guilherme Lage and Menezes, Roberto Ribeiro Castro},
journal = {S\~{a}o Paulo: Novatec},
keywords = {SBGames},
mendeley-tags = {SBGames},
title = {{Desenvolvimento de jogos eletr\^{o}nicos}},
year = {2005}
}
@misc{CNISENAI2012,
author = {{CNI SENAI}},
title = {{Olimp\'{\i}ada do Conhecimento 2012 - Etapa Nacional}},
url = {http://www.senai.br/olimpiada},
urldate = {10/02/2012},
year = {2012}
}
@article{Heibeck2013,
address = {New York, New York, USA},
author = {Heibeck, Felix},
doi = {10.1145/2468356.2479578},
isbn = {9781450319522},
journal = {CHI '13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA '13},
keywords = {game design,physical computing,tangible play},
pages = {4503},
publisher = {ACM Press},
title = {{Cuboino. Extending Physical Games. An Example}},
url = {http://dl.acm.org/citation.cfm?doid=2468356.2479578},
year = {2013}
}
@article{Paidimarri2006,
abstract = {igh-resolution portable projectors have become commodity items now to own – but not to use. It is not always possible to find a display area where the camera can be properly aligned so that an undistorted image be seen. We present a method to project an undistorted image using a digital projector on a piecewise-planar display area. We use uncalibrated structured light ranging to segment the unknown projection area and further compute the homographies that map the projector space to the camera space through each of the planes. The edge detection and point-correspondences are subpixel precise. Finally, we use these computed homographies to pre-warp the display image so that a distortion-free image is visible. Our results show a seamless and correct rectification with accurate segmentation of the planes.},
author = {Paidimarri, K and Chandran, S},
doi = {10.1007/11949619\_26},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Computer Vision, Graphics and Image Processing/2006/Paidimarri, Chandran/Paidimarri, Chandran - 2006 - Ad-Hoc Multi-planar Projector Displays.pdf:pdf},
journal = {Computer Vision, Graphics and Image Processing},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {289--298},
title = {{Ad-Hoc Multi-planar Projector Displays}},
url = {http://link.springer.com/chapter/10.1007/11949619_26},
volume = {4338},
year = {2006}
}
@article{Mould2011,
abstract = {There is no standard method for classifying eye fixations. Thresholds for speed, acceleration, duration, and stability of point of gaze have each been employed to demarcate data, but they have no commonly accepted values. Here, some general distributional properties of eye movements were used to construct a simple method for classifying fixations, without parametric assumptions or expert judgment. The method was primarily speed-based, but the required optimum speed threshold was derived automatically from individual data for each observer and stimulus with the aid of Tibshirani, Walther, and Hastie's 'gap statistic'. An optimum duration threshold, also derived automatically from individual data, was used to eliminate the effects of instrumental noise. The method was tested on data recorded from a video eye-tracker sampling at 250 frames a second while experimental observers viewed static natural scenes in over 30,000 one-second trials. The resulting classifications were compared with those by three independent expert visual classifiers, with 88-94\% agreement, and also against two existing parametric methods. Robustness to instrumental noise and sampling rate were verified in separate simulations. The method was applied to the recorded data to illustrate the variation of mean fixation duration and saccade amplitude across observers and scenes.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Mould, Matthew S and Foster, David H and Amano, Kinjiro and Oakley, John P},
doi = {10.1016/j.visres.2011.12.006},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Vision Research/2012/Mould et al/Mould et al. - 2012 - A simple nonparametric method for classifying eye fixations.pdf:pdf},
issn = {1878-5646},
journal = {Vision Research},
keywords = {Adult,Female,Fixation,Humans,Male,Nonparametric,Ocular,Ocular: physiology,Photic Stimulation,Photic Stimulation: methods,Saccades,Saccades: physiology,Sensory Thresholds,Sensory Thresholds: physiology,Statistics,Time Factors,Young Adult,gaze analysis},
mendeley-tags = {gaze analysis},
month = mar,
pages = {18--25},
pmid = {22227608},
title = {{A simple nonparametric method for classifying eye fixations.}},
url = {http://personalpages.manchester.ac.uk/staff/david.foster/Research/My_PDFs/Mould_etal_VR_12_MS.pdf http://www.ncbi.nlm.nih.gov/pubmed/22227608 http://www.sciencedirect.com/science/article/pii/S0042698911004214},
volume = {57},
year = {2012}
}
@article{Komogortsev2007,
author = {Komogortsev, OV},
file = {::},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
title = {{EYE MOVEMENT PREDICTION BY OCULOMOTOR PLANT MODELING WITH KALMAN FILTER 2003-2007}},
url = {http://scholar.google.com.br/scholar?start=70&q=identification+fixation+eye&hl=pt-BR&as_sdt=2005&sciodt=0,5&cites=12738018990440336398&scipsc=1#5},
year = {2007}
}
@article{Lacey2007,
author = {Lacey, Gerard and Ryan, Donncha and Cassidy, Derek and Young, Derek},
doi = {10.1109/MMUL.2007.79},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Multimedia/2007/Lacey et al/Lacey et al. - 2007 - Mixed-Reality Simulation of Minimally Invasive Surgeries.pdf:pdf},
issn = {1070-986X},
journal = {IEEE Multimedia},
month = oct,
number = {4},
pages = {76--87},
title = {{Mixed-Reality Simulation of Minimally Invasive Surgeries}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4354160},
volume = {14},
year = {2007}
}
@article{Wu2010,
abstract = {This study is to investigate the fundamental problems of, (1) facial feature detection and localization, especially eye features; and (2) eye dynamics, including tracking and blink detection. We first describe our contribution to eye localization. Following that, we discuss a simultaneous eye tracking and blink detection system. Facial feature detection is solved in a general object detection framework and its performance for eye localization is presented. A binary tree representation based on feature dependency partitions the object feature space in a coarse to fine manner. In each compact feature subspace, independent component analysis (ICA) is used to get the independent sources, whose probability density functions (PDFs) are modeled by Gaussian mixtures. When applying this representation for the task of eye detection, a subwindow is used to scan the entire image and each obtained image patch is examined using Bayesian criteria to determine the presence of an eye subject. After the eyes are automatically located with binary tree-based probability learning, interactive particle filters are used for simultaneously tracking the eyes and detecting the blinks. The particle filters use classification-based observation models, in which the posterior probabilities are evaluated by logistic regressions in tensor subspaces. Extensive experiments are used to evaluate the performance from two aspects, (1) blink detection rate and the accuracy of blink duration in terms of the frame numbers; (2) eye tracking accuracy. We also present an experimental setup for obtaining the benchmark data in tracking accuracy evaluation. The experimental evaluation demonstrates the capability of this approach.},
author = {Wu, Junwen and Trivedi, Mohan M.},
doi = {10.1145/1671962.1671964},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM Transactions on Multimedia Computing, Communications, and Applications/2010/Wu, Trivedi/Wu, Trivedi - 2010 - An eye localization, tracking and blink pattern recognition system.pdf:pdf},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = mar,
number = {2},
pages = {1--23},
title = {{An eye localization, tracking and blink pattern recognition system}},
url = {http://dl.acm.org/citation.cfm?id=1671964 http://portal.acm.org/citation.cfm?doid=1671962.1671964},
volume = {6},
year = {2010}
}
@article{Dewhurst2012,
abstract = {Eye movement sequences-or scanpaths-vary depending on the stimulus characteristics and the task (Foulsham \& Underwood Journal of Vision, 8(2), 6:1-17, 2008; Land, Mennie, \& Rusted, Perception, 28, 1311-1328, 1999). Common methods for comparing scanpaths, however, are limited in their ability to capture both the spatial and temporal properties of which a scanpath consists. Here, we validated a new method for scanpath comparison based on geometric vectors, which compares scanpaths over multiple dimensions while retaining positional and sequential information (Jarodzka, Holmqvist, \& Nystr\"{o}m, Symposium on Eye-Tracking Research and Applications (pp. 211-218), 2010). "MultiMatch" was tested in two experiments and pitted against ScanMatch (Cristino, Math\^{o}t, Theeuwes, \& Gilchrist, Behavior Research Methods, 42, 692-700, 2010), the most comprehensive adaptation of the popular Levenshtein method. In Experiment 1, we used synthetic data, demonstrating the greater sensitivity of MultiMatch to variations in spatial position. In Experiment 2, real eye movement recordings were taken from participants viewing sequences of dots, designed to elicit scanpath pairs with commonalities known to be problematic for algorithms (e.g., when one scanpath is shifted in locus or when fixations fall on either side of an AOI boundary). The results illustrate the advantages of a multidimensional approach, revealing how two scanpaths differ. For instance, if one scanpath is the reverse copy of another, the difference is in the direction but not the positions of fixations; or if a scanpath is scaled down, the difference is in the length of the saccadic vectors but not in the overall shape. As well as having enormous potential for any task in which consistency in eye movements is important (e.g., learning), MultiMatch is particularly relevant for "eye movements to nothing" in mental imagery and embodiment-of-cognition research, where satisfactory scanpath comparison algorithms are lacking.},
author = {Dewhurst, Richard and Nystr\"{o}m, Marcus and Jarodzka, Halszka and Foulsham, Tom and Johansson, Roger and Holmqvist, Kenneth},
doi = {10.3758/s13428-012-0212-2},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2012/Dewhurst et al/Dewhurst et al. - 2012 - It depends on how you look at it scanpath comparison in multiple dimensions with MultiMatch, a vector-based app.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Adult,Algorithms,Attention,Attention: physiology,Cognition,Episodic,Eye Movements,Eye Movements: physiology,Female,Humans,Imagination,Imagination: physiology,Male,Memory,Models,Posture,Psychological,Saccades,Saccades: physiology,eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
month = dec,
number = {4},
pages = {1079--100},
pmid = {22648695},
title = {{It depends on how you look at it: scanpath comparison in multiple dimensions with MultiMatch, a vector-based approach.}},
url = {http://link.springer.com/article/10.3758/s13428-012-0212-2 http://www.ncbi.nlm.nih.gov/pubmed/22648695},
volume = {44},
year = {2012}
}
@inproceedings{Aguilera2005,
author = {Aguilera, D G and Lahoz, J G\'{o}mez and Codes, J Finat},
booktitle = {Proceedings of the ISPRS Working Group V4 Workshop 3DARCH 2005 Virtual Reconstruction and Visualization of Complex Architectures},
keywords = {3d reconstruction,geometry,photogrammetry,single image technique,vanishing points estimation},
title = {{A New Method for Vanishing Point Detection in 3D Reconstruction from a Single View}},
year = {2005}
}
@inproceedings{Chen2011,
abstract = {Free viewpoint video presentation is a new challenge in multimedia analysis. This paper presents an innovative physics-based scheme to reconstruct the 3D ball trajectory from single-camera volleyball video sequences for free viewpoint virtual replay. The problem of 2D-to-3D inference is arduous due to the loss of 3D information in projection to 2D images. The proposed scheme incorporates the domain knowledge of court specification and the physical characteristics of ball motion to accomplish the 2D-to-3D inference. Motion equations with the parameters are set up to define the 3D trajectories based on physical characteristics. Utilizing the geometric transformation of camera calibration, the 2D ball coordinates extracted over frames are used to approximate the parameters of the 3D motion equations, and finally the 3D ball trajectory can be reconstructed from single-camera sequences. The experiments show promising results. The reconstructed 3D trajectory enables the free viewpoint virtual replay and enriched visual presentation, making game watching a whole new experience.},
author = {Chen, Hua-Tsung and Chou, Chien-Li and Tsai, Wen-Jiin and Lee, Suh-Yin},
booktitle = {2011 Visual Communications and Image Processing (VCIP)},
doi = {10.1109/VCIP.2011.6115930},
isbn = {978-1-4577-1322-4},
keywords = {2D-to-3D inference problem,3D ball trajectory reconstruction,3D trajectories,Cameras,Equations,Games,Image reconstruction,Mathematical model,Three dimensional displays,Trajectory,camera calibration,free viewpoint video presentation,free viewpoint virtual replay,geometric transformation,image sequences,multimedia analysis,reconstruction,single-camera sports video,single-camera volleyball video sequences,sport,video cameras},
mendeley-tags = {reconstruction},
month = nov,
pages = {1--4},
publisher = {IEEE},
shorttitle = {Visual Communications and Image Processing (VCIP),},
title = {{3D ball trajectory reconstruction from single-camera sports video for free viewpoint virtual replay}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6115930},
year = {2011}
}
@article{Rodriguez2005,
author = {a.a. Rodriguez and Metzger, R.P. and Cifdaloz, O. and Dhirasakdanon, T.},
doi = {10.1109/TE.2004.842915},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Education/2005/Rodriguez et al/Rodriguez et al. - 2005 - Description of a Modeling, Simulation, Animation, and Real-Time Control (MoSART) Environment for a Class of El.pdf:pdf},
issn = {0018-9359},
journal = {IEEE Transactions on Education},
month = aug,
number = {3},
pages = {359--374},
title = {{Description of a Modeling, Simulation, Animation, and Real-Time Control (MoSART) Environment for a Class of Electromechanical Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1495643},
volume = {48},
year = {2005}
}
@article{Arai2010,
author = {Arai, K and Mardiyanto, R},
journal = {International Journal of Human  \ldots},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
title = {{Real time blinking detection based on Gabor filter}},
url = {http://download.neurosky.com.cn/marketing/学术论文/人机交互论文/IJHCI-11.pdf},
year = {2010}
}
@inproceedings{Audet2009,
abstract = {Projector-camera systems drive applications in many fields such as measurement and spatial augmented reality. When needed, we can find their internal and external parameters via geometric calibration. For this process, we have to use both a printed pattern and a projector pattern, but they can easily interfere with each other. Current methods compensate by decoupling their calibrations or by leveraging structured light and color channels, but the required manipulations are not user-friendly. Therefore, we cannot expect normal users to execute the procedure, which can also become a burden for researchers. Although not always required, knowledge of the geometric parameters can often facilitate development of new systems. To make the calibration process easier, we propose a method that uses fiducial markers, from which we can easily derive a prewarp that, once applied to the projector calibration pattern, prevents its interference. Using our method, we confirmed that users can easily calibrate a projector-camera system in less than one minute, which we consider to be user-friendly, while still achieving typical subpixel accuracy.},
author = {Audet, S and Okutomi, M},
booktitle = {2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
doi = {10.1109/CVPRW.2009.5204319},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops/2009/Audet, Okutomi/Audet, Okutomi - 2009 - A user-friendly method to geometrically calibrate projector-camera systems.pdf:pdf},
isbn = {978-1-4244-3994-2},
keywords = {anamorphism},
mendeley-tags = {anamorphism},
month = jun,
pages = {47--54},
publisher = {IEEE},
title = {{A user-friendly method to geometrically calibrate projector-camera systems}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5204319 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5204319},
year = {2009}
}
@article{Myers2005,
author = {Myers, CW},
journal = {Journal of Vision},
keywords = {scanpath,similarity},
mendeley-tags = {scanpath,similarity},
title = {{Toward a method of objectively determining scanpath similarity}},
url = {http://www-mtl.journalofvision.org/content/5/8/693.short},
year = {2005}
}
@article{Kramer2013,
address = {New York, New York, USA},
author = {Kr\"{a}mer, Jan-Peter and Karrer, Thorsten and Kurz, Joachim and Wittenhagen, Moritz and Borchers, Jan},
doi = {10.1145/2470654.2466419},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3073},
publisher = {ACM Press},
title = {{How tools in IDEs shape developers' navigation behavior}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466419},
year = {2013}
}
@article{Brasil2011,
author = {Brasil, Igor Saraiva and Neto, Francisco Milton Mendes and Chagas, Jos\'{e} Ferdinandy Silva and Lima, Rodrigo Monteiro De and Souza, Daniel Faustino Lacerda and Bonates, Mara Franklin and Dantas, Andre},
doi = {10.1109/SVR.2011.13},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 XIII Symposium on Virtual Reality/2011/Brasil et al/Brasil et al. - 2011 - An Inteligent Agent-Based Virtual Game for Oil Drilling Operators Training.pdf:pdf},
isbn = {978-1-4577-0661-5},
journal = {2011 XIII Symposium on Virtual Reality},
keywords = {-educative games,multi-agent systems,virtual re-},
month = may,
pages = {9--17},
publisher = {Ieee},
title = {{An Inteligent Agent-Based Virtual Game for Oil Drilling Operators Training}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5951830},
year = {2011}
}
@inproceedings{Fosh2013,
abstract = {We apply the HCI concept of trajectories to the design of a sculpture trail. We crafted a trajectory through each sculpture, combining textual and audio instructions to drive directed viewing, movement and touching while listening to accompanying music. We designed key transitions along the way to oscillate between moments of social interaction and isolated personal engagement, and to deliver official interpretation only after visitors had been given the opportunity to make their own. We describe how visitors generally followed our trajectory, engaging with sculptures and making interpretations that sometimes challenged the received interpretation. We relate our findings to discussions of sense-making and design for multiple interpretations, concluding that curators and designers may benefit from considering, trajectories of interpretation‟.},
address = {New York, New York, USA},
author = {Fosh, Lesley and Benford, Steve and Reeves, Stuart and Koleva, Boriana and Brundell, Patrick},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470675},
isbn = {9781450318990},
pages = {149--158},
publisher = {ACM Press},
title = {{‘See Me, Feel Me, Touch Me, Hear Me’: Trajectories and Interpretation in a Sculpture Garden}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470675},
year = {2013}
}
@book{Cassandras2010,
author = {Cassandras, Christos G. and Lafortune, Stephane},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2010/Cassandras, Lafortune/Cassandras, Lafortune - 2010 - Introduction to Discrete Event Systems.pdf:pdf},
isbn = {1441941193},
pages = {800},
publisher = {Springer},
title = {{Introduction to Discrete Event Systems}},
url = {http://www.amazon.com/Introduction-Discrete-Systems-Christos-Cassandras /dp/1441941193},
year = {2010}
}
@book{Szeliski2010,
author = {Szeliski, R},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2010/Szeliski/Szeliski - 2010 - Computer vision Algorithms and applications.pdf:pdf;:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2010/Szeliski/Szeliski - 2010 - Computer vision Algorithms and applications(2).pdf:pdf},
keywords = {Computer Vision,Image Processing},
mendeley-tags = {Computer Vision,Image Processing},
title = {{Computer vision: Algorithms and applications}},
url = {http://books.google.com.br/books?hl=en&lr=&id=bXzAlkODwa8C&oi=fnd&pg=PR9&dq=Computer+Vision:+Algorithms+and+Applications&ots=gY1280pyCD&sig=LgFpAO_cJ5JvXpVU70q6IjDiZY0},
year = {2010}
}
@article{Laubrock2005,
abstract = {We compared effects of covert spatial-attention shifts induced with exogenous or endogenous cues on microsaccade rate and direction. Separate and dissociated effects were obtained in rate and direction measures. Display changes caused microsaccade rate inhibition, followed by sustained rate enhancement. Effects on microsaccade direction were differentially tied to cue class (exogenous vs. endogenous) and type (neutral vs. directional). For endogenous cues, direction effects were weak and occurred late. Exogenous cues caused a fast direction bias towards the cue (i.e., early automatic triggering of saccade programs), followed by a shift in the opposite direction (i.e, controlled inhibition of cue-directed saccades, leading to a ‘leakage’ of microsaccades in the opposite direction).},
author = {Laubrock, Jochen and Engbert, Ralf and Kliegl, Reinhold},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Vision Research/2005/Laubrock, Engbert, Kliegl/Laubrock, Engbert, Kliegl - 2005 - Microsaccade dynamics during covert attention.pdf:pdf},
journal = {Vision Research},
keywords = {Attention,Eye movements,Fixation,Reaction time,gaze analysis: microsaccade},
mendeley-tags = {gaze analysis: microsaccade},
number = {6},
pages = {721--730},
title = {{Microsaccade dynamics during covert attention}},
url = {http://www.sciencedirect.com/science/article/pii/S004269890400495X},
volume = {45},
year = {2005}
}
@article{Taylor2013,
address = {New York, New York, USA},
author = {Taylor, Alex S. and Piterman, Nir and Ishtiaq, Samin and Fisher, Jasmin and Cook, Byron and Cockerton, Caitlin and Bourton, Sam and Benque, David},
doi = {10.1145/2470654.2470725},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {493},
publisher = {ACM Press},
title = {{At the interface of biology and computation}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470725},
year = {2013}
}
@article{Juhola1988,
abstract = {A method based on a recursive digital filter is presented that recognizes minima and maxima of nystagmus. The method does not require user assistance. However, it takes into account the type and changes of input by adapting itself to these. The method has been tested with nystagmus data. If the algorithm is slightly modified, it can detect other eye movements.},
author = {Juhola, M},
doi = {10.1109/10.1398},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on bio-medical engineering/1988/Juhola/Juhola - 1988 - Detection of nystagmus eye movements using a recursive digital filter.pdf:pdf},
issn = {0018-9294},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Algorithms,Computer-Assisted,Electronystagmography,Electronystagmography: methods,Humans,Signal Processing,gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
month = may,
number = {5},
pages = {389--95},
pmid = {3397089},
title = {{Detection of nystagmus eye movements using a recursive digital filter.}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1398 http://www.ncbi.nlm.nih.gov/pubmed/3397089},
volume = {35},
year = {1988}
}
@article{Alt2013,
address = {New York, New York, USA},
author = {Alt, Florian and Shirazi, Alireza Sahami and Kubitza, Thomas and Schmidt, Albrecht},
doi = {10.1145/2470654.2466226},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {1709},
publisher = {ACM Press},
title = {{Interaction techniques for creating and exchanging content with public displays}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466226},
year = {2013}
}
@book{Casse2006,
abstract = {This lucid and accessible text provides an introductory guide to projective geometry, an area of mathematics concerned with the properties and invariants of geometric figures under projection. Including numerous worked examples and exercises throughout, the book covers axiomatic geometry, field planes and PG(r, F), coordinating a projective plane, non-Desarguesian planes, conics and quadrics in PG(3, F). Assuming familiarity with linear algebra, elementary group theory, partial differentiation and finite fields, as well as some elementary coordinate geometry, this text is ideal for 3rd and 4th year lucid and accessible text provides an introductory guide to projective geometry, an area of mathematics concerned with the properties and invariants of geometric figures under projection. Including numerous worked examples and exercises throughout, the book covers axiomatic geometry, field planes and PG(r, F), coordinatising a projective plane, non-Desarguesian planes, conics and quadrics in PG(3, F). Assuming familiarity with linear algebra, elementary group theory, partial differentiation and finite fields, as well as some elementary coordinate geometry, this text is ideal for 3rd and 4th year mathematics undergraduates.},
author = {Casse, Rey},
booktitle = {Nature},
doi = {10.1038/141535b0},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Nature/2006/Casse/Casse - 2006 - An Introduction to Projective Geometry.pdf:pdf},
isbn = {9781402042485},
issn = {00280836},
number = {3569},
pages = {535--535},
publisher = {Oxford university Press},
title = {{An Introduction to Projective Geometry}},
url = {http://books.google.at/books?hl=de&id=9khtJHzmtTgC&dq=casse+projective+geometry&printsec=frontcover&source=web&ots=vOHQvhknVT&sig=z6EIUjfanqekH082kJ-hmHtoJKc&sa=X&oi=book_result&resnum=10&ct=result},
volume = {141},
year = {2006}
}
@article{Fuchs1967,
abstract = {Voluntary eye movements were measured in the chronic, unanaesthetized monkey. A training technique is described which conditions the animals to follow a large variety of target trajectories. The eye movements of the monkey are not qualitatively different from those of man. In response to random target motions the monkey also employs a combination of saccadic and smooth pursuit movements. Monkeys execute their saccades more rapidly than humans. Monkeys are capable of attaining smooth pursuit velocities which are twice as fast as those of man. Most of the critical experiments showing the separate nature of the saccadic and smooth pursuit modes in man have been performed on monkeys with similar results. Therefore, if one remains aware of the quantitative differences between the two primates, results of neurophysiological studies of the occulomotor system of the monkey can be expected to have considerable relevance when extrapolated to man.},
author = {Fuchs, AF},
file = {::},
journal = {The Journal of physiology},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
title = {{Saccadic and smooth pursuit eye movements in the monkey}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1365495/},
year = {1967}
}
@article{Gould1985,
abstract = {This article is both theoretical and empirical. Theoretically, it describes three principles of system design which we believe must be followed to produce a useful and easy to use computer system. These principles are: early and continual focus on users; empirical measurement of usage; and iterative design whereby the system (simulated, prototype, and real) is modified, tested, modified again, tested again, and the cycle is repeated again and again. This approach is contrasted to other principled design approaches, for example, get it right the first time, reliance on design guidelines. Empirically, the article presents data which show that our design principles are not always intuitive to designers; identifies the arguments which designers often offer for not using these principles—and answers them; and provides an example in which our principles have been used successfully.},
author = {Gould, John D and Lewis, Clayton},
doi = {10.1145/3166.3170},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Communications of the ACM/1985/Gould, Lewis/Gould, Lewis - 1985 - Designing for usability key principles and what designers think.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = mar,
number = {3},
pages = {300--311},
title = {{Designing for usability: key principles and what designers think}},
url = {http://dl.acm.org/citation.cfm?id=3170 http://portal.acm.org/citation.cfm?doid=3166.3170},
volume = {28},
year = {1985}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Bernstein2013,
abstract = {When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users' perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27\% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000 Facebook users' posts over the course of one month and find that publicly visible signals --- friend count, likes, and comments --- vary widely and do not strongly indicate the audience of a single post. Despite the variation, users typically reach 61\% of their friends each month. Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.},
address = {New York, New York, USA},
author = {Bernstein, Michael S. and Bakshy, Eytan and Burke, Moira and Karrer, Brian},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470658},
isbn = {9781450318990},
keywords = {Social networks,audience,information distribution},
pages = {21--30},
publisher = {ACM Press},
title = {{Quantifying the invisible audience in social networks}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470658},
year = {2013}
}
@article{Leahu2013,
address = {New York, New York, USA},
author = {Leahu, Lucian and Cohn, Marisa and March, Wendy},
doi = {10.1145/2470654.2466455},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3331},
publisher = {ACM Press},
title = {{How categories come to matter}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466455},
year = {2013}
}
@article{Teixeira2012,
author = {Teixeira, Joao Marcelo and Reis, Bernardo and Macedo, Samuel and Kelner, Judith},
doi = {10.1109/SVR.2012.20},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2012 14th Symposium on Virtual and Augmented Reality/2012/Teixeira et al/Teixeira et al. - 2012 - OpenClosed Hand Classification Using Kinect Data.pdf:pdf},
isbn = {978-1-4673-1929-4},
journal = {2012 14th Symposium on Virtual and Augmented Reality},
keywords = {-hand gesture classification,natural interaction},
month = may,
pages = {18--25},
publisher = {Ieee},
title = {{Open/Closed Hand Classification Using Kinect Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297556},
year = {2012}
}
@misc{Simscript2011,
author = {Simscript},
title = {{Simscript}},
url = {http://www.simscript.com},
year = {2011}
}
@article{Zhang2000,
author = {Zhang, Z},
doi = {10.1109/34.888718},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Pattern Analysis and Machine Intelligence/2000/Zhang/Zhang - 2000 - A flexible new technique for camera calibration.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {11},
pages = {1330--1334},
title = {{A flexible new technique for camera calibration}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=888718 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=888718},
volume = {22},
year = {2000}
}
@inproceedings{Sukthankar2001a,
author = {Sukthankar, R and Stockton, R.G. and Mullin, M.D.},
booktitle = {Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},
doi = {10.1109/ICCV.2001.937525},
file = {::},
isbn = {0-7695-1143-0},
keywords = {anamorphism,keystone},
mendeley-tags = {anamorphism,keystone},
pages = {247--253},
publisher = {IEEE Comput. Soc},
title = {{Smarter presentations: exploiting homography in camera-projector systems}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=937525 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=937525},
volume = {1},
year = {2001}
}
@inproceedings{Niu2013,
abstract = {The increasing popularity of stereoscopic 3D brings the demand for tools for editing and authoring stereoscopic images and videos. This paper shows that even a simple task like cropping is difficult for amateur users with little stereoscopic photography knowledge. Unlike regular monocular (2D) images, cropping a stereoscopic image needs to be carefully executed to avoid stereoscopic violations, which otherwise cause an unpleasant stereoscopic viewing experience. In this paper, we present a system that assists in stereoscopic photo cropping by automatically measuring the stereoscopic photography violations and alerting users with the potential violations. Our study shows that compared to a popular stereoscopic photo editing system, our system makes stereoscopic photo cropping easier even for amateur users with little stereoscopic photography knowledge and provides a good user experience.},
author = {Niu, Yuzhen},
booktitle = {2013 IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2013.6607587},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2013 IEEE International Conference on Multimedia and Expo (ICME)/2013/Niu/Niu - 2013 - Making stereo photo cropping easy.pdf:pdf},
isbn = {978-1-4799-0015-2},
issn = {1945-7871},
keywords = {Agriculture,Histograms,Image color analysis,Image edge detection,Photography,Stereo image processing,Stereoscopic photography,Three-dimensional displays,anamorphism,digital photography,keystone,photo cropping,photo editing,stereo photo cropping,stereoscopic 3D,stereoscopic photo editing system,stereoscopic photography violations},
mendeley-tags = {anamorphism,keystone},
month = jul,
pages = {1--6},
publisher = {IEEE},
shorttitle = {Multimedia and Expo (ICME), 2013 IEEE Internationa},
title = {{Making stereo photo cropping easy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6607587},
year = {2013}
}
@inproceedings{Schild2013,
abstract = {Creating graphical user interfaces (GUI) for stereoscopic 3D (S3D) games is a difficult choice between visual comfort and effect. We pres ent a S3D Game GUI Desi gn Space and a list s of S3D-specific attributes that emphasizes integrating visually comfort able interfaces into the ga me world, story and S3D view. To showcase our approach, we created two GUI concepts and evaluated them with 32 users. Our results show quality improvements for combination of bottom position and visual attachment fo r a menu. In a referencing inter face, placing the reference n ear to the target depth significantly improved perceived quali ty, game integration, and increased presence. These resu lts confirm the need to create S3D GUIs with perceptual constraints in mind, demons trt ating the potential to exte nd the user experience. Additionally, our design space offers a formal and flexible way to create new effects in S3D GUIs.},
address = {New York, New York, USA},
author = {Schild, Jonas and B\"{o}licke, Liane and {LaViola Jr.}, Joseph J. and Masuch, Maic},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470678},
isbn = {9781450318990},
pages = {169--178},
publisher = {ACM Press},
title = {{Creating and analyzing stereoscopic 3D graphical user interfaces in digital games}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470678},
year = {2013}
}
@article{Kelley2013,
address = {New York, New York, USA},
author = {Kelley, Patrick Gage and Cranor, Lorrie Faith and Sadeh, Norman},
doi = {10.1145/2470654.2466466},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {3393},
publisher = {ACM Press},
title = {{Privacy as part of the app decision-making process}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466466},
year = {2013}
}
@inproceedings{Komogortsev2009,
abstract = {In this paper, we introduce and evaluate a new Instantaneous Saccade (IS) selection scheme for eye gaze driven interfaces where the speed of the target selection is of utmost importance. In the IS selection scheme, target selection occurs at the start (onset) of a saccade requiring only constant amount of time to be completed. The IS performance is compared to the conventional Dwell Time (DT) selection scheme where target selection is triggered when a user fixates on an object for a certain amount of time. The IS method is also compared to the Saccade Offset (SO) selection scheme where target selection occurs at the end of a saccade. All three schemes were evaluated in terms of task completion time and the throughput of input performance in horizontal target selection task by six subjects. Results show that the Instantaneous Saccade selection was 57\% faster than the DT selection to complete a task. In terms of throughput comparison, the throughput of the IS selection is 1.9 times greater than the throughput of DT selection. We hypothesize that Instantaneous Saccade selection will be beneficial in gaming environments that require fast very interaction speeds.},
address = {New York, New York, USA},
author = {Komogortsev, Oleg V. and Ryu, Young Sam and Koh, Do Hyong and Gowda, Sandeep M.},
booktitle = {Proceedings of the International Conference on Advances in Computer Enterntainment Technology - ACE '09},
doi = {10.1145/1690388.1690412},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the International Conference on Advances in Computer Enterntainment Technology - ACE '09/2009/Komogortsev et al/Komogortsev et al. - 2009 - Instantaneous saccade driven eye gaze interaction.pdf:pdf},
isbn = {9781605588643},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {140},
publisher = {ACM Press},
title = {{Instantaneous saccade driven eye gaze interaction}},
url = {http://dl.acm.org/citation.cfm?id=1690412 http://portal.acm.org/citation.cfm?doid=1690388.1690412},
year = {2009}
}
@article{LeMeur2013,
abstract = {In this article, we are interested in the computational modeling of visual attention. We report methods commonly used to assess the performance of these kinds of models. We survey the strengths and weaknesses of common assessment methods based on diachronic eye-tracking data. We then illustrate the use of some methods to benchmark computational models of visual attention.},
annote = {crossRef(Jarodzka2010)},
author = {{Le Meur}, Olivier and Baccino, Thierry},
doi = {10.3758/s13428-012-0226-9},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2013/Le Meur, Baccino/Le Meur, Baccino - 2013 - Methods for comparing scanpaths and saliency maps strengths and weaknesses.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Algorithms,Attention,Attention: classification,Biological,Differential Threshold,Eye Movement Measurements,Eye Movements,Humans,Models,Optic Flow,Pattern Recognition,ROC Curve,Visual,Visual Field Tests,Visual Fields,Visual: classification,eye tracking,scanpath,similarity},
mendeley-tags = {eye tracking,scanpath,similarity},
month = mar,
number = {1},
pages = {251--66},
pmid = {22773434},
title = {{Methods for comparing scanpaths and saliency maps: strengths and weaknesses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22773434},
volume = {45},
year = {2013}
}
@inproceedings{Siscoutto2006,
abstract = {This chapter introduces stereoscopy, showing how stereo images are composed by the human vision as well as artificially, presenting some techniques and devices to generate stereoscopy and some related mathematical fundaments. In addition, some problems related to computer-generated stereoscopic visualization are discussed. At the end, two virtual reality applications involving stereoscopy are presented.},
address = {Bel\'{e}m-PA},
author = {Siscoutto, Robson and Szenberg, Fl\'{a}vio and Tori, Romero and Raposo, Alberto Barbosa and Celes, Waldemar and Gattass, Marcelo},
booktitle = {Symposium of Virtual Reality},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Symposium of Virtual Reality/2006/Tori, Kirner/Tori, Kirner - 2006 - Fundamentos de Realidade Virtual.pdf:pdf},
pages = {221--245},
publisher = {SBC},
title = {{Estereoscopia}},
year = {2006}
}
@inproceedings{Jung2013,
abstract = {Past research has demonstrated a link between perceptions of social capital and use of the popular social network site, Facebook. Williams' Internet Social Capital Scales, based on Putnam's formulation, tap into sub-dimensions of social capital that have not been broadly used yet may enlighten our understanding of the different ways in which connecting with others online can facilitate access to resources embedded within our social relationships. In this study, we segment Williams' Internet Social Capital Scales into various sub-dimensions using factor analysis and explicate the distinct facets of social capital through a lab experiment in which Facebook users (N=98) request a small favor from their Facebook network. We find that some sub-dimensions play a significant role in getting favors from Facebook friends while bonding and bridging social capital do not significantly predict responses to favor requests.},
address = {New York, New York, USA},
author = {Jung, Yumi and Gray, Rebecca and Lampe, Cliff and Ellison, Nicole},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470657},
isbn = {9781450318990},
pages = {11--20},
publisher = {ACM Press},
title = {{Favors from facebook friends: unpacking dimensions of social capital}},
url = {https://www.msu.edu/~nellison/JungGrayLampeEllison2013CHI.pdf http://dl.acm.org/citation.cfm?doid=2470654.2470657},
year = {2013}
}
@article{Ruttle,
abstract = {3D reconstruction from multiple view images requires that camera parameters are very accurately known and standard camera calibration techniques [1] often fail to provide the required level of accuracy for the extrinsic camera parameters. Using the Kinect depth camera, we propose to estimate camera parameters by minimising the cross correlation between density functions modelled for each recorded depth images. We illustrate experimentally how this improves the modelling for estimating 3D shape from Depths.},
author = {Ruttle, J. and Arellano, C. and Dahyot, R.},
title = {{Extrinsic camera parameters estimation for shape-from-depths}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6334154&contentType=Conference+Publications&searchField=Search_All&queryText=kinect+calibration}
}
@article{Kaufmann2013,
address = {New York, New York, USA},
author = {Kaufmann, Bonifaz and Ahlstr\"{o}m, David},
doi = {10.1145/2470654.2466434},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {Map navigation,handheld projector,peephole interaction,spatial memory,touch interaction},
pages = {3173},
publisher = {ACM Press},
title = {{Studying spatial memory and map navigation performance on projector phones with peephole interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2466434},
year = {2013}
}
@inproceedings{Liu2013,
abstract = {Health video blogs (vlogs) allow individuals with chronic illnesses to share their stories, experiences, and knowledge with the general public. Furthermore, health vlogs help in creating a connection between the vlogger and the viewers. In this work, we present a qualitative study examining the various methods that health vloggers use to establish a connection with their viewers. We found that vloggers used genres to express specific messages to their viewers while using the uniqueness of video to establish a deeper connection with their viewers. Health vloggers also explicitly sought interaction with their viewers. Based on these results, we present design implications to help facilitate and build sustainable communities for vloggers.},
address = {New York, New York, USA},
author = {Liu, Leslie S. and Huh, Jina and Neogi, Tina and Inkpen, Kori and Pratt, Wanda},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
doi = {10.1145/2470654.2470663},
isbn = {9781450318990},
pages = {49--58},
publisher = {ACM Press},
title = {{Health vlogger-viewer interaction in chronic illness management}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470663},
year = {2013}
}
@article{Smeets2003,
abstract = {We studied the variability in saccades by comparing the peak velocities of saccades with the same target amplitude made with different actual amplitudes. We tested three hypotheses: the pulse-height noise hypothesis (peak velocity and amplitude vary proportionally), the localization noise hypothesis (variability in amplitude and peak velocity lie along the main sequence), and the independent noise hypothesis (variability in amplitude and peak velocity are independent). We measured eye orientation in two experiments by a scleral coil and a video system. Surprisingly, the main source of variability of saccades depended on the measurement system used. A combination of localization noise and independent noise best describes the data obtained by the video system. The independent noise (e.g., measurement inaccuracy) was the main source of variability. For the scleral coils, the variability was considerably larger than for the less accurate video system. The pulse-height noise hypothesis best describes this additional variability. Therefore we conclude that pulse-height noise is the main source of variability in saccades measured with scleral coils. We discuss the influence of scleral coils on saccade generation and suggest that a change in motor strategy due to the discomfort of wearing the coils might be the cause of the increased variability.},
annote = {- cited by: 35
- kw: Nature of variability in saccades
- engine: Google Scholar
- crossref: Larsson2010},
author = {Smeets, JBJ and Hooge, ITC},
doi = {10.​1152/​jn.​01075.​2002},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of neurophysiology/2003/Smeets, Hooge/Smeets, Hooge - 2003 - Nature of variability in saccades.pdf:pdf},
journal = {Journal of neurophysiology},
keywords = {gaze analysis,saccade},
mendeley-tags = {gaze analysis,saccade},
number = {1},
pages = {12--20},
title = {{Nature of variability in saccades}},
url = {http://jn.physiology.org/content/90/1/12.short},
volume = {90},
year = {2003}
}
@article{Reniers2009a,
author = {Reniers, Dennie and Telea, A.},
file = {::},
journal = {Computing and Visualization in Science},
keywords = {Point-Based Rendering,algebraic multigrid,extreme model simplification,point set models,real-time rendering},
mendeley-tags = {Point-Based Rendering},
number = {1},
pages = {9--22},
publisher = {Springer},
title = {{Extreme simplification and rendering of point sets using algebraic multigrid}},
url = {http://www.springerlink.com/index/rkv5571752q38wr8.pdf},
volume = {12},
year = {2009}
}
@phdthesis{Stone1971b,
author = {Stone, John Edward},
file = {::},
school = {University of Missouri-Rolla},
title = {{An Efficient Library for Parallel Ray Tracing and Animation}},
year = {1971}
}
@article{Kirchera,
author = {Kircher, Scott},
file = {::},
keywords = {alpha-,deferred shading,fast dynamic lighting,polygon shadows,real-time rendering},
title = {{Inferred Lighting: Fast dynamic lighting and shadows for opaque and translucent objects}}
}
@article{Everitta,
author = {Everitt, Cass},
file = {::},
journal = {Engineering},
keywords = {GPU,OIT,Transparency,graphics,nvidia},
mendeley-tags = {GPU,OIT,Transparency,graphics,nvidia},
title = {{Interactive Order-Independent Transparency}}
}
@inproceedings{Germs2001a,
author = {Germs, Rick and Jansen, F.W.},
booktitle = {Proc. of WSCG},
file = {::},
keywords = {geometric simplification,occlusion culling,virtual occluders,walkthrough visualization},
publisher = {Citeseer},
title = {{Geometric simplification for efficient occlusion culling in urban scenes}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.8189&amp;rep=rep1&amp;type=pdf},
volume = {2001},
year = {2001}
}
@article{Hasselgren2009a,
author = {Hasselgren, Jon and Munkberg, Jacob and Akenine-M\"{o}ller, Tomas},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {3D Graphics,Real-Time Rendering},
mendeley-tags = {3D Graphics,Real-Time Rendering},
number = {2},
pages = {1--10},
title = {{Automatic pre-tessellation culling}},
url = {http://portal.acm.org/citation.cfm?doid=1516522.1516530},
volume = {28},
year = {2009}
}
@article{Gaiazov2005a,
author = {Gaiazov, Leonid},
file = {::},
journal = {Science},
keywords = {gpu,graphics,npr,shaders},
mendeley-tags = {gpu,graphics,npr,shaders},
pages = {1--9},
title = {{Real-Time NPR System with Multiple Styles}},
year = {2005}
}
@article{E.Kee2011,
author = {{E. Kee}, M. K. Johnson and H. Farid},
journal = {IEEE Transactions on Information Forensics and Security},
keywords = {authentication verification jpg forensics},
number = {3},
pages = {1066--1075},
title = {{Digital image Authentication from JPEG headers}},
url = {http://www.cs.dartmouth.edu/~farid/Hany_Farid/Papers/Entries/2011/6/4_Digital_image_Authentication_from_JPEG_headers.html},
volume = {6},
year = {2011}
}
@article{Case2009a,
author = {Case, Colleen and Cunningham, Steve},
file = {::},
pages = {1--6},
title = {{Teaching Computer Graphics in Context Computer Graphics Education 09 Workshop Munich, Germany, March 31-April 1, 2009}},
year = {2009}
}
@inproceedings{Deines2007a,
author = {Deines, Eduard and Michel, Frank and Hering-Bertram, Martin and Mohring, Jan and Hagen, Hans},
booktitle = {19th International Congress on Acoustics (ICA) 2007},
file = {::},
number = {September},
pages = {2--7},
title = {{Simulation, visualization, and virtual reality based modeling of room acoustics}},
url = {http://www-hagen.informatik.uni-kl.de/~bertram/papers/},
year = {2007}
}
@article{Bierens2004,
address = {Cambridge},
author = {Bierens, Herman J.},
doi = {10.1017/CBO9780511754012},
isbn = {9780511754012},
publisher = {Cambridge University Press},
title = {{Introduction to the Mathematical and Satistical Foundations of Econometrics}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511754012},
year = {2004}
}
@inproceedings{Mensmann2008a,
author = {Mensmann, J\"{o}rg and Hinrichs, Klaus},
booktitle = {16th International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision},
file = {::},
keywords = {Volume Rendering,illustration,volume cutting,volume deformation,volume rendering,voreen},
mendeley-tags = {Volume Rendering,voreen},
pages = {89--96},
title = {{Interactive Cutting Operations for Generating Anatomical Illustrations from Volumetric Data Sets}},
volume = {d},
year = {2008}
}
@book{Mason2009,
author = {Mason, Charlie},
booktitle = {American journal of orthodontics and dentofacial orthopedics : official publication of the American Association of Orthodontists, its constituent societies, and the American Board of Orthodontics},
doi = {10.1016/j.ajodo.2009.10.012},
isbn = {0821807854},
issn = {1097-6752},
keywords = {Clinical Competence,General Practice, Dental,General Practice, Dental: standards,Humans,Orthodontic Appliances, Functional,Orthodontic Appliances, Removable,Orthodontics,Orthodontics: instrumentation,Orthodontics: standards,Tooth Movement,Tooth Movement: instrumentation,Tooth Movement: standards,Treatment Outcome},
month = dec,
number = {6},
pages = {759},
pmid = {19962587},
title = {{Mixed motives.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21614721},
volume = {136},
year = {2009}
}
@inproceedings{Liang2009a,
author = {Liang, XiaoHui and Zhao, QinPing and He, ZhiYing and Xie, Ke and Liu, YuBo},
file = {::},
keywords = {Point-Based Rendering},
mendeley-tags = {Point-Based Rendering},
number = {8},
title = {{A point-based rendering approach for real-time interaction on mobile devices}},
volume = {3},
year = {2009}
}
@inproceedings{Ropinski2005a,
author = {Ropinski, Timo and Steinicke, Frank and Hinrichs, KH},
booktitle = {proceedings of the 10th International Fall Workshop on Vision, Modeling, and Visualization},
file = {::},
keywords = {Volume Rendering,voreen},
mendeley-tags = {Volume Rendering,voreen},
pages = {273--280},
publisher = {Citeseer},
title = {{Interactive importance-driven visualization techniques for medical volume data}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.4332&amp;rep=rep1&amp;type=pdf},
volume = {D},
year = {2005}
}
@article{Fauser2002,
abstract = {Quantum Clifford Algebras (QCA), i.e. Clifford Hopf gebras based on bilinear forms of arbitrary symmetry, are treated in a broad sense. Five alternative constructions of QCAs are exhibited. Grade free Hopf gebraic product formulas are derived for meet and join of Grassmann-Cayley algebras including co-meet and co-join for Grassmann-Cayley co-gebras which are very efficient and may be used in Robotics, left and right contractions, left and right co-contractions, Clifford and co-Clifford products, etc. The Chevalley deformation, using a Clifford map, arises as a special case. We discuss Hopf algebra versus Hopf gebra, the latter emerging naturally from a bi-convolution. Antipode and crossing are consequences of the product and co-product structure tensors and not subjectable to a choice. A frequently used Kuperberg lemma is revisited necessitating the definition of non-local products and interacting Hopf gebras which are generically non-perturbative. A `spinorial' generalization of the antipode is given. The non-existence of non-trivial integrals in low-dimensional Clifford co-gebras is shown. Generalized cliffordization is discussed which is based on non-exponentially generated bilinear forms in general resulting in non unital, non-associative products. Reasonable assumptions lead to bilinear forms based on 2-cocycles. Cliffordization is used to derive time- and normal-ordered generating functionals for the Schwinger-Dyson hierarchies of non-linear spinor field theory and spinor electrodynamics. The relation between the vacuum structure, the operator ordering, and the Hopf gebraic counit is discussed. QCAs are proposed as the natural language for (fermionic) quantum field theory.},
archivePrefix = {arXiv},
arxivId = {math.QA/0202059},
author = {Fauser, Bertfried},
eprint = {0202059},
keywords = {Mathematical Physics,Quantum Algebra},
month = feb,
primaryClass = {math.QA},
title = {{A Treatise on Quantum Clifford Algebras}},
url = {http://arxiv.org/abs/math.QA/0202059},
year = {2002}
}
@article{Ren2002a,
author = {Ren, Liu and Pfister, Hanspeter and Zwicker, Matthias},
file = {::},
journal = {Computer Graphics Forum},
keywords = {Point-Based Rendering},
mendeley-tags = {Point-Based Rendering},
month = sep,
number = {3},
pages = {461--470},
title = {{Object Space EWA Surface Splatting: A Hardware Accelerated Approach to High Quality Point Rendering}},
url = {http://blackwell-synergy.com/doi/abs/10.1111/1467-8659.00606},
volume = {21},
year = {2002}
}
@article{Hecker2008a,
author = {Hecker, Chris and Raabe, Bernd and Enslow, Ryan W. and DeWeese, John and Maynard, Jordan and van Prooijen, Kees},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {ated content,character animation,games,inverse kinematics,motion retargeting,procedural animation,user gene},
month = aug,
number = {3},
pages = {1},
title = {{Real-time motion retargeting to highly varied user-created morphologies}},
url = {http://portal.acm.org/citation.cfm?doid=1360612.1360626},
volume = {27},
year = {2008}
}
@article{Shanmugam2007,
address = {New York, New York, USA},
author = {Shanmugam, Perumaal and Arikan, Okan},
doi = {10.1145/1230100.1230113},
file = {::},
isbn = {9781595936288},
journal = {Proceedings of the 2007 symposium on Interactive 3D graphics and games - I3D '07},
keywords = {Computer Graphics,GPU,I3D07,Real-Time Rendering,Shaders,ambient occlusion,gpu,real-time render-,soft shadows},
mendeley-tags = {Computer Graphics,GPU,I3D07,Real-Time Rendering,Shaders},
pages = {73},
publisher = {ACM Press},
title = {{Hardware accelerated ambient occlusion techniques on GPUs}},
url = {http://portal.acm.org/citation.cfm?doid=1230100.1230113},
year = {2007}
}
@article{Perlin2002a,
address = {New York, New York, USA},
author = {Perlin, Ken},
file = {::},
journal = {Proceedings of the 29th annual conference on Computer graphics and interactive techniques - SIGGRAPH '02},
pages = {681},
publisher = {ACM Press},
title = {{Improving noise}},
url = {http://portal.acm.org/citation.cfm?doid=566570.566636},
year = {2002}
}
@article{Zeng2009b,
author = {Zeng, Kun and Zhao, Mingtian and Xiong, Caiming and Zhu, Song-Chun},
file = {::},
journal = {ACM Transactions on Graphics},
number = {1},
pages = {1--11},
title = {{From image parsing to painterly rendering}},
url = {http://portal.acm.org/citation.cfm?doid=1640443.1640445},
volume = {29},
year = {2009}
}
@article{Oliveira2000a,
address = {New York, New York, USA},
author = {Oliveira, Manuel M. and Bishop, Gary and McAllister, David},
file = {::},
journal = {Proceedings of the 27th annual conference on Computer graphics and interactive techniques - SIGGRAPH '00},
keywords = {Computer Graphics},
mendeley-tags = {Computer Graphics},
pages = {359--368},
publisher = {ACM Press},
title = {{Relief texture mapping}},
url = {http://portal.acm.org/citation.cfm?doid=344779.344947},
year = {2000}
}
@article{Habel2007a,
abstract = {This paper introduces a technique for rendering animated grass in real time. The technique uses front-to-back compositing of implicitly defined grass slices in a fragment shader and therefore significantly reduces the overhead associated with common vegetation rendering systems. We also introduce a texture-based animation scheme that combines global wind movements with local turbulences. Since the technique is confined to a fragment shader, it can be easily integrated into any rendering system and used as a material in existing scenes.},
author = {Habel, Ralf and Wimmer, Michael and Jeschke, Stefan},
file = {::},
journal = {Journal of WSCG},
keywords = {3D Graphics,Grass,OGRE,Real-Time Rendering,gpu programming,natural phenomena,natural scene rendering,real-time rendering},
mendeley-tags = {3D Graphics,Grass,OGRE,Real-Time Rendering},
pages = {123----128},
title = {{Instant Animated Grass}},
url = {http://www.cg.tuwien.ac.at/research/publications/2007/Habel_2007_IAG/},
volume = {15},
year = {2007}
}
@article{Mehra2009a,
author = {Mehra, Ravish and Zhou, Qingnan and Long, Jeremy and Sheffer, Alla and Gooch, Amy and Mitra, Niloy J.},
file = {::},
journal = {Journal of the Electrochemical Society},
keywords = {communities have resulted in,curve network,geometry,good,growth of online modeling,in such collections do,large col-,lections of such models,most models of man-made,not satisfy the notion,npr,objects present,of,perception,shape analysis},
title = {{Abstraction of Man-Made Shapes}},
year = {2009}
}
@article{Gooch1998a,
author = {Gooch, Amy and Gooch, Bruce and Shirley, Peter and Cohen, Elaine},
file = {::},
title = {{A Non-Photorealistic Lighting Model For Automatic Technical Illustration.}},
year = {1998}
}
@article{Blass1984,
author = {Blass, Andreas and Burris, Stanley and Sankappanavar, H. P.},
doi = {10.2307/2322184},
issn = {00029890},
journal = {The American Mathematical Monthly},
month = jan,
number = {1},
pages = {64},
title = {{A Course in Universal Algebra.}},
url = {http://www.jstor.org/stable/2322184?origin=crossref},
volume = {91},
year = {1984}
}
@article{Card2001c,
author = {Card, Drew and Mitchell, Jason L},
file = {::},
journal = {ATI Research},
title = {{Non-photorealistic rendering with pixel and vertex shaders}},
year = {2001}
}
@book{Yang2005,
address = {Hoboken, NJ, USA},
author = {Yang, Won Young and Cao, Wenwu and Chung, Tae-Sang and Morris, John},
doi = {10.1002/0471705195},
isbn = {9780471705192},
month = jan,
publisher = {John Wiley \& Sons, Inc.},
title = {{Applied Numerical Methods Using MATLAB®}},
url = {http://doi.wiley.com/10.1002/0471705195},
year = {2005}
}
@article{Cook2007a,
author = {Cook, Robert L. and Halstead, John and Planck, Maxwell and Ryu, David},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {000 leaves,Pixar,SIGGRAPH07,a plant with 320,figure 1,level of detail,simpli cation,stochastic sampling},
mendeley-tags = {Pixar,SIGGRAPH07},
month = jul,
number = {3},
pages = {79},
title = {{Stochastic simplification of aggregate detail}},
url = {http://portal.acm.org/citation.cfm?doid=1276377.1276476 http://graphics.pixar.com/library/},
volume = {26},
year = {2007}
}
@article{Reshetov2009a,
address = {New York, New York, USA},
author = {Reshetov, Alexander},
file = {::},
journal = {Proceedings of the 1st ACM conference on High Performance Graphics - HPG '09},
keywords = {Antialiasing,Real-Time Rendering,antialiasing,image enhancement,morphological analysis},
mendeley-tags = {Antialiasing,Real-Time Rendering},
pages = {109},
publisher = {ACM Press},
title = {{Morphological antialiasing}},
url = {http://portal.acm.org/citation.cfm?doid=1572769.1572787},
year = {2009}
}
@article{Alexa2003a,
author = {Alexa, M. and Behr, J. and Cohen-Or, D. and Fleishman, S. and Levin, D. and Silva, C.T.},
file = {::},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {3d acquisition,Point-Based Rendering,least squares,moving,point sample rendering,surface representation and reconstruction},
mendeley-tags = {Point-Based Rendering},
month = jan,
number = {1},
pages = {3--15},
title = {{Computing and rendering point set surfaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1175093},
volume = {9},
year = {2003}
}
@article{Bridson2007a,
author = {Bridson, Robert and Houriham, Jim and Nordenstam, Marcus},
doi = {10.1145/1276377.1276435},
file = {::},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {a of distance from,a smoothed step function,by a modu-,figure 1,fluids,incompressible 2d noise with,lation function,n,noise,procedural animation,pute the potential $\psi$,solid boundaries,t,the,to com-,turbulence,we multiply scaled noise,x},
month = jul,
number = {3},
pages = {46},
title = {{Curl-noise for procedural fluid flow}},
url = {http://portal.acm.org/citation.cfm?doid=1276377.1276435 http://www.cs.ubc.ca/~rbridson/},
volume = {26},
year = {2007}
}
@inproceedings{Crassin2009a,
author = {Crassin, Cyril and Neyret, Fabrice and Lefebvre, Sylvain and Eisemann, Elmar},
booktitle = {ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D)},
file = {::},
title = {{GigaVoxels: Ray-Guided Streaming for Efficient and Detailed Voxel Rendering}},
url = {ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D)},
volume = {d},
year = {2009}
}
@inproceedings{Roßler2008,
author = {R\"{o}\ss ler, F. and Botchen, RP and Ertl, Thomas},
booktitle = {Proceedings of IEEE Pacific Visualization Symposium},
file = {::},
pages = {17--24},
title = {{Dynamic shader generation for flexible multi-volume visualization}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Dynamic+Shader+Generation+for+Flexible+Multi-Volume+Visualization#0},
volume = {2008},
year = {2008}
}
@article{Irving2007a,
author = {Irving, Geoffrey and Schroeder, Craig and Fedkiw, Ronald},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {collisions,deformable solids,incompressibility},
month = jul,
number = {3},
pages = {13},
title = {{Volume conserving finite element simulations of deformable models}},
url = {http://portal.acm.org/citation.cfm?doid=1276377.1276394 http://naml.us/~irving/},
volume = {26},
year = {2007}
}
@article{Palubicki2009a,
author = {Palubicki, Wojciech and Horel, Kipp and Longay, Steven and Runions, Adam and Lane, Brendan},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {3D Graphics,Procedural Modeling,apical control,bud fate,emergence,generative tree model,interactive-procedural modeling,tree development},
mendeley-tags = {3D Graphics,Procedural Modeling},
month = apr,
number = {2},
pages = {1--10},
publisher = {ACM New York, NY, USA},
title = {{Self-organizing tree models for image synthesis}},
url = {http://portal.acm.org/citation.cfm?doid=1516522.1516530},
volume = {28},
year = {2009}
}
@inproceedings{Stegmaier2005a,
author = {Stegmaier, Simon and Klein, Thomas},
booktitle = {Volume Graphics 2005},
file = {::},
title = {{A Simple and Flexible Volume Rendering Framework for Graphics-Hardware-based Raycasting}},
year = {2005}
}
@inproceedings{Zafar2010a,
address = {Saarbrucken, Germany},
author = {Zafar, Fahad and Olano, Marc and Curtis, Aaron},
booktitle = {Proceedings of the ACM SIGGRAPH/Eurographics Symposium on High Performance Graphics},
file = {::},
keywords = {GPU,Noise,Real-Time Rendering,Shaders,cryptographic hash,noise,shadows},
mendeley-tags = {GPU,Noise,Real-Time Rendering,Shaders},
pages = {25--27},
title = {{GPU Random Numbers via the Tiny Encryption Algorithm}},
url = {http://www.csee.umbc.edu/~olano/papers/},
volume = {xx},
year = {2010}
}
@article{Speakers2012,
author = {Speakers, Invited},
doi = {10.1093/carcin/bgs054},
issn = {1460-2180},
journal = {Carcinogenesis},
month = mar,
number = {3},
pages = {NP},
pmid = {22383472},
title = {{Table of contents.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22383472},
volume = {33},
year = {2012}
}
@article{Linsen2007a,
author = {Linsen, Lars and Muller, Karsten and Rosenthal, Paul},
file = {::},
journal = {Journal of WSCG},
keywords = {Point-Based Rendering,photo-realistic rendering,point-based rendering,ray tracing,splatting},
mendeley-tags = {Point-Based Rendering},
number = {1-3},
pages = {51--58},
title = {{Splat-based ray tracing of point clouds}},
url = {http://www.cse.iitb.ac.in/~kashyap/seminar/final/Splat-based Ray Tracing of Point Clouds.pdf},
volume = {15},
year = {2007}
}
@article{Sainz2004a,
author = {Sainz, Miguel and Parajola, Renato},
file = {::},
journal = {Computers \& Graphics},
keywords = {Point-Based Rendering,hardware acceleration,level-of-detail,point-based rendering},
mendeley-tags = {Point-Based Rendering},
pages = {869--879},
title = {{Point-based rendering techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849304001530},
volume = {28},
year = {2004}
}
@article{McGuire2004b,
address = {New York, New York, USA},
author = {McGuire, Morgan and Hughes, John F.},
file = {::},
journal = {Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering - NPAR '04},
keywords = {GPU,NPR,contour,shadow volume,silhouette},
pages = {35},
publisher = {ACM Press},
title = {{Hardware-determined feature edges}},
url = {http://portal.acm.org/citation.cfm?doid=987657.987663},
year = {2004}
}
@article{Mikkelsen2010a,
author = {Mikkelsen, Morten S},
file = {::},
keywords = {GPU,Real-Time Rendering},
mendeley-tags = {GPU,Real-Time Rendering},
title = {{Bump Mapping Unparametrized Surfaces on the GPU}},
year = {2010}
}
@article{Bajaj2001a,
author = {Bajaj, C. and Blanke, W.},
file = {::},
journal = {Proceedings IEEE 2001 Symposium on Parallel and Large-Data Visualization and Graphics (Cat. No.01EX520)},
keywords = {Parallel Rendering,gressive mesh,metabuffer,multi-resolution,parallel and out-of-core isocontouring,parallel rendering,pro-},
mendeley-tags = {Parallel Rendering},
pages = {51--150},
publisher = {Ieee},
title = {{Scalable isosurface visualization of massive datasets on COTS clusters}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=964404},
year = {2001}
}
@article{Luft2006,
author = {Luft, Thomas and Colditz, Carsten and Deussen, Oliver},
file = {::},
journal = {ACM Transactions on Graphics (TOG)},
keywords = {Real-Time Rendering,SIGGRAPH06,SSAO,a dull appearance,ambient occlusion,artistic tone reproduction,complex scenes,complex spatial arrange-,gpu,image enhancement,ing,ments sometimes suffers from,non-photorealistic render-,shaders,since the rendering of,the desired quality,this is especially},
mendeley-tags = {Real-Time Rendering,SIGGRAPH06,SSAO,ambient occlusion,gpu,shaders},
title = {{Image enhancement by unsharp masking the depth buffer}},
url = {http://portal.acm.org/citation.cfm?id=1141911.1142016 http://graphics.uni-konstanz.de/publikationen/2006/unsharp_masking/webseite/},
year = {2006}
}
@incollection{Bunnell2005b,
author = {Bunnell, M.},
booktitle = {GPU Gems},
file = {::},
keywords = {GPU Gems,ambient occlusion,graphics,nvidia},
mendeley-tags = {graphics,nvidia},
pages = {223--233},
title = {{Dynamic ambient occlusion and indirect lighting}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Dynamic+Ambient+Occlusion+and+Indirect+Lighting#0},
volume = {2},
year = {2005}
}
@phdthesis{Stone1971c,
author = {Stone, J.},
booktitle = {Computer Science Department, University of Missouri-Rolla Masters Thesis},
file = {::},
publisher = {Citeseer},
title = {{An efficient library for parallel ray tracing and animation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.7193&amp;rep=rep1&amp;type=pdf},
year = {1971}
}
@article{Maim2009,
abstract = {A solution that allows each individual to look unique in a real-time large crowd simulation. First, it provides a simple, efficient method for attaching accessories to individuals to modify their look. Second, it provides a new, generic technique based on segmentation maps for adding detailed color variety and patterns to human meshes as well as accessories. Both methods are scalable to suit all human levels of detail exploited in crowd simulations; that is, impostors and rigid and deformable meshes. Tests and comparisons show that the algorithm provides the crowd with an appealing visual aspect and is adequate for real-time simulations of thousands of unique characters.},
author = {Ma\"{\i} m, Jonathan and Yersin, Barbara and Thalmann, Daniel},
journal = {Computer Graphics and Applications, IEEE},
number = {6},
pages = {82 -- 90},
title = {{Unique Character Instances for Crowds}},
url = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=5307631&arnumber=5307646},
volume = {29},
year = {2009}
}
@article{Krugera,
author = {Kruger, J. and Westermann, R.},
file = {::},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics and Frequency Control},
keywords = {programmable graphics hard-,volume rendering},
pages = {287--292},
publisher = {Ieee},
title = {{Acceleration techniques for GPU-based volume rendering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1250384}
}
@incollection{Card2001b,
author = {Card, Drew and Mitchell, Jason L},
booktitle = {ShaderX},
file = {::},
keywords = {NPR,Non-Photorealistic Rendering,Real-Time Rendering,Shaders},
mendeley-tags = {NPR,Non-Photorealistic Rendering,Real-Time Rendering,Shaders},
title = {{Non-photorealistic rendering with pixel and vertex shaders}},
year = {2001}
}
@article{Filion2008c,
address = {New York, New York, USA},
author = {Filion, Dominic and McNaughton, Rob},
file = {::},
journal = {ACM SIGGRAPH 2008 classes on - SIGGRAPH '08},
pages = {133},
publisher = {ACM Press},
title = {{Starcraft 2 : Effects \& techniques}},
url = {http://portal.acm.org/citation.cfm?doid=1404435.1404441},
year = {2008}
}
@article{Banks1997,
abstract = {This is an expanded version of talks given by the author at the Trieste Spring School on Supergravity and Superstrings in April of 1997 and at the accompanying workshop. The manuscript is intended to be a mini-review of Matrix Theory. The motivations and some of the evidence for the theory are presented, as well as a clear statement of the current puzzles about compactification to low dimensions.},
archivePrefix = {arXiv},
arxivId = {hep-th/9710231},
author = {Banks, Tom},
doi = {10.1016/S0920-5632(98)00130-3},
eprint = {9710231},
journal = {Matrix},
month = oct,
number = {September},
pages = {72},
primaryClass = {hep-th},
title = {{Matrix Theory}},
url = {http://arxiv.org/abs/hep-th/9710231},
year = {1997}
}
@article{Murnaghan1961,
author = {Murnaghan, F. D. and Hoffman, Kenneth and Kunze, Ray},
doi = {10.2307/2002915},
issn = {00255718},
journal = {Mathematics of Computation},
month = jul,
number = {75},
pages = {303},
title = {{Linear Algebra.}},
url = {http://www.jstor.org/stable/2002915?origin=crossref},
volume = {15},
year = {1961}
}
@article{Cole2009b,
address = {New York, New York, USA},
author = {Cole, Forrester and Finkelstein, Adam},
file = {::},
journal = {Proceedings of the 2009 symposium on Interactive 3D graphics and games - I3D '09},
keywords = {3D Graphics,NPR,Non-Photorealistic Rendering,a major dif culty,broad strokes,conventional,figure 2,hidden line removal,in drawing strokes is,insuf cient for drawing,item buffer intro-,line drawing,npr,per-fragment depth testing is,techniques such as the,visibility,visibility computation},
mendeley-tags = {3D Graphics,NPR,Non-Photorealistic Rendering},
pages = {115},
publisher = {ACM Press},
title = {{Fast high-quality line visibility}},
url = {http://portal.acm.org/citation.cfm?doid=1507149.1507168},
year = {2009}
}
@article{Gustavson2005a,
author = {Gustavson, Stefan},
file = {::},
title = {{Simplex noise demystified}},
year = {2005}
}
@article{Dachsbacher2003a,
author = {Dachsbacher, Carsten and Vogelgsang, Christian and Stamminger, Marc},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {Point-Based Rendering,hardware accelerated graphics,level,point rendering},
mendeley-tags = {Point-Based Rendering},
month = jul,
number = {3},
pages = {657},
title = {{Sequential point trees}},
url = {http://portal.acm.org/citation.cfm?doid=882262.882321},
volume = {22},
year = {2003}
}
@inproceedings{Botsch2005a,
author = {Botsch, M. and Hornung, A. and Zwicker, M. and Kobbelt, L.},
booktitle = {Proceedings Eurographics/IEEE VGTC Symposium Point-Based Graphics, 2005.},
file = {::},
keywords = {Point-Based Rendering},
mendeley-tags = {Point-Based Rendering},
pages = {17--141},
publisher = {Ieee},
title = {{High-quality surface splatting on today's GPUs}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1500313},
volume = {5},
year = {2005}
}
@article{Sugerman2009a,
author = {Sugerman, Jeremy and Fatahalian, Kayvon and Boulos, Solomon and Akeley, Kurt and Hanrahan, Pat},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {3D Graphics},
mendeley-tags = {3D Graphics},
number = {1},
pages = {1--11},
title = {{Gramps: A Programming Model for Graphics Pipelines}},
url = {http://portal.acm.org/citation.cfm?doid=1477926.1477930},
volume = {28},
year = {2009}
}
@article{Zhaia,
author = {Zhai, Yun and Liu, Jingen and Cao, Xiaochun and Basharat, Arslan and Hakeem, Asaad and Ali, Saad and Shah, Mubarak and Grana, Costantino and Cucchiara, Rita},
file = {::},
journal = {Search},
number = {1},
title = {{Video Understanding and Content-Based Retrieval}}
}
@inproceedings{Lagae2010a,
author = {Lagae, A. and Lefebvre, S. and Cook, R. and DeRose, T. and Drettakis, G. and Ebert, D.S. and Lewis, J.P. and Perlin, K. and Zwicker, M.},
booktitle = {EG 2010 Proceedings},
file = {::},
keywords = {analysis,anisotropic noise,anti-aliasing,filtering,gabor noise,noise,perlin noise,power spectrum estimation,procedural,procedural modeling,procedural noise function,procedural texture,solid noise,solid texture,sparse convolution noise,spectral,spot noise,stochastic modeling,stochastic process,surface noise,texture synthesis,wavelet noise},
title = {{State of the Art in Procedural Noise Functions}},
url = {http://www.cs.kuleuven.be/~ares/publications/LLCDDELPZ10STARPNF/LLCDDELPZ10STARPNF.pdf},
year = {2010}
}
@article{Ziegel1994,
author = {Ziegel, Eric R. and Khuri, Andre},
doi = {10.2307/1269402},
issn = {00401706},
journal = {Technometrics},
keywords = {Calculus, Probability, Statistics, Mulivariable Ca},
month = aug,
number = {3},
pages = {333},
title = {{Advanced Calculus with Applications in Statistics}},
url = {http://www.jstor.org/stable/1269402?origin=crossref},
volume = {36},
year = {1994}
}
@inproceedings{Parker2010a,
author = {Parker, Steven G and Bigler, James and Dietrich, Andreas and Friedrich, Heiko and Hoberock, Jared and Luebke, David and Mcallister, David and Stich, Martin},
booktitle = {SIGGRAPH 2010},
file = {::},
keywords = {graphics hardware,graphics systems,ray tracing},
title = {{OptiX : A General Purpose Ray Tracing Engine}},
year = {2010}
}
@article{McGuire2004c,
address = {New York, New York, USA},
author = {McGuire, Morgan and Hughes, John F.},
file = {::},
journal = {Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering - NPAR '04},
keywords = {NPR,Non-Photorealistic Rendering,a bottleneck,and,buffer to discern edges,components of the frame,computing the,contour,cpu and transmitting it,edge list on the,for the first class,gpu,npr,of algorithms,reading back the frame-buffer,shadow volume,silhouette,to the gpu is},
mendeley-tags = {NPR,Non-Photorealistic Rendering},
pages = {35},
publisher = {ACM Press},
title = {{Hardware-determined feature edges}},
url = {http://portal.acm.org/citation.cfm?doid=987657.987663},
year = {2004}
}
@article{Bailey2009,
author = {Bailey, Mike},
file = {::},
issn = {0272-1716},
journal = {Computer Graphics and Applications, IEEE},
number = {5},
pages = {96--100},
publisher = {IEEE},
title = {{Using GPU shaders for visualization}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5230472},
volume = {29},
year = {2009}
}
@article{McGuire2006a,
address = {New York, New York, USA},
author = {McGuire, Morgan and Stathis, George and Pfister, Hanspeter and Krishnamurthi, Shriram},
file = {::},
journal = {Proceedings of the 2006 symposium on Interactive 3D graphics and games - SI3D '06},
pages = {79},
publisher = {ACM Press},
title = {{Abstract shade trees}},
url = {http://portal.acm.org/citation.cfm?doid=1111411.1111425},
year = {2006}
}
@inproceedings{McGuire2010a,
author = {McGuire, M.},
booktitle = {ACM SIGGRAPH/Eurographics High Performance Graphics 2009},
file = {::},
keywords = {AO,Ambient Occlusion,Real-Time Rendering},
mendeley-tags = {AO,Ambient Occlusion,Real-Time Rendering},
pages = {1},
publisher = {ACM},
title = {{Ambient occlusion volumes}},
url = {http://graphics.cs.williams.edu/papers/AOVHPG10/},
year = {2010}
}
@article{Shanmugam2007a,
address = {New York, New York, USA},
author = {Shanmugam, Perumaal and Arikan, Okan},
doi = {10.1145/1230100.1230113},
file = {::},
isbn = {9781595936288},
journal = {Proceedings of the 2007 symposium on Interactive 3D graphics and games - I3D '07},
keywords = {Computer Graphics,GPU,I3D07,Real-Time Rendering,Shaders,ambient occlusion,gpu,real-time render-,soft shadows},
mendeley-tags = {Computer Graphics,GPU,I3D07,Real-Time Rendering,Shaders},
pages = {73},
publisher = {ACM Press},
title = {{Hardware accelerated ambient occlusion techniques on GPUs}},
url = {http://portal.acm.org/citation.cfm?doid=1230100.1230113},
year = {2007}
}
@article{Burns2008a,
author = {Burns, Michael and Finkelstein, Adam},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {cutaway diagram,distance transform,npr,visibility},
month = dec,
number = {5},
pages = {1},
title = {{Adaptive cutaways for comprehensible rendering of polygonal scenes}},
url = {http://portal.acm.org/citation.cfm?doid=1409060.1409107},
volume = {27},
year = {2008}
}
@article{Nichols2009c,
author = {Nichols, Greg and Shopf, Jeremy and Wyman, Chris},
file = {::},
journal = {Computer Graphics Forum},
keywords = {3D Graphics,EG09,Global Illumination,Real-Time Rendering,Shaders},
mendeley-tags = {3D Graphics,EG09,Global Illumination,Real-Time Rendering,Shaders},
month = jun,
number = {4},
pages = {1141--1149},
title = {{Hierarchical Image-Space Radiosity for Interactive Global Illumination}},
url = {http://blackwell-synergy.com/doi/abs/10.1111/j.1467-8659.2009.01491.x},
volume = {28},
year = {2009}
}
@article{Nichols2009b,
author = {Nichols, Greg and Shopf, Jeremy and Wyman, Chris},
file = {::},
journal = {Computer Graphics Forum},
month = jun,
number = {4},
pages = {1141--1149},
title = {{Hierarchical Image-Space Radiosity for Interactive Global Illumination}},
url = {http://blackwell-synergy.com/doi/abs/10.1111/j.1467-8659.2009.01491.x},
volume = {28},
year = {2009}
}
@inproceedings{Rusinkiewicz2000a,
author = {Rusinkiewicz, S. and Levoy, Marc},
booktitle = {Proceedings of the 27th annual conference on Computer graphics and interactive techniques},
file = {::},
keywords = {3d scan-,Point-Based Rendering,algorithms,and software components of,compression algorithms,data they produce,improvements in the hardware,level of detail,over the past several,rendering systems,spatial data structures,the large amounts of,years},
mendeley-tags = {Point-Based Rendering},
pages = {343--352},
publisher = {ACM Press/Addison-Wesley Publishing Co. New York, NY, USA},
title = {{QSplat: A multiresolution point rendering system for large meshes}},
url = {http://portal.acm.org/citation.cfm?id=344779.344940},
year = {2000}
}
@phdthesis{Cole2009c,
address = {New York, New York, USA},
author = {Cole, Forrester},
booktitle = {ACM SIGGRAPH 2005 Courses on - SIGGRAPH '05},
file = {::},
keywords = {3D Graphics,NPR,Non-Photorealistic Rendering},
mendeley-tags = {3D Graphics,NPR,Non-Photorealistic Rendering},
number = {June},
pages = {1},
publisher = {ACM Press},
school = {Princeton},
title = {{Line drawings of 3D models}},
url = {http://www.cs.princeton.edu/gfx/pubs/_2009_LDO/index.php},
year = {2009}
}
@inproceedings{Sigg2006a,
author = {Sigg, Christian and Weyrich, Tim and Botsch, Mario and Gross, Markus},
booktitle = {Eurographics Symposium on Point-Based Graphics (2006)},
editor = {Botsch, M. and Chen, B.},
file = {::},
title = {{GPU-Based Ray-Casting of Quadratic Surfaces}},
year = {2006}
}
@inproceedings{Kircher2009a,
author = {Kircher, S. and Lawrance, A.},
booktitle = {Proceedings of the 2009 ACM SIGGRAPH Symposium on Video Games},
file = {::},
keywords = {Lighting,Real-Time Rendering,SIGGRAPH09: GPU,Shaders,alpha-,deferred shading,fast dynamic lighting,polygon shadows,real-time rendering},
mendeley-tags = {Lighting,Real-Time Rendering,SIGGRAPH09: GPU,Shaders},
pages = {39--45},
publisher = {ACM},
title = {{Inferred lighting: fast dynamic lighting and shadows for opaque and translucent objects}},
url = {http://portal.acm.org/citation.cfm?id=1581080 http://graphics.cs.uiuc.edu/~kircher/publications.html},
year = {2009}
}
@article{Hunt2006,
author = {Hunt, Warren and Mark, William and Stoll, Gordon},
doi = {10.1109/RT.2006.280218},
file = {::},
isbn = {1-4244-0693-5},
journal = {2006 IEEE Symposium on Interactive Ray Tracing},
keywords = {approximation,error,heuristic,kd-tree},
month = sep,
number = {v},
pages = {81--88},
publisher = {Ieee},
title = {{Fast kd-tree Construction with an Adaptive Error-Bounded Heuristic}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4061549},
year = {2006}
}
@article{Haseman2008,
address = {Berkeley, CA},
author = {Haseman, Chris},
doi = {10.1007/978-1-4302-1063-4},
isbn = {978-1-4302-1064-1},
publisher = {Apress},
title = {{Android Essentials}},
url = {http://www.springerlink.com/index/10.1007/978-1-4302-1063-4},
year = {2008}
}
@article{Machines2012,
author = {Machines, Business},
doi = {10.1093/carcin/bgs054},
issn = {1460-2180},
journal = {Carcinogenesis},
month = mar,
number = {3},
pages = {NP},
pmid = {22383472},
title = {{Table of contents.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22383472},
volume = {33},
year = {2012}
}
@inproceedings{Mcguire2009a,
author = {Mcguire, Morgan and Luebke, David},
booktitle = {Proceedings of HPG'09},
file = {::},
keywords = {global illumination,photon mapping,photon volumes},
title = {{Hardware-Accelerated Global Illumination by Image Space Photon Mapping}},
year = {2009}
}
@article{Benard2010,
address = {New York, New York, USA},
author = {B\'{e}nard, Pierre and Cole, Forrester and Golovinskiy, Aleksey and Finkelstein, Adam},
file = {::},
journal = {Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering - NPAR '10},
keywords = {line drawing,non-photorealistic rendering,temporal},
pages = {91},
publisher = {ACM Press},
title = {{Self-similar texture for coherent line stylization}},
url = {http://portal.acm.org/citation.cfm?doid=1809939.1809950 http://artis.imag.fr/Publications/2010/BCGF10/},
year = {2010}
}
@inproceedings{Lagae2009a,
author = {Lagae, Ares and Lefebvre, Sylvain and Drettakis, George and Dutr\'{e}, Philip},
booktitle = {ACM Transactions on Graphics},
file = {::},
keywords = {noise,procedural texture,rendering,shading},
month = jul,
number = {3},
pages = {1},
publisher = {ACM},
title = {{Procedural noise using sparse Gabor convolution}},
url = {http://portal.acm.org/citation.cfm?doid=1531326.1531360},
volume = {28},
year = {2009}
}
@article{Schollmeyer2009a,
author = {Schollmeyer, Andre and Fr\"{o}hlich, Bernd},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {3D Graphics,Real-Time Rendering,cation,figure 1,ne sampling of the,parametric surfaces,per-pixel accuracy for arbitrary,point classi -,programmable graphics hardware,ray casting,recent on-the- y tessellation,root nding,trim boundaries,trimmed nurbs,zoom levels},
mendeley-tags = {3D Graphics,Real-Time Rendering},
month = jul,
number = {3},
pages = {1},
title = {{Direct trimming of NURBS surfaces on the GPU}},
url = {http://portal.acm.org/citation.cfm?doid=1531326.1531353},
volume = {28},
year = {2009}
}
@book{Yang2005a,
address = {Hoboken, NJ, USA},
author = {Yang, Won Young and Cao, Wenwu and Chung, Tae-Sang and Morris, John},
doi = {10.1002/0471705195},
isbn = {9780471705192},
month = jan,
publisher = {John Wiley \& Sons, Inc.},
title = {{Applied Numerical Methods Using MATLAB®}},
url = {http://doi.wiley.com/10.1002/0471705195},
year = {2005}
}
@article{Leitmann1982,
author = {Leitmann, George},
doi = {10.1115/1.3139697},
journal = {Journal of Dynamic Systems, Measurement, and Control},
number = {2},
pages = {202},
title = {{The Calculus of Variations and Optimal Control}},
volume = {104},
year = {1982}
}
@article{Bigler2006a,
author = {Bigler, J. and Stephens, A. and Parker, S.G.},
file = {::},
journal = {Proceedings of the IEEE Symposium on Interactive Ray Tracing},
keywords = {interactive ray tracing,ray tracing,software architec-},
pages = {187--195},
publisher = {Citeseer},
title = {{Design for parallel interactive ray tracing systems}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Design+for+Parallel+Interactive+Ray+Tracing+Systems#0},
year = {2006}
}
@article{Thiruvathukal2008b,
author = {Thiruvathukal, Editors George K and L\"{a}ufer, Konstantin and Messmer, By Peter and Mullowney, Paul J and Granger, Brian E},
file = {::},
journal = {Compare A Journal Of Comparative Education},
keywords = {gpu,python},
mendeley-tags = {gpu,python},
title = {{GPULib: GPU Computing in High-Level Languages}},
year = {2008}
}
@article{Pfister2002a,
author = {Pfister, Hanspeter and Gross, Markus},
file = {::},
journal = {IEEE computer graphics and applications},
keywords = {Algorithms,Art,Computer Graphics,Computer-Aided Design,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Point-Based Rendering,Signal Processing, Computer-Assisted,Software,User-Computer Interface},
mendeley-tags = {Point-Based Rendering},
number = {4},
pages = {22--3},
title = {{Point-based computer graphics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15628082},
volume = {24},
year = {2002}
}
@article{Ritter2007a,
author = {Ritter, Justin and King, Chris and Gronsky, Stefan},
file = {::},
journal = {ACM SIGGRAPH 2007 sketches},
keywords = {Lighting,Pixar,SIGGRAPH07},
mendeley-tags = {Lighting,Pixar,SIGGRAPH07},
pages = {2007--2007},
title = {{Fast, Soft Reflections Using Radiance Caches}},
url = {http://portal.acm.org/citation.cfm?id=1278780.1278843 http://graphics.pixar.com/library/SoftReflections/},
year = {2007}
}
@article{Rekimoto1995a,
author = {Rekimoto, Jun and Nagao, Katashi},
file = {::},
journal = {Proc. 8th Ann. ACM Symp. User Interface and Software Technology (UIST), ACM Press},
pages = {29--36},
title = {{The World through the Computer: Computer Augmented Interaction with Real World Environments}},
year = {1995}
}
@phdthesis{Milvich2004b,
author = {Milvich, Michael Lazar},
number = {July},
title = {{JavaCave: A 3D Immersive Environment in Java}},
year = {2004}
}
@phdthesis{Systeme2004a,
author = {Systeme, Interaktive and Universit, Technischen and Schmalstieg, Dieter and Reitmayr, Gerhard},
file = {::},
title = {{XML Databases for Augmented Reality}},
year = {2004}
}
@article{Barakonyi2007,
author = {Barakonyi, Istvan and Prendinger, Helmut and Schmalstieg, Dieter and Ishizuka, Mitsuru},
doi = {10.1109/3DUI.2007.340777},
file = {::},
isbn = {1-4244-0907-1},
journal = {2007 IEEE Symposium on 3D User Interfaces},
keywords = {augmented reality,eye tracking,multimodal interaction,remote collaboration,tangible interface},
pages = {71--78},
publisher = {Ieee},
title = {{Cascading Hand and Eye Movement for Augmented Reality Videoconferencing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4142848},
year = {2007}
}
@article{Adcock2004,
author = {Adcock, Matt and Hutchins, Matthew and Gunn, Chris},
doi = {10.1145/1186415.1186463},
file = {::},
isbn = {1581138962},
journal = {ACM SIGGRAPH 2004 Posters on SIGGRAPH 04},
pages = {41},
publisher = {ACM Press},
title = {{Haptic collaboration with augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=1186415.1186463},
year = {2004}
}
@article{Badeche2006,
author = {Badeche, M. and Benmohamed, M.},
doi = {10.1109/ICTTA.2006.1684654},
file = {::},
isbn = {0-7803-9521-2},
journal = {2006 2nd International Conference on Information \& Communication Technologies},
keywords = {augmented reality,corner detection,corner tracking,in certain applications of,is very critical,kalman filter,process of tracking,real-,s factor,time,time tracking,what impose that the},
pages = {1773--1778},
publisher = {Ieee},
title = {{Real-Time Tracking for Augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1684654},
volume = {1},
year = {2006}
}
@article{Courtiat2004,
abstract = {This paper presents LabFuture, an advanced e-learning platform that uses novel Information and Communication Technologies to support and expand laboratory teaching practices. For this purpose, LabFuture uses real and computer generated objects that are interfaced using mechatronic systems, augmented reality, mobile technologies and 3D multi user environments. The main aim is to develop and demonstrate technological support for practical experiments in the following focused disciplines namely: Fluid Dynamics - Science subject in Germany, Geometry - Mathematics subject in Austria, History and Environmental Awareness Arts and Humanities subjects in Greece and Slovenia. In order to pedagogically enhance the design and functional aspects of this e-learning technology, we are investigating the dialogical operationalisation of learning theories so as to leverage our understanding of teaching and learning practices in the targeted context of deployment. To be able to evaluate the labfuture system in its entire complexity an evaluation methodology including several phases has been developed, performing formative as well as summative evaluations.},
author = {Courtiat, Jean-Pierre and Davarakis, Costas and Totter, Alexandra and Mwanza, Daisy and Faust, Martin and Kaufmann, Hannes},
file = {::},
journal = {Learning},
title = {{Evaluating LAB@FUTURE, a Collaborative E-Learning Laboratory Experiments Platform}},
url = {http://www.eden-online.org/eden.php?menuId=222&contentId=285},
year = {2004}
}
@article{Martens2004,
author = {Martens, Jean-Bernard and Qi, Wen and Aliakseyeu, Dima and Kok, Arjan J F and {Van Liere}, Robert},
doi = {10.1145/1031419.1031425},
file = {::},
isbn = {1581139926},
journal = {Proceedings of the 2nd European Union symposium on Ambient intelligence EUSAI 04},
keywords = {3d interaction,augmented reality,human computer interaction,natural,optical tracking,virtual reality},
number = {November},
pages = {25},
publisher = {ACM Press},
title = {{Experiencing 3D interactions in virtual reality and augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=1031419.1031425},
volume = {telligence},
year = {2004}
}
@inproceedings{Buchmann2004,
author = {Buchmann, Volkert and Violich, S. and Billinghurst, M. and Cockburn, A.},
booktitle = {Proceedings of the 2nd international conference on Computer graphics and interactive techniques in Australasia and South East Asia},
file = {::},
keywords = {augmented reality,gesture interaction,occlusion},
pages = {212--221},
publisher = {ACM},
title = {{FingARtips: gesture based direct manipulation in Augmented Reality}},
url = {http://portal.acm.org/citation.cfm?id=988871},
year = {2004}
}
@article{Klineca,
author = {Klinec, Darko and Leonhardi, Alexander},
file = {::},
journal = {ifp.uni-stuttgart.de},
pages = {1--12},
title = {{POSITIONING AND LOCATION SERVICES}},
url = {http://www.ifp.uni-stuttgart.de/publications/2001/Klinec_Indoornav2001.pdf}
}
@article{Papagiannakis2008,
abstract = {Recent advances in hardware and software for mobile computing have enabled a new breed of mobile AR systems and applications. A new breed of computing called augmented ubiquitous computing has resulted from the convergence of wearable computing, wireless networking and mobile AR interfaces. In this paper we provide a survey of different mobile and wireless technologies and how they have impact AR. Our goal is to place them into different categories so that it becomes easier to understand the state of art and to help identify new directions of research.},
author = {Papagiannakis, George and Singh, Gurminder and Magnenat-Thalmann, Nadia},
doi = {10.1002/cav.221},
file = {::},
institution = {MIRALab, University of Geneva},
issn = {15464261},
journal = {Computer Animation And Virtual Worlds},
keywords = {augmented mixed reality,mobile systems,wireless networking},
number = {1},
pages = {3--22},
publisher = {Wiley Online Library},
title = {{A survey of mobile and wireless technologies for augmented reality systems}},
url = {http://doi.wiley.com/10.1002/cav.221},
volume = {19},
year = {2008}
}
@article{Rosenblum2008a,
author = {Rosenblum, Editors Lawrence and Julier, Simon and Bruns, Erich},
file = {::},
journal = {IEEE Computer Graphics and Applications},
pages = {98--102},
publisher = {IEEE Computer Society},
title = {{Projects in VR}},
url = {http://doi.ieeecomputersociety.org/10.1109/MCG.2008.77},
year = {2008}
}
@article{Schmalstieg2007e,
author = {Schmalstieg, Dieter and Wagner, Daniel},
file = {::},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
keywords = {augmented reality games,cultural heritage,mobile augmented reality,wearable computing},
month = nov,
pages = {1--13},
publisher = {Ieee},
title = {{Experiences with Handheld Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538819},
year = {2007}
}
@article{Fischer2005,
author = {Fischer, J. and Bartz, D. and Strasser, W.},
doi = {10.1109/VR.2005.1492774},
file = {::},
isbn = {0-7803-8929-8},
journal = {IEEE Proceedings. VR 2005. Virtual Reality, 2005.},
keywords = {augmented reality,immersion,non-,painterly filtering,photorealistic rendering},
pages = {195--325},
publisher = {Ieee},
title = {{Stylized augmented reality for improved immersion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1492774},
volume = {2005},
year = {2005}
}
@article{Systems2003,
author = {Systems, Interactive Graphics},
file = {::},
journal = {Science},
publisher = {Citeseer},
title = {{Storytelling in Collaborative Augmented Reality Environments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.1924&amp;rep=rep1&amp;type=pdf},
year = {2003}
}
@article{Jiang2004a,
author = {Jiang, B. and Neumann, U. and You, S.},
file = {::},
journal = {IEEE Virtual Reality, 2004. Proceedings},
pages = {3--275},
title = {{A robust hybrid tracking system for outdoor augmented reality}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1310049},
year = {2004}
}
@article{Nilsson2009a,
abstract = {This paper presents results from a study on using an AR application to support collaborative command and control activities requiring the collaboration of three different civil service organisations. The technology is used to create a common ground between the organisations and allows the users to interact, plan resources and react to the ongoing events on a digital map. The AR application was developed and evaluated in a study where a forest fire scenario was simulated. Participants from the involved organisations acted as command and control teams in the simulated scenario and both quantitative and qualitative results were obtained. The results show that AR can become a useful tool in these situations in the future.},
author = {Nilsson, Susanna and Johansson, Bj\"{o}rn J E and J\"{o}nsson, Arne},
doi = {10.1145/1670252.1670291},
file = {::},
isbn = {9781605589121},
journal = {Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry VRCAI 09},
pages = {179},
publisher = {ACM Press},
series = {VRCAI '09},
title = {{A co-located collaborative augmented reality application}},
url = {http://portal.acm.org/citation.cfm?doid=1670252.1670291},
year = {2009}
}
@incollection{Liarokapis2002,
abstract = {This paper presents an innovative approach to enhance students learning and understanding of digital design using complex commercial design flows. The architecture of our experimental system is based on new technologies such as Augmented Reality (AR), XML metadata, and an XML integrated database system. The database provides the content for multimedia presentation in a virtual environment, visualised through AR, which enables students to engage effectively in the process of learning. These include textual descriptions, animated videos, auditory information, images and 3D computer generated objects of related diagrams and designs. An XML interface will allow the teacher to input multimedia information into the database remotely in a simple way. Using an AR interface the content of the database will be visualized in real time using state-of-the-art virtual reality technologies, i.e. head mounted displays, tracking devices, etc. Through this interface, users will be able to interact collaboratively. Using collaborative AR the students will also develop team skills that play a significant role in the learning process. Finally, we provide an illustrative description of how our experimental system will operate, and we present some initial results.},
author = {Liarokapis, F and Mourkoussis, N and Petridis, P and Rumsey, S and Lister, P F and White, M},
file = {::},
keywords = {l education (general),qa75 electronic computers. computer science,qa76 computer software},
publisher = {UICEE},
title = {{An Interactive Augmented Reality System for Engineering Education}},
url = {http://eprints.sussex.ac.uk/1176/},
year = {2002}
}
@article{Morrison2011,
author = {Morrison, Ann and Mulloni, Alessandro and Lemmel\"{a}, Saija and Oulasvirta, Antti and Jacucci, Giulio and Peltonen, Peter and Schmalstieg, Dieter and Regenbrecht, Holger},
doi = {10.1016/j.cag.2011.04.009},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {mobile augmented reality},
month = aug,
number = {4},
pages = {789--799},
title = {{Collaborative use of mobile augmented reality with paper maps}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849311001129},
volume = {35},
year = {2011}
}
@article{Nilsson2009,
author = {Nilsson, Susanna and Gustafsson, Torbj\"{o}rn and Carleberg, Per},
file = {::},
journal = {PsychNology Journal},
keywords = {augmented reality,gaze,gaze controlled augmented reality,mixed reality},
number = {2},
pages = {175 -- 196},
publisher = {Citeseer},
title = {{Hands Free Interaction with Virtual Information in a Real Environment : Eye Gaze as an Interaction Tool in an Augmented Reality System}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Hands+Free+Interaction+with+Virtual+Information+in+a+Real+Environment+:+Eye+Gaze+as+an+Interaction+Tool+in+an+Augmented+Reality+System#0},
volume = {7},
year = {2009}
}
@article{Kroeker2010,
author = {Kroeker, Kirk L.},
doi = {10.1145/1785414.1785422},
file = {::},
issn = {00010782},
journal = {Communications of the ACM},
month = jul,
number = {7},
pages = {19},
title = {{Mainstreaming augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=1785414.1785422},
volume = {53},
year = {2010}
}
@phdthesis{Flintham2009,
abstract = {Mobile mixed-reality experiences mix physical and digital spaces, enabling participants to simultaneously inhabit a shared environment online and on the streets. These experiences take the form of games, educational applications and new forms of performance and art, and engender new opportunities for interaction, collaboration and play. As mobile mixed-reality experiences move out of the laboratory and into more public settings they raise new challenges concerning how to support these experiences in the wild. This thesis argues that mobile mixed-reality experiences in which artists retain creative control over the content and operation of each experience, particularly those that are deployed as theatrical performances, require dedicated support for content authoring and reactive orchestration tools and paradigms in order to be successfully and robustly operated in public settings. These requirements are examined in detail, drawing on the experience of supporting four publicly toured mobile mixed-reality experiences; Can You See Me Now?, Uncle Roy All Around You, I Like Frank in Adelaide and Savannah, which have provided a platform to practically develop, refine and evaluate new solutions to answer these challenges in the face of presenting the experiences to many thousands of participants over a four year period. This thesis presents two significant supporting frameworks. The ColourMaps system enables designers to author location-based content by directly colouring over maps; providing a simple, familiar and yet highly flexible approach to matching location-triggers to complex physical spaces. It provides support for multiple and specialised content layers, and the ability to configure and manage other aspects of an experience, including filtering inaccurate position data and underpinning orchestration tools. Second, the Orchestration framework supports the day-to-day operation of public experiences; providing dedicated control-room tools for monitoring that reveal the content landscape and historical events, intervention and improvisation techniques for steering and shaping each participant's experience as it unfolds both physically and virtually, and processes to manage a constant flow of participants.},
author = {Flintham, Martin},
booktitle = {Computing Systems},
file = {::},
keywords = {qa 75 electronic computers. computer science},
number = {December},
pages = {234},
school = {University of Nottingham},
title = {{Supporting mobile mixed-reality experiences}},
url = {http://etheses.nottingham.ac.uk/632/},
year = {2009}
}
@article{Humphreys2002a,
author = {Humphreys, Greg and Houston, Mike and Ng, Ren and Frank, Randall and Ahern, Sean and Kirchner, Peter D. and Klosowski, James T.},
journal = {Work},
keywords = {cluster rendering,dering,parallel ren-,remote graphics,scalable rendering,stream,tiled displays,virtual graphics},
month = jul,
number = {3},
title = {{Chromium: a stream-processing framework for interactive rendering on clusters}},
url = {http://portal.acm.org/citation.cfm?doid=566654.566639},
volume = {21},
year = {2002}
}
@article{Shin2009,
author = {Shin, Do Hyoung and Jang, Won-Suk},
doi = {10.1016/j.autcon.2009.06.001},
file = {::},
issn = {09265805},
journal = {Automation in Construction},
month = dec,
number = {8},
pages = {1063--1069},
publisher = {Elsevier B.V.},
title = {{Utilization of ubiquitous computing for construction AR technology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580509000922},
volume = {18},
year = {2009}
}
@article{Reitmayr2005,
author = {Reitmayr, G. and Eade, E. and Drummond, T.},
doi = {10.1109/ISMAR.2005.39},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)/2005/Reitmayr, Eade, Drummond/Reitmayr, Eade, Drummond - 2005 - Localisation and interaction for augmented maps.pdf:pdf},
isbn = {0-7695-2459-1},
journal = {Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)},
keywords = {a control,a user interacting with,augmented,device to pick up,figure 1,maps using a pda,optical tracking,plays,projection dis-,spatially augmented reality,tangible user interfaces},
pages = {120--129},
publisher = {Ieee},
title = {{Localisation and interaction for augmented maps}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544673},
year = {2005}
}
@article{Klein2007,
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2007.4538852},
file = {::},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = nov,
pages = {1--10},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping for Small AR Workspaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538852},
year = {2007}
}
@inproceedings{Starner2000,
abstract = {Computer gaming offers a unique test-bed and market for advanced concepts in computer science, such as Human Computer Interaction (HCI), computer-supported collaborative work (CSCW), intelligent agents, graphics, and sensing technology. In addition, computer gaming is especially wellsuited for explorations in the relatively young fields of wearable computing and augmented reality (AR). This paper presents a developing multi-player augmented reality game, patterned as a cross between a martial arts fighting game and an agent controller, as implemented using the Wearable Augmented Reality for Personal, Intelligent, and Networked Gaming (WARPING) system. Through interactions based on gesture, voice, and head movement input and audio and graphical output, the WARPING system demonstrates how computer vision techniques can be exploited for advanced, intelligent interfaces. Keywords Augmented reality, wearable computing, computer vision 1. INTRODUCTION: WHY GAMES? Computer gaming provides...},
author = {Starner, Thad and Leibe, Bastian and Singletary, Brad and Pair, Jarrell},
booktitle = {Interface},
doi = {10.1145/325737.325864},
file = {::},
isbn = {1581131348},
keywords = {augmented reality,computer vision,wearable computing},
pages = {256--259},
publisher = {ACM},
title = {{MIND-WARPING : Towards Creating a Compelling Collaborative Augmented Reality Game}},
url = {http://portal.acm.org/citation.cfm?id=325737.325864},
year = {2000}
}
@article{Wang2009a,
author = {Wang, Xiangyu and Chen, Rui (Irene)},
doi = {10.1080/15710880903320020},
file = {::},
issn = {1571-0882},
journal = {CoDesign},
keywords = {augmented reality,collaborative design,urban design,virtual reality},
month = dec,
number = {4},
pages = {229--244},
title = {{An experimental study on collaborative effectiveness of augmented reality potentials in urban design}},
url = {http://www.tandfonline.com/doi/abs/10.1080/15710880903320020},
volume = {5},
year = {2009}
}
@incollection{Khoo2010,
abstract = {This chapter presents steps for designing an intergenerational mixed reality entertainment system, which focuses on physical and social interactions using a mixed reality floor system. The main design goals include the following: facilitating interactions between users with varied levels of skill in utilizing technology, utilizing the familiar physical motions from other activities to make an intuitive physical interface, and encouraging social interactions among families and friends. Detailed implementation of these steps is presented in the design of our intergenerational entertainment system, Age Invaders. Our design process is based on user-centered design. The results of the study help to focus the refinements of the existing platform from a usability standpoint and also aid in the development of new physical entertainment and interactive applications. This study provides insights into user issues including how users interact in a complex mixed reality experience.},
author = {Khoo, Eng Tat and Merritt, Tim and Cheok, Adrian David},
booktitle = {The Engineering of Mixed Reality Systems},
chapter = {7},
doi = {10.1007/978-1-84882-733-2},
editor = {Dubois, Emmanuel and Gray, Philip and Nigay, Laurence},
file = {::},
isbn = {9781848827349},
pages = {121--141},
publisher = {Springer London},
series = {Human-Computer Interaction Series},
title = {{Designing a Mixed Reality Intergenerational Entertainment System}},
url = {http://www.springerlink.com/content/r60h1v521r572j71},
year = {2010}
}
@phdthesis{Glenncross2002a,
author = {Glenncross, Masshuda},
file = {::},
school = {University of Manchester},
title = {{A Framework for Physically Based Modelling in Virtual Reality}},
year = {2002}
}
@article{Vasilakos2008,
abstract = {Our system of Mixed Reality and 3D Live with Ambient Intelligence (AmI) is indented to bring performance art to the people while offering to the performance artists a creative tool to extend the grammar of the traditional theatre. Actors and dancers at different places are captured by multiple cameras and their images are rendered in 3D form in such a way that they can play and dance together on the same place in real-time. Our Quanticum Man is an allegory of the time of the General Relativity and the matter of the Quantum Mechanics. The new type of interactive theatre enables social networking by supporting simultaneous participants in human-to-human social manner.},
author = {Vasilakos, A and Wei, L and Nguyen, T and Thienqui, T and Chen, L and Boj, C and Diaz, D and Cheok, A and Marentakis, G},
doi = {10.1016/j.ins.2007.08.029},
file = {::},
issn = {00200255},
journal = {Information Sciences},
keywords = {3d live,ambient intelligence,interactive theatre,mixed reality,performance art},
number = {3},
pages = {679--693},
publisher = {Elsevier Science Inc.},
title = {{Interactive theatre via mixed reality and Ambient Intelligence}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025507004033},
volume = {178},
year = {2008}
}
@article{Gjosaeter2009,
author = {Gjosaeter, Tor},
doi = {10.1109/SocInfo.2009.21},
file = {::},
isbn = {978-0-7695-3706-1},
journal = {2009 International Workshop on Social Informatics},
keywords = {-component,augmented reality,cscd,cscw},
month = jun,
pages = {35--40},
publisher = {Ieee},
title = {{Computer Supported Collaborative Design Using Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5230716},
year = {2009}
}
@inproceedings{Kurz2011a,
author = {Kurz, Daniel and Benhimane, Selim},
booktitle = {IEEE and ACM International Symposium on Mixed and Augmented Reality},
keywords = {Handheld Augmented Reality Inertial Sensors Gravit},
pages = {111--120},
title = {{Gravity-Aware Handheld Augmented Reality}},
url = {http://da.nielkurz.de/content/Gravity-Aware_Handheld_Augmented_Reality},
year = {2011}
}
@article{Ag,
author = {Ag, Daimlerchrysler},
file = {::},
journal = {Virtual Reality},
number = {3},
pages = {338--355},
title = {{Using Augmented Virtuality for}},
volume = {13}
}
@article{Steinicke2008a,
author = {Steinicke, Frank and Bruder, Gerd and Ropinski, Timo and Hinrichs, Klaus},
file = {::},
journal = {Proceedings of IEEE VRIC 2008 : 10th International Conference on Virtual Reality},
title = {{Moving Towards Generally Applicable Redirected Walking}},
url = {http://viscg.uni-muenster.de/publications/2008/SBRH08/},
year = {2008}
}
@article{Juan2011,
author = {Juan, M. Carmen and Joele, Dennis},
doi = {10.1016/j.ijhcs.2011.03.002},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {augmented reality,invisible markers,phobia towards small animals},
month = jun,
number = {6},
pages = {440--453},
publisher = {Elsevier},
title = {{A comparative study of the sense of presence and anxiety in an invisible marker versus a marker augmented reality system for the treatment of phobia towards small animals}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S107158191100036X},
volume = {69},
year = {2011}
}
@article{Pilet2010,
author = {Pilet, Julien and Saito, Hideo},
doi = {10.1109/VR.2010.5444811},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 IEEE Virtual Reality Conference (VR)/2010/Pilet, Saito/Pilet, Saito - 2010 - Virtually augmenting hundreds of real pictures An approach based on learning, retrieval, and tracking.pdf:pdf},
isbn = {978-1-4244-6237-7},
journal = {2010 IEEE Virtual Reality Conference (VR)},
month = mar,
pages = {71--78},
publisher = {Ieee},
title = {{Virtually augmenting hundreds of real pictures: An approach based on learning, retrieval, and tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5444811},
year = {2010}
}
@article{Hile2008a,
author = {Hile, Harlan and Borriello, Gaetano},
file = {::},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {32--39},
title = {{Positioning and Orientation in Indoor Environments Using Camera Phones}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557953},
volume = {28},
year = {2008}
}
@article{Castle2011,
abstract = {We show how a system for video-rate parallel camera tracking and 3D map-building can be readily extended to allow one or more cameras to work in several maps, separately or simultaneously. The ability to handle several thousand features per map at video-rate, and for the cameras to switch automatically between maps, allows spatially localized AR workcells to be constructed and used with very little intervention from the user of a wearable vision system. The user can explore an environment in a natural way, acquiring local maps in real-time. When revisiting those areas the camera will select the correct local map from store and continue tracking and structural acquisition, while the user views relevant AR constructs registered to that map. The method is shown working in a progressively larger environments, from desktop to large building.},
author = {Castle, Robert O and Klein, Georg and Murray, David W},
doi = {10.1016/j.cviu.2011.02.007},
file = {::},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {augmented reality},
number = {6},
pages = {854--867},
publisher = {Elsevier Inc.},
title = {{Wide-area Augmented Reality using Camera Tracking and Mapping in Multiple Regions}},
url = {http://www.sciencedirect.com/science/article/B6WCX-528YXFJ-1/2/34212f30c9fe494b6317046adfc20777},
volume = {In Press,},
year = {2011}
}
@inproceedings{Reitmayr2004,
abstract = {Augmented reality (AR) can provide an excellent user interface for visualization in a mobile computing application. The user's view is augmented with location based information at the correct spatial location, thus providing an intuitive way of presenting such information. In this work we demonstrate the use of AR for collaborative navigation and information browsing tasks in an urban environment. A navigation function allows one or more users to roam through a city and guides them to selected destinations. Information browsing presents users with information about objects in their surrounding. Both functions feature support for collaboration. The developed system does not only concentrate on the user interface aspects but also provides a scalable infrastructure to support mobile applications. To this end we developed a 3-tier architecture to manage a common data model for a set of applications. It is inspired by current Internet application frameworks and consists of a central storage layer using a common data model, a transformation layer responsible for filtering and adapting the data to the requirements of a particular applications on request, and finally of the applications itself.},
author = {Reitmayr, Gerhard and Schmalstieg, Dieter},
booktitle = {Science},
file = {::},
pages = {31--41},
publisher = {Citeseer},
title = {{Collaborative augmented reality for outdoor navigation and information browsing}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.1864&amp;rep=rep1&amp;type=pdf},
volume = {66},
year = {2004}
}
@article{Juillet2003a,
author = {Juillet, Roberto Ortelli and Mireille, Jury and Nova, Nicolas and Schneider, Daniel K},
file = {::},
journal = {Recherche},
title = {{Styles d’interaction dans les PocketPC: analyses et comparaisons}},
year = {2003}
}
@article{Azuma1997,
abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
author = {Azuma, Ronald T},
doi = {10.1.1.30.4999},
file = {::},
issn = {10547460},
journal = {Media},
number = {4},
pages = {355--385},
publisher = {Citeseer},
title = {{A Survey of Augmented Reality}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.5387&amp;rep=rep1&amp;type=pdf},
volume = {6},
year = {1997}
}
@article{Godet-Bar2010,
abstract = {Context: Every interactive system is composed of a functional core and a user interface. However, the software engineering (SE) and human-computer interaction (HCI) communities do not share the same methods, models or tools. This usually induces a large work overhead when specialists from the two domains try to connect their applicative studies, especially when developing augmented reality systems that feature complex interaction cores. Objective: We present in this paper the essential activities and concepts of a development method integrating the SE and HCI development practices, from the specifications down to the design, as well as their application on a case study. Method: The efficiency of the method was tested in a qualitative study involving four pairs of SE and HCI experts in the design of an application for which an augmented reality interaction would provide better user performance than a classic interactive system. The effectivity of the method was evaluated in a qualitative study comparing the quality of three implementations of the same application fragment (based on the same analysis model), using software engineering metrics. Results: The first evaluation confirmed the ease of use of our method and the relevance of our tools for guiding the design process, but raised concerns on the handling of conflicting collaborative activities. The second evaluation gave indications that the structure of the analysis model facilitates the implementation of quality software (in terms of coupling, stability and complexity). Conclusion: It is concluded that our method enables design teams with different backgrounds in application development to collaborate for integrating augmented reality applications with information systems. Areas of improvement are also described. 2009 Elsevier B.V. All rights reserved.},
author = {Godet-Bar, G and Rieu, D and Dupuy-Chessa, S},
doi = {10.1016/j.infsof.2009.11.007},
file = {::},
issn = {09505849},
journal = {Information and Software Technology},
number = {5},
pages = {492--505},
publisher = {Elsevier B.V.},
title = {{HCI and business practices in a collaborative method for augmented reality systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584909002079},
volume = {52},
year = {2010}
}
@article{Conole2004a,
abstract = {This paper considers the increasing impact of Information and Communication Technologies (ICT) and the associated rise in e-learning as a recognised and respected research area. The paper provides a summary of some of the current research areas under investigation and provides a list of characteristics of the area. The paper goes on to consider the professional identities of researchers in the area and the tensions which have resulted in terms of aligning with this new emergent group of professionals within existing institutional structures.},
author = {Conole, Grainne},
file = {::},
journal = {Journal of Interactive Media in Education},
pages = {1--18},
title = {{E-Learning: The Hype and the Reality}},
url = {http://www-jime.open.ac.uk/2004/12/},
volume = {2004},
year = {2004}
}
@article{Rohs2007,
abstract = {A user study was conducted to compare the performance of three methods for map navigation with mobile devices. These methods are joystick navigation, the dynamic peep- hole method without visual context, and the magic lens paradigm using external visual context. The joystick method is the familiar scrolling and panning of a virtual map keep- ing the device itself static. In the dynamic peephole method the device is moved and the map is fixed with respect to an external frame of reference, but no visual information is present outside the devices display. The magic lens method augments an external content with graphical overlays, hence providing visual context outside the device display. Here too motion of the device serves to steer navigation. We compare these methods in a study measuring user performance, mo- tion patterns, and subjective preference via questionnaires. The study demonstrates the advantage of dynamic peephole and magic lens interaction over joystick interaction in terms of search time and degree of exploration of the search space.},
author = {Rohs, Michael and Sch\"{o}ning, Johannes and Raubal, Martin and Essl, Georg and Kr\"{u}ger, A},
doi = {10.1145/1322192.1322219},
file = {::},
isbn = {9781595938176},
journal = {Computing},
keywords = {augmented reality,camera based interaction,camera phones,handheld displays,interac,maps,mobile devices,navigation,spatially aware displays,tion techniques},
pages = {146--153},
publisher = {ACM Press},
title = {{Map navigation with mobile devices: virtual versus physical movement with and without visual context}},
url = {http://portal.acm.org/citation.cfm?id=1322219},
year = {2007}
}
@article{Do-Lenh2010,
abstract = {Tangible User Interfaces (TUIs) offer the potential to facilitate collaborative learning in new ways. This paper presents an empirical study that investigated the effects of a TUI in a classroom setting on task performance and learning outcomes. In the tangible condition, apprentices worked together around an interactive tabletop warehouse simulation using tangible inputs. In the paper condition, they performed the same activity with only paper and pens. Results showed that the tangible condition resulted in better task performance (more alternative solutions explored and better final solution) but did not affect learning outcomes, i.e. understanding of important concepts and applying them to a problem-solving question. We discuss reasons for this in terms of task structure and type, nature of tangible user interfaces and effective interaction requirements.},
author = {Do-Lenh, Son and Jermann, Patrick},
doi = {10.1007/978-3-642-16020-2},
editor = {Wolpers, Martin and Kirschner, Paul A and Scheffel, Maren and Lindstaedt, Stefanie and Dimitrova, Vania},
file = {::},
isbn = {9783642160196},
journal = {Learning},
keywords = {augmented reality,collaborative learning,human computer,tabletop,tangible user interface,technology enhanced learning},
pages = {78--92},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Task Performance vs . Learning Outcomes : A Study of a Tangible User Interface in the Classroom}},
url = {http://www.springerlink.com/content/dt71j12632438276/},
volume = {6383},
year = {2010}
}
@article{Regenbrecht2002a,
author = {Regenbrecht, H and Wagner, M and Baratoff, G},
doi = {10.1007/s100550200016},
file = {::},
issn = {13594338},
journal = {Virtual Reality},
number = {3},
pages = {151--166},
publisher = {Springer},
title = {{Magicmeeting: A collaborative tangible augmented reality system}},
url = {http://www.springerlink.com/openurl.asp?genre=article&id=doi:10.1007/s100550200016},
volume = {6},
year = {2002}
}
@inproceedings{Kurz2012,
author = {Kurz, Daniel and Olszamowski, Thomas and Benhimane, Selim},
booktitle = { IEEE and ACM International Symposium on Mixed and Augmented Reality},
title = {{Representative Feature Descriptor Sets for Robust Handheld Camera Localization}},
url = {http://da.nielkurz.de/content/Representative_Feature_Descriptor_Sets_for_Robust_Handheld_Camera_Localization},
year = {2012}
}
@article{Ahn,
author = {Ahn, M.H.},
doi = {10.1109/ICPR.1998.712048},
file = {::},
isbn = {0-8186-8512-3},
journal = {Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)},
pages = {1694--1696},
publisher = {IEEE Comput. Soc},
title = {{Video augmentation by image-based rendering under the perspective camera model}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=712048},
volume = {2}
}
@article{Kaufmann2003,
author = {Kaufmann, Hannes and Schmalstieg, Dieter},
doi = {10.1016/S0097-8493(03)00028-1},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {augmented reality,geometry education,mathematics education,spatial intelligence},
month = jun,
number = {3},
pages = {339--345},
title = {{Mathematics and geometry education with collaborative augmented reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849303000281},
volume = {27},
year = {2003}
}
@article{Lee2009,
abstract = {We describe a novel markerless camera tracking approach and user interaction methodology for augmented reality (AR) on unprepared tabletop environments. We propose a real-time system architecture that combines two types of feature tracking. Distinctive image features of the scene are detected and tracked frame-to-frame by computing optical flow. In order to achieve real-time performance, multiple operations are processed in a synchronized multi-threaded manner: capturing a video frame, tracking features using optical flow, detecting distinctive invariant features, and rendering an output frame. We also introduce user interaction methodology for establishing a global coordinate system and for placing virtual objects in the AR environment by tracking a user's outstretched hand and estimating a camera pose relative to it. We evaluate the speed and accuracy of our hybrid feature tracking approach, and demonstrate a proof-of-concept application for enabling AR in unprepared tabletop environments, using bare hands for interaction.},
author = {Lee, Taehee and H\"{o}llerer, Tobias},
doi = {10.1109/TVCG.2008.190},
file = {::},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Artificial Intelligence,Computer Graphics,Computer Simulation,Hand,Hand: anatomy \& histology,Hand: physiology,Humans,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Models, Biological,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,User-Computer Interface},
number = {3},
pages = {355--68},
pmid = {19282544},
title = {{Multithreaded hybrid feature tracking for markerless augmented reality.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19282544},
volume = {15},
year = {2009}
}
@article{Regenbrecht2002,
address = {New York, New York, USA},
author = {Regenbrecht, HT},
doi = {10.1145/506444.506451},
file = {::},
isbn = {1581134541},
journal = {CHI\&\#39;02 extended abstracts on},
keywords = {augmented reality,collaboration,cscw,tangible user},
number = {figure 3},
pages = {504},
publisher = {ACM Press},
title = {{Interaction in a collaborative augmented reality environment}},
url = {http://portal.acm.org/citation.cfm?doid=506443.506451 http://portal.acm.org/citation.cfm?id=506451},
year = {2002}
}
@article{Liarokapis2002a,
abstract = {An interactive Multimedia Augmented Reality Interface for E-Learning (MARIE) is presented in the article. Its application for engineering education is discussed in order to enhance traditional teaching and learning methods; however, it is equally applicable to other areas. The authors have developed and implemented a user-friendly interface to experimentally explore the potential of augmented reality by superimposing Virtual Multimedia Content (VMC) information in an Augmented Reality (AR) tabletop environment, such as a student desk workspace. The user can interact with the VMC, which is composed of threedimensional objects, images, animations, text (ASCII or three-dimensional) and sound. To prove the feasibility of the system only a small part of the teaching material was digitised and some experimental results are presented in the article.},
author = {Liarokapis, F and Petridis, P and Lister, P F and White, M},
file = {::},
journal = {World Transactions on Engineering and Technology Education},
keywords = {l education (general),qa75 electronic computers. computer science,qa76 computer software},
number = {2},
pages = {173--176},
publisher = {Citeseer},
title = {{Multimedia Augmented Reality Interface for E-Learning (MARIE)}},
url = {http://eprints.sussex.ac.uk/1088/},
volume = {1},
year = {2002}
}
@article{Rashid2006,
abstract = {RFID is often cited as the next big evolution in computing as it effectively enables everyday objects to be connected to the Internet. RFID readers are now available on mobile phones and in this paper we present an example of their use in a location based mobile game. Location based games are a new entertainment genre that allow users to play games in mixed reality in that they incorporate knowledge of their physical location and then provide them with the ability to interact with both real and virtual objects within that location. The game presented in this paper is the first of its kind and shows the potential for using RFID with mobile phones.},
author = {Rashid, Omer and Coulton, Paul and Edwards, Reuben and Bamford, Will},
file = {::},
journal = {Consumer Electronics 2006 ICCE 06 2006 Digest of Technical Papers International Conference on},
keywords = {qa76 computer software},
pages = {459--460},
title = {{Utilising RFID for mixed reality mobile games.}},
url = {http://ieeexplore.ieee.org/search/wrapper.jsp?arnumber=1598509},
year = {2006}
}
@article{Krohn2005a,
author = {Krohn, a. and Beigl, M. and Hazas, M. and Gellersen, H.-W.},
file = {::},
journal = {25th IEEE International Conference on Distributed Computing Systems Workshops},
pages = {463--468},
publisher = {Ieee},
title = {{Using Fine-Grained Infrared Positioning to Support the Surface-Based Activities of Mobile Users}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1437212},
year = {2005}
}
@inproceedings{Wang2009,
author = {Wang, R.Y. and Popovi\'{c}, Jovan},
booktitle = {ACM SIGGRAPH 2009 papers},
doi = {10.1145/1531326.1531369},
file = {::},
issn = {07300301},
keywords = {augmented reality,hand tracking,motion capture,user},
month = jul,
number = {3},
pages = {1--8},
publisher = {ACM},
title = {{Real-time hand-tracking with a color glove}},
url = {http://portal.acm.org/citation.cfm?doid=1531326.1531369 http://portal.acm.org/citation.cfm?id=1531369},
volume = {28},
year = {2009}
}
@article{Bencina2005c,
author = {Bencina, R. and Kaltenbrunner, M. and Jorda, S.},
file = {::},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},
pages = {99--99},
publisher = {Ieee},
title = {{Improved Topological Fiducial Tracking in the reacTIVision System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1565409},
year = {2005}
}
@article{Park2006,
author = {Park, Sang-cheol and Lee, Sang-woong and Lee, Seong-whan},
doi = {10.1109/ICPR.2006.1093},
file = {::},
isbn = {0-7695-2521-0},
journal = {18th International Conference on Pattern Recognition (ICPR'06)},
pages = {897--900},
publisher = {Ieee},
title = {{Superimposing 3D Virtual Objects using Markerless Tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1699670},
year = {2006}
}
@article{Zhou2008a,
author = {Zhou, F. and Duh, H.B.L. and Billinghurst, Mark},
doi = {10.1109/ISMAR.2008.4637362},
file = {::},
isbn = {978-1-4244-2840-3},
journal = {2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
month = sep,
pages = {193--202},
publisher = {IEEE},
title = {{Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4637362 http://www.computer.org/portal/web/csdl/doi/10.1109/ISMAR.2008.4637362},
year = {2008}
}
@article{Carmigniani2010,
author = {Carmigniani, Julie and Furht, Borko and Anisetti, Marco and Ceravolo, Paolo and Damiani, Ernesto and Ivkovic, Misa},
doi = {10.1007/s11042-010-0660-6},
file = {::},
issn = {1380-7501},
journal = {Multimedia Tools and Applications},
keywords = {ar,augmented,augmented reality,augmented reality applications,augmented reality iphone4,augmented reality technologies,b,carmigniani,furht,j,reality on mobile devices,systems},
month = dec,
number = {1},
pages = {341--377},
title = {{Augmented reality technologies, systems and applications}},
url = {http://www.springerlink.com/index/10.1007/s11042-010-0660-6},
volume = {51},
year = {2010}
}
@article{Guan2010,
abstract = {This paper focuses on online scene learning and fast camera relocalisation which are two key problems currently limiting the performance of wide area augmented reality systems. Firstly, we propose to use adaptive random trees to deal with the online scene learning problem. The algorithm can provide more accurate recognition rates than traditional methods, especially with large scale workspaces. Secondly, we use the enhanced PROSAC algorithm to obtain a fast camera relocalisation method. Compared with traditional algorithms, our method can significantly reduce the computation complexity, which facilitates to a large degree the process of online camera relocalisation. Finally, we implement our algorithms in a multithreaded manner by using a parallel-computing scheme. Camera tracking, scene mapping, scene learning and relocalisation are separated into four threads by using multi-CPU hardware architecture. While providing real-time tracking performance, the resulting system also possesses the ability to track multiple maps simultaneously. Some experiments have been conducted to demonstrate the validity of our methods.},
author = {Guan, Tao and Duan, Liya and Chen, Yongjian and Yu, Junqing},
doi = {10.3390/s100606017},
file = {::},
issn = {1424-8220},
journal = {Sensors},
month = jun,
number = {6},
pages = {6017--6043},
title = {{Fast Scene Recognition and Camera Relocalisation for Wide Area Augmented Reality Systems}},
url = {http://www.mdpi.com/1424-8220/10/6/6017/},
volume = {10},
year = {2010}
}
@incollection{Costanza2009,
abstract = {This chapter presents an overview of the Mixed Reality (MR) paradigm, which proposes to overlay our real-world environment with digital, computer-generated objects. It presents example applications and outlines limitations and solutions for their technical implementation. In MR systems, users perceive both the physical environment around them and digital elements presented through, for example, the use of semitransparent displays. By its very nature, MR is a highly interdisciplinary field engaging signal processing, computer vision, computer graphics, user interfaces, human factors, wearable computing, mobile computing, information visualization, and the design of displays and sensors. This chapter presents potential MR applications, technical challenges in realizing MR systems, as well as issues related to usability and collaboration in MR. It separately presents a section offering a selection of MR projects which have either been partly or fully undertaken at Swiss universities and rounds off with a section on current challenges and trends.},
author = {Costanza, Enrico and Kunz, Andreas and Fjeld, Morten},
booktitle = {Human Machine Interaction},
file = {::},
pages = {47--68},
publisher = {Springer-Verlag},
title = {{Mixed Reality: A Survey}},
url = {http://eprints.ecs.soton.ac.uk/20953/},
volume = {LNCS 5440},
year = {2009}
}
@article{Lee2005,
author = {Lee, W and Woo, Woontack and Lee, Jongweon},
file = {::},
journal = {Personal Computing},
keywords = {augmented reality,table top game,tangible user interface},
pages = {0--4},
title = {{TARBoard: Tangible Augmented Reality System for Table-top Game Environment}},
url = {http://www.ipsi.fraunhofer.de/ambiente/pergames2005/papers_2005/PerGames2005_TARBoard_WLee.pdf},
volume = {5},
year = {2005}
}
@incollection{Christian2007,
abstract = {There is evidence that recent developments in Augmented Reality (AR) technology has the potential to be applied as pervasive media on multiple devices in different ways and contexts, especially with low-cost devices including Mobile Augmented Reality (MAR) applications on smart phones or Pocket-PCs. In this paper we present a framework in order to combine the pervasive e-education concept with augmented reality content for e-training. We analyze current research, discuss some examples from ultralight light sport aircraft maintenance and show how to apply this framework generically. We present a learning engine to deliver this special type of content and provide a further outlook of future research. A user-centered approach must ensure that the developments can stimulate motivation and enhance performance of the end users in different training sessions. The main benefit is, that the end users are enabled to better perceive complex, technical facts, systems and components.},
author = {Christian, Johannes and Krieger, Horst and Holzinger, Andreas and Behringer, Reinhold},
booktitle = {Universal Access to Applications and Services Lecture Notes in Computer Science LNCS 4556},
editor = {Stephanidis, C},
file = {::},
isbn = {9783540732822},
keywords = {augmented reality,learning performance,performance},
pages = {520--529},
publisher = {Springer},
title = {{Virtual and mixed reality interface for e-training: examples of applications in ultralight / light sport aircraft maintenance}},
year = {2007}
}
@article{Broll2008a,
author = {Broll, Wolfgang and Lindt, Irma and Herbst, Iris and Ohlenburg, Jan and Braun, Anne-kathrin and Wetzel, Richard},
file = {::},
journal = {Advances},
title = {{Toward Next-Gen Mobile AR Games}},
year = {2008}
}
@article{Hachet2008a,
author = {Hachet, M and Kitamura, Y},
file = {::},
journal = {Science},
pages = {1--4},
title = {{3D interaction with and from handheld computers}},
url = {http://www.recolecta.net/buscador/single_page.jsp?id=oai:hal.archives-ouvertes.fr:hal-00308241_v1},
year = {2008}
}
@article{Shih2003,
author = {Shih, T.K. and Lin, N.H.},
doi = {10.1109/ICDCSW.2003.1203626},
file = {::},
isbn = {0-7695-1921-0},
journal = {23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.},
keywords = {analog technology,communication will replace traditional,distance learning,mpeg,multimedia communication system,synchronization,video conferencing},
pages = {646--651},
publisher = {Ieee},
title = {{Augmented video conferencing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1203626},
year = {2003}
}
@inproceedings{Jin2007,
author = {Jin, Yoon-suk and Kim, Yang-wook and Park, Jun},
booktitle = {Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2007.4538863},
file = {::},
isbn = {978-1-4244-1749-0},
keywords = {augmented reality,design evaluation,mock-up},
month = nov,
pages = {1--2},
publisher = {IEEE Computer Society},
title = {{ARMO: Augmented Reality based Reconfigurable MOck-up}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538863 http://portal.acm.org/citation.cfm?id=1514374},
year = {2007}
}
@article{Schall2008,
abstract = {In this paper we present a natural feature tracking algorithm based on on-line boosting used for localizing a mobile computer. Mobile augmented reality requires highly accurate and fast six degrees of freedom tracking in order to provide registered graphical overlays to a mobile user. With advances in mobile computer hardware, vision-based tracking approaches have the potential to provide efficient solutions that are non-invasive in contrast to the currently dominating marker-based approaches. We propose to use a tracking approach which can use in an unknown environment, i.e. the target has not be known beforehand. The core of the tracker is an on-line learning algorithm, which updates the tracker as new data becomes available. This is suitable in many mobile augmented reality applications. We demonstrate the applicability of our approach on tasks where the target objects are not known beforehand, i.e. interactive planing.},
author = {Schall, Gerhard and Grabner, Helmut and Grabner, Michael and Wohlhart, Paul and Schmalstieg, Dieter and Bischof, Horst},
doi = {10.1109/CVPRW.2008.4563134},
file = {::},
isbn = {9781424423392},
journal = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
number = {c},
pages = {1--8},
publisher = {Ieee},
title = {{3D tracking in unknown environments using on-line keypoint learning for mobile augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4563134},
year = {2008}
}
@article{Bruder2009a,
author = {Bruder, G. and Steinicke, F. and Hinrichs, K.H.},
file = {::},
journal = {2009 IEEE Symposium on 3D User Interfaces},
keywords = {3d user interfaces,architectural walkthroughs,locomotion,passive haptic feed-,redirected walking,virtual environments},
month = mar,
pages = {75--82},
publisher = {Ieee},
title = {{Arch-Explore: A natural user interface for immersive architectural walkthroughs}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4811208},
year = {2009}
}
@inproceedings{Wagner2007,
abstract = {In this paper we present ARToolKitPlus, a successor to the popular ARToolKit pose tracking library. ARToolKitPlus has been optimized and extended for the usage on mobile devices such as smartphones, PDAs and Ultra Mobile PCs (UMPCs). We explain the need and specific requirements of pose tracking on mobile devices and how we met those requirements. To prove the applicability we performed an extensive benchmark series on a braod range of off-the-shelf handhelds.},
author = {Wagner, Daniel and Schmalstieg, Dieter},
booktitle = {Proceedings of 12th Computer Vision Winter Workshop CVWW07},
doi = {10.1.1.157.1879},
file = {::},
pages = {139--146},
publisher = {Citeseer},
title = {{ARToolKitPlus for Pose Tracking on Mobile Devices ARToolKit}},
url = {http://www.icg.tu-graz.ac.at/Members/daniel/ARToolKitPlusMobilePoseTracking},
year = {2007}
}
@article{Chen2009a,
author = {Chen, David M. and Tsai, Sam S. and Vedantham, Ramakrishna and Grzeszczuk, Radek and Girod, Bernd},
doi = {10.1109/ISMAR.2009.5336472},
file = {::},
isbn = {978-1-4244-5390-0},
journal = {2009 8th IEEE International Symposium on Mixed and Augmented Reality},
month = oct,
pages = {181--182},
publisher = {Ieee},
title = {{Streaming mobile augmented reality on mobile phones}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5336472},
year = {2009}
}
@article{Billinghurst2002,
author = {Billinghurst, Mark and Kato, Hirokazu},
doi = {10.1145/514236.514265},
issn = {00010782},
journal = {Communications of the ACM},
month = jul,
number = {7},
pages = {64--70},
publisher = {ACM},
title = {{Collaborative augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=514236.514265 http://portal.acm.org/citation.cfm?id=514265},
volume = {45},
year = {2002}
}
@article{Newman2006a,
author = {Newman, J. and Schall, G. and Barakonyi, I. and Schurzinger, A. and Schmalstieg, D.},
file = {::},
journal = {Advances in Pervasive Computing},
pages = {3--6},
title = {{Wide-Area Tracking Tools for Augmented Reality}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Wide-Area+Tracking+Tools+for+Augmented+Reality#0},
volume = {207},
year = {2006}
}
@article{Chen2008,
author = {Chen, R and Wang, X},
doi = {10.1016/S1007-0214(08)70120-2},
file = {::},
issn = {10070214},
journal = {Tsinghua Science \& Technology},
keywords = {augmented reality,design learning,physicality,tangible augmented reality,tangible interface},
month = oct,
number = {October},
pages = {13--18},
publisher = {Tsinghua University Press},
title = {{An Empirical Study on Tangible Augmented Reality Learning Space for Design Skill Transfer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1007021408701202},
volume = {13},
year = {2008}
}
@article{Chen2009,
abstract = {This paper combines Tangible Augmented Reality and shape grammar into collaborative design learning to bridge the gaps such as the difficulties of imaging the spatial form in a complex content and the obstacle of communication during the collaborative design. This work has been successful in mapping out a space of technical possibilities and providing a possible system setup to pursue the innovative idea. It not only describes the latent trends and assumptions that might be used to motivate and guide the design in cooperative work, but also makes links with existing research in cognitive science and education.},
author = {Chen, I R and Wang, X and Wang, W},
doi = {10.1109/CSCWD.2009.4968103},
file = {::},
isbn = {9781424435340},
journal = {2009 13th International Conference on Computer Supported Cooperative Work in Design},
keywords = {augmented reality,shape grammar,tangible augmented reality,tangible user},
pages = {468--473},
publisher = {IEEE Comput. Soc},
title = {{Bridging shape grammar and Tangible Augmented Reality into collaborative design learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4968103},
year = {2009}
}
@article{Attfield2005,
author = {Attfield, S and Blandford, A and Mottram, C and Penn, A and {Fatah Gen Schieck}, A},
file = {::},
publisher = {Key Centre of Design Computing and Cognition, University of Sydney},
title = {{Exploring the effects of introducing real-time simulation on collaborative urban design in augmented reality}},
url = {http://discovery.ucl.ac.uk/1472/},
year = {2005}
}
@phdthesis{Bimber2005a,
author = {Bimber, O. and Raskar, R.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2005/Bimber, Raskar/Bimber, Raskar - 2005 - Spatial augmented reality.pdf:pdf},
publisher = {Peters},
title = {{Spatial augmented reality}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Spatial+Augmented+Reality#0},
year = {2005}
}
@article{Hirakawa2004,
author = {Hirakawa, Masahito and Koike, Satoshi},
file = {::},
journal = {Proceedings of the IEEE},
keywords = {augmented reality,collaboration,single camera tracking,transparent},
title = {{A Collaborative Augmented Reality System using Transparent Display}},
year = {2004}
}
@article{Reitmayr2001,
abstract = {The combination of mobile computing and collaborative augmented reality into a single system makes the power of computer enhanced interaction and communication in the real world accessible anytime and everywhere. The paper describes our work to build a mobile collaborative augmented reality system that supports true stereoscopic 3D graphics, a pen and pad interface and direct interaction with virtual objects. The system is assembled from off-the-shelf hardware components and serves as a basic test bed for user interface experiments related to computer supported collaborative work in augmented reality. A mobile platform implementing the described features and collaboration between mobile and stationary users are demonstrated},
author = {Reitmayr, G and Schmalstieg, D},
doi = {10.1109/ISAR.2001.970521},
file = {::},
isbn = {0769513751},
journal = {Proceedings IEEE and ACM International Symposium on Augmented Reality},
keywords = {3d interaction,a user wearing,able computing,augmented reality,computer supported collaborative work,figure 1,hybrid tracking,mobile aug,mobile computing,wear},
pages = {114--123},
publisher = {IEEE Comput. Soc},
title = {{Mobile collaborative augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=970521},
year = {2001}
}
@article{Lamberti2003a,
address = {New York, New York, USA},
author = {Lamberti, Fabrizio and Zunino, Claudio and Sanna, Andrea and Fiume, Antonino and Maniezzo, Marco},
file = {::},
journal = {Proceeding of the eighth international conference on 3D web technology - Web3D '03},
pages = {55},
publisher = {ACM Press},
title = {{An accelerated remote graphics architecture for PDAS}},
url = {http://portal.acm.org/citation.cfm?doid=636593.636602},
year = {2003}
}
@article{Cheok2002,
abstract = {This paper presents an interactive theatre based on an embodied mixed reality space and wearable computers. Embodied computing mixed reality spaces integrate ubiquitous computing, tangible interaction and social computing within a mixed reality space, which enables intuitive interaction with physical world and virtual world. We believe it has potential advantages to support novel interactive theatre experiences. Therefore, we explored the novel interactive theatre experience supported in the embodied mixed reality space, and implemented live 3D characters to interact with user in such a system.},
author = {Cheok, A D and Weihua, Wang and Yang, Xubo and Prince, S and Wan, Fong Siew and Billinghurst, M and Kato, H},
doi = {10.1109/ISMAR.2002.1115073},
file = {::},
isbn = {0769517811},
journal = {Proceedings International Symposium on Mixed and Augmented Reality},
pages = {59--317},
publisher = {IEEE Computer Society},
title = {{Interactive theatre experience in embodied + wearable mixed reality space}},
url = {http://portal.acm.org/citation.cfm?id=850976.854978},
year = {2002}
}
@article{Nam2009,
author = {Nam, Tek-Jin and Sakong, Kyung},
file = {::},
journal = {International Journal of Design},
keywords = {augmented reality,collaborative design,interaction,shared 3d workspace,tangible interaction,tele presence},
number = {1},
pages = {43--55},
title = {{Collaborative 3D Workspace and Interaction Techniques for Synchronous Distributed Product Design Reviews}},
url = {http://www.ijdesign.org/ojs/index.php/IJDesign/article/view/387/240},
volume = {3},
year = {2009}
}
@article{Jung2010,
author = {Jung, Sungmo and Song, Jae-gu and Hwang, Dae-Joon and Ahn, Jae Young and Kim, Seoksoo},
doi = {10.3390/s101109857},
file = {::},
issn = {1424-8220},
journal = {Sensors},
month = nov,
number = {11},
pages = {9857--9871},
title = {{A Study on Software-based Sensing Technology for Multiple Object Control in AR Video}},
url = {http://www.mdpi.com/1424-8220/10/11/9857/},
volume = {10},
year = {2010}
}
@inproceedings{Field2004a,
address = {Hobart, Tasmania},
author = {Field, Tom and Bay, Sandy and Vamplew, Peter},
booktitle = {AISAT2004: International Conference on Artificial Intelligence in Science and Technology},
file = {::},
title = {{Generalised Algorithms for Redirected Walking in Virtual Environments}},
url = {http://eprints.utas.edu.au/109/},
year = {2004}
}
@article{Watsen1999a,
author = {Watsen, K and Darken, R and Capps, M},
file = {::},
journal = {3rd International Immersive Projection Technology Workshop (IPTW'},
publisher = {Citeseer},
title = {{A Handheld Computer as an Interaction Device to a Virtual Environment}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:A+Handheld+Computer+as+an+Interaction+Device+to+a+Virtual+Environment#0},
volume = {99},
year = {1999}
}
@article{Geller2008b,
author = {Geller, T.},
file = {::},
journal = {IEEE Computer Graphics and Applications},
number = {4},
pages = {11--17},
publisher = {IEEE Computer Society Press},
title = {{Overcoming the uncanny valley}},
url = {http://www.computer.org/portal/cms_docs_cga/cga/content/mcg2008040011.pdf},
volume = {28},
year = {2008}
}
@article{Nurminen2008c,
author = {Nurminen, Antti},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {20--31},
title = {{Mobile 3D City Maps}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557952},
volume = {28},
year = {2008}
}
@article{Kaufmann2003a,
abstract = {Construct3D is a 3D geometric construction tool specifically designed for mathematics and geometry education. It is based on the mobile collaborative augmented reality system Studierstube. We describe our efforts in developing a system for the improvement of spatial abilities and maximization of transfer of learning. In order to support various teacher-student interaction scenarios we implemented flexible methods for context and user dependent rendering of parts of the construction. Together with hybrid hardware setups they allow the use of Construct3D in today's classrooms and provide a testbed for future evaluations. Means of application and integration in mathematics and geometry education at high school as well as university level are being discussed. Anecdotal evidence supports our claim that Construct3D is easy to learn, encourages experimentation with geometric constructions and improves spatial skills.},
author = {Kaufmann, Hannes and Schmalstieg, Dieter},
doi = {10.1016/S0097-8493(03)00028-1},
file = {::},
isbn = {1581135254},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {augmented reality,geometry education,mathematics education,spatial intelligence},
number = {3},
pages = {339--345},
publisher = {ACM Press},
title = {{Mathematics and geometry education with collaborative augmented reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849303000281},
volume = {27},
year = {2003}
}
@article{Anastassova2009,
abstract = {The paper presents an ergonomic analysis carried out in the early phases of an R\&D project. The purpose was to investigate the functioning of today's Automotive Service Technicians (ASTs) training in order to inform the design of an Augmented Reality (AR) teaching aid. The first part of the paper presents a literature review of some major problems encountered by ASTs today. The benefits of AR as technological aid are also introduced. Then, the methodology and the results of two case studies are presented. The first study is based on interviews with trainers and trainees; the second one on observations in real training settings. The results support the assumption that today's ASTs' training could be regarded as a community-of-practice (CoP). Therefore, AR could be useful as a collaboration tool, offering a shared virtual representation of real vehicle's parts, which are normally invisible unless dismantled (e.g. the parts of a hydraulic automatic transmission). We conclude on the methods and the technologies to support the automotive CoP.},
author = {Anastassova, Margarita and Burkhardt, Jean-Marie},
doi = {10.1016/j.apergo.2008.06.008},
file = {::},
issn = {1872-9126},
journal = {Applied ergonomics},
keywords = {Adult,Automobiles,Human Engineering,Humans,Male,Middle Aged,Task Performance and Analysis,Teaching,Teaching: methods,Technology,User-Computer Interface,Workplace,Young Adult},
month = jul,
number = {4},
pages = {713--21},
pmid = {18703179},
title = {{Automotive technicians' training as a community-of-practice: implications for the design of an augmented reality teaching aid.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18703179},
volume = {40},
year = {2009}
}
@article{Nini2004,
author = {Nini, B and Batouche, M C},
doi = {10.1109/ICIT.2004.1490732},
file = {::},
isbn = {0780386620},
journal = {2004 IEEE International Conference on Industrial Technology 2004 IEEE ICIT 04},
keywords = {augmented reality,collaboration,departure,do,encrustation,manipulation,network,object,pattern,supposed superposed,used,virtual object},
pages = {1204--1208},
publisher = {Ieee},
title = {{Virtual object manipulation in collaborative augmented reality environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1490732},
year = {2004}
}
@article{Ziaei2011,
author = {Ziaei, Z. and Hahto, a. and Mattila, J. and Siuko, M. and Semeraro, L.},
doi = {10.1016/j.fusengdes.2010.12.082},
file = {::},
issn = {09203796},
journal = {Fusion Engineering and Design},
month = feb,
publisher = {Elsevier B.V.},
title = {{Real-time markerless Augmented Reality for Remote Handling system in bad viewing conditions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0920379611000160},
year = {2011}
}
@article{Schmalstieg2002,
author = {Schmalstieg, Dieter and Fuhrmann, Anton and Hesina, Gerd and Szalav\'{a}ri, Zsolt and Encarna\c{c}\~{a}o, L. Miguel and Gervautz, Michael and Purgathofer, Werner},
doi = {10.1162/105474602317343640},
file = {::},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
month = feb,
number = {1},
pages = {33--54},
title = {{The Studierstube Augmented Reality Project}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/105474602317343640},
volume = {11},
year = {2002}
}
@article{Nirnimesh2007a,
abstract = {Cluster-based tiled display walls can provide cost-effective and scalable displays with high resolution and a large display area. The software to drive them needs to scale too if arbitrarily large displays are to be built. Chromium is a popular software API used to construct such displays. Chromium transparently renders any OpenGL application to a tiled display by partitioning and sending individual OpenGL primitives to each client per frame. Visualization applications often deal with massive geometric data with millions of primitives. Transmitting them every frame results in huge network requirements that adversely affect the scalability of the system. In this paper, we present Garuda, a client-server-based display wall framework that uses off-the-shelf hardware and a standard network. Garuda is scalable to large tile configurations and massive environments. It can transparently render any application built using the Open Scene Graph (OSG) API to a tiled display without any modification by the user. The Garuda server uses an object-based scene structure represented using a scene graph. The server determines the objects visible to each display tile using a novel adaptive algorithm that culls the scene graph to a hierarchy of frustums. Required parts of the scene graph are transmitted to the clients, which cache them to exploit the interframe redundancy. A multicast-based protocol is used to transmit the geometry to exploit the spatial redundancy present in tiled display systems. A geometry push philosophy from the server helps keep the clients in sync with one another. Neither the server nor a client needs to render the entire scene, making the system suitable for interactive rendering of massive models. Transparent rendering is achieved by intercepting the cull, draw, and swap functions of OSG and replacing them with our own. We demonstrate the performance and scalability of the Garuda system for different configurations of display wall. We also show that the server and network loads grow sublinearly with the increase in the number of tiles, which makes our scheme suitable to construct very large displays.},
author = {Nirnimesh, Harish P. and Narayanan, Pawan J.},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Algorithms,Computer Communication Networks,Computer Communication Networks: instrumentation,Computer Graphics,Computer Graphics: instrumentation,Computer-Assisted,Computer-Assisted: instrumen,Computer-Assisted: instrumentat,Computer-Assisted: methods,Data Display,Equipment Design,Equipment Failure Analysis,Image Enhancement,Image Enhancement: instrumentation,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Microcomputers,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,User-Computer Interface},
number = {5},
pages = {864--77},
title = {{Garuda: A Scalable Tiled Display Wall Using Commodity PCs}},
volume = {13},
year = {2007}
}
@article{ElSayed2011,
author = {a.M. {El Sayed}, Neven and Zayed, Hala H. and Sharawy, Mohamed I.},
doi = {10.1016/j.compedu.2010.10.019},
file = {::},
isbn = {0101355491},
issn = {03601315},
journal = {Computers \& Education},
month = may,
number = {4},
pages = {1045--1061},
publisher = {Elsevier Ltd},
title = {{ARSC: Augmented reality student card}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360131510003040},
volume = {56},
year = {2011}
}
@article{Ong2007,
author = {Ong, S.K. and Pang, Y. and a.Y.C. Nee},
doi = {10.1016/j.cirp.2007.05.014},
file = {::},
issn = {00078506},
journal = {CIRP Annals - Manufacturing Technology},
keywords = {assembly design,augmented reality,product evaluation},
number = {1},
pages = {49--52},
title = {{Augmented Reality Aided Assembly Design and Planning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0007850607000145},
volume = {56},
year = {2007}
}
@inproceedings{Prince2002,
abstract = {We present a complete system for live capture of 3D content and simultaneous presentation in augmented reality. The user sees the real world from his viewpoint, but modified so that the image of a remote collaborator is rendered into the scene. Fifteen cameras surround the collaborator, and the resulting video streams are used to construct a three-dimensional model of the subject using a shape-from-silhouette algorithm. Users view a two-dimensional fiducial marker using a video-see-through augmented reality interface. The geometric relationship between the marker and head-mounted camera is calculated, and the equivalent view of the subject is computed and drawn into the scene. Our system can generate 384 288 pixel images of the models at 25 fps, with a latency of < 100 ms. The result gives the strong impression that the subject is a real part of the 3D scene. We demonstrate applications of this system in 3D videoconferencing and entertainment.},
author = {Prince, S J D and Cheok, A D and Farbiz, F and Williamson, T and Johnson, N and Billinghurst, M and Kato, H},
booktitle = {International Symposium on Mixed and Augmented Reality ISMAR},
doi = {10.1109/ISMAR.2002.1115062},
file = {::},
isbn = {0769517811},
pages = {7--13},
publisher = {IEEE Comput. Soc},
title = {3d live: real time captured content for mixed reality},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1115062},
year = {2002}
}
@article{Kurz2012a,
author = {Kurz, Daniel and Benhimane, Selim},
journal = {Computers \& Graphics},
number = {7},
pages = {866--883},
title = {{Handheld Augmented Reality involving gravity measurements}},
url = {http://da.nielkurz.de/content/Handheld_Augmented_Reality_involving_gravity_measurements},
volume = {36},
year = {2012}
}
@article{Shen2010,
author = {Shen, Y. and Ong, S.K. and a.Y.C. Nee},
doi = {10.1016/j.destud.2009.11.001},
file = {::},
issn = {0142694X},
journal = {Design Studies},
keywords = {collaborative design,interface design,product design,virtual reality},
month = mar,
number = {2},
pages = {118--145},
publisher = {Elsevier Ltd},
title = {{Augmented reality for collaborative product design and development}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0142694X0900091X},
volume = {31},
year = {2010}
}
@article{Platonov2006,
author = {Platonov, Juri and Heibel, Hauke and Meier, Peter},
doi = {10.1109/ISMAR.2006.297800},
file = {:home/acmt/Dropbox/Documentos/Mendeley/of the 5th IEEE and ACM/2006/Platonov, Heibel, Meier/Platonov, Heibel, Meier - 2006 - A mobile markerless AR system for maintenance and repair.pdf:pdf},
isbn = {1-4244-0650-1},
journal = {of the 5th IEEE and ACM},
keywords = {17,a laptop,and the user,augmented reality,augmented video stream are,computer,e,g,has been inspired by,lessly transmitted between a,maintenance,markerless tracking,our markerless tracking algorithm,solution both,the raw and the,wire-},
month = oct,
pages = {105--108},
publisher = {Ieee},
title = {{A mobile markerless AR system for maintenance and repair}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4079262 http://portal.acm.org/citation.cfm?id=1514222},
year = {2006}
}
@article{Capin2008b,
author = {Capin, Tolga and Pulli, Kari and Akenine-M\"{o}ller, Tomas},
file = {::},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {74--84},
title = {{The State of the Art in Mobile Graphics Research}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557959},
volume = {28},
year = {2008}
}
@article{Bajura1995a,
author = {Bajura, M. and Neumann, U.},
file = {::},
journal = {IEEE Computer Graphics and Applications},
keywords = {augmented reality,reality,registration,virtual},
number = {5},
pages = {52--60},
title = {{Dynamic registration correction in video-based augmented reality systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=403828},
volume = {15},
year = {1995}
}
@article{Fjeld2004,
author = {Fjeld, Morten},
doi = {10.1145/1029036.1029044},
file = {::},
issn = {10725520},
journal = {Interactions},
month = nov,
number = {6},
pages = {11},
title = {{Usability and collaborative aspects of augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=1029036.1029044},
volume = {11},
year = {2004}
}
@article{Schmalstieg2007c,
author = {Schmalstieg, Dieter and Schall, Gerhard and Wagner, Daniel and Barakonyi, Istv\'{a}n and Reitmayr, Gerhard and Newman, Joseph and Ledermann, Florian},
journal = {IEEE Computer Graphics and Applications},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer Graphics,Computer-Assisted,Computer-Assisted: methods,Database Management Systems,Databases,Ecosystem,Factual,Geographic Information Systems,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models,Pattern Recognition,Theoretical,Three-Dimensional,Three-Dimensional: methods,User-Computer Interface},
number = {4},
pages = {48--57},
publisher = {IEEE Computer Society},
title = {{Managing complex augmented reality models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17713234 http://doi.ieeecomputersociety.org/10.110910.1109/MCG.2007.85},
volume = {27},
year = {2007}
}
@article{Choi2010,
author = {Choi, Jinhyuk and Jang, Bongkyu and Kim, Gerard J.},
doi = {10.1007/s00779-010-0343-3},
file = {::},
issn = {1617-4909},
journal = {Personal and Ubiquitous Computing},
keywords = {augmented reality,geospatial tags,mobile interface},
month = nov,
pages = {641--647},
title = {{Organizing and presenting geospatial tags in location-based augmented reality}},
url = {http://www.springerlink.com/index/10.1007/s00779-010-0343-3},
year = {2010}
}
@article{Siegl2007,
author = {Siegl, H and Hanheide, M and Wrede, S and Pinz, a},
doi = {10.1016/j.imavis.2006.04.027},
file = {::},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {3d cursor,cognitive vision system,computer interaction,human,mobile augmented reality},
month = dec,
number = {12},
pages = {1895--1903},
title = {{An augmented reality human–computer interface for object localization in a cognitive vision system}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885606002873},
volume = {25},
year = {2007}
}
@article{Pan2006,
author = {Pan, Z and Cheok, a and Yang, H and Zhu, J and Shi, J},
doi = {10.1016/j.cag.2005.10.004},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {collaborative,cooperative,edutainment,mixed reality,virtual learning environment,virtual reality,vle},
month = feb,
number = {1},
pages = {20--28},
title = {{Virtual reality and mixed reality for virtual learning environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849305002025},
volume = {30},
year = {2006}
}
@article{Gintautas2006,
abstract = {We present experimental data on the limiting behavior of an interreality system comprising a virtual horizontally driven pendulum coupled to its real-world counterpart, where the interaction time scale is much shorter than the time scale of the dynamical system. We present experimental evidence that if the physical parameters of the simplified virtual system match those of the real system within a certain tolerance, there is a transition from an uncorrelated dual reality state to a mixed reality state of the system in which the motion of the two pendula is highly correlated. The region in parameter space for stable solutions has an Arnold tongue structure for both the experimental data and for a numerical simulation. As virtual systems better approximate real ones, even weak coupling in other interreality systems may produce sudden changes to mixed reality states.},
author = {Gintautas, Vadas and Hubler, Alfred},
file = {::},
pages = {4},
title = {{Mixed Reality States in a Bidirectionally Coupled Interreality System}},
url = {http://arxiv.org/abs/physics/0611293},
year = {2006}
}
@article{Lee2009a,
author = {Lee, Sang and Choi, Junyeong and Park, Jong-il},
doi = {10.1109/TCE.2009.5174470},
file = {::},
issn = {0098-3063},
journal = {IEEE Transactions on Consumer Electronics},
month = may,
number = {2},
pages = {883--890},
title = {{Interactive e-learning system using pattern recognition and augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5174470},
volume = {55},
year = {2009}
}
@article{Brudera,
author = {Bruder, Gerd},
file = {::},
journal = {Image (Rochester, N.Y.)},
keywords = {3d user interfaces,architectural walkthroughs,locomotion,passive haptic feed-,redirected walking,virtual environments},
title = {{A Natural User Interface for Immersive Architectural Walkthroughs}}
}
@article{Baudin2004,
abstract = {This paper presents'LabFuture', an advanced e-learning platform that uses novel Information and Communication Technologies to support and expand laboratory teaching practices. For this purpose, LabFuture uses real and computer-generated objects that are interfaced using mechatronic systems,augmented reality, mobile technologies and 3D multi user environments. The main aim is to develop and demonstrate technological support for practical experiments in the following focused subjects namely: Fluid Dynamics -Science subject in Germany, Geometry - Mathematics subject in Austria,History and Environmental Awareness - Arts and Humanities subjects in Greece and Slovenia. In order to pedagogically enhance the design and functional aspects of this e-learning technology, we are investigating the dialogical operationalisation of learning theories so as to leverage our understanding of teaching and learning practices in the targeted context of deployment.},
author = {Baudin, Veronique and Faust, Martin and Kaufmann, Hannes and Litsa, Vivian and Mwanza, Daisy and Pierre, Arnaud and Totter, Alexandra},
file = {::},
publisher = {Springer Boston},
title = {{The Lab@Future Project: ‘Moving towards the future of e-Learning}},
url = {http://www.ims.tuwien.ac.at/publication_detail.php?ims_id=152},
year = {2004}
}
@article{Wang2008,
author = {Wang, X and Dunston, P},
doi = {10.1016/j.autcon.2007.07.002},
file = {::},
issn = {09265805},
journal = {Automation in Construction},
keywords = {3d models,computer supported cooperative work,cscw,design review,mixed reality,usability},
month = may,
number = {4},
pages = {399--412},
title = {{User perspectives on mixed reality tabletop visualization for face-to-face collaborative design review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580507000933},
volume = {17},
year = {2008}
}
@inproceedings{Kurz2011,
author = {Kurz, Daniel and Benhimane, Selim},
booktitle = {IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR2011)},
keywords = {Handheld Augmented Reality Inertial Sensors Gravit},
pages = {111--120},
title = {{Gravity-Aware Handheld Augmented Reality}},
year = {2011}
}
@article{Pape1999a,
author = {Pape, Dave},
file = {::},
journal = {Proceedings of SPIE},
keywords = {application framework,stereo perspective},
number = {Figure 1},
pages = {346--353},
publisher = {Spie},
title = {{Transparently supporting a wide range of VR and stereoscopic display devices}},
url = {http://link.aip.org/link/?PSI/3639/346/1&Agg=doi},
year = {1999}
}
@article{Tian2010,
abstract = {To produce a realistic augmentation in Augmented Reality, the correct relative positions of real objects and virtual objects are very important. In this paper, we propose a novel real-time occlusion handling method based on an object tracking approach. Our method is divided into three steps: selection of the occluding object, object tracking and occlusion handling. The user selects the occluding object using an interactive segmentation method. The contour of the selected object is then tracked in the subsequent frames in real-time. In the occlusion handling step, all the pixels on the tracked object are redrawn on the unprocessed augmented image to produce a new synthesized image in which the relative position between the real and virtual object is correct. The proposed method has several advantages. First, it is robust and stable, since it remains effective when the camera is moved through large changes of viewing angles and volumes or when the object and the background have similar colors. Second, it is fast, since the real object can be tracked in real-time. Last, a smoothing technique provides seamless merging between the augmented and virtual object. Several experiments are provided to validate the performance of the proposed method.},
author = {Tian, Yuan and Guan, Tao and Wang, Cheng},
doi = {10.3390/s100402885},
file = {::},
issn = {1424-8220},
journal = {Sensors},
keywords = {augmented reality,graph cuts,mean shift,occlusion,optical flow,tracking},
month = mar,
number = {4},
pages = {2885--2900},
title = {{Real-Time Occlusion Handling in Augmented Reality Based on an Object Tracking Approach}},
url = {http://www.mdpi.com/1424-8220/10/4/2885/},
volume = {10},
year = {2010}
}
@article{Comport2006,
abstract = {Tracking is a very important research subject in a real-time augmented reality context. The main requirements for trackers are high accuracy and little latency at a reasonable cost. In order to address these issues, a real-time, robust, and efficient 3D model-based tracking algorithm is proposed for a "video see through" monocular vision system. The tracking of objects in the scene amounts to calculating the pose between the camera and the objects. Virtual objects can then be projected into the scene using the pose. Here, nonlinear pose estimation is formulated by means of a virtual visual servoing approach. In this context, the derivation of point-to-curves interaction matrices are given for different 3D geometrical primitives including straight lines, circles, cylinders, and spheres. A local moving edges tracker is used in order to provide real-time tracking of points normal to the object contours. Robustness is obtained by integrating an M-estimator into the visual control law via an iteratively reweighted least squares implementation. This approach is then extended to address the 3D model-free augmented reality problem. The method presented in this paper has been validated on several complex image sequences including outdoor environments. Results show the method to be robust to occlusion, changes in illumination, and mistracking.},
author = {Comport, A.I. and Marchand, Eric and Pressigout, Muriel and Chaumette, Fran\c{c}ois},
doi = {10.1109/TVCG.2006.78},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Visualization and Computer Graphics/2006/Comport et al/Comport et al. - 2006 - Real-time markerless tracking for augmented reality the virtual visual servoing framework.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithms,Computer Graphics,Computer Systems,Computer-Assisted,Computer-Assisted: methods,Feedback,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Signal Processing,Three-Dimensional,Three-Dimensional: methods,User-Computer Interface},
number = {4},
pages = {615--628},
pmid = {16805268},
publisher = {IEEE Computer Society},
title = {{Real-time markerless tracking for augmented reality: the virtual visual servoing framework}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16805268 http://www.computer.org/portal/web/csdl/doi/10.1109/tvcg.2006.78},
volume = {12},
year = {2006}
}
@article{Dunston2003,
abstract = {Design visualization is key to the communication and shared perception of designs and is essential for meaningful design development and collaborations. The initial development of an Augmented Reality Computer Aided Drawing (AR CAD) system for enhancing visualization of models created in standard CAD was presented at the 17th ISARC. AR CAD features a more natural mode for changing views of the model and completely understanding the model content. Expected benefits are improved efficiency in the design detailing function, both for the individual detailer and for design collaborations where maintaining an accurate shared understanding of the design model is critical. An experimental program is under way to examine the impact of AR CAD upon a users perception and recall of a design model. Related experiments with desktop and immersive virtual environments have found that motion cues can indeed markedly improve spatial cognition. It is expected that we will see the same benefits in our AR CAD system, although until now such studies have not been conducted in an AR environment. This paper presents the rationale for experiments to measure the impact of AR CAD in terms of cognition cost, and it lays the foundation for further application of Mixed Reality (MR) technology to the design, construction, and maintenance phases of a facilitys life cycle. MR applications may prove promising for effective communication of designs for prefabrication, site installation, and the planning and excecution of maintenance operations.},
author = {Dunston, P and Wang, X and Billinghurst, M and Hampson, B},
file = {::},
journal = {NIST SPECIAL PUBLICATION SP},
keywords = {3d cad,augmented reality,mixed reality,spatial cognition,visualization},
pages = {1--6},
publisher = {NATIONAL INSTIUTE OF STANDARDS \& TECHNOLOGY},
title = {{Mixed Reality benefits for design perception}},
url = {http://www.hitlabnz.org/publications/2002-ISARC-MixedReality.pdf},
year = {2003}
}
@article{Fuge2011,
author = {Fuge, Mark and Yumer, Mehmet Ersin and Orbay, Gunay and Kara, Levent Burak},
doi = {10.1016/j.cad.2011.05.009},
file = {::},
issn = {00104485},
journal = {Computer-Aided Design},
month = jun,
pages = {1--13},
publisher = {Elsevier Ltd},
title = {{Conceptual design and modification of freeform surfaces using dual shape representations in augmented reality environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S001044851100128X},
year = {2011}
}
@article{Barakonyi2003,
author = {Barakonyi, I. and Fahmy, T. and Schmalstieg, Dieter},
file = {::},
isbn = {0769520065},
journal = {and Augmented Reality},
keywords = {augmented reality,computer supported col-,laborative work,videoconferencing,volume rendering},
pages = {333},
publisher = {IEEE Computer Society},
title = {{Collaborative work with volumetric data using augmented reality videoconferencing}},
url = {http://portal.acm.org/citation.cfm?id=946833},
year = {2003}
}
@article{Bajuraa,
author = {Bajura, Michael and Hill, U N C Chapel and Neumann, Ulrich and Reality, Keywords Augmented},
file = {::},
keywords = {augmented reality,reality,registration,virtual},
title = {{Dynamic Registration Correction in Video-Based Augmented Reality Systems}}
}
@article{Abdullah2002,
abstract = {Camera calibration is an essential and important part of an Augmented Reality (AR) system. The use of a planebased calibration technique can give a good accuracy, which can be important for AR applications. The calibration technique used in the current ARToolKit requires user intervention, which is prone to error and involves a lengthy calibration time. The camera has to be recalibrated every time the focal length changes which is cumbersome and less suitable for applications where a more automated and easier approach is needed. This paper investigates the use of camera self-calibration for the ARToolKit, which has the advantage of simplicity of implementation. In order to improve its accuracy, a distortion model is also investigated. In this context several interesting results are presented.},
author = {Abdullah, Junaidi and Martinez, Kirk},
file = {::},
title = {{Camera Self-Calibration for the ARToolkit}},
url = {http://eprints.ecs.soton.ac.uk/8885/},
year = {2002}
}
@inproceedings{You2010,
author = {You, Suya and Neumann, Ulrich},
booktitle = {Internet Technology and Applications 2010 International Conference on},
file = {::},
keywords = {augmented reality,e,e business,image reacognition,internet,learning,mobile augmented reality enhancing e learning},
pages = {1--4},
publisher = {IEEE},
title = {{Mobile Augmented Reality for Enhancing E-Learning and E-Business}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5566168},
year = {2010}
}
@article{Sheng2010,
author = {Sheng, Yu and Yapo, Theodore C. and Cutler, Barbara},
doi = {10.1111/j.1467-8659.2009.01608.x},
file = {::},
issn = {01677055},
journal = {Computer Graphics Forum},
month = jun,
number = {2},
pages = {387--396},
title = {{Global Illumination Compensation for Spatially Augmented Reality}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2009.01608.x},
volume = {29},
year = {2010}
}
@article{RobinKirk2005,
author = {{Robin Kirk}, Jan Newmarch},
file = {::},
journal = {Second IEEE Consumer Communications and Networking Conference, 2005. CCNC. 2005},
keywords = {- home networks,interoperability,location-based services,middleware,mobility,multimedia distribution protocols,multimedia technologies,network architecture,pervasive computing,session user and device},
number = {C},
pages = {343--347},
publisher = {Ieee},
title = {{A location-aware, service-based audio system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1405194},
volume = {00},
year = {2005}
}
@article{Pilet2005,
author = {Pilet, J. and Lepetit, V. and Fua, P.},
doi = {10.1109/ISMAR.2005.18},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)/2005/Pilet, Lepetit, Fua/Pilet, Lepetit, Fua - 2005 - Augmenting deformable objects in real-time.pdf:pdf},
isbn = {0-7695-2459-1},
journal = {Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)},
pages = {134--137},
publisher = {Ieee},
title = {{Augmenting deformable objects in real-time}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544675},
volume = {1},
year = {2005}
}
@article{Gelb2010,
author = {Gelb, Dan and Subramanian, A},
file = {::},
isbn = {9781612840352},
journal = {Person-Oriented Vision (POV),},
pages = {1--6},
title = {{Augmented reality for immersive remote collaboration}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5712368},
year = {2010}
}
@article{Juan2010,
author = {Juan, Carmen M. and Llop, Edith and Abad, Francisco and Lluch, Javier},
doi = {10.1109/ICALT.2010.123},
file = {::},
isbn = {978-1-4244-7144-7},
journal = {2010 10th IEEE International Conference on Advanced Learning Technologies},
keywords = {augmented reality,edutainment,learning words},
month = jul,
pages = {422--426},
publisher = {Ieee},
title = {{Learning Words Using Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5572407},
year = {2010}
}
@article{Butz1999,
author = {Butz, A and H\"{o}llerer, T and Feiner, S and MacIntyre, B and Beshers, C},
doi = {10.1109/IWAR.1999.803804},
file = {::},
isbn = {0769503594},
journal = {Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality IWAR99},
pages = {35--44},
publisher = {IEEE Comput. Soc},
title = {{Enveloping users and computers in a collaborative 3D augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=803804},
volume = {99},
year = {1999}
}
@article{Martin-Gutierrez2010,
author = {Mart\'{\i}n-Guti\'{e}rrez, Jorge and {Lu\'{\i}s Saor\'{\i}n}, Jos\'{e} and Contero, Manuel and Alca\~{n}iz, Mariano and P\'{e}rez-L\'{o}pez, David C. and Ortega, Mario},
doi = {10.1016/j.cag.2009.11.003},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
month = feb,
number = {1},
pages = {77--91},
title = {{Design and validation of an augmented book for spatial abilities development in engineering students}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849309001514},
volume = {34},
year = {2010}
}
@article{Ni2006b,
author = {Ni, T and Schmidt, G S and Staadt, O G and Livingston, M A and Ball, R and May, R},
journal = {Virtual Reality},
title = {{A Survey of Large High-Resolution Display Technologies, Techniques, and Applications}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:A+Survey+of+Large+High-Resolution+Display+Technologies,+Techniques,+and+Applications#0},
year = {2006}
}
@article{Klinec1988a,
author = {Klinec, Darko and Leonhardi, Alexander},
file = {::},
number = {19-20},
pages = {xiii},
title = {{Positioning and Location Services for Infoor Areas in neXus}},
volume = {7},
year = {1988}
}
@article{Ong2009,
author = {Ong, S.K. and Shen, Y.},
doi = {10.1016/j.cirp.2009.03.020},
file = {::},
issn = {00078506},
journal = {CIRP Annals - Manufacturing Technology},
number = {1},
pages = {139--142},
title = {{A mixed reality environment for collaborative product design and development}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0007850609000225},
volume = {58},
year = {2009}
}
@article{Klopfer2005,
address = {Morristown, NJ, USA},
author = {Klopfer, Eric and Perry, Judy and Squire, Kurt and Jan, Ming-Fong},
doi = {10.3115/1149293.1149333},
file = {::},
isbn = {0805857826},
journal = {Proceedings of the 2005 conference on Computer support for collaborative learning learning 2005: the next 10 years! - CSCL '05},
keywords = {games,handhelds,pda,role play,simulations},
pages = {311--315},
publisher = {Association for Computational Linguistics},
title = {{Collaborative learning through augmented reality role playing}},
url = {http://portal.acm.org/citation.cfm?doid=1149293.1149333},
year = {2005}
}
@article{Regenbrecht2006,
author = {Regenbrecht, H. and Ott, C. and Wagner, M. and Lum, T. and Kohler, P. and Wilke, W. and Mueller, E.},
doi = {10.1109/ISMAR.2003.1240725},
file = {::},
isbn = {0-7695-2006-5},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {290--291},
publisher = {IEEE Comput. Soc},
title = {{An augmented virtuality approach to 3D videoconferencing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240725},
year = {2006}
}
@inproceedings{Buscher2000,
address = {New York, New York, USA},
author = {B\"{u}scher, Monika and Christensen, Michael and Gr\o nb\ae k, Kaj and Krogh, Peter and Mogensen, Preben and Shapiro, Dan and \O rb\ae k, Peter},
booktitle = {Proceedings of the third international conference on Collaborative virtual environments - CVE '00},
doi = {10.1145/351006.351012},
file = {::},
isbn = {1581133030},
pages = {47--56},
publisher = {ACM Press},
title = {{Collaborative augmented reality environments}},
url = {http://portal.acm.org/citation.cfm?id=351012 http://portal.acm.org/citation.cfm?doid=351006.351012},
year = {2000}
}
@article{Green2008,
abstract = {Future space exploration will demand the cultivation of human-robotic systems, however, little attention has been paid to the development of human-robot teams. Current methods for autonomous plan creation are often complex and difficult to use. So a system is needed that enables humans and robotic systems to naturally and effectively collaborate. Effective collaboration takes place when the participants are able to communicate in a natural and effective manner. Grounding, the common understanding between conversational participants, shared spatial referencing and situational awareness, are crucial components of communication and collaboration. This paper briefly reviews the fields of human-robot interaction and Augmented Reality (AR), the overlaying of computer graphics onto the real worldview. The strengths of AR are discussed and how they might be used for human-robot collaboration is described. Then a description of an architecture that we have developed is given that uses AR as a means for real time understanding of the shared spatial scene. This architecture enables grounding and enhances situational awareness, thus laying the necessary groundwork for natural and effective human-robot collaboration.},
author = {Green, Scott A and Billinghurst, Mark and Chen, Xiaoqi and Chase, J Geoffrey},
file = {::},
journal = {International Journal of Advanced Robotic Systems},
keywords = {augmented reality,collaboration,communication,computer interaction,human,robot,robot interaction,robotics},
number = {1},
pages = {1--18},
publisher = {ASME},
title = {{Human-robot collaboration: A literature review and augmented reality approach in design}},
url = {http://ir.canterbury.ac.nz/handle/10092/2262},
volume = {5},
year = {2008}
}
@article{Teichrieb2007,
author = {Teichrieb, Veronica and Lima, Monte and Lourenc, Eduardo and Bueno, Silva and Kelner, Judith and Santos, Ismael H F},
file = {::},
journal = {International Journal of Modeling and Simulation for the Petroleum Industry},
number = {1},
pages = {1--7},
title = {{A Survey of Online Monocular Markerless Augmented Reality}},
url = {http://rpcmod.ganer.ex-br.com/revista/articles/1.pdf},
volume = {1},
year = {2007}
}
@article{Kim2010,
author = {Kim, Seungjun and Dey, Anind K.},
doi = {10.1016/j.cad.2008.10.009},
file = {::},
issn = {00104485},
journal = {Computer-Aided Design},
month = may,
number = {5},
pages = {373--386},
publisher = {Elsevier Ltd},
title = {{AR interfacing with prototype 3D applications based on user-centered interactivity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S001044850800198X},
volume = {42},
year = {2010}
}
@article{Malkawi2005,
author = {Malkawi, a and Srinivasan, R},
doi = {10.1016/j.autcon.2004.08.001},
file = {::},
issn = {09265805},
journal = {Automation in Construction},
keywords = {augmented reality,building interaction,cfd,gesture recognition,hci,human,speech recognition,visualization},
month = jan,
number = {1},
pages = {71--84},
title = {{A new paradigm for Human-Building Interaction: the use of CFD and Augmented Reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580504000998},
volume = {14},
year = {2005}
}
@phdthesis{DeLaRiviere2001,
author = {{De La Rivi\`{e}re}, Jean-Baptiste},
file = {::},
title = {{Interaction 3D : Utilisations Conjointes d’un pointeur Laser et d’un Grand Ecran}},
year = {2001}
}
@inproceedings{Fuhrmann1997,
author = {Fuhrmann, Anton and Liiffelmamr, Helwig and Schmalstieg, Dieter},
booktitle = {IEEE Visualization},
file = {::},
isbn = {0818682620},
pages = {459--462},
publisher = {IEEE Computer Society Press},
title = {{Collaborative augmented reality: exploring dynamical systems}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Collaborative+Augmented+Reality+:+Exploring+Dynamical+Systems#0},
volume = {97},
year = {1997}
}
@article{Schmalstieg2000,
abstract = {Studierstube is an experimental user integace system, which uses collaborative augmented reality to incorporate true 30 interaction into a productivity environment. This concept is extended to bridge multiple user integace dimensions by including multiple users, multiple host platforms, multiple display types, multiple concurrent applications, and a multi-context (i. e., 30 document) integace into a heterogeneous distributed environment. With this architecture, we can explore the user integace design space between pure augmented reality and the popular ubiquitous computing paradigm. We report on our design philosophy centered around the notion of contexts and locales, as well as the underlying sofhare and hardware architecture. Contexts encapsulate a live application together with 30 (visual) and other data, while locales are used to organize geometric reference systems. By separating geometric relationships (locales) from semantic relationships (contexts), we achieve a great amount of flexibility in the configuration of displays. To illustrate our claims, we present several applications including a cinematographic design tool which showcases many features of our system},
author = {Schmalstieg, D and Fuhrmann, A and Hesina, G},
doi = {10.1109/ISAR.2000.880919},
file = {::},
isbn = {0769508464},
journal = {Proceedings IEEE and ACM International Symposium on Augmented Reality ISAR 2000},
pages = {20--29},
publisher = {Ieee},
title = {{Bridging multiple user interface dimensions with augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=880919},
year = {2000}
}
@article{Pasman2006a,
author = {Woodward, Charles and Pasman, W.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings/2006/Woodward, Pasman/Woodward, Pasman - 2006 - Implementation of an Augmented Reality System on a PDA.pdf:pdf},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {276--277},
publisher = {IEEE Comput. Soc},
title = {{Implementation of an Augmented Reality System on a PDA}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240718},
year = {2006}
}
@article{Thomas2006,
author = {Thomas, GA},
doi = {10.1109/MCG.2010.23},
file = {::},
issn = {0272-1716},
journal = {Visual Media Production, 2006. CVMP 2006. 3rd},
month = may,
number = {3},
pages = {56--68},
title = {{Real-time camera pose estimation for augmenting sports scenes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5396282 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4156005},
volume = {31},
year = {2006}
}
@article{Mower2009,
author = {Mower, James E.},
doi = {10.1080/13658810802001313},
file = {::},
issn = {1365-8816},
journal = {International Journal of Geographical Information Science},
keywords = {augmented reality,dem,perspective imaging,tin},
month = aug,
number = {8},
pages = {993--1011},
title = {{Creating and delivering augmented scenes}},
url = {http://www.tandfonline.com/doi/abs/10.1080/13658810802001313},
volume = {23},
year = {2009}
}
@article{Coiras2007,
abstract = {A proof of concept for a model-less target detection and classification system for side-scan imagery is presented. The system is based on a supervised approach that uses augmented reality (AR) images for training computer added detection and classification (CAD/CAC) algorithms, which are then deployed on real data. The algorithms are able to generalise and detect real targets when trained on AR ones, with performances comparable with the state-of-the-art in CAD/CAC. To illustrate the approach, the focus is on one specific algorithm, which uses Bayesian decision and the novel, purpose-designed central filter feature extractors. Depending on how the training database is partitioned, the algorithm can be used either for detection or classification. Performance figures for these two modes of operation are presented, both for synthetic and real targets. Typical results show a detection rate of more that 95\% and a false alarm rate of less than 5\%. The proposed supervised approach can be directly applied to train and evaluate other learning algorithms and data representations. In fact, a most important aspect is that it enables the use of a wealth of legacy pattern recognition algorithms for the sonar CAD/CAC applications of target detection and target classification},
author = {Coiras, E and Mignotte, P Y and Petillot, Y and Bell, J and Lebart, K},
doi = {10.1049/iet-rsn:20060098},
file = {::},
issn = {17518784},
journal = {Radar Sonar Navigation IET},
number = {1},
pages = {83--90},
title = {{Supervised target detection and classification by training on augmented reality data}},
volume = {1},
year = {2007}
}
@article{Wither2011,
author = {Wither, Jason and Tsai, Yun-Ta and Azuma, Ronald},
doi = {10.1016/j.cag.2011.04.010},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Evaluation,Information Presentation,Mixed Reality,User Interface},
month = aug,
number = {4},
pages = {810--822},
publisher = {Elsevier},
title = {{Indirect augmented reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849311001130},
volume = {35},
year = {2011}
}
@article{Thomas2010,
abstract = {The use of Virtual Environments has been widely reported as a method of teaching anatomy. Generally such environments only convey the shape of the anatomy to the student. We present the Bangor Augmented Reality Education Tool for Anatomy (BARETA), a system that combines Augmented Reality (AR) technology with models produced using Rapid Prototyping (RP) technology, to provide the student with stimulation for touch as well as sight. The principal aims of this work were to provide an interface more intuitive than a mouse and keyboard, and to evaluate such a system as a viable supplement to traditional cadaver based education.},
author = {Thomas, Rhys Gethin and John, Nigel William and Delieu, John Michael},
doi = {10.3109/17453050903557359},
file = {::},
issn = {1745-3062},
journal = {Journal of visual communication in medicine},
keywords = {Anatomy,Anatomy: education,Cadaver,Computer Simulation,Consumer Satisfaction,Female,Humans,Magnetic Resonance Imaging,Male,Models, Biological,Pilot Projects,Sex Factors,User-Computer Interface},
month = mar,
number = {1},
pages = {6--15},
pmid = {20297908},
title = {{Augmented reality for anatomical education.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20297908},
volume = {33},
year = {2010}
}
@article{DeBoer2011,
author = {de Boer, Jelle and a.M. Kommers, Piet and de Brock, Bert},
doi = {10.1016/j.compedu.2010.10.015},
file = {::},
issn = {03601315},
journal = {Computers \& Education},
month = apr,
number = {3},
pages = {727--735},
publisher = {Elsevier Ltd},
title = {{Using learning styles and viewing styles in streaming video}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360131510003003},
volume = {56},
year = {2011}
}
@article{Kiyokawa2002,
author = {Kiyokawa, K. and Billinghurst, M. and Hayes, S.E. and Gupta, a. and Sannohe, Y. and Kato, H.},
doi = {10.1109/ISMAR.2002.1115083},
file = {::},
isbn = {0-7695-1781-1},
journal = {Proceedings. International Symposium on Mixed and Augmented Reality},
pages = {139--148},
publisher = {IEEE Comput. Soc},
title = {{Communication behaviors of co-located users in collaborative AR interfaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1115083},
year = {2002}
}
@article{Broll2004,
author = {Broll, Wolfgang and Lindt, Irma and Ohlenburg, J and Wittkamper, Michael and Yuan, C and Novotny, T and Schieck, A F and Mottram, C and Strothman, A},
file = {::},
issn = {18602037},
journal = {Journal of Virtual Reality and Broadcasting},
keywords = {architectural design,augmented reality,simu,tangible user,terfaces,urban planning},
number = {1},
pages = {1--10},
publisher = {Citeseer},
title = {{ARTHUR: A Collaborative Augmented Environment for Architectural Design and Urban Planning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.184&amp;rep=rep1&amp;type=pdf},
volume = {1},
year = {2004}
}
@article{Gee2011,
author = {Gee, Andrew P. and Webb, Matthew and Escamilla-Ambrosio, Jorge and Mayol-Cuevas, Walterio and Calway, Andrew},
doi = {10.1016/j.cag.2011.04.006},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Augmented reality,GPS,Topometric,UWB,Visual SLAM},
month = aug,
number = {4},
pages = {854--868},
publisher = {Elsevier},
title = {{A topometric system for wide area augmented reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849311001099},
volume = {35},
year = {2011}
}
@article{Wrzesien2010,
abstract = {Recent research presents Augmented Reality Exposure Therapy (ARET) for treatment of phobia of cockroaches as a potentially effective technique. However, to the authors' knowledge no studies have been published concerning the Human-Computer-Interaction issues of such a system. The aim of this paper is to report some preliminary data on how patients, therapists and an Augmented Reality system collaborate and interact during the therapeutic process. The results show that the therapeutic process is distributed between individuals (patient and therapist) and artifacts (e.g. AR cockroaches, a computer screen, a Head Mounted Display (HMD), a keyboard, a swatter and therapists' notes on paper). The results are discussed in terms of possible improvement of the ARET system.},
author = {Wrzesien, Maja and Burkhardt, Jean-Marie and {Alca\~{n}iz Raya}, Mariano and Botella, Cristina and {Bret\'{o}n L\'{o}pez}, Juana Maria},
file = {::},
institution = {Instituto Interuniversitario de Investigaci\'{o}n en Bioingenier\'{\i}a y Tecnolog\'{\i}a Orientada al Ser Humano, Universidad Polit\'{e}cnica de Valencia (I3BH), (UPV), 46022 Valencia, Espa\~{n}a. mwrzesien@labhuman.i3bh.es},
journal = {Studies In Health Technology And Informatics},
pages = {134--139},
pmid = {20543285},
title = {{Analysis of distributed-collaborative activity during augmented reality exposure therapy for cockroach phobia.}},
volume = {154},
year = {2010}
}
@article{Lamboray2004,
author = {Lamboray, E. and Wurmlin, S. and Gross, M.},
doi = {10.1109/VR.2004.1310060},
file = {::},
isbn = {0-7803-8415-6},
journal = {IEEE Virtual Reality 2004},
pages = {91--281},
publisher = {Ieee},
title = {{Real-time streaming of point-based 3D video}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1310060},
year = {2004}
}
@article{Lee2011,
author = {Lee, Jae Yeol and Seo, Dong Woo and Rhee, Gue Won},
doi = {10.1016/j.compind.2010.07.003},
file = {::},
issn = {01663615},
journal = {Computers in Industry},
month = jan,
number = {1},
pages = {107--119},
publisher = {Elsevier B.V.},
title = {{Tangible authoring of 3D virtual scenes in dynamic augmented reality environment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166361510001077},
volume = {62},
year = {2011}
}
@article{Bradley2007,
author = {Bradley, Derek and Roth, Gerhard and Bose, Prosenjit},
doi = {10.1007/s00138-007-0108-9},
file = {::},
isbn = {0013800701},
issn = {0932-8092},
journal = {Machine Vision and Applications},
keywords = {augmented reality,common illumination,marker systems,non-rigid object,tracking},
month = nov,
number = {2},
pages = {85--92},
title = {{Augmented reality on cloth with realistic illumination}},
url = {http://www.springerlink.com/index/10.1007/s00138-007-0108-9},
volume = {20},
year = {2007}
}
@article{Langlotz2011,
author = {Langlotz, Tobias and Degendorfer, Claus and Mulloni, Alessandro and Schall, Gerhard and Reitmayr, Gerhard and Schmalstieg, Dieter},
doi = {10.1016/j.cag.2011.04.004},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Annotation,Augmented reality,Mobile phone,Tracking},
month = aug,
number = {4},
pages = {831--840},
publisher = {Elsevier},
title = {{Robust detection and tracking of annotations for outdoor augmented reality browsing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849311001075},
volume = {35},
year = {2011}
}
@article{Nakanishi2008,
author = {Nakanishi, Miwa and Ozeki, Mugihiko and Akasaka, Toshiya and Okada, Yusaku},
doi = {10.4304/jmm.3.3.34-43},
file = {::},
issn = {17962048},
journal = {Journal of Multimedia},
number = {3},
pages = {34--43},
title = {{What Conditions are Required to Effectively Use Augmented Reality for Manuals in Actual Work}},
url = {http://ojs.academypublisher.com/index.php/jmm/article/view/2204},
volume = {3},
year = {2008}
}
@article{Xu2008,
author = {Xu, K},
doi = {10.1016/j.imavis.2007.08.015},
file = {::},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {augmented reality,fundamental matrix,homography,optical flow,vision based tracking},
month = may,
number = {5},
pages = {673--689},
title = {{Real-time camera tracking for marker-less and unprepared augmented reality environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885607001266},
volume = {26},
year = {2008}
}
@article{Knoerlein2007,
address = {New York, New York, USA},
author = {Knoerlein, Benjamin},
doi = {10.1145/1255047.1255065},
file = {::},
isbn = {9781595936400},
journal = {Proceedings of the},
keywords = {augmented reality,collaboration,haptics},
pages = {91},
publisher = {ACM Press},
title = {{Visuo-haptic collaborative augmented reality ping-pong}},
url = {http://portal.acm.org/citation.cfm?doid=1255047.1255065 http://portal.acm.org/citation.cfm?id=1255065},
year = {2007}
}
@article{Kala2010,
abstract = {Handwriting Recognition enables a person to scribble something on a piece of paper and then convert it into text. If we look into the practical reality there are enumerable styles in which a character may be written. These styles can be self combined to generate more styles. Even if a small child knows the basic styles a character can be written, he would be able to recognize characters written in styles intermediate between them or formed by their mixture. This motivates the use of Genetic Algorithms for the problem. In order to prove this, we made a pool of images of characters. We converted them to graphs. The graph of every character was intermixed to generate styles intermediate between the styles of parent character. Character recognition involved the matching of the graph generated from the unknown character image with the graphs generated by mixing. Using this method we received an accuracy of 98.44\%.},
author = {Kala, Rahul and Vazirani, Harsh and Shukla, Anupam and Tiwari, Ritu},
file = {::},
journal = {International Journal of Computer Science},
number = {2},
pages = {16--25},
title = {{Offline Handwriting Recognition using Genetic Algorithm}},
url = {http://arxiv.org/abs/1004.3257},
volume = {7},
year = {2010}
}
@inproceedings{Brauer-Burchardt2000,
author = {Brauer-Burchardt, C and Voss, K},
booktitle = {Proceedings 15th International Conference on Pattern Recognition ICPR2000},
pages = {559--562},
publisher = {IEEE Comput. Soc},
title = {{Robust vanishing point determination in noisy images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=905399},
year = {2000}
}
@book{Hartley2004,
author = {Hartley, R and Zisserman, Andrew},
booktitle = {Cambridge UK Cambridge Univ Press},
title = {{Multiple View Geometry in Computer Vision, 2nd ed}},
volume = {0521540518},
year = {2004}
}
@article{Wang1991,
author = {Wang, Ling-Ling and Tsai, Wen-Hsiang},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {4},
pages = {370--376},
title = {{Camera calibration by vanishing lines for 3-D computer vision}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=88572},
volume = {13},
year = {1991}
}
@book{Hartley2004a,
abstract = {How to reconstruct scenes from images using geometry and algebra, with applications to computer vision.},
author = {Hartley, R and Zisserman, Andrew},
chapter = {189},
pages = {672},
publisher = {Cambridge University Press},
title = {{Multiple View Geometry in Computer Vision}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0521540518},
year = {2004}
}
@incollection{Mohr1992,
abstract = {Une petite lecon de geometrie avec des parties nouvelles dans le domaine.},
author = {Mohr, R},
booktitle = {Handbook of Pattern Recognition and Computer Vision},
chapter = {2.4},
pages = {369--393},
publisher = {World Scientific},
title = {{Projective Geometry and Computer Vision}},
year = {1992}
}
@article{Cantzler1981,
author = {Cantzler, H},
journal = {Institute for PerceptionAction and Behaviour Division},
pages = {2--5},
title = {{Random sample consensus (ransac)}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.3035&amp;rep=rep1&amp;type=pdf},
year = {1981}
}
@article{Leung2006,
abstract = {For Gaussian regression, we develop and analyze methods for combining estimators from various models. For squared-error loss, an unbiased estimator of the risk of the mixture of general estimators is developed. Special attention is given to the case that the component estimators are least-squares projections into arbitrary linear subspaces, such as those spanned by subsets of explanatory variables in a given design. We relate the unbiased estimate of the risk of the mixture estimator to estimates of the risks achieved by the components. This results in simple and accurate bounds on the risk and its estimate, in the form of sharp and exact oracle inequalities. That is, without advance knowledge of which model is best, the resulting performance is comparable to or perhaps even superior to what is achieved by the best of the individual models. Furthermore, in the case that the unknown parameter has a sparse representation, our mixture estimator adapts to the underlying sparsity. Simulations show that the performance of these mixture estimators is better than that of a related model-selection estimator which picks a model with the highest weight. Also, the connection between our mixtures with Bayes procedures is discussed.},
author = {Leung, G},
journal = {IEEE Transactions on Information Theory},
number = {8},
pages = {3396--3410},
title = {{Information Theory and Mixing Least-Squares Regressions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1661826},
volume = {52},
year = {2006}
}
@article{Nieto2007,
author = {Nieto, Marcos and Salgado, Luis and Jaureguizar, Fernando and Cabrera, Julian},
journal = {2007 IEEE Intelligent Vehicles Symposium},
pages = {315--320},
publisher = {Ieee},
title = {{Stabilization of Inverse Perspective Mapping Images based on Robust Vanishing Point Estimation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4290133},
year = {2007}
}
@article{Torr2000,
author = {Torr, P},
institution = {MSR},
journal = {Computer Vision and Image Understanding},
number = {1},
pages = {138--156},
publisher = {Citeseer},
title = {{MLESAC: A New Robust Estimator with Application to Estimating Image Geometry}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314299908329},
volume = {78},
year = {2000}
}
@article{Landsberg2002,
abstract = {We give an elementary introduction to our papers relating the geometry of rational homogeneous varieties to representation theory. We also describe related work and recent progress.},
author = {Landsberg, J M and Manivel, L},
journal = {Algebraic transformation groups and algebraic varieties proceedings of the conference Interesting algebraic varieties arising in algebraic transformation group theory held at the Erwin Schr\"{o}dinger Institute Vienna October 2226 2001},
pages = {37},
publisher = {Springer Verlag},
title = {{Representation theory and projective geometry}},
url = {http://arxiv.org/abs/math/0203260},
volume = {132},
year = {2002}
}
@article{Kong2009,
abstract = {Given a single image of an arbitrary road, that may not be well-paved, or have clearly delineated edges, or some a priori known color or texture distribution, is it possible for a computer to find this road? This paper addresses this question by decomposing the road detection process into two steps: the estimation of the vanishing point associated with the main (straight) part of the road, followed by the segmentation of the corresponding road area based on the detected vanishing point. The main technical contributions of the proposed approach are a novel adaptive soft voting scheme based on variable-sized voting region using confidence-weighted Gabor filters, which compute the dominant texture orientation at each pixel, and a new vanishingpoint- constrained edge detection technique for detecting road boundaries. The proposed method has been implemented, and experiments with 1003 general road images demonstrate that it is both computationally efficient and effective at detecting road regions in challenging conditions.},
author = {Kong, Hui and Audibert, Jean-Yves and Ponce, Jean},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (2009)},
keywords = {machine vision},
number = {3},
pages = {96--103},
publisher = {Ieee},
title = {{Vanishing point detection for road detection}},
url = {http://eprints.pascal-network.org/archive/00006913/},
year = {2009}
}
@article{Derpanis2005,
author = {Derpanis, K G},
journal = {csyorkuca},
pages = {1--2},
title = {{Overview of the RANSAC Algorithm}},
url = {http://www.cs.yorku.ca/~kosta/CompVis_Notes/ransac.pdf},
volume = {4},
year = {2005}
}
@misc{Tokekar2008,
author = {Tokekar, Pratap},
booktitle = {Transform},
title = {{Vanishing points based navigation}},
year = {2008}
}
@article{Dornaika1999,
abstract = {The problem of a real-time pose estimation between a 3D scene and a single camera is a fundamental task in most 3D computer vision and robotics applications such as object tracking, visual servoing, and virtual reality. In this paper we present two fast methods for estimating the 3D pose using 2D to 3D point and line correspondences. The first method is based on the iterative use of a weak perspective camera model and forms a generalization of DeMenthon's method (1995) which consists of determining the pose from point correspondences. In this method the pose is iteratively improved with a weak perspective camera model and at convergence the computed pose corresponds to the perspective camera model. The second method is based on the iterative use of a paraperspective camera model which is a first order approximation of perspective. We describe in detail these two methods for both non-planar and planar objects. Experiments involving synthetic data as well as real range data indicate the feasibility and robustness of these two methods. We analyse the convergence of these methods and we conclude that the iterative paraperspective method has better convergence properties than the iterative weak perspective method. We also introduce a non-linear optimization method for solving the pose problem. (C) 1999 Academic Press.},
author = {Dornaika, F},
journal = {RealTime Imaging},
number = {3},
pages = {215--230},
title = {{Pose estimation using point and line correspondences}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077201497901170},
volume = {5},
year = {1999}
}
@article{Barnard1983,
abstract = {Ce papier parle des contraintes perspective: notamment les points de fuite, l'angle etc. pas mal.},
author = {Barnard, S T},
journal = {Artificial Intelligence},
number = {4},
pages = {435--462},
title = {{Interpreting Perspective Images}},
url = {http://dx.doi.org/10.1016/S0004-3702(83)80021-6},
volume = {21},
year = {1983}
}
@article{Havasi2006,
abstract = {Knowledge of the position of the vanishing point is the key for geometrical modeling of an image containing a reflective surface or cast shadows. Such an image can be analyzed as two subimages that constitute a stereo pair. For this model-estimation task an automatic method is presented that utilizes motion statistics and the statistical properties of image points for the determination of point correspondence and the subsequent estimation of vanishing point position, optimized by use of a goodness-of-fit function. We show that this approach gives robust results in widely different real-world environments, even when the correspondence is corrupted with considerable amounts of noise.},
author = {Havasi, L\'{a}szl\'{o} and Szir\'{a}nyi, Tam\'{a}s},
institution = {Faculty of Information Technology, P\'{e}ter P\'{a}zm\'{a}ny Catholic University, Budapest Pr\'{a}ter Utca, Hungary. havasi@digitus.itk.ppke.hu},
journal = {Optics Letters},
number = {10},
pages = {1411--1413},
title = {{Estimation of the vanishing point in camera-mirror scenes from video.}},
volume = {31},
year = {2006}
}
@book{Trucco1998,
author = {Trucco, E and Verri, A},
pages = {1--212},
publisher = {Prentice Hall},
title = {{Introductory Techniques for 3-D Computer Vision}},
url = {http://www.amazon.com/Introductory-Techniques-3-D-Computer-Vision/dp/0132611082},
year = {1998}
}
@article{Chen1996,
abstract = {An inverse eigenvalue problem, where a matrix is to be constructed from some or all of its eigenvalues, may not have a real-valued solution at all. An approximate solution in the sense of least squares is sometimes desirable. Two types of least squares problems are formulated and explored in this paper. In spite of their different appearance, the two problems are shown to be equivalent. Thus one new numerical method, modified from the conventional alternating projection method, is proposed. The method converges linearly and globally and can be used to generate good starting values for other faster but more expensive and locally convergent methods. The idea can be applied to multiplicative inverse eigenvalue problems for the purpose of preconditioning. Numerical examples are presented.},
author = {Chen, Xuzhou and Chu, Moody Ten-Chao},
journal = {SIAM Journal on Numerical Analysis},
keywords = {inverse eigenvalue problem,least squares,lift projection},
number = {6},
pages = {2417},
title = {{On the Least Squares Solution of Inverse Eigenvalue Problems}},
url = {http://link.aip.org/link/SJNAAM/v33/i6/p2417/s1&Agg=doi},
volume = {33},
year = {1996}
}
@article{Tai1993,
author = {Tai, A and Kittler, J and Petrou, M and Windeatt, T},
journal = {Image and Vision Computing},
number = {4},
pages = {240--245},
title = {{Vanishing point detection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/026288569390042F},
volume = {11},
year = {1993}
}
@article{Marquez-Neila2008,
author = {Marquez-Neila, Pablo and {Garcia Miro}, Jacobo and Buenaposada, Jose M and Baumela, Luis},
journal = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
pages = {1--8},
publisher = {Ieee},
title = {{Improving RANSAC for fast landmark recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4563138},
year = {2008}
}
@article{McLean1995,
abstract = {This paper presents a new method for the detection of vanishing points based on sub-pixel line descriptions which recognizes the existence of errors in feature detection and which does not rely on supervision or the arbitrary specification of thresholds. Image processing and image analysis are integrated into a coherent scheme which extracts straight line structure from images, develops a measure of line quality for each line, estimates the number of vanishing points and their approximate orientations, and then computes optimal vanishing point estimates through combined clustering and numerical optimization. Both qualitative and quantitative evaluation of the algorithms performance is included in the presentation},
author = {McLean, G F and Kotturi, D},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {11},
pages = {1090--1095},
title = {{Vanishing point detection by line clustering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=473236},
volume = {17},
year = {1995}
}
@inproceedings{Belluta1989,
author = {Belluta, P and Collini, G and Verri, V and Torre, V},
booktitle = {IEEE Workshop on interpretation of 3D scenes},
pages = {41--49},
title = {{3D visual information from vanishing points}},
year = {1989}
}
@inproceedings{Castelpietra2000,
abstract = {Coordination among multiple robots has been extensively studied, since a number of practical tasks can be performed in a more effective way by employing a fleet of coordinated robotic bases. In particular, distributed coordination among robotic agents has been considered within the framework offered by the robotic soccer competitions. We describe the methods and the results achieved in coordinating the players of the ART team participating in the RoboCup F-2000 league. The team is formed by several heterogeneous robots having different mechanics, different sensors, different control software, and, in general, different abilities for playing soccer. The coordination framework we have developed has been successfully applied during the 1999 official competitions allowing both for a significant improvement of the overall team performance and for a complete interchangeability of all the robots},
author = {Castelpietra, C and Iocchi, L and Nardi, D and Piaggio, M and Scalzo, A and Sgorbissa, A},
booktitle = {Intelligent Robots and Systems 2000 IROS 2000 Proceedings 2000 IEEERSJ International Conference on},
pages = {1385 --1390 vol.2},
title = {{Coordination among Heterogeneous Robotic Soccer Players}},
volume = {2},
year = {2000}
}
@article{Zhang2009,
abstract = {Road detection is a crucial part of autonomous driving system. Most of the methods proposed nowadays only achieve reliable results in relatively clean environments. In this paper, we combine edge detection with road area extraction to solve this problem. Our method works well even on noisy campus road whose boundaries are blurred with sidewalks and surface is often covered with unbalanced sunlight. First, segmentation is done and the segments which belong to road are chosen and merged. Second, we use Hough transform and a voting method to get the vanishing point. Then, the boundaries are searched according to the road shape. We also employ prediction to make our method achieve better performance in video sequence. Our method is fast enough to meet real-time requirement. Experiments were carried out on the intelligent vehicle SpringRobot (Fig. 1) on campus roads, which is a good representation of urban environment.},
author = {Zhang, G and Zheng, N N and Cui, C and Yan, Y Z and Yuan, Z J},
journal = {2009 Ieee Intelligent Vehicles Symposium Vols 1 and 2},
keywords = {segmentation,system},
pages = {556--561 1424},
title = {{An Efficient Road Detection Method In Noisy Urban Environment}},
year = {2009}
}
@book{Fusiello2005,
author = {Fusiello, Andrea},
booktitle = {International Journal of Computer Vision},
number = {2},
pages = {123--140},
title = {{Elements of Computer Vision: Multiple View Geometry}},
url = {http://www.springerlink.com/index/10.1007/s11263-005-3954-9},
volume = {66},
year = {2005}
}
@misc{Toussaint1990,
author = {Toussaint, G},
institution = {McGill Univ.},
title = {{Computational geometry and computer vision}},
year = {1990}
}
@article{Guillemaut2005,
abstract = {The majority of camera calibration methods, including the Gold Standard algorithm, use point-based information and simultaneously estimate all calibration parameters. In contrast, we propose a novel calibration method that exploits line orientation information and decouples the problem into two simpler stages. We formulate the problem as minimization of the lateral displacement between single projected image lines and their vanishing points. Unlike previous vanishing point methods, parallel line pairs are not required. Additionally, the invariance properties of vanishing points mean that multiple images related by pure translation can be used to increase the calibration data set size without increasing the number of estimated parameters. We compare this method with vanishing point methods and the Gold Standard algorithm and demonstrate that it has comparable performance.},
author = {Guillemaut, Jean-Yves and Aguado, Alberto S and Illingworth, John},
institution = {School of Electronics and Physical Sciences, University of Surrey, Guildford, Surrey, GU2 7XH, UK. jean-yves.guillemaut@surrey.ac.uk},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {2},
pages = {265--270},
title = {{Using points at infinity for parameter decoupling in camera calibration.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15688563},
volume = {27},
year = {2005}
}
@inproceedings{Rother2002,
author = {Rother, C},
booktitle = {Proceedings of the British Machine Vision Conference BMVC},
keywords = {computer,vision},
title = {{A new approach for vanishing point detection in architectural environments}},
volume = {20},
year = {2002}
}
@incollection{Baer2007,
author = {Baer, Philipp A},
chapter = {Communicat},
pages = {1--28},
publisher = {I-Tech Education and Publishing},
title = {{Robotic Soccer}},
url = {http://purl.org/spica/robotic-soccer-ars},
year = {2007}
}
@article{Okada2003,
author = {Okada, Ryuzo and Taniguchi, Yasuhiro and Furukawa, Kenji and Onoguchi, Kazunori and Corporation, Toshiba},
journal = {Proceedings Ninth IEEE International Conference on Computer Vision},
number = {Iccv},
pages = {330--337 vol.1},
publisher = {Ieee},
title = {{Obstacle detection using projective invariant and vanishing lines}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1238363},
year = {2003}
}
@article{York1966,
author = {York, D},
journal = {Canadian J of Phys},
keywords = {VAN},
pages = {1079--1086},
title = {{Least squares fitting of a straight line}},
volume = {44},
year = {1966}
}
@article{Caprile1990,
abstract = {D crire qq. proprietes interessantes de points de fuite, et de l , ils calibrent la camera.},
author = {Caprile, B and Torre, V},
journal = {International Journal of Computer Vision},
number = {2},
pages = {127--140},
publisher = {Springer},
title = {{Using vanishing points for camera calibration}},
url = {http://www.springerlink.com/index/k75077108473tm15.pdf},
volume = {4},
year = {1990}
}
@article{Magee1984,
author = {Magee, M J and Aggarwal, J K},
journal = {Computer Vision Graphics and Image Processing},
number = {2},
pages = {256--267},
publisher = {Elsevier},
title = {{Determining Vanishing Points From Perspective Images}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0734189X84901889},
volume = {26},
year = {1984}
}
@article{Geyer2001,
author = {Geyer, C and Daniilidis, K},
journal = {International Journal of Computer Vision},
number = {3},
pages = {223--243},
title = {{Catadioptric Projective Geometry}},
volume = {45},
year = {2001}
}
@misc{Zuliani2008,
author = {Zuliani, Marco},
booktitle = {October},
publisher = {MathWorks, URL:" http://www. mathworks. com", November},
title = {{RANSAC for Dummies}},
url = {http://vision.ece.ucsb.edu/~zuliani/Research/RANSAC/docs/RANSAC4Dummies.pdf},
year = {2008}
}
@article{Brillault-O'Mahony1991,
abstract = {Another method to extract major vanishing points in a inddor secne. .},
author = {Brillault-O'Mahony, B},
institution = {EDF-Direction des Etudes et Recherches},
pages = {289--300},
title = {{New Method for Vanishing Point Detection}},
volume = {54},
year = {1991}
}
@article{Barwick2006,
abstract = {The ARIANNA concept utilizes the Ross Ice Shelf near the coast of Antarctica to increase the sensitivity to cosmogenic neutrinos by roughly an order of magnitude when compared to the sensitivity of existing detectors and those under construction. Therefore, ARIANNA can test a wide variety of scenarios for GZK neutrino production, and probe for physics beyond the standard model by measuring the neutrino cross-section at center of momentum energies near 100 TeV. ARIANNA capitalizes on several remarkable properties of the Ross Ice Shelf: shelf ice is relatively transparent to electromagnetic radiation at radio frequencies and the water-ice boundary below the shelf creates a good mirror to reflect radio signals from neutrino interactions in any downward direction. The high sensitivity results from nearly six months of continuous operation, low energy threshold (\~{}3x10\^{}17 eV), and more than 2pi of sky coverage. The baseline concept for ARIANNA consists of moderately high gain antenna stations arranged on a 100 x 100 square grid, separated by about 300m. Each station consists of a small group of cross-polarized antennas residing just beneath the snow surface and facing downwards. They communicate with a central control hub by wireless links to generate global triggers.},
author = {Barwick, Steven W},
pages = {8},
title = {{ARIANNA: A New Concept for UHE Neutrino Detection}},
url = {http://arxiv.org/abs/astro-ph/0610631},
year = {2006}
}
@article{Stone2001,
author = {Stone, Peter and McAllester, David},
editor = {M�ller, J�rg P and Andre, Elisabeth and Sen, Sandip and Frasson, Claude},
journal = {International Conference on Autonomous Agents},
pages = {316--323},
publisher = {ACM Press},
title = {{An Architecture for Action Selection in Robotic Soccer}},
year = {2001}
}
@article{Schaffalitzky2000,
abstract = {A method for detecting repeated patterns in images and, based on repetitions, vanishing points and lines. Peter.},
author = {Schaffalitzky, F and Zisserman, Andrew},
journal = {Image and Vision Computing},
pages = {647--658},
title = {{Planar Grouping for Automatic Detection of Vanishing Lines and Points}},
url = {http://www.robots.ox.ac.uk/~vgg},
volume = {18},
year = {2000}
}
@inproceedings{Hartley1999,
author = {Hartley, Richard and Zisserman, Andrew},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (2008)},
number = {June},
title = {{Tutorial on Multiple View Geometry}},
year = {1999}
}
@inproceedings{Rasmussen2004,
author = {Rasmussen, C},
booktitle = {British Machine Vision Conference},
title = {{Texture-Based Vanishing Point Voting for Road Shape Estimation}},
year = {2004}
}
@incollection{Bevington2002,
author = {Bevington, Philip},
booktitle = {Data Reduction and Error Analysis for the Physical Sciences},
chapter = {6},
title = {{Least-Squares Fit to a Straight Line}},
year = {2002}
}
@inproceedings{Dubrofsky2008,
author = {Dubrofsky, Elan and Woodham, Robert J},
booktitle = {4th International Symposium ISVC 2008},
pages = {202--213},
publisher = {Springer},
title = {{Combining Line and Point Correspondences for Homography Estimation}},
year = {2008}
}
@misc{Mohr1996,
author = {Mohr, R and Triggs, B},
booktitle = {Int Symp Photogrammetry and Remote Sensing},
institution = {ISPRS workshop tutorial},
number = {July},
publisher = {Citeseer},
title = {{Projective Geometry for Image Analysis}},
url = {http://www-kogs.iitb.fhg.de/~cveducat/ECV_Tut_Proj_Geom/ProjGeometry.html},
year = {1996}
}
@article{Delphenich2005,
abstract = {Some concepts of real and complex projective geometry are applied to the fundamental physical notions that relate to Minkowski space and the Lorentz group. In particular, it is shown that the transition from an infinite speed of propagation for light waves to a finite one entails the replacement of a hyperplane at infinity with a light cone and the replacement of an affine hyperplane - or rest space - with a proper time hyperboloid. The transition from the metric theory of electromagnetism to the pre-metric theory is discussed in the context of complex projective geometry, and ultimately it is proposed that the geometrical issues are more general than electromagnetism, namely, they pertain to the transition from point mechanics to wave mechanics.},
author = {Delphenich, David},
journal = {Philosophy of Science},
number = {425--438},
pages = {41},
title = {{Projective geometry and special relativity}},
url = {http://arxiv.org/abs/gr-qc/0512125},
volume = {46},
year = {2005}
}
@article{Almansa2003,
abstract = {Even though vanishing points in digital images result from parallel lines in the 3D scene, most of the proposed detection algorithms are forced to rely heavily either on additional properties (like orthogonality or coplanarity and equal distance) of the underlying 3D lines, or on knowledge of the camera calibration parameters, in order to avoid spurious responses. In this work, we develop a new detection algorithm that relies on the Helmoltz principle recently proposed for computer vision by Desolneux et al (2001; 2003), both at the line detection and line grouping stages. This leads to a vanishing point detector with a low false alarms rate and a high precision level, which does not rely on any a priori information on the image or calibration parameters, and does not require any parameter tuning.},
author = {Almansa, A and Desolneux, A and Vamech, S},
journal = {Transactions on Pattern Analysis and Machine Intelligence},
number = {4},
pages = {502--507},
title = {{Vanishing point detection without any a priori information}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190575},
volume = {25},
year = {2003}
}
@article{Burkhard2007,
author = {Burkhard, Hans-Dieter and Berger, Ralf},
journal = {CaseBased Reasoning Research and Development},
pages = {1--15},
title = {{Cases in Robotic Soccer}},
url = {http://dx.doi.org/10.1007/978-3-540-74141-1_1},
year = {2007}
}
@article{Schaefer2006,
abstract = {We provide an image deformation method based on Moving Least Squares using various classes of linear functions including affine, similarity and rigid transformations. These deformations are realistic and give the user the impression of manipulating real-world objects. We also allow the user to specify the deformations using either sets of points or line segments, the later useful for controlling curves and profiles present in the image. For each of these techniques, we provide simple closed-form solutions that yield fast deformations, which can be performed in real-time.},
author = {Schaefer, S and McPhail, T and Warren, J},
journal = {ACM Transactions on Graphics},
keywords = {deformations,moving least squares,rigid transforma},
number = {3},
pages = {533},
publisher = {ACM},
title = {{Image deformation using moving least squares}},
url = {http://portal.acm.org/citation.cfm?doid=1141911.1141920},
volume = {25},
year = {2006}
}
@inproceedings{Liebowitz1998a,
abstract = {We describe the geometry constraints and algorithmic implementation for metric rectification of planes. The rectification allows metric properties, such as angles and length ratios, to be measured on the world plane from a perspective image. The novel contributions are: first, that in a stratified context the various forms of providing metric information, which include a known angle, two equal though unknown angles, and a known length ratio; can all be represented as circular constraints on the parameters of an affine transformation of the plane-this provides a simple and uniform framework for integrating constraints; second, direct rectification from right angles in the plane; third, it is shown that metric rectification enables calibration of the internal camera parameters; fourth, vanishing points are estimated using a Maximum Likelihood estimator; fifth, an algorithm for automatic rectification. Examples are given for a number of images, and applications demonstrated for texture map acquisition and metric measurements},
author = {Liebowitz, David and Zisserman, Andrew},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
organization = {Citeseer},
pages = {482--488},
publisher = {IEEE Comput. Soc},
title = {{Metric rectification for perspective images of planes}},
url = {http://www.robots.ox.ac.uk/~vgg/publications/papers/liebowitz98.pdf},
year = {1998}
}
@article{Tardif2009,
author = {Tardif, J P},
journal = {12th IEEE International Conference on Computer Vision Kyoto Japan September 27 October 4 2009},
number = {Iccv},
title = {{Non-iterative Approach for Fast and Accurate Vanishing Point Detection}},
year = {2009}
}
@article{Birchfield1998,
abstract = {These lecture notes attempt to explain the main ideas of the theory of the quantum Hall effect. The emphasis is on the localization and interaction physics in the extreme quantum limit which gives rise to the quantum Hall effect. The interaction physics in the extreme quantum limit which is responsible for the fractional quantum Hall effect is discussed at length and from an elementary point of view.},
author = {Birchfield, Stan},
pages = {278},
publisher = {Springer},
title = {{An Introduction to Projective Geometry}},
url = {http://arxiv.org/abs/cond-mat/9410047},
year = {1998}
}
@article{Fischler1981,
abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing},
author = {Fischler, Martin A and Bolles, Robert C},
journal = {Communications of the ACM},
number = {6},
pages = {381--395},
publisher = {ACM},
title = {{Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography}},
url = {http://portal.acm.org/citation.cfm?doid=358669.358692},
volume = {24},
year = {1981}
}
@article{Grammatikopoulos2007,
author = {Grammatikopoulos, L and Karras, G and Petsa, E},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {automation,calibration,distortion,edge,extraction},
number = {1},
pages = {64--76},
title = {{An automatic approach for camera calibration from vanishing points}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0924271607000081},
volume = {62},
year = {2007}
}
@article{Liu2007,
abstract = {A fast method for vanishing point (VP) estimation and tracking in road images and its application for lane detection are investigated in this paper. After determine the region of interest of the road images, we use 'Sobel' operator to detect boundaries. Then the boundary image is transformed to the Hough Space by Hough Transform. We proposed a Gaussian Predication Model on the basis of the latest vanishing point to predicate the current VP, and we constructed an objective function including the linear segment intensity and the predicated VP, subsequently the optimal position of the VP is estimated through the least square method. The computational complexity of the estimation algorithm is 0(n), which can operate in real time. We test our algorithm on many structured road and semi-structured road images, the results show that it can robustly determine the VP position regardless the disturbance of around pedestrian, crowd and vehicles. Moreover, experiments on PETS2001 dataset show its application to the road lane detection for the driver assistant system. 2006 IEEE.},
author = {Liu, Hua-Jun and Birner, Regina},
pages = {170},
publisher = {John Benjamins Publishing Co},
title = {{A fast method for vanishing point estimation and tracking and its application in road images}},
url = {http://dx.doi.org/10.1109/ITST.2006.288791},
year = {2007}
}
@book{Hartley2003,
abstract = {How to reconstruct scenes from images using geometry and algebra, with applications to computer vision.},
author = {Hartley, R and Zisserman, A},
institution = {Cambridge University Press},
publisher = {Cambridge Univ Pr},
title = {{Multiple View Geometry in Computer Vision}},
url = {http://books.google.co.uk/books?hl=en&lr=&id=si3R3Pfa98QC&oi=fnd&pg=PR11&dq=multi+view+geometry+hartley&ots=aPv1ip987I&sig=NkRc7wSgKBQ8EVhqqJoDCzr-z0k},
year = {2003}
}
@article{Barnard1983a,
abstract = {Ce papier parle des contraintes perspective: notamment les points de fuite, l'angle etc. pas mal.},
author = {Barnard, S T},
journal = {Artificial Intelligence},
number = {4},
pages = {435--462},
title = {{Interpreting Perspective Images}},
url = {http://dx.doi.org/10.1016/S0004-3702(83)80021-6},
volume = {21},
year = {1983}
}
@article{Almansa2003a,
abstract = {Even though vanishing points in digital images result from parallel lines in the 3D scene, most of the proposed detection algorithms are forced to rely heavily either on additional properties (like orthogonality or coplanarity and equal distance) of the underlying 3D lines, or on knowledge of the camera calibration parameters, in order to avoid spurious responses. In this work, we develop a new detection algorithm that relies on the Helmoltz principle recently proposed for computer vision by Desolneux et al (2001; 2003), both at the line detection and line grouping stages. This leads to a vanishing point detector with a low false alarms rate and a high precision level, which does not rely on any a priori information on the image or calibration parameters, and does not require any parameter tuning.},
author = {Almansa, A and Desolneux, A and Vamech, S},
journal = {Transactions on Pattern Analysis and Machine Intelligence},
number = {4},
pages = {502--507},
title = {{Vanishing point detection without any a priori information}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190575},
volume = {25},
year = {2003}
}
@article{Olsson2009,
abstract = {Work in multiple view geometry has focused on obtaining globally optimal solutions at the price of computational time efficiency. On the other hand, traditional bundle adjustment algorithms have been found to provide good solutions even though there may be multiple local minima. In this paper we justify this observation by giving a simple sufficient condition for global optimality that can be used to verify that a solution obtained from any local method is indeed global. The method is tested on numerous problem instances of both synthetic and real data sets. In the vast majority of cases we are able to verify that the solutions are optimal, in particular for small-scale problems. We also develop a branch and bound procedure that goes beyond verification. In cases where the sufficient condition does not hold, the algorithm returns either of the following two results: (i) a certificate of global optimality for the local solution or (ii) the global solution.},
author = {Olsson, Carl and Kahl, Fredrik},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (2009)},
pages = {1216--1223},
publisher = {Ieee},
title = {{Projective Least-Squares: Global Solutions with Local Optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206864},
year = {2009}
}
@inproceedings{Kumar2003,
abstract = {This paper considers video surveillance applied to traffic video streams. We present a framework for analyzing and recognizing different traffic behaviors from image sequences acquired from a fixed camera. Two types of interactions have been mainly considered. In one there is interaction between two or more mobile objects in the Field of View (FOV) of the camera. The other is interaction between mobile objects and static objects in the environment. The framework is based on two types of a priori information: (1) the contextual information of the cameras FOV, in terms of the description of the different static objects of the scene and (2) sets of predefined behavior scenarios, which need to be analyzed in different contexts. At present the system is designed to recognize behavior from stored videos and retrieve the frames in which the specific behaviors took place. We demonstrate successful behavior recognition results for pedestrian-vehicle interaction and vehicle-checkpost interactions.},
author = {Kumar, Pankaj and Ranganath, Surendra and Sengupta, Kuntal},
booktitle = {Intelligent Transportation Systems 2003 Proceedings 2003 IEEE},
number = {2},
pages = {201--209},
publisher = {IEEE},
title = {{Behavior Interpretation from Traffic Video Streams}},
volume = {25},
year = {2003}
}
@article{Zhang1997,
abstract = {The most commonly used techniques for parameter estimation are presented. Particular attention has been devoted to discussions about the choice of appropriate minimization criteria and the robustness of the different techniques. Their application to conic fitting is described. Zhong-Dan LAN zhong-dan.lanimag.fr},
author = {Zhang, Z},
institution = {$\backslash$sc inria},
journal = {Image and Vision Computing},
number = {1},
pages = {59--76},
title = {{Parameter estimation techniques: a tutorial with application to conic fitting}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885696011122},
volume = {15},
year = {1997}
}
@article{Lozano1992,
author = {Lozano, R and Brogliato, B},
journal = {IEEE Transactions on Automatic Control},
number = {1},
pages = {30--37},
title = {{Adaptive control of a simple nonlinear system without a priori information on the plant parameters}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=109636},
volume = {37},
year = {1992}
}
@techreport{Kim2006,
author = {Kim, Zuwhan},
title = {{Geometry of Vanishing Points and its Application to External Calibration and Realtime Pose Estimation}},
year = {2006}
}
@article{Gonzalez2009,
author = {Gonz\'{a}lez, Javier and Pe\~{n}a, Daniel and Romera, Rosario},
journal = {Journal of Chemometrics},
keywords = {donoho estimator,kurtosis,projections,robust covariance matrix,stahel},
number = {2},
pages = {78--90},
title = {{A robust partial least squares regression method with applications}},
url = {http://doi.wiley.com/10.1002/cem.1195},
volume = {23},
year = {2009}
}
@article{Li2005,
abstract = {We describe an algorithm, ReAS, to recover ancestral sequences for transposable elements (TEs) from the unassembled reads of a whole genome shotgun. The main assumptions are that these TEs must exist at high copy numbers across the genome and must not be so old that they are no longer recognizable in comparison to their ancestral sequences. Tested on the japonica rice genome, ReAS was able to reconstruct all of the high copy sequences in the Repbase repository of known TEs, and increase the effectiveness of RepeatMasker in identifying TEs from genome sequences.},
author = {Li, Ruiqiang and Ye, Jia},
institution = {James D. Watson Institute of Genome Sciences of Zhejiang University, Hangzhou, China.},
journal = {Computational Statistics},
keywords = {robust estimation},
number = {4},
pages = {329--339},
title = {{Trimmed Least Squares Estimator Resistant to Leverage Points}},
volume = {2},
year = {2005}
}
@article{Barreto2005,
abstract = {In central catadioptric systems, lines in a scene are projected to conic curves in the image. This work studies the geometry of the central catadioptric projection of lines and its use in calibration. It is shown that the conic curves where the lines are mapped possess several projective invariant properties. From these properties, it follows that any central catadioptric system can be fully calibrated from an image of three or more lines. The image of the absolute conic, the relative pose between the camera and the mirror, and the shape of the reflective surface can be recovered using a geometric construction based on the conic loci where the lines are projected. This result is valid for any central catadioptric system and generalizes previous results for paracatadioptric sensors. Moreover, it is proven that systems with a hyperbolic/elliptical mirror can be calibrated from the image of two lines. If both the shape and the pose of the mirror are known, then two line images are enough to determine the image of the absolute conic encoding the camera's intrinsic parameters. The sensitivity to errors is evaluated and the approach is used to calibrate a real camera.},
author = {Barreto, Jo\~{a}o P and Araujo, Helder},
institution = {Institute for Systems and Robotics, Department of Electrical and Computer Engineering, Polo II, University of Coimbra, 3030 Coimbra, Portugal. jpbar@isr.uc.pt},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {8},
pages = {1327--1333},
title = {{Geometric properties of central catadioptric line images and their application in calibration.}},
volume = {27},
year = {2005}
}
@article{Rasmussen2008,
abstract = {We present a vision- and ladar-based approach to autonomous driving on rural and desert roads that has been tested extensively in a closed-loop system. The vision component uses Gabor wavelet filters for texture analysis to find ruts and tracks from which the road vanishing point can be inferred via Hough-style voting, yielding a direction estimate for steering control. The ladar component projects detected obstacles along the road direction onto the plane of the front of the vehicle and tracks the 1-D obstacle "gap" presumed due to the road to yield a lateral offset estimate. Several image- and state-based tests to detect failure conditions such as off-road poses (i.e., there is no road to follow) and poor lighting due to sun glare or distracting shadows are also explained. The system's efficacy is demonstrated with analysis of diverse logged data including from the 2005 DARPA Grand Challenge, as well as tests with full control of a vehicle over 15 km of difficult roads at up to 37 km/h with no waypoints. 2008 Springer Science+Business Media, LLC.},
author = {Rasmussen, Christopher},
journal = {Autonomous Robots},
keywords = {control system analysis,estimation,roads streets,testing,vehicles},
number = {3},
pages = {205--229},
publisher = {Kluwer Academic Publishers},
title = {{RoadCompass : following rural roads with vision + ladar using vanishing point tracking}},
url = {http://dx.doi.org/10.1007/s10514-008-9091-x},
volume = {25},
year = {2008}
}
@inproceedings{Aguilera2005,
author = {Aguilera, D G and Lahoz, J G\'{o}mez and Codes, J Finat},
booktitle = {Proceedings of the ISPRS Working Group V4 Workshop 3DARCH 2005 Virtual Reconstruction and Visualization of Complex Architectures},
keywords = {3d reconstruction,geometry,photogrammetry,single image technique,vanishing points estimation},
title = {{A New Method for Vanishing Point Detection in 3D Reconstruction from a Single View}},
year = {2005}
}
@article{Kogan2009,
author = {Kogan, H and Maurer, R and Keshet, R},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (2009)},
number = {1},
pages = {755--761},
publisher = {Ieee},
title = {{Vanishing points estimation by self-similarity}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206713},
year = {2009}
}
@article{Chang2007,
abstract = {In recent years, the success of single-robot SLAM has led to more multi-robot SLAM (MR-SLAM) research. A team of robots with MR-SLAM can explore an environment more efficiently and reliably; however, MR-SLAM also raises many challenging problems, including map fusion, unknown robot poses and scalability issues. The first two problems can be considered as an optimization problem of finding a consistent joint map based on robots\&x2019; relative poses and sensory data. This optimization problem exhibits a similar property of a singlerobot topological/metric mapping. To exploit this property, we propose a multi-robot SLAM (MR-SLAM) algorithm, which builds a graph-like topological map with vertices representing local metric maps and edges describing relative positions of adjacent local maps. In this MR-SLAM algorithm, the map fusion between two robots can be naturally done by adding an edge that connects two topological maps, and the estimation of relative robot pose is simply performed by optimizing this edge. For the third scalable problem, the proposed algorithm is also scalable to the number of robots and the size of an environment. Computer simulations with a public data set and experimental work on Pioneer 3-DX robots have been conducted to validate the performance of the proposed MR-SLAM algorithm.},
author = {Chang, H Jacky and Lee, C S George and Hu, Y Charlie and {Yung-Hsiang Lu}, A Yung-Hsiang Lu},
journal = {2007 IEEERSJ International Conference on Intelligent Robots and Systems},
pages = {1467--1472},
publisher = {Ieee},
title = {{Multi-robot SLAM with topological/metric maps}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4399142},
year = {2007}
}
@article{Colombo2005,
abstract = {Image analysis and computer vision can be effectively employed to recover the three-dimensional structure of imaged objects, together with their surface properties. In this paper, we address the problem of metric reconstruction and texture acquisition from a single uncalibrated view of a surface of revolution (SOR). Geometric constraints induced in the image by the symmetry properties of the SOR structure are exploited to perform self-calibration of a natural camera, 3D metric reconstruction, and texture acquisition. By exploiting the analogy with the geometry of single axis motion, we demonstrate that the imaged apparent contour and the visible segments of two imaged cross sections in a single SOR view provide enough information for these tasks. Original contributions of the paper are: single view self-calibration and reconstruction based on planar rectification, previously developed for planar surfaces, has been extended to deal also with the SOR class of curved surfaces; self-calibration is obtained by estimating both camera focal length (one parameter) and principal point (two parameters) from three independent linear constraints for the SOR fixed entities; the invariant-based description of the SOR scaling function has been extended from affine to perspective projection. The solution proposed exploits both the geometric and topological properties of the transformation that relates the apparent contour to the SOR scaling function. Therefore, with this method, a metric localization of the SOR occluded parts can be made, so as to cope with them correctly. For the reconstruction of textured SORs, texture acquisition is performed without requiring the estimation of external camera calibration parameters, but only using internal camera parameters obtained from self-calibration.},
author = {Colombo, Carlo and {Del Bimbo}, Alberto and Pernici, Federico},
institution = {Dipartimento di Sistemi e Informatica-Universit\`{a} di Firenze, Via Santa Marta 3, 1-50139 Firenze, Italy. colombo@dsi.unifi.it},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {1},
pages = {99--114},
title = {{Metric 3D reconstruction and texture acquisition of surfaces of revolution from a single uncalibrated view.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15628272},
volume = {27},
year = {2005}
}
@book{Faugeras1993,
author = {Faugeras, Olivier},
pages = {695},
publisher = {MIT Press},
title = {{Three-Dimensional Computer Vision: A Geometric Viewpoint}},
year = {1993}
}
@book{Hartley2000,
author = {Hartley, Richard and Zisserman, Andrew},
booktitle = {axiomanueduau},
publisher = {Cambridge University Press},
title = {{Multiple View Geometry}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Multiple+view+geometry#0},
volume = {4},
year = {2000}
}
@article{Kogecka2002,
author = {Kogecka, J},
journal = {Proceedings 2002 IEEE International Conference on Robotics and Automation Cat No02CH37292},
keywords = {bile aerial robots,calibration using vanishing points,from vanishing points,lines image,plane,relative orienta,tion,vanishing point estimation,vision guided mo},
pages = {223--228},
publisher = {Ieee},
title = {{Efficient computation of vanishing points}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1013365},
year = {2002}
}
@article{Rother2002a,
abstract = {A man-made environment is characterized by a lot of parallel lines and a lot of orthogonal edges. In this article, a new method for detecting the three mutual orthogonal directions of such an environment is presented. Since real-time performance is not necessary for architectural application, like building reconstruction, a computationally more intensive approach was chosen. On the other hand, our approach is more rigorous than existing techniques, since the information given by the condition of three mutual orthogonal directions in the scene is identified and incorporated. Since knowledge about the camera geometry can be deduced from the vanishing points of three mutual orthogonal directions, we use this knowledge to reject falsely detected vanishing points. Results are presented from interpreting outdoor scenes of buildings.},
author = {Rother, C},
journal = {Image and Vision Computing},
keywords = {architecture,camera calibration,geometric constraints,vanishing lines,vanishing points},
number = {9-10},
pages = {647--655},
publisher = {Elsevier},
title = {{A new approach to vanishing point detection in architectural environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885602000549},
volume = {20},
year = {2002}
}
@inproceedings{Liebowitz1998,
abstract = {We describe the geometry constraints and algorithmic implementation for metric rectification of planes. The rectification allows metric properties, such as angles and length ratios, to be measured on the world plane from a perspective image. The novel contributions are: first, that in a stratified context the various forms of providing metric information, which include a known angle, two equal though unknown angles, and a known length ratio; can all be represented as circular constraints on the parameters of an affine transformation of the plane-this provides a simple and uniform framework for integrating constraints; second, direct rectification from right angles in the plane; third, it is shown that metric rectification enables calibration of the internal camera parameters; fourth, vanishing points are estimated using a Maximum Likelihood estimator; fifth, an algorithm for automatic rectification. Examples are given for a number of images, and applications demonstrated for texture map acquisition and metric measurements},
author = {Liebowitz, D and Zisserman, A},
booktitle = {Proceedings 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
file = {::},
organization = {Citeseer},
pages = {482--488},
publisher = {IEEE Comput. Soc},
title = {{Metric rectification for perspective images of planes}},
url = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=698649},
year = {1998}
}
@article{Shufelt1999,
abstract = {Vanishing point detection algorithms based on a Gaussian sphere representation have been employed in a variety of computer vision systems, for extracting 3D line orientations as a first step towards object detection. Typically, these algorithms have been applied to imagery with strong perspective effects and with little noise or texture, resulting in good solutions for line orientations. However, these algorithms can fail if perspective effects are weak, or if texture edges are predominant; they also fail to take advantage of knowledge about the objects to be detected. In this paper, two new techniques for robust vanishing point detection on the Gaussian sphere are presented; primitive-based vanishing point analysis and interpretation plane error modeling. The performance of these methods, along with two other existing methods from the literature, are quantitatively evaluated and compared for the task of building detection in complex aerial imagery},
author = {Shufelt, J A},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {3},
pages = {282--288},
title = {{Performance evaluation and analysis of vanishing point detection techniques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=754631},
volume = {21},
year = {1999}
}
@article{Lutton1994,
author = {Lutton, E and Maitre, H and Lopez-Krahe, J},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {4},
pages = {430--438},
publisher = {Published by the IEEE Computer Society},
title = {{Contribution to the determination of vanishing points using hough transform}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/34.277598},
volume = {16},
year = {1994}
}
@article{Wang2008,
abstract = {In this paper, we present a robust road detection and tracking method based on a condensation particle filter for real-time video-based navigation applications. The image is divided into horizontal strips, and vanishing point (VP) detection is performed on each image strip. We propose a method for estimating the density of road boundary line segments in the image so that VP detection in an image strip takes into account the detection results in the neighboring image strips. This use of contextual information for VP detection leads to more accurate detection results. The estimated road parameters are then used to initialize the condensation tracker. Experiments using real road videos demonstrate the robustness of our method to difficult road conditions due to the presence of partial occlusion, shadows and road signs.},
author = {Wang, Y and Bai, Li and Fairhurst, M C},
journal = {Intelligent Transportation Systems IEEE Transactions on},
keywords = {image processing,ta1637 image analysis},
number = {4},
pages = {570--579},
title = {{Robust Road Modeling and Tracking using Condensation}},
url = {http://dx.doi.org/10.1109/TITS.2008.2006733},
volume = {9},
year = {2008}
}
@inproceedings{Petillot2008,
author = {Petillot, Yvan R and Salvi, Joaquim and Batlle, Elisabet},
booktitle = {Second IFAC Workshop Navigation, Guidance and Control of Underwater Vehicles},
file = {::},
keywords = {computer vision,simultaneous localization and mapping,stereo vision,surface registration,underwater imaging,visual slam},
number = {0},
title = {{3D Large-Scale Seabed Reconstruction for UUV Simultaneous Localization and Mapping}},
volume = {44},
year = {2008}
}
@phdthesis{Eustice2008,
author = {Eustice, Ryan M.},
file = {::},
month = apr,
number = {2},
pages = {103--122},
school = {MIT},
title = {{Large-Area Visually Augmented Navigation for Autonomous Underwater Vehicles}},
type = {PhD},
volume = {33},
year = {2008}
}
@inproceedings{Saez,
author = {Saez, J.M. and Hogue, A. and Escolano, F. and Jenkin, M.},
booktitle = {Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.},
file = {::},
pages = {3562--3567},
publisher = {Ieee},
title = {{Underwater 3D SLAM through entropy minimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1642246},
year = {2006}
}
@phdthesis{Architecture2008,
author = {Thomas, Stephen},
file = {::},
title = {{Real-time Stereo Visual SLAM}},
type = {MSc},
year = {2008}
}
@article{Zhen2005,
author = {Zhen, GUO and Feng, SUN},
file = {::},
journal = {Marine Science},
keywords = {auv,dvl,integrated navigation system,sins},
number = {2},
pages = {34--38},
title = {{Research on integrated navigation method for AUV}},
volume = {4},
year = {2005}
}
@inproceedings{Hogue2007,
author = {Hogue, Andrew and German, Andrew and Jenkin, Michael},
booktitle = {2007 IEEE International Conference on Systems, Man and Cybernetics},
file = {::},
month = oct,
pages = {2372--2377},
publisher = {Ieee},
title = {{Underwater environment reconstruction using stereo and inertial data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4413666},
year = {2007}
}
@phdthesis{Shahrabi2000,
author = {Shahrabi, Babak Ameri},
booktitle = {Perspective},
file = {::},
school = {University of Stuttgart},
title = {{Automatic Recognition and 3D Reconstruction of Buildings through Computer Vision and Digital Photogrammetry}},
type = {Dissertation},
year = {2000}
}
@inproceedings{Dudek,
author = {Dudek, G. and Jenkin, M. and Prahacs, C. and Hogue, A. and Sattar, J. and German, Andrew and Giguere, P. and Saunderson, S. and Ripsman, A. and Simhon, S. and Torres, L. and Milios, E. and Rekletis, I.},
booktitle = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems},
file = {::},
keywords = {-autonomous robot,aquatic robot,robotic sensing},
pages = {1749--1754},
publisher = {Ieee},
title = {{A visually guided swimming robot}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1545231},
year = {2005}
}
@article{Corke2007,
author = {Corke, Peter and Lobo, J. and Dias, J.},
file = {::},
journal = {The International Journal of Robotics Research},
keywords = {inertial sensing,sensor fusion,vision},
month = jun,
number = {6},
pages = {519--535},
title = {{An Introduction to Inertial and Visual Sensing}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364907079279},
volume = {26},
year = {2007}
}
@article{Olson2006,
author = {Olson, Edwin and Leonard, John J. and Teller, Seth},
file = {::},
journal = {IEEE Journal of Oceanic Engineering},
month = oct,
number = {4},
pages = {949--958},
title = {{Robust Range-Only Beacon Localization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4089076},
volume = {31},
year = {2006}
}
@article{Eustice2006a,
author = {Eustice, Ryan M. and Singh, Hanumant and Leonard, John J.},
file = {::},
journal = {IEEE Transactions on Robotics},
month = dec,
number = {6},
pages = {1100--1114},
title = {{Exactly Sparse Delayed-State Filters for View-Based SLAM}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4020357},
volume = {22},
year = {2006}
}
@inproceedings{Kim2005,
author = {Kim, Jae-hean and Chung, Myung Jin},
booktitle = {Proceedings of the 2005 IEEE International Conference on Robotics and Automation},
file = {::},
number = {April},
pages = {3360--3365},
publisher = {Ieee},
title = {{Absolute Stereo SFM without Stereo Correspondence for Vision Based SLAM}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1570629},
year = {2005}
}
@inproceedings{Newman2003,
address = {Sienna},
author = {Newman, Paul M and Leonard, John J. and Rikoski, Richard J},
booktitle = {Proceedings of the Eleventh International Symposium on Robotics Research},
file = {::},
title = {{Towards Constant-Time SLAM on an Autonomous Underwater Vehicle Using Synthetic Aperture Sonar}},
year = {2003}
}
@article{Konolige2008,
author = {Konolige, K. and Agrawal, M.},
file = {::},
journal = {IEEE Transactions on Robotics},
month = oct,
number = {5},
pages = {1066--1077},
title = {{FrameSLAM: From Bundle Adjustment to Real-Time Visual Mapping}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4648456},
volume = {24},
year = {2008}
}
@inproceedings{Leonard1991,
author = {Leonard, John J. and Durrant-Whyte, H.F.},
booktitle = {Intelligence for Mechanical Systems, Proceedings IROS'91},
file = {::},
number = {91},
pages = {1442--1447},
publisher = {Ieee},
title = {{Simultaneous map building and localization for an autonomous mobile robot}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=174711},
year = {1991}
}
@inproceedings{Nicosevici2008,
address = {Kobe},
author = {Nicosevici, Tudor and Garcia, Rafael},
booktitle = {OCEANS 2008 - MTS/IEEE Kobe Techno-Ocean},
file = {::},
month = apr,
pages = {1--7},
publisher = {IEEE},
title = {{Online Robust 3D Mapping Using Structure from Motion Cues}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4531022},
year = {2008}
}
@article{Eustice2008a,
author = {Eustice, Ryan M. and Singh, Hanumant and Pizarro, O.},
file = {::},
journal = {IEEE Journal of Oceanic Engineering},
month = apr,
number = {2},
pages = {103--122},
title = {{Visually Augmented Navigation for Autonomous Underwater Vehicles}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4625213},
volume = {33},
year = {2005}
}
@article{Brown2009,
author = {Brown, Hunter C. and Kim, Ayoung and Eustice, Ryan M.},
file = {::},
journal = {Marine Technology Society Journal},
keywords = {auvs,mapping,navigation,slam,testbed},
month = may,
number = {2},
pages = {33--47},
title = {{An Overview of Autonomous Underwater Vehicle Research and Testbed at PeRL}},
url = {http://openurl.ingenta.com/content/xref?genre=article&issn=0025-3324&volume=43&issue=2&spage=33},
volume = {43},
year = {2009}
}
@inproceedings{Richmond2006,
author = {Richmond, Kristof and Rock, Stephen},
booktitle = {Oceans 2006},
file = {::},
month = sep,
pages = {1--6},
publisher = {Ieee},
title = {{An Operational Real-Time Large-Scale Visual Mosaicking and Navigation System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4099052},
year = {2006}
}
@article{Davison2007,
author = {Davison, Andrew J and Reid, Ian D and Molton, Nicholas D and Stasse, Olivier},
file = {::},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer Systems,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Numerical Analysis,Pattern Recognition,Photogrammetry,Photogrammetry: methods,Signal Processing,Three-Dimensional,Three-Dimensional: methods,Video Recording,Video Recording: methods},
month = jun,
number = {6},
pages = {1052--67},
title = {{MonoSLAM: real-time single camera SLAM.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17431302},
volume = {29},
year = {2007}
}
@article{Bay2008,
author = {Bay, H and Ess, a and Tuytelaars, T and Vangool, L},
file = {::},
journal = {Computer Vision and Image Understanding},
keywords = {camera calibration,feature description,interest points,local features,object recognition},
month = jun,
number = {3},
pages = {346--359},
title = {{Speeded-Up Robust Features (SURF)}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314207001555},
volume = {110},
year = {2008}
}
@article{Smith1990,
author = {Smith, R and Self, M and Cheeseman, P},
file = {::},
journal = {UAI '86. Proceedings of the Second Annual Conference on Uncertainty in Artificial Intelligence.},
pages = {167--193},
title = {{Estimating uncertain spatial relationships in robotics}},
year = {1990}
}
@phdthesis{Chang2002,
author = {Chang, Peng},
booktitle = {Camera},
file = {::},
school = {Carnegie Mellon University},
title = {{Robust tracking and structure from motion with sampling method}},
type = {Dissertation},
year = {2002}
}
@phdthesis{Gracias2003,
author = {Gracias, N.R.},
file = {::},
month = oct,
number = {4},
pages = {609--624},
title = {{Mosaic-based navigation for autonomous underwater vehicles}},
type = {Dissertation},
volume = {28},
year = {2003}
}
@phdthesis{Aulinas2008,
author = {Aulinas, Josep},
file = {::},
school = {Heriot-Watt University},
title = {{MSc. Thesis dissertation: 3D Visual SLAM applied to large-scale underwater scenarios}},
type = {M.SC},
year = {2008}
}
@phdthesis{Thomas2008,
author = {Thomas, Stephen and Salvi, Joaquim and Petillot, Yvan R},
file = {::},
school = {Heriot-Watt University},
title = {{Real-time stereo visual SLAM for autonomous underwater vehicles}},
type = {Project Thesis},
year = {2008}
}
@article{Eustice2006,
author = {Eustice, Ryan M. and Singh, Hanumant and Leonard, John J. and Walter, M. R.},
file = {::},
journal = {The International Journal of Robotics Research},
keywords = {and the woods,and underwater vehicles,cambridge,computer vision,data association,engineering of,eustice was with the,information lters,joint program in oceanographic,ma,mobile robotics,r,slam,technology,the massachusetts institute of},
month = dec,
number = {12},
pages = {1223--1242},
title = {{Visually Mapping the RMS Titanic: Conservative Covariance Estimates for SLAM Information Filters}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364906072512},
volume = {25},
year = {2006}
}
@article{Lemaire2007,
author = {Lemaire, Thomas and Berger, Cyrille and Jung, Il-Kyun and Lacroix, Simon},
file = {::},
journal = {International Journal of Computer Vision},
keywords = {3d slam,bearing only slam,finally,interest point matching,knowledge of robot motions,planners relies on the,precise,the correct execution of,the geometric trajec-,tories provided by the},
number = {3},
pages = {343--364},
title = {{Vision-Based SLAM: Stereo and Monocular Approaches}},
url = {http://www.springerlink.com/index/10.1007/s11263-007-0042-3},
volume = {74},
year = {2007}
}
@article{Se2008,
author = {Se, Stephen and Jasiobedzki, Piotr},
file = {::},
journal = {International Journal},
number = {1},
pages = {46--57},
title = {{Stereo-Vision Based 3D Modeling and Localization for Unmanned Vehicles}},
volume = {13},
year = {2008}
}
@article{Potyrailo2012,
abstract = {New sensor technologies for homeland security applications must meet the key requirements of sensitivity to detect agents below risk levels, selectivity to provide minimal false-alarm rates, and response speed to operate in high throughput environments, such as airports, sea ports, and other public places. Chemical detection using existing sensor systems is facing a major challenge of selectivity. In this review, we provide a brief summary of chemical threats of homeland security importance; focus in detail on modern concepts in chemical sensing; examine the origins of the most significant unmet needs in existing chemical sensors; and, analyze opportunities, specific requirements, and challenges for wireless chemical sensors and wireless sensor networks (WSNs). We further review a new approach for selective chemical sensing that involves the combination of a sensing material that has different response mechanisms to different species of interest, with a transducer that has a multi-variable signal-transduction ability. This new selective chemical-sensing approach was realized using an attractive ubiquitous platform of battery-free passive radio-frequency identification (RFID) tags adapted for chemical sensing. We illustrate the performance of RFID sensors developed in measurements of toxic industrial materials, humidity-independent detection of toxic vapors, and detection of chemical-agent simulants, explosives, and strong oxidizers.},
author = {Potyrailo, Radislav a and Nagraj, Nandini and Surman, Cheryl and Boudries, Hacene and Lai, Hanh and Slocik, Joseph M and Kelley-Loughnane, Nancy and Naik, Rajesh R},
doi = {10.1016/j.trac.2012.07.013},
issn = {0165-9936},
journal = {Trends in analytical chemistry : TRAC},
keywords = {Radio-frequency identification (RFID),Response speed,Toxic industrial material (TIM),Wireless sensor network (WSN),chemical agent,chemical sensing,homeland security,multivariate statistical analysis,radio-frequency identification,response,rfid,selectivity,sensitivity,speed,tim,toxic industrial material,wireless sensor network,wsn},
month = nov,
number = {4},
pages = {133--145},
pmid = {23175590},
publisher = {Elsevier Ltd},
title = {{Wireless sensors and sensor networks for homeland security applications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23175590},
volume = {40},
year = {2012}
}
@article{Michalos2012,
author = {Michalos, G. and Makris, S. and Eytan, a. and Matthaiakis, S. and Chryssolouris, G.},
doi = {10.1016/j.procir.2012.07.061},
issn = {22128271},
journal = {Procedia CIRP},
keywords = {assembly,robotic welding,vision system},
month = jan,
pages = {352--357},
title = {{Robot Path Correction Using Stereo Vision System}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212827112002338},
volume = {3},
year = {2012}
}
@article{Wu2012,
author = {Wu, Di and Sun, Da-Wen},
doi = {10.1016/j.tifs.2012.08.004},
file = {::},
issn = {09242244},
journal = {Trends in Food Science \& Technology},
month = sep,
title = {{Colour measurements by computer vision for food quality control – A review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0924224412001835},
year = {2012}
}
@article{Chen2012,
author = {Chen, Gang and Guo, Yubo and Wang, Hanping and Ye, Dong and Gu, Yanfeng},
doi = {10.1016/j.ijleo.2011.05.030},
issn = {00304026},
journal = {Optik - International Journal for Light and Electron Optics},
month = apr,
number = {8},
pages = {731--734},
publisher = {Elsevier GmbH.},
title = {{Stereo vision sensor calibration based on random spatial points given by CMM}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0030402611003081},
volume = {123},
year = {2012}
}
@article{Kim2012,
author = {Kim, Jung-Rack and Lin, Shih-Yuan and Hong, Jeong-Woo and Kim, Young-Hwi and Park, Chin-Kang},
doi = {10.1016/j.cageo.2011.09.018},
issn = {00983004},
journal = {Computers \& Geosciences},
keywords = {Geomorphology,High resolution DTM,Mars,Ortho-image,Stereo analysis,Virtual reality},
month = jul,
pages = {184--195},
publisher = {Elsevier},
title = {{Implementation of Martian virtual reality environment using very high-resolution stereo topographic data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0098300411003475},
volume = {44},
year = {2012}
}
@article{Ambrosch2011,
author = {Ambrosch, Kristian and Kubinger, Wilfried},
doi = {10.1016/j.cviu.2010.11.008},
file = {::},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = feb,
number = {2},
pages = {287},
title = {{Corrigendum to “Accurate hardware-based stereo vision” [Comput. Vis. Image Understanding 114 (2010) 1303–1316}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314210002444},
volume = {115},
year = {2011}
}
@article{Liebe2006,
author = {Liebe, C.C. and Padgett, C. and Chapsky, J. and Wilson, D. and Brown, K. and Jerebets, S. and Goldberg, H. and Schroeder, J.},
doi = {10.1109/AERO.2006.1655898},
file = {::},
isbn = {0-7803-9545-X},
journal = {2006 IEEE Aerospace Conference},
pages = {1--10},
publisher = {Ieee},
title = {{Spacecraft Hazard Avoidance Utilizing Structured Light}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1655898},
year = {2006}
}
@article{Losada2012,
author = {Losada, Cristina and Mazo, Manuel and Palazuelos, Sira E. and Pizarro, Daniel and Marr\'{o}n, Marta and Velasco, Jos\'{e} F.},
doi = {10.1016/j.robot.2012.11.007},
file = {::},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = dec,
title = {{Identification and tracking of robots in an intelligent space using static cameras and an XPFCP}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889012002187},
year = {2012}
}
@article{Gerla2011,
author = {Gerla, Mario and Kleinrock, Leonard},
doi = {10.1016/j.comnet.2010.10.015},
issn = {13891286},
journal = {Computer Networks},
month = feb,
number = {2},
pages = {457--469},
publisher = {Elsevier B.V.},
title = {{Vehicular networks and the future of the mobile internet}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389128610003324},
volume = {55},
year = {2011}
}
@article{Esmaeilabadi2012,
author = {Esmaeilabadi, Mir Ebad Ahmadzadeh},
doi = {10.1016/j.protcy.2012.03.013},
file = {::},
issn = {22120173},
journal = {Procedia Technology},
keywords = {face detection,head tracking,lighting,skin color,thresholding,virtual reality},
month = jan,
pages = {121--131},
title = {{3D Virtual Reality Navigation by Human's Head Movements Using a Generic Webcam}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212017312002423},
volume = {3},
year = {2012}
}
@article{Tang2011a,
author = {Tang, Xinxing and Yamada, Hironao},
doi = {10.1016/j.proeng.2011.08.198},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {computer graphics,hydraulic servo system,tele-operation construction robot,virtual reality},
month = jan,
pages = {1071--1076},
title = {{Tele-operation Construction Robot Control System with Virtual Reality Technology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705811016997},
volume = {15},
year = {2011}
}
@article{Arroqui2012,
author = {Arroqui, Mauricio and Mateos, Cristian and Machado, Claudio and Zunino, Alejandro},
doi = {10.1016/j.compag.2012.05.016},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {agricultural information systems},
month = sep,
pages = {14--18},
publisher = {Elsevier B.V.},
title = {{RESTful Web Services improve the efficiency of data transfer of a whole-farm simulator accessed by Android smartphones}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168169912001305},
volume = {87},
year = {2012}
}
@inproceedings{Blum1998,
address = {New York, New York, USA},
author = {Blum, Avrim and Mitchell, Tom},
booktitle = {Proceedings of the eleventh annual conference on Computational learning theory - COLT' 98},
file = {::},
number = {4},
pages = {92--100},
publisher = {ACM Press},
title = {{Combining labeled and unlabeled data with co-training}},
url = {http://www.mendeley.com/catalog/combining-labeled-unlabeled-data-co-training/},
volume = {98},
year = {1998}
}
@article{Koong2012,
author = {Koong, Chorng-Shiuh and Shih, Chihhsiong and Hsiung, Pao-Ann and Lai, Hung-Jui and Chang, Chih-Hung and Chu, William C. and Hsueh, Nien-Lin and Yang, Chao-Tung},
doi = {10.1016/j.jss.2011.08.030},
issn = {01641212},
journal = {Journal of Systems and Software},
month = jan,
number = {1},
pages = {43--60},
publisher = {Elsevier Inc.},
title = {{Automatic testing environment for multi-core embedded software—ATEMES}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121211002305},
volume = {85},
year = {2012}
}
@article{Nordin2010,
author = {Nordin, Norazah and Embi, Mohamed Amin and Yunus, Melor Md.},
doi = {10.1016/j.sbspro.2010.10.019},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {conceptual framework,design system,learning applications,lifelong learning,mobile learning},
month = jan,
number = {C},
pages = {130--138},
title = {{Mobile Learning Framework for Lifelong Learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042810020239},
volume = {7},
year = {2010}
}
@article{Bakar2012,
author = {Bakar, Mohd Nazri Abu and Saad, Abdul Rahman Mohd.},
doi = {10.1016/j.proeng.2012.07.138},
file = {::},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {autonomous robot,detection and tracking,doctor following robot,monocular vision,range finding},
month = jan,
number = {Iris},
pages = {22--31},
title = {{A Monocular Vision-based Specific Person Detection System for Mobile Robot Applications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812025246},
volume = {41},
year = {2012}
}
@article{Milanes2012,
author = {Milan\'{e}s, Vicente and Llorca, David F. and Villagr\'{a}, Jorge and P\'{e}rez, Joshu\'{e} and Fern\'{a}ndez, Carlos and Parra, Ignacio and Gonz\'{a}lez, Carlos and Sotelo, Miguel a.},
doi = {10.1016/j.eswa.2011.09.024},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {advanced vehicle control and,safety},
month = feb,
number = {3},
pages = {3362--3373},
title = {{Intelligent automatic overtaking system using vision for vehicle detection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417411013339},
volume = {39},
year = {2012}
}
@article{Bayro-Corrochano2011,
author = {Bayro-Corrochano, Eduardo and Eklundh, Jan-Olof},
doi = {10.1016/j.patrec.2011.10.008},
file = {::},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = dec,
number = {16},
pages = {2143--2144},
publisher = {Elsevier B.V.},
title = {{Advances in theory and applications of pattern recognition, image processing and computer vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865511003527},
volume = {32},
year = {2011}
}
@article{Wasfy2012,
author = {Wasfy, Wael and Zheng, Hong},
doi = {10.1016/j.phpro.2012.05.122},
file = {::},
issn = {18753892},
journal = {Physics Procedia},
month = jan,
pages = {690--697},
title = {{General Structure Design for Fast Image Processing Algorithms Based upon FPGA DSP Slice}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1875389212014356},
volume = {33},
year = {2012}
}
@article{Menezes2011,
author = {Menezes, Paulo and Lerasle, Fr\'{e}d\'{e}ric and Dias, Jorge},
doi = {10.1016/j.imavis.2011.01.003},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Assistant robot,Computer vision,Data fusion,Human motion capture,Particle filtering},
month = may,
number = {6},
pages = {382--393},
publisher = {Elsevier B.V.},
title = {{Towards human motion capture from a camera mounted on a mobile robot}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885611000102},
volume = {29},
year = {2011}
}
@article{Shabeer2012,
author = {Shabeer, H. Abdul and Wahidabanu, R.S.D.},
doi = {10.1016/j.proeng.2012.01.907},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {cell phone while driving,locate the vehicle using,mobile jammer,mobile phone,vehicle number plate},
month = jan,
number = {2011},
pages = {623--630},
title = {{Averting mobile phone use while driving and technique to locate the mobile phone used vehicle}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812009174},
volume = {30},
year = {2012}
}
@article{Han2001,
author = {Han, Kyu-phil and Song, Kun-woen and Chung, Eui-yoon and Cho, Seok-je and Ha, Yeong-ho},
file = {::},
keywords = {crossover,disparity,fitness function,genetic algorithm,informed generation,intensity similarity,mutation,natural selection,smoothness,stereo matching},
pages = {1729--1740},
title = {{Stereo matching using genetic algorithm with adaptive chromosomes}},
volume = {34},
year = {2001}
}
@article{Chatterjee2011,
author = {Chatterjee, Avishek and Ray, Olive and Chatterjee, Amitava and Rakshit, Anjan},
doi = {10.1016/j.eswa.2011.01.007},
file = {::},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {extended kalman filter},
month = jul,
number = {7},
pages = {8266--8274},
publisher = {Elsevier Ltd},
title = {{Development of a real-life EKF based SLAM system for mobile robots employing vision sensing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417411000273},
volume = {38},
year = {2011}
}
@article{Barnes2012,
author = {Barnes, Nick},
doi = {10.1016/j.imavis.2012.05.007},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Bionic eye,Computer vision,Face recognition,Orientation and mobility,Prosthetic vision,Retinal implants},
month = aug,
number = {8},
pages = {478--479},
publisher = {Elsevier B.V.},
title = {{The role of computer vision in prosthetic vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885612000832},
volume = {30},
year = {2012}
}
@article{Bardsley,
author = {Bardsley, Daniel},
file = {::},
pages = {1--11},
title = {{3D Reconstruction Using the Direct Linear Transform}}
}
@article{Sun2012,
author = {Sun, Wei and Chen, Long and Liu, Kai},
doi = {10.7321/jscse.v2.n5.1},
issn = {22517545},
journal = {International Journal of Soft Computing and Software Engineering},
keywords = {autonomous navigation,binocular,object recognition,optical measurement,rvd},
month = may,
number = {5},
pages = {1--12},
title = {{Research on Vision-based Autonomous Navigation Algorithm for RVD between Spacecrafts}},
url = {http://www.jscse.com/papers/?vol=2&no=5&n=1},
volume = {2},
year = {2012}
}
@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M},
booktitle = {Pattern Recognition},
chapter = {Graphical},
doi = {10.1117/1.2819119},
editor = {Jordan, M and Kleinberg, J and Sch\"{o}lkopf, B},
eprint = {0-387-31073-8},
file = {::},
isbn = {9780387310732},
issn = {10179909},
number = {4},
pages = {738},
publisher = {Springer},
series = {Information science and statistics},
title = {{Pattern Recognition and Machine Learning}},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}
@article{Mustafah2012,
author = {Mustafah, Yasir Mohd and Azman, Amelia Wong and Akbar, Fajril},
doi = {10.1016/j.proeng.2012.07.214},
isbn = {6012604270},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {indoor localization,stereo vision,uav},
month = jan,
number = {Iris},
pages = {575--579},
title = {{Indoor UAV Positioning Using Stereo Vision Sensor}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812026148},
volume = {41},
year = {2012}
}
@article{NirmalSingh2011,
author = {{Nirmal Singh}, N. and Chatterjee, Avishek and Chatterjee, Amitava and Rakshit, Anjan},
doi = {10.1016/j.measurement.2010.12.002},
file = {::},
issn = {02632241},
journal = {Measurement},
month = may,
number = {4},
pages = {620--641},
publisher = {Elsevier Ltd},
title = {{A two-layered subgoal based mobile robot navigation algorithm with vision system and IR sensors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0263224110003271},
volume = {44},
year = {2011}
}
@article{Tsai2012,
abstract = {During nuclear accidents, when radioactive materials spread into the environment, the people in the affected areas should evacuate immediately. However, few information systems are available regarding escape guidelines for nuclear accidents. Therefore, this study constructs escape guidelines on mobile phones. This application is called Mobile Escape Guidelines (MEG) and adopts two techniques. One technique is the geographical information that offers multiple representations; the other is the augmented reality that provides semi-realistic information services. When this study tested the mobile escape guidelines, the results showed that this application was capable of identifying the correct locations of users, showing the escape routes, filtering geographical layers, and rapidly generating the relief reports. Users could evacuate from nuclear accident sites easily, even without relief personnel, since using slim devices to access the mobile escape guidelines is convenient. Overall, this study is a useful reference for a nuclear accident emergency response.},
author = {Tsai, Ming-Kuan and Lee, Yung-Ching and Lu, Chung-Hsin and Chen, Mei-Hsin and Chou, Tien-Yin and Yau, Nie-Jia},
doi = {10.1016/j.jenvrad.2011.12.025},
issn = {1879-1700},
journal = {Journal of environmental radioactivity},
keywords = {Geographic Information Systems,Guidelines as Topic,Nuclear Power Plants,Radioactive Hazard Release},
month = jul,
pages = {36--44},
pmid = {22260929},
publisher = {Elsevier Ltd},
title = {{Integrating geographical information and augmented reality techniques for mobile escape guidelines on nuclear accident sites.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22260929},
volume = {109},
year = {2012}
}
@article{Doctorants2003,
author = {Doctorants, Guilde Des},
file = {::},
keywords = {doctorat,guide,recherche,th\`{e}se},
mendeley-tags = {doctorat,guide,recherche,th\`{e}se},
pages = {1--107},
title = {{Guide du Doctorant}},
url = {http://guilde.jeunes-chercheurs.org/Alire/guide/},
year = {2003}
}
@article{Owens2013,
author = {Owens, Gary M},
issn = {1944-706X},
journal = {Journal of managed care pharmacy : JMCP},
month = jan,
number = {1 Suppl A},
pages = {S3},
pmid = {23383727},
title = {{Introduction.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23404255},
volume = {19},
year = {2013}
}
@article{Vidal-Calleja2011,
author = {Vidal-Calleja, Teresa a. and Berger, Cyrille and Sol\`{a}, Joan and Lacroix, Simon},
doi = {10.1016/j.robot.2011.05.008},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {multi-robots cooperation},
month = sep,
number = {9},
pages = {654--674},
publisher = {Elsevier B.V.},
title = {{Large scale multiple robot visual mapping with heterogeneous landmarks in semi-structured terrain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889011000923},
volume = {59},
year = {2011}
}
@incollection{Sokratis2011,
author = {Vavilis, Sokratis and Kavallieratou, Ergina and Paredes, Roberto and Sotiropoulos, Kostas},
booktitle = {LEARNING STRUCTURE AND SCHEMAS FROM DOCUMENTS},
file = {::},
keywords = {binarization algorithm,document image processing,historical document images,hybrid algorithm},
pages = {165--179},
publisher = {Springer},
title = {{A Hybrid Binarization Technique for Document Images}},
year = {2011}
}
@article{Garcia2011,
author = {Garc\'{\i}a, Antonio and Erenas, M.M. and Marinetto, Eugenio D. and Abad, Carlos a. and de Orbe-Paya, Ignacio and Palma, Alberto J. and Capit\'{a}n-Vallvey, Luis F.},
doi = {10.1016/j.snb.2011.04.045},
issn = {09254005},
journal = {Sensors and Actuators B: Chemical},
month = aug,
number = {1},
pages = {350--359},
title = {{Mobile phone platform as portable chemical analyzer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S092540051100342X},
volume = {156},
year = {2011}
}
@article{Hoseinnezhad2011,
author = {Hoseinnezhad, Reza and Bab-Hadiashar, Alireza},
doi = {10.1016/j.cviu.2011.03.007},
file = {::},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = aug,
number = {8},
pages = {1145--1156},
publisher = {Elsevier Inc.},
title = {{An M-estimator for high breakdown robust estimation in computer vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314211000956},
volume = {115},
year = {2011}
}
@article{Kim2012a,
author = {Kim, Jeongdae and Do, Yongtae},
doi = {10.1016/j.proeng.2012.07.262},
isbn = {8253850662},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {block-based motion estimation,mobile robot,obstacle avoidance,robot vision},
month = jan,
number = {Iris},
pages = {911--916},
title = {{Moving Obstacle Avoidance of a Mobile Robot Using a Single Camera}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812026628},
volume = {41},
year = {2012}
}
@inproceedings{Sokratis2011a,
author = {Vavilis, Sokratis and Kavallieratou, Ergina},
booktitle = {2011 International Conference on Document Analysis and Recognition},
file = {::},
keywords = {- document,algorithms,binarization,tool,training,user-feedback},
month = sep,
pages = {1--5},
publisher = {Ieee},
title = {{A Tool for Tuning Binarization Techniques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6065265},
year = {2011}
}
@article{Zhou2012,
author = {Zhou, Fuqiang and Wang, Yexin and Peng, Bin and Cui, Yi},
doi = {10.1016/j.measurement.2012.10.031},
file = {::},
issn = {02632241},
journal = {Measurement},
month = nov,
publisher = {Elsevier Ltd},
title = {{A Novel Way of Understanding for Calibrating Stereo Vision Sensor Constructed by a Single Camera and Mirrors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0263224112004034},
year = {2012}
}
@article{Glette2006,
author = {Glette, K. and Torresen, J. and Yasunaga, M. and Yamaguchi, Y.},
doi = {10.1109/AHS.2006.55},
isbn = {0-7695-2614-4},
journal = {First NASA/ESA Conference on Adaptive Hardware and Systems (AHS'06)},
pages = {373--380},
publisher = {Ieee},
title = {{On-Chip Evolution Using a Soft Processor Core Applied to Image Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1638187},
year = {2006}
}
@article{Chapitrea,
author = {Chapitre, Cours},
pages = {1--5},
title = {{1. Probl\`{e}me g\'{e}n\'{e}ral de la vision du relief. 1.1.}}
}
@unpublished{Vezien,
abstract = {Ce cours est l’aboutissement d’un travail de r\'{e}daction coll\'{e}gial initi\'{e} par le professeur A. Gagalowicz au d\'{e}but des ann\'{e}es 1990 dans le cadre de cours dispens\'{e}s \`{a} l’ESIEA. Il a depuis fait l’objet de constants remaniements et additions, notamment au regard de l’explosion de la manipulation d’images et de contenus multim\'{e}dias dans le domaine grand public, et reste en \'{e}volution constante. 2},
author = {V\'{e}zien, Jean-Marc},
title = {{TRAITEMENT DES IMAGES et VISION PAR MACHINE}},
url = {http://www.limsi.fr/~vezien/pdf_cours_ima_jmv.pdf}
}
@article{Kolter2009,
author = {Kolter, J. Zico and Ng, Andrew Y.},
doi = {10.1109/ROBOT.2009.5152795},
isbn = {978-1-4244-2788-8},
journal = {2009 IEEE International Conference on Robotics and Automation},
month = may,
pages = {1557--1564},
publisher = {Ieee},
title = {{Stereo vision and terrain modeling for quadruped robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5152795},
year = {2009}
}
@article{Sabto2012,
author = {Sabto, Nosaiba a. and {Al Mutib}, Khalid},
doi = {10.1016/j.jksuci.2012.10.001},
file = {::},
issn = {13191578},
journal = {Journal of King Saud University - Computer and Information Sciences},
month = oct,
number = {October},
publisher = {King Saud University},
title = {{Autonomous mobile robot localization based on RSSI measurements using an RFID sensor and neural network BPANN}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1319157812000377},
year = {2012}
}
@misc{TheMendeleySupportTeam2011a,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {::},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Costa2012,
annote = {		L’article d\'{e}crit l’utilisation de une method de d\'{e}tection des objets mobile ( ie : obstacle mobile /humain)  en se basant sur la technique block based motion estimation , \c{c}a consiste \`{a} comparer deux bloc de deux images , prise par une cam\'{e}ra fix\'{e} sur un robot mobile , la comparaison des deux bloc d’images suit le m\^{e}me principe du block matching d’un objet pris par deux cameras , sauf que dans notre cas , l’image est prise par la m\^{e}me camera , mais en deux moment diff\`{e}rent  , 
Le technique block based motion estimation nous permet ainsi de construire  un vecteur de mouvement indiquant le sens mouvement de l’objet.           
Supposition : Surface simple / le robot dispose d’une carte pour \'{e}viter les objets fixe (i e murs.).           
R\'{e}sultats        
-          D\'{e}tecter des objets 
-          Eviter les objets mobiles.           
Limitations : 
-           Effet des couleurs sur la d\'{e}tection des objets et le block matching ! 
-          Relativit\'{e}  mouvement du robot/ mouvement de l’objet   (un objet se d\'{e}pla\c{c}ant de la m\^{e}me vitesse et sens du robot parait fixe .) },
author = {Costa, Paulo and Fernandes, Hugo and Martins, Paulo and Barroso, Jo\~{a}o and Hadjileontiadis, Leontios J.},
doi = {10.1016/j.procs.2012.10.010},
issn = {18770509},
journal = {Procedia Computer Science},
month = jan,
number = {Dsai},
pages = {83--93},
title = {{Obstacle Detection using Stereo Imaging to Assist the Navigation of Visually Impaired People}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050912007727},
volume = {14},
year = {2012}
}
@article{Nundy2013,
abstract = {Behavioral models for mobile phone-based diabetes interventions are lacking. This study explores the potential mechanisms by which a text message-based diabetes program affected self-management among African-Americans.},
author = {Nundy, Shantanu and Dick, Jonathan J and Solomon, Marla C and Peek, Monica E},
doi = {10.1016/j.pec.2012.09.008},
issn = {1873-5134},
journal = {Patient education and counseling},
month = jan,
number = {1},
pages = {125--32},
pmid = {23063349},
publisher = {Elsevier Ireland Ltd},
title = {{Developing a behavioral model for mobile phone-based diabetes interventions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23063349},
volume = {90},
year = {2013}
}
@article{Moreda2012,
author = {Moreda, G.P. and Mu\~{n}oz, M.a. and Ruiz-Altisent, M. and Perdigones, a.},
doi = {10.1016/j.jfoodeng.2011.08.011},
issn = {02608774},
journal = {Journal of Food Engineering},
month = jan,
number = {2},
pages = {245--261},
publisher = {Elsevier Ltd},
title = {{Shape determination of horticultural produce using two-dimensional computer vision – A review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0260877411004511},
volume = {108},
year = {2012}
}
@article{REN2011,
abstract = {This paper proposes a simple and discriminative framework, using graphical model and 3D geometry to understand the diversity of urban scenes with varying viewpoints. Our algorithm constructs a conditional random field (CRF) network using over-segmented superpixels and learns the appearance model from different set of features for specific classes of our interest. Also, we introduce a training algorithm to learn a model for edge potential among these superpixel areas based on their feature difference. The proposed algorithm gives competitive and visually pleasing results for urban scene segmentation. We show the inference from our trained network improves the class labeling performance compared to the result when using the appearance model solely.},
author = {REN, Ke-yan and SUN, Han-xu and JIA, Qing-xuan and WU, Yao-hong and ZHANG, Wei-yu and GAO, Xin and YE, Ping and SONG, Jing-zhou},
doi = {10.1016/S1005-8885(10)60072-6},
issn = {10058885},
journal = {The Journal of China Universities of Posts and Telecommunications},
keywords = {3d geometry,crf,graphical model,scene recognition},
month = jun,
number = {3},
pages = {110--119},
publisher = {The Journal of China Universities of Posts and Telecommunications},
title = {{Urban scene recognition by graphical model and 3D geometry}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1005888510600726},
volume = {18},
year = {2011}
}
@article{Boyer2012,
author = {Boyer, Kim and Cetin, Mujdat and Jain, Anil and Lee, Seong-Whan},
doi = {10.1016/j.patrec.2012.02.010},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = may,
number = {7},
pages = {808--810},
publisher = {Elsevier B.V.},
title = {{Special Issue on Awards from ICPR 2010}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865512000517},
volume = {33},
year = {2012}
}
@article{Niu2012,
author = {Niu, Yan and Xia, Heng and Huan, Lele},
doi = {10.1016/j.phpro.2012.03.105},
issn = {18753892},
journal = {Physics Procedia},
month = jan,
pages = {415--420},
publisher = {Elsevier Srl},
title = {{MIDP-based Realization of a Simple Phone Contact Book}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1875389212005214},
volume = {25},
year = {2012}
}
@article{Deepa2012,
author = {Deepa, P. and Vasanthanayaki, C.},
doi = {10.1016/j.mejo.2012.05.001},
file = {::},
issn = {00262692},
journal = {Microelectronics Journal},
keywords = {Field programmable gate arrays,Image processing,Low power,Scan order,Single port SRAM,True dual port SRAM},
month = nov,
number = {11},
pages = {916--928},
publisher = {Elsevier},
title = {{FPGA based efficient on-chip memory for image processing algorithms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0026269212000985},
volume = {43},
year = {2012}
}
@article{Schneider2012,
author = {Schneider, Frank E. and Wildermuth, Dennis},
doi = {10.1016/j.robot.2012.05.001},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = nov,
number = {11},
pages = {1421--1428},
publisher = {Elsevier B.V.},
title = {{Influences of the robot group size on cooperative multi-robot localisation—Analysis and experimental validation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889012000577},
volume = {60},
year = {2012}
}
@article{Simoes2013,
author = {Sim\~{o}es, Jorge and Redondo, Rebeca D\'{\i}az and Vilas, Ana Fern\'{a}ndez},
doi = {10.1016/j.chb.2012.06.007},
issn = {07475632},
journal = {Computers in Human Behavior},
month = mar,
number = {2},
pages = {345--353},
title = {{A social gamification framework for a K-6 learning platform}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0747563212001574},
volume = {29},
year = {2013}
}
@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
author = {Lowe, David G},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {::},
isbn = {1568811012},
issn = {09205691},
journal = {International Journal of Computer Vision},
number = {2},
pages = {91--110},
pmid = {20064111},
publisher = {Springer},
series = {Int. J. Comput. Vis. (Netherlands)},
title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
url = {http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000029664.99615.94},
volume = {60},
year = {2004}
}
@article{Xue2012a,
author = {Xue, Ting and Qu, Liqun and Cao, Zhaofeng and Zhang, Tao},
doi = {10.1016/j.flowmeasinst.2012.07.007},
issn = {09555986},
journal = {Flow Measurement and Instrumentation},
keywords = {gas,liquid two-phase flow},
month = oct,
pages = {29--36},
publisher = {Elsevier Ltd},
title = {{Three-dimensional feature parameters measurement of bubbles in gas–liquid two-phase flow based on virtual stereo vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0955598612000799},
volume = {27},
year = {2012}
}
@article{Xue2012,
author = {Xue, Junpeng and Su, Xianyu},
doi = {10.1016/j.ijleo.2011.09.025},
file = {::},
issn = {00304026},
journal = {Optik - International Journal for Light and Electron Optics},
month = nov,
number = {21},
pages = {1923--1927},
publisher = {Elsevier GmbH.},
title = {{A new approach for the bundle adjustment problem with fixed constraints in stereo vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0030402611005390},
volume = {123},
year = {2012}
}
@article{Blas2011,
author = {Blas, Morten Rufus and Blanke, Mogens},
doi = {10.1016/j.compag.2010.10.012},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {texture classification},
month = jan,
number = {1},
pages = {159--168},
publisher = {Elsevier B.V.},
title = {{Stereo vision with texture learning for fault-tolerant automatic baling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016816991000222X},
volume = {75},
year = {2011}
}
@article{Chapitre,
author = {Chapitre, Cours},
pages = {1--11},
title = {{1. Qu'est-ce que la vision ? 1.1.}}
}
@article{Wanga2012,
author = {Wanga, Jijing},
doi = {10.1016/j.proeng.2012.01.259},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {data fusion,map-matching,mixed navigation,mobile phone net},
month = jan,
pages = {2045--2049},
title = {{Design of Mobile Phone Networks and Map-matching Navigation System}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S187770581200269X},
volume = {29},
year = {2012}
}
